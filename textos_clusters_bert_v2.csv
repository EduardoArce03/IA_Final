Documento,Texto_Procesado,Embeddings,Cluster,Cluster_Nombre
Wasserstein GAN based architecture to generate collaborative filtering synthetic datasets.pdf,httpsdoiorgs wasserstein ganbased architecture to generate collaborative filtering synthetic datasets jesús bobadilla abraham gutiérrez accepted february the authors abstract currently generative applications are reshaping different fields such as art computer vision speech processing and natural language the computer science personalization area is increasingly relevant since large companies such as spotify netflix tripadvisor amazon and google use recommender systems then it is rational to expect that generative learning will increasingly be used to improve current recommender systems in this paper a method is proposed to generate synthetic recommender system datasets that can be used to test the recommendation performance and accuracy of a company on dif ferent simulated scenarios such as large increases in their dataset sizes number of users or number of items specifically an improvement in the stateoftheart method is proposed by applying the wasserstein concept to the generative adversarial network for recommender systems ganrs seminal method to generate synthetic datasets the results show that our pro posed method reduces the mode collapse increases the sizes of the synthetic datasets improves their ratings distributions and maintains the potential to choose the desired number of users number of items and starting size of the dataset both the baseline ganrs and the proposed wassersteinbased wganrs deep learning architectures generate fake profiles from dense short and continuous embeddings in the latent space instead of the sparse large and discrete raw samples that previ ous gan models used as a source to enable reproducibility the python and keras codes are provided in open repositories along with the synthetic datasets generated to test the proposed architecture httpsgithubcomjesusbobadillaganrsgit keywords wganrs generative adversarial networks recommender systems wasserstein distance synthetic datasets collaborative filtering introduction recommender systems rss are used to provide personali zation facilities to users of internet services large compa nies that use rss are spotify tripadvisor netflix google music etc rss are becoming increasingly important due to its capacity to provide both accurate recommendations and recommendations designed to retain people using the service recommendations are provided by suggesting the products or services that have a higher probability of being liked by the user consequently it is necessary to filter the available items products or services in the rs for this reason rss are usually classified according to their filtering approach social contentbased demographic contextaware collaborative filtering cf and their ensembles are the most commonly used strategies social filtering recommends to the active users items that their followed group of friends contacts etc like contentbased recommendations include items with similar content to those the active user liked it is usual to compare descriptions or even item images demographic filtering selects users having demographic features such as those of the active user similar age same sex same zip code or near zip code etc and then extracts those item preferences contextaware filtering usually relies on geographic information such as gps coordinates the most accurate and relevant filtering strategy is the jesús bobadilla jesusbobadillaupmes abraham gutiérrez abrahamgutierrezupmes universidad politécnica de madrid etsisi ctra de valencia km madrid spain technical university of madrid etsisi ctra de valencia km madrid spain published online february applied intelligence collaborative strategy in this strategy recommendations are based on the preferences of the most similar users the machine learning method that best fits the cf concept is the knearest neighbours algorithm knn it is simple and directly implements the cf concept where the neigh bours are the most similar users to the active users the main drawbacks of the knn are that it is a memorybased method it runs slowly and it is not sufficiently accurate the modelbased matrix factorization mf solves the knn limitations moreover it contains two vectors of hidden factors the first vector is used to code compress the relevant information of users whereas the second vec tor is used to code the relevant information of items both vectors belong to the same latent space and they are com bined using a dot product additionally the hidden factors are optimized by minimizing the prediction errors non negative matrix factorization nmf ensures that the hidden factors are nonnegative to enable some semantic interpretations of predictions deep learning can currently be implemented to obtain improved mf results the simplest deep learn ing architecture is similar to that of mf in this method the hidden factors of the user are replaced by neural user embedding and analogously the hidden factors of items are replaced by neural item embedding this model is called deep matrix factorization deepmf and it is better than mf due to the ability of its neural networks to remove complex nonlinear patterns in raw data deepmf combines the embeddings using a dot layer an improved deepmf model is the variational deep matrix factorization vdeepmf where an intermediate layer codes the parameters of a chosen distribution usually gaussian and from it a stochasticbased sampling process spreads samples in the latent space the deepmf or vdeepmf dot layer can be improved by replacing it with a multilayer perceptron mlp that combines the hidden factors of users and item embeddings and generates a manifold this approach is called neural collaborative filtering ncf our proposed architecture combines a deepmf model and a wasserstein generative adversarial network gan gan networks can generate fake samples fol lowing the distribution of a source set of real data samples the most common use of gan networks is to generate realistic fake faces from a dataset of real human faces similarly our objective is to generate synthetic fake cf samples from an existing dataset of cf samples such as movielens then by collecting many fake samples a synthetic cf dataset can be created generating synthetic cf datasets makes it possible to simulate the stress situation in the rs as it can be gener ated families of datasets where gradually some of the parameters can be selected for example we can gener ate a family of cf datasets where the number of users grows from several thousands to millions and then test in advance the performance of our system in different scenarios where the number of users gradually or sud denly grows eg due to a marketing campaign or an influ encer action this simulation can avoid system failures in extreme situations similarly a family of datasets can be generated with a growing number of items it leads to more sparse scenarios where the rs accuracy could decrease this type of simulation gives us the conveni ence of incorporating many products or services in a short period of time additionally the generation of synthetic datasets makes possible that researchers test their machine learning models in bounded scenarios difficult to find in real datasets such as increasingly sparse data matrices different cold start situations or extreme pattern variations in the user profiles the stateoftheart methods in cf generation include statistical methods that are not able to adequately determine the patterns of complex datasets therefore adversarial approaches and ganbased approaches have been proposed preventing shilling attacks is a relevant objective in the rs field and some ganbased approaches act as a defence against them data augmentation is an obvi ous field where gans can be applied purchase profiles are used in the collaborative filtering generative adversarial net work model cfgan model to increase the number of training samples in a dataset of commercial products the identitypreservation generative adversarial network model ipgan incorporates negative sampling information to improve accuracy results it allows two separate generative models to be incorporated with one method managing posi tive data and the other method processing negative samples session information is used in the deep collaborative filter ing generative adversarial network dcfgan model instead of matrices of votes combining gan and reinforce ment learning to run recommendation training the neural collaborative generative adversarial network ncgan incorporates a regular gan that processes the intermediate cf results provided by a neural network stage the recurrent generative adversarial network recgan combines a recurrent neural network rnn and a gan to process temporal patterns unbalanced datasets are managed using a wasserstein gan acting as a generator and the packing generative adversarial network pacgan as a discriminator finally a conditional generative adversarial network cgan performs a conditional generation of ratings the rs stateoftheart method that generates synthetic cf datasets is divided into statistical and machine learning approaches solutions in the first group allow us to param eterize the results to change the number of items users etc but they do not adequately capture the complex non linear relations between users and items consequently the accuracy of this method is poor the second group makes wasserstein ganbased architecture to generate collaborative filtering synthetic datasets use of deep learning generative adversarial networks to cre ate fake profiles or fake samples the accuracy is improved but the gan architectures in this group take discrete and heavily sparse cf datasets as a source leading to results that are obtained slowly and the subjecttomode collapse prob lem in addition the number of items cannot be changed nevertheless the existing generative adversarial network for recommender systems ganrs method makes its gan generation start from dense and continuous latent space embeddings obtaining more accurate results and enabling us to choose the number of users and the number of items in the synthetic datasets the method proposed in this paper borrows the ganrs architecture making the necessary changes to introduce the wasserstein concept wasserstein generative adversarial networks wgans are designed to reduce the inherent mode collapse of the gan architecture in the model regularization wasserstein generative adver sarial network mrwgan an rs is implemented moreover an autoencoder is used to implement the genera tive model and a modelwasserstein regularized distance is used as the function loss it achieves better accuracy with missing data than the stateoftheart methods analogously an l regularized wasserstein loss function has been used for autoencoderbased cf to learn a lowrank repre sentation of variables in the latent space the wasserstein distance has also been implemented to tackle the coldstart issue in cf minimizing it under user embedding constraints gan approaches also have their own drawbacks particu larly a a long training time b a long inference time when the gan model is very deep c difficulty to set relevant cf parameters such as the number of items and the number of users in the dataset d possibility of suffering from the mode collapse behaviour e difficulty to adequately learn from the sparse data sets of cf and e lack of fine tuning the variation of the results in successive executions no standard machine learning quality measures are defined to compare synthetic datasets created or gener ated using different statistical or generative models this is because these models are designed to catch the complex nonlinear patterns of the source data and there are no simple comparations able to discriminate the quality of the gen erated results such as in regression mae msd etc or classification accuracy precision recall etc to better understand this drawback we can analyse the face image quality assessment strategies which are based on the character fidelity and utility features of facial biometrics in the rs field we do not have such type of information to make a similar process since what we are generating are user item vector profiles in addition face image quality makes a distinction between approaches that require a reference a reduced reference and no reference of faces where only the two first cases have some accurate quality measure pre cisely those situations that rs cannot manage as they do not have the equivalent reference to the face image quality field finally the conceptual problem of the quality para dox inherent in these quality measures is heavily present in the rs scenario where a generated dataset should not be too similar to the source otherwise it would not be useful and should not be too different from the source otherwise it would not be representative therefore research papers that generate synthetic datasets test them by run ning several cf machine learning models and comparing the results obtained on different instances of the generated datasets from the same source data this is the strategy that our paper follows in its results section in the seminal ganrs paper relevant innovations are incorporated and the previous rs gan architectures are compared to generate synthetic datasets however a signifi cant drawback occurs the process to convert from the latent space generated samples dense small and continuous to the raw samples sparse large and discrete that form the synthetic dataset generates duplicated samples that must be removed this is a common drawback in a discretization task but if the number of duplicated samples is high a col lapse in the gan generation can occur the innovation of our proposed wasserstein gan approach wganrs is the introduction of the wasserstein design function loss weight constraints etc to the existing ganrs method in the hope that the mode collapse situations are reduced the proposed method borrows the stages defined in and replaces the regular gan generation kernel by a wasserstein approach wgan the wgan provides four relevant improvements it incorporates a new loss function that is interpretable and has clear stopping criteria it empirically returns better results the gan mode collapse is significantly reduced and it provides a clear theoretical backing the wgan loss function is based on the earth movers distance and it incorporates an fw function that acts as a discrimina tor model called the critic the critic estimates the earth movers distance processing the highest difference between the generated distribution and the real distribution under sev eral parameterizations of the fw function the critic makes the generator work harder by looking at different projec tions our most relevant predictor that measures the mode collapse mitigation will reduce the removed samples and consequently increase the number of samples of the syn thetic files their sizes we will also test some other quality measures such as the precision recall and the distribution of the ratings users and items figure shows the innovation of the proposed method com pared to sota particularly with the most currently published baseline ganrs on which our method is based as shown in a top of fig sota methods that generate cf datasets take only raw profiles and generate synthetic rs datasets this is an analogous process to fake face creation which can be generated by gans from datasets of real faces it is known j bobadilla a gutiérrez that a recurrent problem in these processes is mode collapse which leads to a lack of balanced generation of samples some categories are overrepresented whereas other categories are underrepresented as an example we could obtain an enor mous quantity of fake samples of number by using the modi fied national institute of standards and technology mnist dataset however some other numbers are rarely generated notably in fig a sota methods the gan module is fed with raw data such as image pixels or in our case user pro files these raw data are large discrete and sparse leading to the mode collapse problem the most current research in the area is the ganrs method our baseline its highlevel architecture is shown in fig b where the gan model is not fed with raw data instead it is fed with deep learning embedded data these embedded data are short continuous and dense vectors the embedded data contain compressed information on the items and users in the rs as a result both the performance and the accuracy of the ganrs are improved compared to the previous sota models and methods in the ganrs baseline the mode collapse problem is reduced and the rs datasets generated are less biased than those created using sota methods regardless the mode collapse remains and it produces a certain degree of redundant samples to reduce mode collapse even further our proposed wganrs method introduces the wasserstein concept into the gan kernel fig c the wasserstein approach has been shown to yield better results by reducing mode collapse when applied to gans this approach requires the introduction of a new loss function and benefits from a theoretical backing and a defined stopping criterion the hypothesis of the paper claims that incorporating the wasserstein concept into the generative kernel of the ganrs method will lead to a decrease in the mode collapse problem inherent to the gan when applied to cf scenarios consequently the proposed wganrs is expected to gener ate more accurate cf datasets the structure of the paper is as follows in section the proposed wganrs method from the existing ganrs infor mation is explained and formalized in section the design of the experimental executions of code is introduced and the results are shown and analysed using the movielens and net flix datasets as a source moreover the most relevant results are provided in section the most remarkable conclusions are presented and some future work is proposed additionally the references section includes current representative papers in the main rs area and in the specific gan generation of cf datasets method this section is divided into two subsections in the first subsection the proposed method concepts its architecture and the sequence of processes and stages to both train the model and generate the synthetic datasets in a feedforward prediction are explained the second subsection contains the necessary equations to formalize the method grouped into the main stages of the architecture the python and keras codes of the proposed method is available in httpsgithub comjesusbobadillaganrsgit concepts and architecture the proposed deep learning architecture is based on five sequential stages in which a neural cf a wgan model and a clustering process are involved moreover a cf dataset is used as the source and a synthetic dataset that has the same format as the source dataset and similar data distributions is generated the key issue involving both the ganrs seminal baseline and the wganrs proposed architecture is that the gan or wgan stages are fed with dense short and continuous embeddings in the latent space instead of sparse large and discrete raw data it makes the work of both the generator and the discriminator models easier faster and more accurate the obvious drawback of the proposed design is the theoretical loss of quality involved in the com pression stage coder and particularly in the subsequent decompression decoder however when converting from embedded to raw samples a significant benefit emerges we can choose the target number of users and items mak ing the ganrs and wganrs models more flexible and useful than the stateoftheart methods figure shows an overview of the proposed wganrs architecture from an existing source dataset mostleft side in fig such as movielens a synthetic dataset mostright side in fig is generated with the same format to be useful to researchers and similar patterns and distributions of the users items and ratings this dataset can be generated by choosing the desired number of users items and starting number of sam ples to be useful for companies and researchers as a base for simulations anticipating diverse future scenarios or as ground data for new machine learning models the proposed wganrs first converts compresses the input sparse dataset to its embeddingbased representation and converts decompresses the generated fake embed dingbased dataset to its raw and sparse representation a deepmf model left side in fig was chosen to perform the compression stage due to its simplicity and performance and kmeans clustering right side in fig was used to run the necessary decompression in this scenario the kmeans algorithm has the advantage of setting the k number of users and k number of items we want the generated dataset to hold finally our architecture kernel is based on a wgan model centre of fig to generate fake embedding samples from real embedding samples the deepmf model used for the compression task has a previous learning stage topleft draw in fig where the wasserstein ganbased architecture to generate collaborative filtering synthetic datasets embedding weights are set by means of backpropagation optimization the deepmf model contains two separate embedding layers one layer for users and the other layer for items these embeddings must have the same size which usually ranges from to neurons it is expected that similar users will be coded with similar embedding maps codes and the same applies for items once the deepmf model has been trained we can feedforward each existing user id to obtain its embedding representation topright draw in fig the same process is performed with all existing item ids thus we obtain a matrix i x e containing the embedding representations of the items where i is the number of items in the source dataset and e is the embed ding size analogously we obtain a matrix u x e containing the embedding representations of the users where u is the number of users in the source dataset by combining the source dataset left side of fig the compressed item matrix and the compressed user matrix top right draw in fig we can obtain the embedding rep resentation of the source dataset as shown in the embed dingbased cf dataset in the bottom left graph of fig and in fig starting from the embeddingbased cf dataset as a source the proposed wganrs architecture generates the fake embeddingbased cf dataset centre of fig and it is performed by means of a wasserstein gan the first stage of this generative task is the wgan training bottomleft in fig where the generator model creates synthetic samples from gaussian stochastic vectors containing random noise then the wasserstein critic discriminator performs the necessary binary classification to label samples as real or fake notably the fake samples come from the generator model whereas the real samples are randomly taken from the previously generated real embeddingbased cf data set once the training process has finished we can forget the critic model and take the generator model to create as many fake embedding samples as needed the whole pro cess training and feedforward generation is expected to be fast due to the compressed embedding representation and accurate due to the wasserstein restrictions to avoid mode collapse in the last stage of the proposed architecture it is neces sary to decompress the fake embeddingbased cf dataset right side in fig and bottom right draw in fig in this stage we have generated a very large number of fake samples consisting of tuples user_embeddingitem_ embeddingrating where both the user and the item embeddings produce vectors of real numbers we have to convert this set of tuples to a discretized version user_ iditem_idrating where user_ids are integers in the range number of users and analogously item_ids are integers in the range number of items once the neural network has been trained the user embedding assigns simi lar codes to similar users same with the embedding layer this inherent property of the embedding layers makes it possible to incorporate a clustering process to the proposed fig innovation of the proposed method and its expected impact in solving the gan mode collapse figure a shows the traditional gan approach in the cf context fig b shows the improvement introduced in the baseline method to adequately process sparse data and fig c details the proposed introduction of the wasserstein ker nel to reduce the mode collapse problem j bobadilla a gutiérrez method in charge of grouping similar users and items to the desired number of users and items in each synthetic dataset this is a discretization process in which the wganrs has been designed to set the desired number of users and items in the generated dataset to implement it kmeans clustering was performed since it allows us to set the k number of users and the k number of items figure shows the follow ing concept a kmeans is used to cluster k users whereas another kmeans process is used to cluster k items since similar users should have similar embeddings it is expected that they will be grouped in the same clusters analogously with items each user number in the generated dataset corre sponds to the cluster number in the kmeans where the fake user embedding has been grouped for example the leftmost sample in the fake embeddingbased cf dataset left side of fig was grouped with its user green colour in the k group and its item blue colour in group consequently the generated fake sample in the synthetic dataset is k rating in this example the rating is the value of the first sample of the source dataset left side of fig finally due to the discretization process duplicated sam ples can be found this happens when two different generated samples share the same user id and the same item id when the chosen number of users and items is high it is more diffi cult to find duplicated samples since there is a wider variety of clusters and it is expected that the users and the items will be assigned to the groups in a balanced way duplicated samples can be managed by simply removing the spare samples the expected balance in the clustering groups could be broken if the mode collapse is happening in the gan indeed the was serstein concept is used in this paper to avoid mode collapse and the number of removed samples will be used as a quality measure in the results section the lower the removed samples are the better the method is since two of the hyperparameters in the proposed model are the number of users and the number of items the cluster ing method that better fits this information is kmeans where directly we can set k as the number of users and k as the number of items in fact this is one of the unusual situations where the k value is known before the clustering process thus other relevant clustering methods such as hierarchical distribution density or fuzzybased ones are not adequate in this scenario in the following subsection the wganrs approach is for malized moreover equations have been provided formalization cf definitions first we define the main sets in the rs set of users u items i range of ratings v and existing samples s we let u be the set of users who make use of a cf rs we let i be the set of items available to vote on in the cf rs we let v be the range of allowed votes where v we let s be the set of samples contained in the cf dataset where n s the total number of cast votes s u i v u i v u i v n where each u ueach i i and each v v fig overview of the proposed wganrs architecture wasserstein ganbased architecture to generate collaborative filtering synthetic datasets the formalization of the defined cf dataset consists of a set of tuples userid itemid rating number of stars where the rating is the vote assigned for the userid to the itemid deepmf training the deep mf training top left graph in figure is conducted to create a model that can embed each user id and each item idthese two embeddings feed the wganrs generative stage each embedding is a compressed representation of the user or the item the embeddings are unidimensional vectors of size e we define f euu as the function that compresses the user u information and analogously f eii as the function that compresses the item i information we let e be the size of the two neural layer embeddings used to vectorize each user and each item belonging to u and i respectively we let f euu eu eu eu eu e where f eu is the embedding layer output of the users and u u we let f eii ei ei ei ei e where f ei is the embedding layer output of the items and i i fig deepmf and wgan models involved in the wganrs architecture below the most relevant equations in the back propaga tion algorithm are defined and we set the output error as the mean squared differences metric these equations are not distinctive of the proposed method deepmf feedforward once deepmf has learned we can collect the embedding representation of each user and each item in the cf rs therefore all the existing itemid and userid in the rs by combining the dense vectors of the user and item embeddings eu eu eu eu e and ei ei ei ei e we can make rating predictions in the deepmf training stage the dot product of the user embedding and the item embedding in each u i v j s provides its rating prediction yj f euu f eii eiu ei eu eu eu e ei ei ei e yj yj is the output error used in the deepmf neural network to start the back propagation algorithm where the neural weights are iteratively improved from the 훿j values δwji 훼yjf neti k wik훿k where k is a hidden layer and δwji 훼yjf neti yk yk if k is the output layeri j and k are successive sequential layers j bobadilla a gutiérrez dataset feed the trained deepmf model and their embed ded representations can then be obtained it can be done by making the feedforward prediction operation topright graph in figure on the trained deepmf model we let e u eu eu eu eu e u u be the set of embeddings for all the rs users we let eu eu eu eu eu e let e i eu eu eu eu e ei ei ei ei e i i be the set of embeddings for all the rs items we let ei ei ei ei ei e setting the dataset of the embeddings now we collect the above embedding representations of all the itemid and userid in the rs to translate the set s to the set r the set r is the embeddingbased dataset version of the original raw dataset we let r eu ei v u i v j s be the embedding based dataset of real samples wgan training the core concept of the gan methodology is to jointly train a generator model and a discriminator model once the architecture has been trained the generator model creates new samples that follow the distribution of the training samples the discriminator model attempts to differentiate between real samples and generated ones this is a minmax optimization problem of the form mingmaxd피xpdata logdx 피zplatent log dgz w h e r e g z x is the generator model which maps from the latent space z to the input space x d x ℝ is the dis criminator model which maps from the input space x to a clas sification value realfake ℝℝ is a concave function the above formula is the optimization function the expression that both networks generator and discriminator try to optimize g aims to minimize it whereas d wants to maximize it the bottomleft graph in fig shows the generative learning the gan architecture consists of a discriminator classifier and a generator model the generator creates fake samples rs profiles in our case whereas the discriminator tries to detect fake samples in generative adversarial training the discriminator progressively learns to accurately differentiate fake profiles from real profiles at the same time the generator learns to make fake sam ples difficult to distinguish from real profiles we call f d the discriminator model and f g the generator fig clustering stage in the wganrs architecture wasserstein ganbased architecture to generate collaborative filtering synthetic datasets model both f d and f g will iteratively learn and improve themselves by minimizing a loss function f gd f gd mingmaxdfd g erfwr ezfwgz where er is the expected value for real samples z is the random noise that feeds generator g and ez is the expected value for the generated fake profiles gz fw is the wasserstein function based on the earth movers distance this function satisfies the lipschitz constraint f x f x x x x x r refers we let f d be the discriminator d model belonging to a gan model we let f g be the generator g model belonging to a gan model we let f gd be the cost function of the gan model to notably the wasserstein concept has been introduced in eq mainly it is implemented in the loss function code of the generative model the wasserstein approach has been designed to reduce the mode collapse problem inherent to the gan we implement it to reduce the mode collapse in our wganrs proposed method and to consequently reduce the number of excessively generated similar profiles in the rs wgan generation once the gan has been trained we can generate as many samples as needed we can introduce batches of random gaussian noise vectors z and implement the feedforward process modelpredict the result are batches of fake embedded profiles bottomright graph in figure we let f f g be the generated dataset of fake samples from different random noise vectorsz clustering of items and users figure shows the clustering process where we set k as the number of users in the generated dataset and k as the number of items on it the n gen erated fake profiles will contain both fake user embed dings and fake item embeddings where nk and n k we let kbe the number of clusters used to group the embeddings of the users we let kbe the number of clusters used to group the embeddings of the items for each generated fake user each user of n we must select the nearest user from the k existing users the hu function makes this group the same process is used for items for each generated fake item each one of the n we must select the nearest item from the k existing items the hi function makes this group we let hu cc k be the clustering operation that assigns a centroid to each user we let hi cc k be the clustering operation that assigns a centroid to each item setting the dataset of the item ids and user ids to create the synthetic dataset the generated set of embed dings f is converted to its discretized version h we let h be the item id and user id discrete dataset obtained from the embeddingbased dataset f of fake samples sometimes different generated samples in set f will be discretized to the same user and item hu hi v hu hi v h hu hi v eu ei v f this particularly happens if the gan suffers from mode collapse in these cases there are samples with identical information and we create the set h where duplicated sam ples are removed we let s h be the synthetic generated dataset version of h where duplicated samples are removed the last transformation removes samples when a fake user casts different votes v v to the same item we let g hu hi v h hu hi v h where hu hu hi hi v v j bobadilla a gutiérrez results the proposed method has been tested using two opensource representative cf datasets movielens m httpsgrouplens orgdatasetsmovielensm and a subset of netflix that we call netflix these two datasets were chosen because they are representative in the cf field movielens is probably the most tested dataset family over the years in cf research the results obtained in movielens are very informative for rs researchers on the other hand netflix is not widely used due to its enor mous size and because it is no longer available we utilized the open version of netflix that is randomly shortened net flix has been selected as the dataset for this research because its internal patterns are different from those of movielens movielens has been created in a relatively short time in an academic environment whereas netflix is an enormous com mercial dataset that has been growing for a long period since this research involves catching the internal patterns of a source dataset and parameterizing and translating those patterns to a generated dataset it is convenient to use such different sources table shows their main parameter values the results of both datasets follow the same trends therefore to ensure that the length of this paper is appropriate we only explain the mov ielens results and group the netflix results figs and in appendix a to test the wganrs method two sets of synthetic datasets have been created the first set has a varied number of users whereas the second set has a varied number of items each row in table shows the values of each set the first row indicates that five synthetic datasets have been generated the first dataset contains users and items the second dataset holds users and items and so on until the last dataset has users and items all the generated datasets were created starting from thousand samples this set of data allows us to test the impact of changing the number of users analogously the second row in table shows that four synthetic datasets have been created all four datasets have users however the number of items varies from in the first dataset to in the last set this allows us to measure the impact of changing the number of items since we will use the ganrs method as the baseline all datasets have also been created using ganrs thirtysix datasets were generated using movielens as a source and using netflix both for ganrs and for wganrs to test these datasets four different exections were conducted number of generated samples the number of samples returned by ganrs and wganrs was compared the wganrs method is expected to perform better as it focuses particularly on avoiding the typical mode collapse in gans the better managed the mode col lapse is the more varied the embedding samples that the wganrs generates the better the performance of the clustering process to create the raw samples and finally the lesser the number of sample collisions increasing the sizes of the synthetic datasets rating distributions it is important that the rating distri bution of the generated datasets be as similar as possible to that of the source particularly on the relevant ratings usually and stars this is an indication that the pat terns of the fake profiles are correct and they contain an adequate proportion of relevant and nonrelevant votes user and item distributions it is interesting to test the user and item distributions as the number of users and items var ies comparing them to the source dataset it is expected that the gaussian random noise used to create the stochastic vector that feeds the wganrs generator will force the dif ferent gaussian distributions of users and items precision and recall regarding the ground distributions balanced votes and high number of samples the gen erated datasets are used to adequately analyse them on the cf task and their recommendation quality measures return suitable values and trends the above executions cover the potential comparatives avail able on the generative creation of synthetic datasets in the cf area figure shows the concept figure a top graph shows the traditional cf analysis different stateoftheart methods or models are applied to one or several existing cf datasets and the recommendation results can be measured using traditional quality prediction and recommendation quality metrics such as the precision recall f and mean absolute error mae however the field of synthetic cf dataset generation is com pletely different from a source dataset fig b we create one or several synthetic datasets we can set different numbers of users items samples etc and each generated dataset will hold to compare the proposed generative method with the selected stateoftheart baseline we must create a synthetic dataset or group of synthetic datasets using the proposed method orange datasets in fig b and a different dataset or group of datasets using the sota baseline blue datasets in fig b now we need to determine which of these datasets or groups are bet ter comparing generated datasets fig b is a very different task than comparing methods or models applied to an existing dataset fig a figure b shows three types of code execution that we can perform to decide whether the generated datasets using the proposed method orange datasets are better than the generated datasets using the baseline method blue datasets table main parameter values of the tested datasets dataset users items ratings scores sparsity movielens m to netflix to wasserstein ganbased architecture to generate collaborative filtering synthetic datasets the mode collapse impact can be measured in the cf field by removing very similar user profiles the gan can collapse to a reduced number of source profiles the higher the number of deleted profiles is the higher the mode collapse impact the higher the deleted profiles are the lower the number of samples in the generated dataset figure b shows a comparison where the yaxis represents the number of samples the proposed method orange colour improves the sota baseline the generated datasets should have probability distribu tions that are similar to that of the source dataset the user item and rating distributions of the synthetic data sets can be compared figure b shows the distribu tion of the ratings from the source dataset green colour compared to the baseline dataset orange colour in this graph and the proposed method dataset blue colour notably the synthetic datasets are not expected to have the same distributions as the source dataset the genera tive process should create similar datasets not identical datasets identical datasets have no value just as rep licating real faces is not valuable in field of computer vision therefore there is no absolute metric to measure this type of quality extreme distribution similarities and large distribution differences must be avoided the quality of the generated datasets can be indirectly meas ured by running stateoftheart cf methods and models on them we expect similar behaviours to those obtained when we apply these methods to the source dataset very different trends or absolute values in the generated dataset graphs compared to those in the source dataset will tell us that the generated dataset does not contain the main patterns of the source dataset figure b shows the precision and recall results on the source dataset left graph and the generated dataset right graph when measured with several sota cf deep learning models both trends and values are similar as explained above we do not expect identical behaviours and values since synthetic datasets should mimic the source pat terns and not copy them for this reason there is no standard quality measure to compare the graphs in fig b taking into account the above considerations several experiments have been performed on the three explained approaches as shown in b b and b of fig individual executions and their explained results have been structured in subsects to followed by the discussion subsection number of generated samples as explained in the previous section the proposed method uses a wgan to generate synthetic embedding samples these dense and continuous samples are then converted to their sparse and discrete versions by means of the clustering process and their translation to the raw tuples in the synthetic dataset this discretization stage causes a proportion of collisions where identical or similar generated samples must be removed the smaller the number of samples removed the more accu rate the generative model and the richer the synthetic dataset the wasserstein gan is expected to improve the results as it is designed to prevent mode collapse inherent to the gan models please note that the hypothesis is that by reducing the mode collapse the variability of the generated embedded samples will increase and then the clustering process will be able to spread users and item ids in a more homogeneous way consequently the number of discretized samples that are repeated and deleted will decrease overall the total size of the generated datasets will increase as the gan mode collapse is reduced using the wasserstein approach the final number of samples generated is a relevant qual ity measure since it is directly related to the impact of mode collapse in the generative process the baseline ganrs method suffers from the mode collapse problem leading to the generation of repeated fake profiles the method han dles this situation by removing spare profiles but it does not provide the necessary diversity of samples the proposed wganrs is expected to improve the results due to the wasserstein ability to reduce the mode collapse and then to improve diversity and increase the synthetic dataset size figure shows the comparison of ganrs gan versus wganrs wgan both for synthetic datasets where the number of users varies left graph and for synthetic datasets where the number of items varies right graph overall the proposed approach wgan significantly improves the base line gan specifically it duplicates the number of gener ated samples a improvement in the left graph and a improvement in the right graph are achieved this is a relevant predictor of the superiority of the proposed method additionally as expected the higher the number of users or items there are the higher the number of generated sam ples this is because the clustering process can better spread the samples in the latent space as the number of centroids increases then the number of duplicated samples decreases the results show a relevant improvement when the pro posed method is applied compared to the baseline this con firms that the paper hypothesis is fulfilled moreover incor porating the wasserstein concept into the generative kernel of the ganrs method will lead to a decrease in the mode collapse problem inherent to the gan when applied to cf scenarios generated datasets have less redundant profiles accordingly they are more diverse and they contain more table parameter values initial samples users items j bobadilla a gutiérrez samples overall the proposed wganrs method generates richer unbiased and longer synthetic datasets rating distributions the distribution of the ratings one star two stars five stars is an important quality measure in the cf synthetic dataset generation process recommendation models are very sensitive to the relevant versus nonrelevant thresh old which is usually set to four or five stars in cf datasets containing five possible ratings it is not enough that the gaussian distribution of ratings in the generated dataset has a similar mean to the gaussian distribution in the source dataset it is also necessary that their standard deviation be analogous figure shows that the proposed wganrs generates a gaussian distribution more similar to the mov ielens distribution than the baseline ganrs specifically it achieves a improvement the improvement aver age obtained using the synthetic datasets in the first row of table the number of users varies is in net flix whereas the second row the number of items varies returns a improvement on average in netflix it is expected that these positive results will contribute to providing adequate recommendation quality results in the next subsection beyond the numeric improvement values shown before we can compare the shapes of the probability distribution in fig the probability distribution of the source movielens dataset greencolour bars is the target the proposed wganrs method bluecolour bars is much closer to the target than the baseline ganrs method orangecolour bars this is the reason for the relevant numerical improvements shown in the above paragraph additionally the baseline method generates a gaussian distribution excessively centred in the average rating three stars whereas the proposed method adequately fits its gaussian distribution to the correct fourstar mean regard ing the gaussian standard deviation the baseline method does not adequately catch the source dataset shape its deviation is smaller and consequently it does not generate enough profiles in the distribution edges one star and five stars in contrast the proposed method performs nearly perfectly on both edges of the source distribution thus the samples generated using the proposed wganrs method are more diverse and unbiased than those obtained running the sota baseline additionally the obtained result better follows the gaussian distribution that describes the source shape of ratings this result reinforces and fig traditional cf validation of the methods and models versus the validation of the synthetic datasets generated by the gan wasserstein ganbased architecture to generate collaborative filtering synthetic datasets complements that obtained in sect overall the proposed method a reduces repeated samples b generates more sam ples c increases diversity d decreases the bias and e better mimics the probability distributions of the ratings precision and recall in this subsection we show the recommendation quality results obtained on synthetic datasets obtained using mov ielens as a source the wganrs method was used for this experiment to generate the synthetic datasets the stateof theart ncf neural collaborative filtering deep learning model has been used to make predictions and recommenda tions the relevancy 휃 threshold was set to five the top graphs in fig show the results when the number of users varies whereas the bottom graphs show the results when the number of items varies both the values and the trends obtained from the synthetic datasets coloured curves are similar and com patible with the source datasets black curves which indi cates that the proposed method generates suitable synthetic datasets to be used in the rs field additionally as expected the higher the number of users the higher the recall is since each user profile will contain fewer relevant ratings recall denominator conversely the higher the number of users the lower the precision is since the denominator is the con stant n number of recommendations whereas the numerator contains the true positives of relevant ratings where a high number of users involves less relevant ratings per user additionally from the set of synthetic datasets where the number of users varies the dataset that holds users pro vides more precision and recall results like the movielens source since movielens m contains users it tells us that the ganbased method generates data patterns where recommendations are easier than using the source dataset this result is consistent with the one reported in most importantly the evolution of all the recommendation curves in the generated datasets coloured curves follow the same trends as those exhibited by the source movielens black curve indicating that the internal patterns of the source data set have been adequately captured by the proposed wganrs method regarding the results when the number of items var ies similar conclusions can be drawn underlying that rec ommendation qualities worsen in absolute values compared to the source dataset this probably occurs because the dis tribution of the item ratings is highly variable compared to the distribution of the user ratings leading to more difficult pattern extraction there is a number of items holding a very low number of ratings user and item distributions once the rating distributions have been tested it is also convenient to compare the user and the item distributions obtained by using both the proposed and the baseline methods the user and item distributions of the synthetic datasets are very dependent on the gaussian parameter values with which the noise vectors that feed the generative model have been created in the original paper that serves as a baseline the standard deviation has been customized for each tested dataset in contrast by using the proposed method we fixed it to one and then removed this hyperparameter making it easier to fine tune the proposed approach compared to the baseline method the top graph in figure shows the results when the number of users varies while its bottom graph shows the result by varying the number of items dashed lines repre sent the baseline results and solid lines show the proposed approaches in all cases as expected the higher the number of users there are the lower the number of ratings assigned to fig number of samples generated using the baseline ganrs method gan versus the proposed wganrs method wgan source dataset movielens m number of samples needed left graph generated datasets with items and a range of and users right graph generated datasets with users and a range of and items the higher the number of generated samples the better the model is j bobadilla a gutiérrez each user since the number of ratings in each dataset is fixed it can also be observed that the proposed method generates gaussian distributions with higher standard deviations than the baseline approach which has been heuristically tailored to the dataset both the proposed and baseline methods generate suitable user and item distributions for the cf area discussion the experimental results show the superiority of the proposed wganrs method compared to the ganrs baseline par ticularly relevant is the high improvement approximately in the number of generated samples this indicates that the proposed wasserstein approach effectively reduces the amount of mode collapse of the gan the wganrs method also effectively mimics the rating distribution of the source dataset obtaining high improvements compared to the baseline and making it possible that their quality precision and recall values and trends are compatible with those from the source dataset furthermore even no standard quality meas ures exist to test rs generated data the user and item distribu tions obtained using the proposed approach are comparable to those of the baseline method additionally the proposed method has the advantage that it is not necessary to assign heuristic values to the standard deviation of the gaussian dis tribution used to create the noisy random vectors that feed the generator model of the wgan finally the results using the netflix dataset reinforce the results obtained by testing movielens appendix a shows the netflix results overall the proposed method improves both the sta tistical baselines and stateoftheart generative methods statistical baselines are reported to reach poor accuracy in contrast they support adequate parameterization generative baselines operate quite differently they do not support full parameterization and exceed the accuracy of statistical meth ods our proposed method is proven to provide both full fig comparative rating distributions among the movielens m ml source dataset the baseline ganrs method gan and the pro posed wganrs method wgan the user and item syn thetic dataset has been chosen as a representative case from the set of generated data in the paper the closer the distribution is to the source ml distribution the better the model is fig quality of the recom mendation precision and recall obtained by varying the number n of recommendations from to the relevancy threshold 휃 was set to the upper graphs show the results on the synthetic datasets containing to users the lower graphs show the results on the synthetic datasets containing to items precision can be seen in the left graphs whereas recall is shown in the right graphs the movielens dataset was used the higher the values are the better the results wasserstein ganbased architecture to generate collaborative filtering synthetic datasets parameterization and high accuracy in addition to a strong reduction of the mode collapse problem inherent to the gan architectures on the other hand our method inherits the most positive and the most negative features of its baseline however its accuracy and performance are very high due to the short dense and continuous vectors that its gan model takes as input its main drawback comes from the clustering stage of the method fig which requires addi tional execution time and involves a discretization process that increases the probability of generating duplicated sam ples for this reason the wasserstein concept has been pro posed to alleviate the explained drawback the results show that the proposed method adequately reduces the mode col lapse problem maintains the baseline advantages reduces its disadvantages and confirms the hypothesis of this paper conclusions the most relevant conclusion in this paper is that the wasser stein approach reduces the mode collapse in the gan genera tion of the cf fake samples compared to the stateoftheart methods this positive effect is reflected in a relevant reduction in duplicated samples and consequently in the generation of larger synthetic datasets furthermore the proposed approach returns very improved distributions of ratings which facilitates obtaining correct values and trends in recommendation qual ity measures finally the distributions of the users and items are comparable to those of the stateoftheart methods these distributions act as quality measures due to the lack of stand ard quality measures for rs generated data moreover exist ing hyperparameters are avoided in the proposed method the standard deviation of the gaussian distribution is used to create the noisy vectors that feed the generator model in the gan overall the results of the experiment show that by applying the wasserstein distance and weight clipping to cf data the generative process is improved compared to the stateoftheart methods that use wassersteinbased gans proposed future work includes a testing the proposed method on different rs datasets with several sparsity ratios and different numbers of users or items b comparing the existing biases in the source datasets with the generated biases in the synthetic datasets and c checking the ability of the generated samples to serve as data augmentation when they are added to the source datasets fig top graph distribu tion of the ratings when the number of users varies from to comparative of the proposed wganrs wgan method and the baseline ganrs gan method bottom graph distribution of ratings when the number of items var ies from to compari son of the proposed wganrs wgan method and the baseline ganrs gan method the source movielens ml dataset is used in both graphs j bobadilla a gutiérrez appendix in this section the same figures used for movielens are shown however in this case the netflix dataset has been used as a source fig number of samples generated using the baseline ganrs method gan versus the proposed wganrs method wgan source dataset netflix number of needed samples left graph generated datasets with items and a range of and users right graph generated datasets with users and a range of and items the higher the num ber of generated samples the better the model is fig comparative rating distributions among the netflix source dataset the baseline ganrs method gan and the proposed wganrs method wgan the users and items synthetic dataset has been chosen as a representative case from the set of generated data in the paper the closer the distribution is to the source ml distribution the better the model is wasserstein ganbased architecture to generate collaborative filtering synthetic datasets fig quality of recommen dation precision and recall obtained by varying the number n of recommendations from to the relevancy threshold 휃 was set to the upper graphs show the results on the synthetic datasets containing to users the lower graphs show the results on the synthetic datasets containing to items precision can be seen in the left graphs whereas recall is shown in the right graphs the netflix dataset was used the higher the values are the better the results fig top graph distribu tion of the ratings when the number of users varies from to comparison of the proposed wganrs wgan method and the baseline ganrs gan method bottom graph distribution of ratings when the number of ratings var ies from to compari son of the proposed wganrs wgan method and the baseline ganrs gan method the source netflix dataset is used in both graph j bobadilla a gutiérrez author contributions abraham gutiérrez ran most of the executions and prepared the figures and the paper format jesús bobadilla provided the paper concept the model design the experimental design and wrote the paper funding open access funding provided thanks to the cruecsic agreement with springer nature this work was partially supported by the ministerio de ciencia e innovación of spain under the pro ject pidrbi dlcemg and the comunidad de madrid under convenio plurianual with the universidad politécnica de madrid in the actuation line of programa de excelencia para el profesorado universitario data availability the datasets generated during andor analysed during the current study are available in the github repository httpsgithub comjesusbobadillaganrsgit declarations ethics for obtaining the data in this paper all the conditions specified for the use of the open datasets taken as a source for the generative process are satisfied including the reference to the paper stated in the readme file conflicts of interest the authors have no competing interests to de clare that are relevant to the content of this article and agree to the publishing of its content open access this article is licensed under a creative commons attri bution international license which permits use sharing adapta tion distribution and reproduction in any medium or format as long as you give appropriate credit to the original authors and the source provide a link to the creative commons licence and indicate if changes were made the images or other third party material in this article are included in the articles creative commons licence unless indicated otherwise in a credit line to the material if material is not included in the articles creative commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use you will need to obtain permission directly from the copyright holder to view a copy of this licence visit httpcreativecommonsorglicensesby references shokeen j rana c a study on features of social recom mender systems artif intell rev httpsdoiorg sw bobadilla j gutiérrez a alonso s gonzálezprieto a neural collaborative filtering classification model to obtain prediction reliabilities international journal of interactive mul timedia and artificial intelligence httpsdoiorg ijimai deldjoo y schedl m cremonesi p pasi g recommender systems leveraging multimedia content acm computing surveys csur httpsdoiorg bobadilla j gonzálezprieto a ortega f laracabrera r deep learning feature selection to unhide demographic recom mender systems factors neural comput appl httpsdoiorgs bobadilla j laracabrera r gonzálezprieto á ortega f deepfair deep learning for improving fairness in recom mender systems international journal of interactive multimedia and artificial intelligence httpsdoiorg ijimai kulkarni s rodd sf context aware recommendation systems a review of the state of the art techniques computer science review httpsdoiorgjcosrev wang z intelligent recommendation model of tourist places based on collaborative filtering and user preferences appl artif intell httpsdoiorg ray b garain a sarkar r an ensemblebased hotel rec ommender system using sentiment analysis and aspect categoriza tion of hotel reviews applied soft computing https doiorgjasoc kabul ms setiawan eb recommender system with userbased and itembased collaborative filtering on twitter using knearest neighbors classification journal of computer system and informat ics httpsdoiorgjosycvi eslami g ghaderi f incremental trustaware matrix factor ization for recommender systems towards green ai appl intell httpsdoiorgs mehdi ha a novel constrained nonnegative matrix fac torization method based on users and items pairwise relationship for recommender systems expert syst appl https doiorgjeswa gheorghe p pérezjiménez m grzegorz r infinite spike trains in spiking neural p systems romanian journal of infor mation science and technology httpsdoiorg romjist liu h zheng c li d shen x lin k wang j zhang z zhang z xiong n edmf efficient deep matrix factorization with review feature learning for industrial recommender system ieee trans industr inf httpsdoi orgtii bobadilla j ortega f gutiérrez a gonzálezprieto á deep variational models for collaborative filteringbased recom mender systems neural comput appl https doiorgs hai c fulan q jie c shu z yanping z attributebased neural collaborative filtering expert syst appl httpsdoiorgjeswa min g junwei z junliang y jundong l junhao w qingyu x recommender systems based on generative adversarial networks a problemdriven perspective inf sci httpsdoiorgjins forouzandeh s berahmand k rostami m presentation of a recommender system with ensemble learning and graph embed ding a case on movielens multimedia tools and applications httpsdoiorgs kumar a aggarwal rk an exploration of semi supervised and languageadversarial transfer learning using hybrid acoustic model for hindi speech recognition j reli able intell environ httpsdoiorg s deldjoo y noia dt merra fa survey on adversarial recommender systems from attackdefense strategies to gen erative adversarial networks acm comput surv httpsdoiorg chae dk kang js kim sw lee jt cfgan a generic collaborative filtering framework based on generative adversarial networks in proceedings of the th acm international con ference on information and knowledge management cikm association for computing machinery new york ny pp httpsdoiorg guo g zhou h chen b et al ipgan generating informa tive item pairs by adversarial sampling ieee transactions on wasserstein ganbased architecture to generate collaborative filtering synthetic datasets neural networks and learning systems https doiorgtnnls zhao j li h qu l zhang q sun q huo h gong m dcf gan an adversarial deep reinforcement learning framework with improved negative sampling for sessionbased recommender systems inf sci httpsdoiorgjins sun j liu b ren h huang w wncgan a neural adver sarial collaborative filtering for recommender system journal of intelligent fuzzy systems httpsdoiorg jifs bharadhwaj h park h lim by recgan recurrent gen erative adversarial networks for recommendation systems in pro ceedings of the th acm conference on recommender systems recsys september association for computing machinery new york ny pp httpsdoiorg shafqat w byun yc a hybrid ganbased approach to solve imbalanced data problem in recommendation systems ieee access httpsdoiorgaccess wen j zhu xr wang cd tian z a framework for per sonalized recommendation with conditional generative adversarial networks knowl inf syst httpsdoiorg sz wang q huang q ma k zhang x a recommender system based on model regularization wasserstein generative adversarial network inf sci httpsdoiorg jins zhang x zhong j liu k wasserstein autoencoders for collaborative filtering neural comput appl httpsdoiorgsw schlett t rathgeb c henniger o galbally j fierrez j busch c face image quality assessment a literature survey acm comput surv httpsdoiorg bobadilla j gutiérrez a yera r martínez l creating syn thetic datasets for collaborative filtering recommender systems using generative adversarial networks knowledge based systems httpsdoiorgjknosys ioandaniel b raduemil p alexandrabianca b improvement of kmeans cluster quality by post processing resulted clusters procedia computer science https doiorgjprocs ortega f mayor j lópezfernández d laracabrera r cfj adapting collaborative filtering for java to new chal lenges of collaborative filtering based recommender sys tems knowledgebased syst httpsdoiorg jknosys gong y distribution constraining for combating mode collapse in generative adversarial networks j electron imaging httpsdoiorgjei publishers note springer nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations jesús bobadilla received the bs and the phd degrees in computer science from the uni versidad politécnica de madrid and the universidad carlos iii currently he is a full professor with the department of informa tion systems universidad poli técnica de madrid he is a habit ual author of programming languages books working with mcgraw hill rama and alfa omega publishers his research interests include information retrieval recommender systems and speech processing he over sees the filmaffinitycom research team working on the collaborative filtering kernel of the web site he has been a researcher into the inter national computer science institute at berkeley university and into the sheffield university abraham gutiérrez received the bs and the phd degrees in computer science from the uni versidad politécnica de madrid currently he is currently an associate professor with the department of information sys tems universidad politécnica de madrid he is the author of research papers in most prestig ious international journals he is a habitual author of program ming languages books working with mcgrawhill rama and alfa omega publishers his research interests include psys tems machine learning data analysis and artificial intelligence he is in charge of this group innovation issues including the commercial projects j bobadilla a gutiérrez,"[0.022679440677165985, 0.07594774663448334, -0.039350371807813644, 0.0021623189095407724, 0.0006096409633755684, -0.021715214475989342, 0.0699181780219078, 0.031684450805187225, 0.010423851199448109, 0.04181118309497833, -0.05945349112153053, -0.058775074779987335, -0.04569004103541374, 0.06527536362409592, 0.026824064552783966, -0.014641331508755684, 0.009253744967281818, 0.031130675226449966, -0.039315078407526016, -0.04738660156726837, -0.010188441723585129, 0.008663988672196865, 0.03403327241539955, 0.02496403641998768, 0.01668664813041687, -0.01841239258646965, -0.022103777155280113, -0.0206522885710001, 0.030816536396741867, -0.031280361115932465, 0.027801334857940674, 0.006280476693063974, -0.0036646793596446514, 0.030498433858156204, 2.308683406226919e-06, 0.005404333584010601, 0.015909021720290184, -0.03428546339273453, 0.009272771887481213, -0.015344730578362942, 0.04878656938672066, 0.07585195451974869, 0.0007134529296308756, 0.047703396528959274, -0.06875118613243103, -0.07030460238456726, -0.011365299113094807, 0.056322094053030014, 0.003292490029707551, 0.04841556400060654, -0.03146801143884659, -0.033086661249399185, 0.01620318740606308, -0.04683437943458557, 0.013333461247384548, -0.0012955291895195842, 0.009617403149604797, 0.011002451181411743, 0.013789637014269829, -0.020939989015460014, -0.010683373548090458, -0.02171821892261505, 0.03359667584300041, -0.00747514795511961, 0.0888887569308281, 0.04411683976650238, -0.013208371587097645, -0.00018629661644808948, 0.009453048929572105, 0.07261613011360168, -0.04113965854048729, -0.003222517669200897, -0.007186925504356623, -0.010680544190108776, -0.0023913830518722534, -0.008357946760952473, 0.00464638089761138, -0.04331878200173378, -0.034090302884578705, 0.027883652597665787, -0.05286809429526329, 0.035263948142528534, 0.041235946118831635, -0.027618449181318283, 0.02995462715625763, 0.01907944120466709, 0.03216380998492241, -0.023745529353618622, 0.01840829662978649, -0.020755674690008163, -0.013518991880118847, -0.040852151811122894, 0.06835736334323883, -0.051448334008455276, -0.023600324988365173, -0.048666730523109436, -0.02777840755879879, 0.026069168001413345, -0.017470071092247963, 0.022906593978405, 0.04464533552527428, -0.0330737829208374, 0.00446136062964797, 0.014591621235013008, -0.005148767493665218, 0.0068663242273032665, -0.028714794665575027, -0.02378837764263153, -0.05198604613542557, 0.02949383109807968, -0.02170691266655922, -0.0002928970498032868, 0.009933185763657093, 0.017686577513813972, -0.04952424019575119, -0.01670576073229313, -0.08220669627189636, 0.01127072423696518, -0.004664511885493994, 0.05275152251124382, 0.025824595242738724, 0.10640651732683182, -0.0013207071460783482, 0.025777366012334824, -0.06450527161359787, -0.018259014934301376, -0.05486873909831047, 0.036926258355379105, 0.01271091215312481, 0.015488303266465664, 0.04999282583594322, 0.03505975380539894, 0.009097426198422909, -0.009853404015302658, 0.0262103583663702, 0.036588720977306366, 0.01831274852156639, 0.006070542149245739, -0.026367297396063805, -0.013201948255300522, 0.01151211280375719, -0.07740525901317596, -0.004723298363387585, -0.039210859686136246, 0.05741288140416145, -0.0005839349469169974, -0.025639371946454048, -0.05213339254260063, -0.02303231693804264, -0.032997120171785355, 0.013789575546979904, 0.06975793838500977, 0.019459083676338196, -0.03373889997601509, -0.019814802333712578, -0.004783021751791239, 0.02888273261487484, -0.013754413463175297, 0.014541389420628548, 0.08097817003726959, 0.027252648025751114, -0.0003208963025826961, 0.01615229621529579, -0.006558476015925407, 0.0005816128104925156, 0.03813664987683296, -0.026797953993082047, -0.008999762125313282, -0.0700870007276535, 0.010547719895839691, 0.02309940755367279, 0.03794366866350174, -0.05286445841193199, -0.03513532504439354, 0.03869590535759926, -0.011600509285926819, 0.07715252786874771, 0.1161213219165802, 0.04076078534126282, -0.002648349618539214, -0.031943704932928085, 0.013755311258137226, 0.027749769389629364, 0.05757667496800423, -0.005914733279496431, -0.0268239788711071, 0.011669745668768883, 0.039635591208934784, -0.047461289912462234, -0.03996167331933975, 0.031618691980838776, -0.022446073591709137, -0.0029315915890038013, 0.0055191596038639545, 0.02786914072930813, -0.011302024126052856, -0.040066611021757126, -0.06102795526385307, 0.011282788589596748, -0.03148246183991432, 0.012049614451825619, -0.001410056953318417, 0.057661592960357666, 0.1112554520368576, 0.08022467792034149, 0.0003185294917784631, 0.05388997867703438, -0.028974387794733047, -0.06617961823940277, -0.05690755695104599, 0.006604562047868967, -0.03989958018064499, -0.01131214015185833, -0.05646916478872299, -0.0398014634847641, -0.008924816735088825, -0.004438363015651703, 0.06267064809799194, -0.025716109201312065, 0.05173828452825546, -0.01573530212044716, 0.007447012700140476, -0.0005717562744393945, -0.017105337232351303, -0.038203347474336624, -0.03318583220243454, 0.04886117950081825, 0.006076715886592865, 0.03938998281955719, 0.015463178046047688, 0.005611706525087357, -0.030852673575282097, 0.03502073511481285, -0.030115677043795586, -0.035984087735414505, -0.007961149327456951, 0.00041050370782613754, -0.023261934518814087, -0.016838902607560158, -0.0759836956858635, 0.04572131112217903, 0.05399704724550247, -0.027864543721079826, -0.019239546731114388, -0.004521322436630726, 0.018296649679541588, -0.018652498722076416, -0.022853871807456017, -0.004458452109247446, 0.027760272845625877, 0.07676135748624802, 0.007246036548167467, 0.02547963708639145, -0.023030584678053856, 0.018325353041291237, -0.03953546658158302, 0.0437171645462513, 0.034879058599472046, -0.04135223850607872, -0.019413486123085022, 0.027727292850613594, 0.011610816232860088, 0.0064269425347447395, -0.006593514233827591, -0.018641004338860512, 0.00530247064307332, -0.004034445155411959, -0.031046947464346886, 0.02228001318871975, 0.004142327234148979, -0.015289509668946266, -0.00939467828720808, 0.013248736970126629, 0.004524875897914171, -0.0007469492848031223, -0.0679255798459053, 0.025250518694519997, -0.011282412335276604, -0.03611410781741142, 0.008117370307445526, 0.007755945436656475, -0.009422393515706062, -0.0053428602404892445, -0.027867933735251427, -0.0017167768673971295, 0.047133225947618484, 0.0007173193735070527, 0.02921413816511631, -0.053691163659095764, -0.0061869993805885315, -0.009017887525260448, 0.04029390960931778, -0.020109688863158226, -0.02800334058701992, -0.03409529849886894, 0.028261441737413406, 0.06073007732629776, 0.026894692331552505, 0.00758435670286417, 0.04784896597266197, 0.05291220545768738, 0.04897741600871086, -0.02139992266893387, 0.024811672046780586, -0.025228329002857208, 0.013789148069918156, -0.018525732681155205, -0.023950787261128426, -0.03378743305802345, -0.029077745974063873, 0.04214516654610634, -0.003194833407178521, -0.05704430863261223, 0.05184554681181908, 0.020123332738876343, -0.026377078145742416, -0.022373411804437637, 0.02053777500987053, -0.024734802544116974, 0.0024793269112706184, 0.003863267134875059, -0.019818048924207687, 0.020097436383366585, 0.023480530828237534, 0.008122585713863373, -0.0347166545689106, -0.04955846443772316, 0.0053420704789459705, -0.025387154892086983, 0.025213999673724174, 0.00212395959533751, 0.005058954004198313, 0.02075343020260334, -0.06027323380112648, 0.060461003333330154, 0.021799147129058838, -0.04960331320762634, -0.028605381026864052, 0.05597666651010513, -0.040099937468767166, -0.005362328607589006, -0.021526023745536804, -0.08539643883705139, -0.031830865889787674, 0.02694457210600376, -0.02201761119067669, 0.0729832872748375, -0.02038927562534809, -0.024358712136745453, -0.03210840001702309, -0.057476554065942764, 0.04378461837768555, -0.008005695417523384, -0.001005224185064435, 0.011723970994353294, 0.08931676298379898, 0.04641156271100044, -0.06424784660339355, -0.025163937360048294, 0.022735102102160454, 0.02970421127974987, 0.03126634657382965, -0.007834462448954582, 0.0020089580211788416, -0.0721169114112854, -0.001532754278741777, 0.015555743128061295, 0.05083783343434334, 0.0246066153049469, 0.006342523731291294, -0.018327094614505768, 0.032552629709243774, 0.03374528884887695, 0.02610352821648121, 0.01636616885662079, -0.10841085016727448, 0.02410151995718479, 0.039688967168331146, 0.02904687076807022, 0.03749069571495056, 0.05128604546189308, -0.07258307188749313, 0.035440053790807724, -0.01585976965725422, 0.025824880227446556, -0.021280629560351372, -0.012957892380654812, -0.00912555493414402, -0.09329087287187576, 0.06775223463773727, 0.0036912846844643354, 0.017508678138256073, -0.009421360678970814, 0.006337777245789766, -0.029505368322134018, -0.009096696972846985, 0.02896648831665516, -0.018104415386915207, 0.02180948108434677, 0.003432766068726778, 0.007556317374110222, 0.006678531877696514, -0.07116544246673584, 0.01340210810303688, -0.014857926405966282, 0.05537998676300049, 0.027063721790909767, 0.06060372292995453, 0.015699997544288635, -0.07655121386051178, -0.05391682684421539, 0.022737979888916016, 0.010494530200958252, 0.008800791576504707, 0.09454724192619324, 0.019703224301338196, 0.0178175438195467, 0.010835816152393818, 0.0576806366443634, -0.03799464553594589, 0.01531258411705494, 0.00838828831911087, -0.0035756949800997972, -0.016571974381804466, -0.050879091024398804, -0.02839813567698002, 0.03085474669933319, 0.042572006583213806, 0.037108201533555984, 0.007157480344176292, -0.053679272532463074, 0.006980685982853174, -0.013379113748669624, 0.0023582230787724257, -0.06292007863521576, -0.05273560434579849, 0.02958337962627411, 0.015069032087922096, 0.01564894989132881, -0.05521340295672417, -0.02171626128256321, -0.005505353678017855, 0.020037421956658363, -0.009082919918000698, 0.02574099786579609, -0.06085038557648659, -0.03634260222315788, 0.0009466818883083761, -0.015959138050675392, 0.05237410217523575, 0.027916083112359047, -0.0237180907279253, -0.013444538228213787, 0.011146822944283485, -0.06341781467199326, -0.0162736177444458, -0.029009437188506126, -0.030896345153450966, -0.015694506466388702, -0.021964633837342262, 0.049290161579847336, 0.013904481194913387, 0.031031232327222824, -0.056889891624450684, -0.05296832323074341, 0.08307608217000961, 0.04701772332191467, -0.015588821843266487, -0.04497997462749481, 0.016371948644518852, 0.03292347118258476, -0.009465239010751247, 0.028571100905537605, -0.014795144088566303, 0.029177024960517883, 0.014054457657039165, -0.02047192119061947, 0.0002691037952899933, 0.017678378149867058, 0.02307020127773285, 0.002305602189153433, 0.02895611897110939, -0.03878060355782509, 0.030192626640200615, -0.03242376074194908, 0.03183632716536522, -0.022732660174369812, 0.011716780252754688, -0.038953352719545364, -0.030410954728722572, 0.053202856332063675, 0.008949448354542255, -0.04244997724890709, 0.005146613344550133, 0.003361970419064164, 0.010789263062179089, -0.06539789587259293, 0.017204325646162033, 0.0384901762008667, 0.024404073134064674, 0.02043362893164158, 0.027112189680337906, 0.016875725239515305, -0.03370457515120506, 0.037014733999967575, 0.02190929464995861, -0.01899983175098896, 0.011098630726337433, 0.013464364223182201, -0.01326688751578331, -0.06091476231813431, 0.06764312088489532, 0.0009560238686390221, 0.0016052464488893747, -0.053368739783763885, 0.07238618284463882, 0.027645356953144073, -0.019812120124697685, -0.016096897423267365, -0.013380433432757854, -0.015893524512648582, -0.029661262407898903, 0.006873502861708403, -0.04073238745331764, -0.017367618158459663, 0.011488504707813263, 0.016219433397054672, -0.012858814559876919, 0.029013285413384438, 0.07387152314186096, 0.04112963005900383, -0.006950834300369024, -0.0443098321557045, -0.032914768904447556, -0.047708429396152496, 0.025094376876950264, -0.0023904929403215647, 0.03580053150653839, -0.02588244341313839, 0.013612892478704453, -0.022761201485991478, -0.06786409765481949, -0.012938931584358215, -0.0026546763256192207, 0.05556774139404297, -0.028195301070809364, 0.021450193598866463, 0.00516618462279439, -0.020754540339112282, 0.017551224678754807, -0.016227848827838898, -0.006054663565009832, -0.016326256096363068, -0.03341282159090042, -0.02155400440096855, -6.725954596794504e-33, 0.0400242917239666, -0.030911972746253014, -0.000213961728150025, -0.010546757839620113, -0.033689484000205994, -0.0409032441675663, -0.0017210814403370023, -0.046079058200120926, 0.06103670224547386, 0.010953456163406372, -0.05158466845750809, -0.003888447070494294, 0.0044953725300729275, 0.01963663473725319, -0.015390036627650261, -0.0031839534640312195, 0.10148026794195175, -0.006109398324042559, 0.011449696496129036, 0.03969517722725868, 0.027596140280365944, 0.05968352034687996, -0.013134785927832127, -0.054316844791173935, -0.05362376570701599, -0.0295378640294075, -0.02397848293185234, -0.035702865570783615, -0.024666445329785347, 0.03260720521211624, -0.02566944807767868, 0.0670456662774086, -0.012524131685495377, -0.023120582103729248, 0.033307645469903946, -0.023403821513056755, -0.059745047241449356, 0.011267950758337975, -0.008740298449993134, 0.0065117646008729935, -0.06487219780683517, -0.013336868956685066, 0.019552193582057953, 0.0043363552540540695, 0.007601277437061071, 0.0035710372030735016, 0.043557025492191315, -0.023307370021939278, -0.04907675459980965, -0.07322659343481064, 0.002132758731022477, 0.004483552649617195, 0.013967570848762989, 0.02790181152522564, 0.004820355214178562, 0.050028618425130844, -0.020406018942594528, 0.043007947504520416, -0.05011659488081932, -0.024244682863354683, -0.024899626150727272, 0.016871169209480286, -0.024079494178295135, 0.011404776014387608, 0.004173320718109608, 0.04079433158040047, 0.04137423262000084, -0.06963613629341125, -0.030839692801237106, 0.0201286468654871, 0.005047233775258064, 0.0597030371427536, -0.009519378654658794, 0.11097247153520584, 0.06365858018398285, -0.07433492690324783, -0.046786218881607056, 0.044917333871126175, 0.009024793282151222, -0.03200753033161163, 0.03632485494017601, 0.04511517286300659, -0.021867714822292328, 0.0014987707836553454, 0.021233443170785904, -0.11418277025222778, -0.03449181094765663, -0.058077044785022736, 0.025941811501979828, 0.02655155584216118, -0.05589132383465767, -0.04148630425333977, -0.007680324371904135, -0.08205082267522812, -0.00024820302496664226, -0.004309858661144972, -0.05248101055622101, -0.004088792949914932, 0.033642444759607315, -0.028196819126605988, -0.005671774502843618, 0.0012962515465915203, 0.004362314008176327, -0.018630893900990486, -0.015025775879621506, -0.006283072289079428, 0.06113722547888756, 0.020883779972791672, 0.002262141788378358, 0.003467559115961194, -0.0015144936041906476, 0.017024992033839226, 0.01810690201818943, 0.013340670615434647, -0.021080700680613518, 0.04169809818267822, -0.029653633013367653, 0.04390144348144531, 0.024693941697478294, 0.08771968632936478, -0.02778005786240101, -0.048934727907180786, 0.02517743594944477, 0.001548617728985846, -0.03990286588668823, -0.0037626447156071663, -0.020566130056977272, -0.010222816839814186, 0.1008753851056099, -0.09321825206279755, -0.02495497278869152, -0.03806135058403015, 3.000376977979613e-07, -0.05431811511516571, -0.0005261516198515892, -0.009387942031025887, -0.04918656125664711, 0.011408804915845394, 0.001039606868289411, 0.0018652118742465973, 0.046128686517477036, -0.014122147113084793, -0.0002138756972271949, 0.04055587202310562, -0.010767496190965176, -0.004041237756609917, 0.03650949150323868, -0.06059195473790169, 0.056598156690597534, -0.030393272638320923, 0.008661272004246712, -0.03917558118700981, -0.04140874370932579, -0.005229463800787926, 0.08494985848665237, 0.06425686925649643, -0.02571987360715866, 0.06823740154504776, 0.04381388798356056, 0.02575026825070381, -0.004524425137788057, -0.013216727413237095, -0.05077427998185158, 0.06832113862037659, -0.0038317509461194277, -0.019906828179955482, 0.021233823150396347, -0.04942893981933594, 0.023898813873529434, 0.011713309213519096, -0.000685202656313777, -0.00995556265115738, -0.04989266023039818, -0.027956975623965263, -0.0017538610845804214, 0.016257235780358315, -0.015032771974802017, 0.059170912951231, 0.011481348425149918, -0.00389186292886734, 0.007857490330934525, -0.06792601197957993, 0.009256631135940552, 0.02424352616071701, -0.017645956948399544, 0.02358056604862213, -0.008698942139744759, -0.0030679511837661266, -0.021472830325365067, 0.02348690666258335, -0.02052641101181507, 0.06427999585866928, -0.00048469670582562685, -0.04570374637842178, -0.037693120539188385, -0.003908852115273476, 0.030944231897592545, 0.03205488994717598, 0.03884261101484299, 0.00471942825242877, 2.547596101126853e-34, 0.01395726390182972, 0.048168718814849854, 0.0031907421071082354, -0.08158162236213684, -0.01167906355112791, -0.04540706053376198, -0.0009149529505521059, 0.01579451374709606, 0.053711406886577606, -0.018770849332213402, -0.06803571432828903]",2,Synthetic Datasets & GANs
Comprehensive Evaluation of Matrix Factorization Models for Collaborative Filtering Recommender Systems.pdf,see discussions stats and author profiles for this publication at httpswwwresearchgatenetpublication comprehensive evaluation of matrix factorization models for collaborative filtering recommender systems article in international journal of interactive multimedia and artificial intelligence january doi ijimai citations reads authors jesus bobadilla universidad politécnica de madrid publications citations see profile jorge dueñaslerín comunidad de madrid publications citations see profile fernando ortega universidad politécnica de madrid publications citations see profile abraham gutierrez universidad la salle méxico publications citations see profile all content following this page was uploaded by jorge dueñaslerín on july the user has requested enhancement of the downloaded file corresponding author email addresses jesusbobadillaupmes j bobadilla jorgedlalumnosupmes j dueñaslerìn fernandoortegaupmes f ortega abrahamgutierrezupmes a gutierrez please cite this article in press as j bobadilla j dueñaslerín f ortega a gutierrez comprehensive evaluation of matrix factorization models for collaborative filtering recommender systems international journal of interactive multimedia and artificial intelligence httpdxdoiorgijimai keywords collaborative filtering matrix factorization recommender systems abstract matrix factorization models are the core of current commercial collaborative filtering recommender systems this paper tested six representative matrix factorization models using four collaborative filtering datasets experiments have tested a variety of accuracy and beyond accuracy quality measures including prediction recommendation of ordered and unordered lists novelty and diversity results show each convenient matrix factorization model attending to their simplicity the required prediction quality the necessary recommendation quality the desired recommendation novelty and diversity the need to explain recommendations the adequacy of assigning semantic interpretations to hidden factors the advisability of recommending to groups of users and the need to obtain reliability values to ensure the reproducibility of the experiments an open framework has been used and the implementation code is provided doi ijimai comprehensive evaluation of matrix factorization models for collaborative filtering recommender systems jesús bobadilla jorge dueñaslerín fernando ortega abraham gutierrez dpt sistemas informáticos and knodis research group universidad politécnica de madrid spain received july accepted march early access april i introduction r ecommender system rs is the field of artificial intelligence specialized in user personalization mainly rss provide accurate item recommendations to users movies trips books music etc recommendations are made following some filtering approach the most accurate filtering approach is the collaborative filtering cf where recommending to an active user involves a first stage to make predictions about all his or her not consumed or voted items then the top predicted items are recommended to the active user the cf approach assumes the existence of a dataset that contains explicitly voted items or implicitly consumed items from a large number of users remarkable commercial rss are amazon spotify netflix or tripadvisor regardless of the machine learning model used to implement cf the key concept is to extract user and item patterns and then to recommend to the active user those items that he or she has not voted or consumed and that similar users have highly valued it fits with the k nearest neighbors knn memorybased algorithm and it is the reason why the initial rs research was based on knn there are also some other filtering approaches such as demographic social content based contextaware and their ensembles demographic filtering makes use of user information such as gender age or zip code and item information such as movie genre country to travel etc social filtering has a growing importance in current rs due to the social networks boom the existence of trust relations and graphs can improve the quality of the cf recommendations in this decentralized and dynamic environment trust between users provides additional information to the centralized set of ratings trust relationships can be local collective or global local information is based on shared users opinions collective information uses friends opinions whereas global information relates to users reputation content based filtering recommends items with the same type content to consumed items eg to recommend java books to a programmer that bought some other java book contextaware filtering uses gps information biometric sensor data etc finally ensemble architectures get high accuracy by merging several types of filtering memorybased algorithms have two main drawbacks their accuracy is not high and each recommendation process requires to recompute the whole dataset modelbased approaches solve both problems their accuracy is higher than that of memorybased methods and they first create a model from the dataset from the created model we can make many different recommendations and it can be efficiently updated when the dataset changes matrix factorization mf is the most popular approach to implement current rss it provides accurate predictions it is conceptually simple it has a straightforward implementation the model learns fast and also updates efficiently the mf model makes a compression of information coding very sparse and large vectors of discrete values ratings to low dimensional embeddings of real numbers called hidden factors the hidden factors both from the user vector and from the item vector are combined by means of a dot product to return predictions this is an iterative process in which the distance between training predictions and their target ratings is minimized the probabilistic matrix factorization pmf model based on mf scales linearly with the size of the data set it also returns accurate international journal of interactive multimedia and artificial intelligence results when applied to sparse large and imbalanced cf datasets pmf has also been extended to include an adaptive prior on the model parameters and it can generalize adequately providing accurate recommendation to coldstart users cf rss are usually biased a typical cf bias source comes from the fact that some users tend to highly rate items mainly and stars whereas some other users tend to be more restrictive in their ratings mainly and stars this fact leads to the extension of the mf model to handle biased data an userbased rating centrality and an itembased rating centrality have been used to improve the accuracy of the regular pmf these centrality measures are obtained by processing the degree of deviation of each rating in the overall rating distribution of the user and the item nonnegative matrix factorization nmf can extract significant features from sparse and nonnegative cf datasets please note that cf ratings are usually a nonnegative number of stars listened songs watched movies etc when nonnegativity is imposed prediction errors are reduced and the semantic interpretability of hidden factors is easier the bernoulli matrix factorization bemf has been designed to provide both prediction and reliability values this model uses the bernoulli distribution to implement a set of binary classification approaches the results of the binary classification are combined by means of an aggregation process the bayesian nonnegative matrix factorization bnmf was designed to provide useful information about user groups in addition to the pmf prediction results the authors factorize the rating matrix into two nonnegative matrices whose components lie within the range the resulting hidden factors provide an understandable probabilistic meaning finally the user ratings profile model urp is a generative latent variable model it produces complete rating user profiles in the urp model first attitudes for each item are generated then a user attitude for the item is selected from the set of existing attitudes urp borrows several concepts from lda and the multinomial aspect model the set of mf models mentioned above pmf biased matrix factorization biasedmf nmf bemf bnmf and urp can be considered representative in the cf area these models will be used in this paper to compare their behavior when applied to representative datasets specifically the following quality measures will be tested mean absolute error mae novelty diversity precision recall and normalized discounted cumulative gain ndcg prediction accuracy will be tested using mae whereas ndcg precision and recall will be used to test recommendation accuracy modern cf models should be tested not only regarding accuracy but also beyond accuracy properties novelty and diversity novelty can be defined as the quality of a system to avoid redundancy diversity is a quality that helps to cope with ambiguity or underspecification the models have been tested using four cf datasets movielens k and m versions filmtrust and myanimelist these are representative open datasets and are popular in rs research overall this paper provides a complete evaluation of mf methods where the pmf biasedmf nmf bemf bnmf and urp models have been tested using representative cf quality measures both for prediction and recommendation and also beyond accuracy ones as far as we know this is the experimental most complete work evaluating current mf models in the cf area the rest of the paper is structured as follows section ii introduces the tested models the experiment design the selected quality measures and the chosen datasets section iii shows the obtained results and provides their explanations in section iv section v highlights the main conclusions of the paper and the suggested future works finally a references section lists current research in the area ii methods and experiments this section abstracts the fundamentals of each baseline model pmf biasedmf nmf bemf bnmf urp introduces the tested quality measures mae precision recall ndcg novelty diversity and shows the main parameters of the tested datasets movielens filmtrust myanimelist experiments are performed by combining the previous entities the vanilla mf is used to generate rating predictions from a matrix of ratings r this matrix contains the set of casted ratings explicit or implicit from a set of users u to a set of items i since regular users only vote or consume a very limited subset of the available items matrix r is very sparse the mf key concept is to compress the very sparse item and user vectors of ratings to small size and dense item and user vectors of real numbers these small size dense vectors can be considered as embeddings and they usually are called hidden factors since each embedding factor codes some complex nonlineal hidden relation of user or item features the parameter k is usually chosen to set the embedding hidden factors size mf makes use of two matrices puk to contain the k hidden factors of each user and qik to contain the k hidden factors of each item to predict how much a user u likes an item i we compare each hidden factor of u with each corresponding hidden factor of i then the dot product u i can be used as suitable cf prediction measure mf predicts ratings by minimizing errors between the original r matrix and the predicted matrix using gradient descent we minimize learning errors differences between real ratings r and predicted ratings to minimize the error we differentiate equation with respect to puk and qki introducing the learning rate α we can iteratively update the required hidden factors puk and qki cf datasets have biases since different users vote or consume items in different ways in particular there are users who are more demanding than others when rating products or services analogously there are items more valued than others on average biased mf is designed to consider data biases the following equations extend the previous ones introducing the bias concept and making the necessary regularization to maintain hidden factor values in their suitable range where μ bu bi are the average bias the user bias and the item bias article in press we minimize the regularized squared error where λ is the regularization term obtaining the following updating rules nmf can be considered as a regular mf subject to the following constraints in the nmf case predictions are made by linearly combining positive coefficients hidden factors nmf hidden factors are easier to semantically interpret than regular mf ones sometimes it is not straightforward to assign semantic meanings to negative coefficient values in the cf context another benefit of using nmf decomposition is the emergence of a natural clustering of users and items intuitively users and items can be clustered according to the dominant factor ie the factor having the highest value in the same way the original features gender age item type item year etc can be grouped according to the factor from the k hidden factors on which they have the greatest influence this is possible due to the condition of positivity of the coefficients bemf is an aggregationbased architecture that combines a set of bernoulli factorization results to provide pairs prediction reliability bemf uses as many bernoulli factorization processes as possible scores in the dataset reliability values can be used to detect shilling attacks to explain the recommendations and to improve prediction and recommendation accuracy bemf is a classification model based on the bernoulli distribution it adequately adapts to the expected binary results of each of the possible scores in the dataset using bemf the prediction for user u to item i is a vector of probabilities where is the probability that i is assigned the sth score from user u the bemf model can be abstracted as follows let s s sd be the set of d possible scores in the dataset eg to stars d from r we generate d distinct matrices each matrix is a sparse matrix such that bemf will attempt to fit the matrices by performing d parallel mfs the bemf assumes that given the user p matrix and the item q matrix containing k hidden factors the rate rui is a bernoulli distribution with the success probability ψpu qi the mass function of this random variable is the associated likelihood is the bemf updating equations are and the aggregation to obtain the final output φ where let the prediction is and the reliability is bnmf provides a bayesianbased nmf model that not only allows accurate prediction of user ratings but also to find groups of users with the same tastes as well as to explain recommendations the bnmf model approximates the real posterior distribution by the distribution where is a random variable from a categorical distribution is a random variable from a binomial distribution which takes values from to d a and b are hidden matrices follows a dirichlet distribution follows a beta distribution follows a categorical distribution λuik are parameters to be learned bnmf iteratively approximates parameters where ψ is the digamma function as the logarithmic derivative of the gamma function urp is a generative latent variable model the model assigns to each user a mixture of user attitudes mixing is performed by a dirichlet random variable international journal of interactive multimedia and artificial intelligence in this paper baseline models will be tested using a prediction measure b recommendation measures and c beyond accuracy measures the chosen prediction measure is the mae where the absolute differences of the errors are averaged absolute precision and relative recall measures are tested to compare the quality of an unordered list of n recommendations the ordered lists of recommendations will be compared using the ndcg quality measure from the beyond accuracy metrics we have selected novelty and diversity novelty returns the distance from the items the user knows has voted or consumed to his recommended set of items diversity tells us about the distance between the set of recommended items recommendations with high novelty values are valuable since they show to the user unknown types of items diverse recommendations are valuable because they provide different types of items and each type of item can be novel or not to the user the grouplens research group made available several cf datasets collected over different intervals of time movielens k and movielens m describe star rating and freetext tagging activity these data were created from to in the movielens k dataset users were selected at random from those who had rated at least movies whereas the movielens m dataset has not this constraint only movies with at least one rating or tag are included in the dataset no demographic information is included each user is represented by an id and no other information is provided the dataset files are written as commaseparated values files with a single header row columns that contain commas areescapedusing doublequotes these files are encoded as utf all ratings are contained in the file named ratingscsv each line of this file after the header row represents one rating of one movie by one user and has the following format userid movieid rating timestamp the lines within this file are ordered first by userid then within user by movieid timestamps represent seconds since midnight coordinated universal time utc of january filmtrust is a small dataset crawled from the entire filmtrust website in june as the movielens datasets it contains ratings voted from users to items additionally it provides social information structured as a graph network finally myanimelist contains information about anime and otaku consumers anime manga video games and computers each user is able to add animes to their completed list and give them a rating this data set is a compilation of those ratings the myanimelist cf information is contained in the file animecsv where their main columns are anime_id myanimelistnets unique id identifying an anime name full name of anime genre comma separated list of genres for this anime type movie tv ova etc episodes how many episodes in this show rating average rating out of for this anime these datasets are available in the kaggle and github repositories as well as in the knodis research group cfj repository httpsgithubcomferortegacfj table i contains the values of the main parameters of the selected cf data sets movielens k movielens m filmtrust and myanimelist we have run the explained mf models on each of the four table i datasets testing the chosen quality measures please note that the myanimelist dataset ratings range from to whereas movielens datasets range from to and filmtrust ranges from to with increments it is also remarkable the sparsity difference between filmtrust and the rest of the tested datasets table i main parameter values of the tested datasets dataset users items ratings scores sparsity movielensk to movielensm to myanimelist to filmtrust to experiments have been performed using random search and applying fourfold crossvalidation to ensure reproducibility we used a seed in the random process results shown in the paper are the average of the partial results obtained by setting the number k of latent factors to and the number of mf iterations to additionally to run the pmf biasedmf and bemf models both the learning rate and the regularization parameters have been set to the bnmf model requires two specific parameters α and β the chosen values por these parameters are α and β the tested number of recommendations n ranges from to we have used stars as recommendation threshold θ for datasets whose ratings range from to while the testing threshold has been when myanimelist was chosen the experiments have been implemented using the open framework and the code has been made available at httpsgithubcomknodisresearchgroupchoiceofmfmodels iii results the prediction quality obtained by testing each baseline model is shown in table ii the bold numbers correspond to the best results and of them those highlighted gray are the top ones as can be seen biasedmf and bnmf models provide the best cf prediction results pmf nmf bemf and urp seem to be more sensitive to the type of cf input data table ii prediction quality results using the mean absolute error mae the lower the error value the better the result pmf biasedmf nmf bemf bnmf urp movielens k movielens m filmtrust myanimelist fig shows the quality of recommendation obtained using the precision measure the most remarkable in fig is the superiority of the models pmf and biasedmf for the remaining models urp and bemf provide the worst results whereas the nonnegative nmf and bnmf return an intermediate quality it is important to highlight the good performance of the biasedmf model for both the prediction and the recommendation tasks to test the quality of cf recommendations of unordered recommendations precision and recall measures are usually processed and they are provided separately or joined in the f score we have done these experiments and we have not found appreciable differences in recall values for the tested models in the selected datasets in order to maintain the paper as short as possible fig only shows the recall results obtained by processing the movielens m dataset results from the rest of datasets are very similar consequently the recall quality measure does not help in this context to find out the best mf models in the cf area article in press fig recall recommendation quality results obtained in the movielens m dataset the results of the other three considered datasets are very similar to this one to maintain the paper as short as possible the results of other datasets are not shown pmf number of recommendations recall biasedmf bemf nmf bnmf urp fig recall recommendation quality results obtained in the movielens m dataset the results of the other three considered datasets are very similar to this one to maintain the paper as short as possible the results of other datasets are not shown in the rss field recommendations are usually provided in an ordered list users trust in rss quickly decays when the first recommendations in the list do not meet their expectations for that reason the ndcg quality measure particularly penalizes errors in the first recommendations of the list fig ndcg results shows a similar behavior to fig where the biasedmf and pmf models provide the best recommendation quality so these two models perform fine both in recommending ordered and unordered lists traditionally rss have been evaluated attending to their prediction and recommendation accuracy nevertheless there are some other valuable beyond accuracy aims and their corresponding quality measures the diversity measure tests the variety of recommendations penalizing recommendations focused on the same area star wars iii star wars i star wars v han solo fig shows the diversity results obtained by testing the selected models the most diverse recommendations are usually returned when the biasedmf model is used followed by both pmf and nmf this fact is particularly interesting since it is not intuitive that the same model biasedmf can simultaneously provide accurate and diverse recommendations novelty is an important beyond accuracy objective in rss users appreciate accurate recommendations but they also want to discover unexpected and accurate enough recommendations please note that a set of recommendations can be diverse and not novel as they can be novel and not diverse it would be great to receive simultaneously accurate novel and diverse recommendations but usually improving some of the objectives leads to worsening others fig shows the results of the novelty quality measure nmf returns novel recommendations compared to other models nmf provides a balance between accuracy and novelty biasedmf and pmf also provide novel recommendations compared to bemf and urp pmf number of recommendations precision biasedmf bemf nmf bnmf urp pmf biasedmf bemf nmf bnmf urp pmf number of recommendations precision biasedmf bemf nmf bnmf urp pmf number of recommendations number of recommendations precision precision biasedmf bemf nmf bnmf urp a b c d fig precision recommendation quality results a movielensk b movielens m c filmtrust d myanimelist the higher the values the better the results international journal of interactive multimedia and artificial intelligence pmf number of recommendations ndcg ndcg biasedmf bemf nmf bnmf urp pmf biasedmf bemf nmf bnmf urp pmf number of recommendations ndcg biasedmf bemf nmf bnmf urp pmf number of recommendations number of recommendations ndcg biasedmf bemf nmf bnmf urp a b c d fig normalized discounted cumulative gain recommendation quality results a movielensk b movielens m c filmtrust d myanimelist the higher the values the better the results pmf diversity diversity biasedmf bemf nmf bnmf urp pmf biasedmf bemf nmf bnmf urp pmf diversity biasedmf bemf nmf bnmf urp pmf number of recommendations number of recommendations number of recommendations number of recommendations diversity biasedmf bemf nmf bnmf urp a b c d fig diversity beyond accuracy results a movielensk b movielens m c filmtrust d myanimelist the higher the values the better the results article in press iv discussion in this section we provide a comparative discussion of the most adequate mf models when applied to a set of different cf databases to judge each mf model we simultaneously measure a set of conflicting goals prediction accuracy recommendation accuracy unordered and ordered lists and beyond accuracy aims we will promote some mf models as winners attending to their high performance overall quality results when applied to the tested datasets we also provide a summary table to better identify those mf models that perform particularly fine on any individual quality objective novelty diversity precision etc as well as any combination of those quality measures table iii mf models comparative pmf biasedmf nmf bemf bnmf urp mae precision ndcg diversity novelty total table iii summarizes the results of this section biasedmf is the most appropriate model when novelty of recommendations is not a particularly relevant issue pmf can be used instead biasedmf when simplicity is required eg educational environments bemf should only be used when reliability information is required or when reliability values are used to improve accuracy nmf and bnmf are adequate when semantic interpretation of hidden factors is needed nmf is the best choice when we want to be recommended with novel items bnmf provides good accuracy and it is designed to recommend to group of users v conclusions this paper makes a comparative of relevant mf models applied to collaborative filtering recommender systems prediction recommendation and beyond accuracy quality measures have been tested on four representative datasets the results show the superiority of the biasedmf model followed by the pmf one biasedmf arises as the most convenient model when novelty is not a particularly important feature pmf combines simplicity with accuracy it can be the best choice for educational or not commercial implementations nmf and bnmf are adequate when we want to do a semantic interpretation of their nonnegative hidden factors nmf is preferable to bnmf when beyond accuracy novelty and diversity results are required whereas it is better to make use of bnmf when prediction accuracy is required or when recommending to group of users or when explaining recommendations is needed nmf and biasedmf are the best choices when beyond accuracy aims are selected whereas pmf or biasedmf performs particularly well in recommendation task both for unordered and ordered options bemf can only be selected when reliability values are required or when they are used to improve accuracy finally urp does not seem to be an adequate choice in any of the combinations tested as future work it is proposed to add new mf models quality measures and datasets to the experiments as well as the possibility of including neural network models such as deepmf or neural collaborative filtering ncf pmf novelty novelty biasedmf bemf nmf bnmf urp pmf biasedmf bemf nmf bnmf urp pmf novelty biasedmf bemf nmf bnmf urp pmf number of recommendations number of recommendations number of recommendations number of recommendations novelty biasedmf bemf nmf bnmf urp a b c d fig novelty beyond accuracy quality results a movielensk b movielens m c filmtrust d myanimelist the higher the values the better the results international journal of interactive multimedia and artificial intelligence acknowledgments this work has been cofunded by the ministerio de ciencia e innovación of spain and european regional development fund feder under grants pidrbi dlcemg and the comunidad de madrid under convenio plurianual with the universidad politécnica de madrid in the actuation line of programa de excelencia para el profesorado universitario references z batmaz a yurekli a bilge c kaleli a review on deep learning for recommender systems challenges and remedies artificial intelligence review vol no pp j bobadilla s alonso a hernando deep learning architecture for collaborative filtering recommender systems applied sciences vol no p b zhu r hurtado j bobadilla f ortega an efficient recommender system method based on the numerical relevances and the nonnumerical structures of the ratings ieee access vol pp j bobadilla r laracabrera á gonzálezprieto f ortega deepfair deep learning for improving fairness in recommender systems international journal of interactive multimedia and artificial intelligence vol no pp doi ijimai j carbó j m molina j dávila fuzzy referral based cooperation in social networks of agents ai communications vol pp d medel c gonzálezgonzález s v aciar social relations and methods in recommender systems a systematic review international journal of interactive multimedia and artificial intelligence vol no p doi ijimai m caromartínez g jiménezdíaz j a recio garcía local model agnostic explanations for blackbox recommender systems using interaction graphs and link prediction techniques international journal of interactive multimedia and artificial intelligence vol inpress no inpress p doi ijimai s afef z brahmi m gammoudi trustbased recommender systems an overview in th ibima conference i pinyol j sabatermir computational trust and reputation models for open multiagent systems a review artificial intelligence review vol pp jun doi sz y deldjoo m schedl p cremonesi g pasi recommender systems leveraging multimedia content acm computing surveys csur vol no pp s kulkarni s f rodd context aware recommendation systems a review of the state of the art techniques computer science review vol p s forouzandeh k berahmand m rostami presentation of a recommender system with ensemble learning and graph embedding a case on movielens multimedia tools and applications vol no pp r salakhutdinov a mnih probabilistic matrix factorization in proceedings of the th international conference on neural information processing systems nips red hook ny usa p curran associates inc z wu h tian x zhu s wang optimization matrix factorization recommendation algorithm based on rating centrality in international conference on data mining and big data pp springer c févotte j idier algorithms for nonnegative matrix factorization with the βdivergence neural computation vol no pp f ortega r laracabrera á gonzálezprieto j bobadilla providing reliability in recommender systems through bernoulli matrix factorization information sciences vol pp a hernando j bobadilla f ortega a non negative matrix factorization for collaborative filtering recommender systems based on a bayesian probabilistic model knowledgebased systems vol pp b m marlin modeling user rating profiles for collaborative filtering advances in neural information processing systems vol d m blei a y ng m i jordan latent dirichlet allocation journal of machine learning research vol no jan pp t hofmann learning what people dont want in european conference on machine learning pp springer a gunawardana g shani evaluating recommender systems in recommender systems handbook springer pp c c aggarwal evaluating recommender systems in recommender systems springer pp j bobadilla a gutiérrez s alonso á gonzález prieto neural collaborative filtering classification model to obtain prediction reliabilities international journal of interactive multimedia and artificial intelligence vol no pp doi ijimai s vargas p castells rank and relevance in novelty and diversity metrics for recommender systems in proceedings of the fifth acm conference on recommender systems pp p castells s vargas j wang novelty and diversity metrics for recommender systems choice discovery and relevance in proceedings of the rd european conference on information retrieval ecir s vargas p castells d vallet intentoriented diversity in recommender systems in proceedings of the th international acm sigir conference on research and development in information retrieval pp f m harper j a konstan the movielens datasets history and context acm transactions on interactive intelligent systems tiis vol no pp doi httpsdoiorg j golbeck j a hendler filmtrust movie recommendations using trust in webbased social networks ccnc rd ieee consumer communications and networking conference vol pp doi ccnc j miller g southern recommender system for animated video issues in information systems vol no pp y koren r bell c volinsky matrix factorization techniques for recommender systems computer vol no pp j bobadilla a gutiérrez s alonso á gonzález prieto neural collaborative filtering classification model to obtain prediction reliabilities international journal of interactive multimedia and artificial intelligence vol no pp doi ijimai f ortega b zhu j bobadilla a hernando cfj collaborative filtering for java knowledge based systems vol pp doi https doiorgjknosys f ortega j mayor d lópezfernández r lara cabrera cfj adapting collaborative filtering for java to new challenges of collaborative filtering based recommender systems knowledgebased systems vol p jorge dueñaslerín jorge dueñaslerín received the bs in computer science from the universidad politécnica de madrid he received the ms degree in highschool vocational training and languages teacher from the universidad nacional de educación a distancia he is currently a phd student as part of the knoledge discovery and information systems knodis research group jesús bobadilla jesús bobadilla received the bs and the phd degrees in computer science from the universidad politécnica de madrid and the universidad carlos iii currently he is a full professor with the department of applied intelligent systems universidad politécnica de madrid he is a habitual author of programming languages books working with mcgrawhill rama and alfa omega publishers his research interests include information retrieval recommender systems and speech processing he oversees the filmaffinitycom research teamworking on the collaborative filtering kernel of the web site he has been a researcher into the international computer science institute at berkeley university and into the sheffield university article in press fernando ortega fernando ortega was born in madrid spain in he received the bs degree in software engineering the ms degree in artificial intelligence and the phd degree in computer sciences from theuniversidad politécnica de madrid in and respectively he is currently associate professor in the universidad politécnica de madrid he is author of more than research papers in most prestigious international journals he leads several national projects to include machine learning algorithms into the society his research interests include machine learning data analysis and artificial intelligence he is the head researcher of the knoledge discovery and information systems knodis research group abraham gutiérrez abraham gutiérrez received the bs and the phd degrees in computer science from the universidad politécnica de madrid currently he is currently an associate professor with the department of information systems universidad politécnica de madrid he is the author of search papers in most prestigious international journals he is a habitual author of programming languages books working with mcgrawhill rama and alfa omega publishers his research interests include psystems machine learning data analysis and artificial intelligence he is in charge of this group innovation issues including the commercial projects view publication stats,"[0.018535353243350983, -0.026471519842743874, -0.01840636506676674, 0.0076896026730537415, 0.015374019742012024, 0.013372259214520454, 0.05974413827061653, 0.02491617761552334, -0.007022180128842592, 0.009209416806697845, -0.07646210491657257, 0.022284282371401787, -0.014550437219440937, 0.05322219431400299, -0.03353678435087204, -0.04912015423178673, -0.0004141819663345814, 0.0007363029289990664, -0.048552803695201874, 0.002331054536625743, 0.007865730673074722, 0.00019953868468292058, 0.033497028052806854, 0.02871844917535782, 0.023646919056773186, 0.014745522290468216, 0.013309216126799583, -0.015652071684598923, -0.010650009848177433, -0.006083600223064423, -0.036842405796051025, 0.014419428072869778, -0.009496073238551617, -0.02694115787744522, 2.1988355456414865e-06, -0.0031330015044659376, -0.0065012359991669655, -0.06217307969927788, 0.058304786682128906, 0.02449486218392849, 0.03225703537464142, 0.08241145312786102, 0.03728567063808441, 0.01950129307806492, -0.0523882694542408, 0.025025758892297745, -0.011830326169729233, 0.020651819184422493, -0.006818441674113274, -0.04960156977176666, 0.000992609653621912, 0.02818518877029419, -0.010820510797202587, 0.006490846164524555, 0.012295009568333626, -0.011902171187102795, 0.01134512759745121, -0.01269971951842308, 0.004566511604934931, 0.002981963800266385, -0.026815006509423256, -0.03680422529578209, -0.015097332186996937, -0.006161626428365707, 0.07214768975973129, 0.02278660424053669, 0.0037522169295698404, -0.05113255977630615, 0.007418670225888491, 0.07898925244808197, 0.047209788113832474, 0.033935364335775375, -0.004740070551633835, 0.010339350439608097, 0.012415974400937557, 0.03990812599658966, -0.028366871178150177, 9.771503391675651e-05, 0.011384434066712856, 0.01782401278614998, -0.008167953230440617, 0.05282008647918701, 0.027025792747735977, 0.01565956138074398, 0.05121920630335808, 0.10949092358350754, 0.030351068824529648, 0.0016990576405078173, -0.006516708061099052, -0.018324946984648705, 0.0600711889564991, -0.044406965374946594, 0.06689590215682983, -0.014536382630467415, -0.03319085016846657, -0.03320379555225372, 0.004904111847281456, 0.02985210344195366, 0.007026299834251404, -0.027284419164061546, 0.053298771381378174, 0.002103428589180112, 0.010496730916202068, 0.030235350131988525, 0.026268526911735535, 0.011344360187649727, -0.0013785994378849864, 0.010398956015706062, -0.019497942179441452, 0.023496830835938454, -0.020364796742796898, 0.02064436674118042, 0.05005199462175369, 0.07344411313533783, -0.02837853506207466, -0.02619190886616707, -0.053546372801065445, 0.03978719189763069, -0.03474266454577446, 0.020810740068554878, 0.008553193882107735, 0.07523825764656067, 0.03819696605205536, 0.03766447678208351, -0.0797797441482544, -0.01072643417865038, -0.07078717648983002, 0.032641541212797165, 0.0030769207514822483, 0.03351128101348877, 0.07207522541284561, -0.002965233288705349, 0.008501560427248478, -0.006678829435259104, 0.034570638090372086, 0.003219526493921876, 0.026140866801142693, -0.03701069578528404, 0.016515910625457764, -0.009113043546676636, 0.0025377979036420584, -0.023074110969901085, -0.0748094767332077, -0.031804218888282776, 0.02480870485305786, 0.02233758568763733, 0.016594266518950462, 0.021980363875627518, 0.0021846869494765997, -0.015955258160829544, -0.022279884666204453, 0.04374723136425018, 0.030400041490793228, -0.018344296142458916, 0.03217668458819389, 0.009971018880605698, -0.00604505417868495, -0.03146617114543915, -0.008940286003053188, 0.07347080111503601, 0.06914514303207397, 0.01585737243294716, 0.00019524891104083508, -0.015371120534837246, -0.0686878189444542, 0.001127910683862865, -0.002861782442778349, 0.03253724426031113, -0.05254482477903366, 0.01883641630411148, -0.016162337735295296, 0.04791773110628128, -0.06264741718769073, 0.014136300422251225, 0.023824289441108704, 0.00026351679116487503, 0.00815137755125761, 0.06848788261413574, 0.045758556574583054, -0.0060393488965928555, -0.011343799531459808, 0.0045248642563819885, 0.04286254197359085, 0.07984039932489395, 0.024930158630013466, -0.04958090931177139, 0.02772345021367073, 0.048152856528759, -0.02775467373430729, -0.05254295468330383, 0.05741901695728302, -0.02734316885471344, 0.048278044909238815, -0.01791403815150261, 0.03349679708480835, -0.020106174051761627, -0.034230660647153854, -0.0637400671839714, 0.02048499509692192, -0.057871825993061066, 0.006556378211826086, -0.007372982334345579, 0.06817327439785004, 0.07933690398931503, 0.045073214918375015, 0.0009091687388718128, 0.02794109843671322, -0.024703988805413246, -0.01843852363526821, -0.1287277638912201, 0.019979208707809448, -0.02765672840178013, -0.04805508255958557, -0.030313778668642044, -0.03725917637348175, 0.01971343718469143, 0.0005901303375139832, 0.014414072968065739, -0.05661633610725403, 0.02541414648294449, 0.01260632835328579, 0.049531616270542145, 0.024639764800667763, -0.0206916406750679, 0.04001842066645622, 0.03621528297662735, 0.061912599951028824, 0.008788411505520344, 0.052323512732982635, 0.05306963622570038, 0.05027495697140694, -0.010081280954182148, 0.03254127874970436, 0.0020957677625119686, 0.012869494967162609, -0.06132413446903229, -0.008227053098380566, 0.04013753682374954, 0.04798158258199692, -0.05579543858766556, 0.06037566065788269, 0.08872483670711517, 0.02411084622144699, -0.022595355287194252, 0.04144570603966713, 0.0356178916990757, -0.056153520941734314, 0.010046995244920254, 0.03249423950910568, -0.022748595103621483, -0.0013094816822558641, 2.3733500711387023e-05, 0.02065179869532585, -0.014918616972863674, 0.003038024064153433, -0.012216703034937382, -0.052642930299043655, 0.021113989874720573, -0.053617991507053375, -0.006613899488002062, 0.01756560616195202, 0.016822736710309982, -0.0078453803434968, -0.006089098285883665, -0.04048765078186989, -0.018321938812732697, 0.012995902448892593, 0.0023895457852631807, 0.003500062972307205, 0.03657348453998566, -0.02315029688179493, 9.852767834672704e-05, -0.013177824206650257, 0.020317308604717255, 0.00685208011418581, -0.027153154835104942, 0.03845052048563957, -0.03905706852674484, -0.011902033351361752, -0.0180851761251688, 0.029092779383063316, -0.013178319670259953, -0.02936616912484169, -0.04452770575881004, -0.010823617689311504, 0.025813529267907143, 0.0010303524322807789, -0.023365655913949013, -0.01778894104063511, -0.02749965712428093, -0.05106547474861145, -0.06432896107435226, -0.0210135318338871, 0.02625887468457222, 0.005416756495833397, 0.024071089923381805, 0.004351350944489241, -0.029313312843441963, 0.002863845555111766, 0.01513737253844738, 0.09904488921165466, 0.0217128898948431, -0.013347030617296696, -0.016414694488048553, -0.009757688269019127, 0.032514188438653946, 0.009676076471805573, -0.060415275394916534, -0.0101317772641778, -0.06431468576192856, 0.0074924686923623085, 0.004161636810749769, -0.02465573325753212, 0.02584466151893139, -0.015245086513459682, 0.011851981282234192, -0.05365277826786041, -0.08086095750331879, -0.0305609293282032, 0.05022135376930237, 0.043701376765966415, 0.013870847411453724, 0.0377812460064888, 0.01561739481985569, 0.01136357057839632, -0.026279471814632416, -0.044425081461668015, -0.015492613427340984, -0.060532547533512115, -0.034564100205898285, -0.0025205693673342466, -0.07358019798994064, 0.028248632326722145, -0.005210994742810726, -0.005836229771375656, 0.05949898436665535, -0.047599878162145615, -0.003526626853272319, 0.047273918986320496, -0.09932029247283936, 0.018109431490302086, -0.02557888813316822, 0.003681063186377287, -0.02886798605322838, -0.0069981953129172325, -0.027526119723916054, 0.03962067514657974, 0.011650379747152328, 0.007003037724643946, -0.02050551027059555, 0.006628717761486769, 0.01660335250198841, -0.009111244231462479, -0.005830715410411358, 0.03555890917778015, 0.039782389998435974, 0.016766035929322243, -0.04792584106326103, 0.012423891574144363, 0.020192453637719154, 0.024024201557040215, 0.028469733893871307, -0.010703463107347488, -0.09082193672657013, -0.06695672124624252, 0.013066945597529411, 0.03293292596936226, 0.008964103646576405, -0.03497608006000519, 0.05464988574385643, -0.04649041220545769, 0.016724340617656708, 0.06761012971401215, 0.002162638818845153, 0.04559900239109993, -0.14267201721668243, -0.01531076431274414, -0.014339550398290157, 0.0006210305728018284, 0.041972752660512924, 0.029994558542966843, -0.002282888861373067, 0.053553029894828796, 0.025878241285681725, 0.03753409534692764, 0.038185905665159225, -0.027962258085608482, 0.018901009112596512, -0.02107383869588375, 0.08056255429983139, 0.002237140666693449, 0.04442295804619789, 0.0031947086099535227, -0.04863988235592842, -0.01723167859017849, -0.03450700268149376, -0.017485929653048515, 0.031029634177684784, 0.0020803995430469513, 0.04465595632791519, 0.014947746880352497, -0.02727852202951908, -0.0035968422889709473, 0.013344930484890938, -0.028463825583457947, 0.02596263214945793, -0.01725728251039982, 0.012878373265266418, -0.028344284743070602, -0.06344783306121826, -0.047850098460912704, -0.005226618610322475, -0.0067124501802027225, -0.01080038771033287, 0.03916101157665253, -0.012918964959681034, 0.03129683434963226, -0.06450904905796051, 0.03378619998693466, 0.011264569126069546, 0.005282722879201174, 0.022879986092448235, 0.057409338653087616, -0.008638393133878708, -0.025275498628616333, -0.037361957132816315, 0.0013391189277172089, -0.016743892803788185, 0.015599271282553673, 0.024354781955480576, -0.045159030705690384, 0.030663538724184036, 0.008891702629625797, -0.006252974271774292, 0.030351072549819946, -0.016787942498922348, -0.005016667768359184, 0.013370162807404995, -0.020546935498714447, -0.04282725602388382, -0.010230962187051773, -0.0015399415278807282, 0.021115951240062714, -0.024324921891093254, 0.03578581660985947, -0.06429938226938248, -0.04173416644334793, 0.03730819374322891, -0.025037594139575958, 0.0751936286687851, 0.027383478358387947, -0.019028011709451675, 0.025852466002106667, -0.01572849042713642, -0.051661018282175064, 0.00487190717831254, -0.0746099129319191, 0.007125176023691893, 0.027706259861588478, -0.03742565959692001, 0.06192740425467491, 0.01051616296172142, -0.016074545681476593, -0.029368925839662552, -0.07640975713729858, 0.018111152574419975, -0.037499841302633286, -0.031169915571808815, -0.022422168403863907, -0.02427550218999386, 0.03927432745695114, -0.014895274303853512, 0.01388506032526493, -0.03612355515360832, -0.010444913059473038, -0.037390850484371185, -0.01499516423791647, -0.05237523838877678, 0.005500949453562498, -0.0029467549175024033, -0.011369436047971249, 0.01728958636522293, -0.015292071737349033, 0.022295722737908363, -0.011237022466957569, 0.0013343379832804203, -0.02442575991153717, -0.0281441081315279, -0.0314226895570755, -0.013232783414423466, 0.08311590552330017, -0.006342119071632624, -0.026572853326797485, -0.04788599908351898, -0.018492503091692924, -0.005975979845970869, -0.0174223855137825, 0.024525504559278488, 0.01862317882478237, -0.00541001558303833, -0.004808382131159306, 0.05310981348156929, 0.028471477329730988, -0.029838427901268005, 0.0059631941840052605, 0.005768238566815853, -0.014378789812326431, 0.008224890567362309, -0.0336766317486763, -0.03431349992752075, -0.026950769126415253, 0.05165692791342735, 0.04995886981487274, 8.278461609734222e-05, -0.00875730812549591, 0.026140790432691574, 0.007503984030336142, -0.0003920256858691573, -0.011652857065200806, 0.006467622239142656, -0.01899142563343048, -0.012544557452201843, -0.011149713769555092, -0.04676511511206627, -0.02348664030432701, 0.016087498515844345, 0.015423295088112354, -0.0038374934811145067, 0.061815954744815826, 0.06262489408254623, -0.002540994668379426, -0.0830499604344368, -0.02504061348736286, -0.06652980297803879, -0.02820397913455963, 0.05740897357463837, -0.01064254716038704, 0.09439725428819656, -0.0491342768073082, -0.036457084119319916, -0.021649567410349846, -0.041909150779247284, -0.00010150353045901284, -0.039456501603126526, 0.04983505979180336, -0.022049685940146446, 0.005678690504282713, 0.026549898087978363, -0.006941458210349083, -0.005829669069498777, -0.03825521841645241, -0.04646610841155052, -0.02075660414993763, -0.004624600522220135, -0.06128749996423721, -6.385917141880233e-33, 0.042859502136707306, -0.01744399033486843, -0.004195717163383961, 0.051214464008808136, 0.02316950634121895, -0.024962877854704857, 0.03000783734023571, 0.02402941882610321, 0.03800190985202789, -0.006086637731641531, -0.016609879210591316, -0.020967409014701843, -0.003292249981313944, -0.020559443160891533, 0.031716566532850266, -0.004163435660302639, 0.016191741451621056, -0.0023989856708794832, -0.0037904975470155478, 0.006510487757623196, 0.014395251870155334, 0.044552478939294815, -0.004198757000267506, -0.09284649789333344, -0.00039758693310432136, -0.02501581981778145, -0.04039474204182625, -0.06034882739186287, 0.0169602632522583, 0.06190938875079155, -0.016044961288571358, -0.006075485609471798, 0.0037753351498395205, -0.036833882331848145, -0.0020683377515524626, -0.02922506257891655, -0.06539415568113327, -0.005989609751850367, 0.024792077019810677, 0.014712853357195854, -0.05398711934685707, -0.03820963203907013, 0.0004726761544588953, 0.042661797255277634, -0.04261283203959465, -0.00512205483391881, 0.04301523417234421, -0.006415143609046936, -0.08632445335388184, -0.01073669083416462, 0.05851474031805992, -0.005313335917890072, -0.015774549916386604, 0.02879098616540432, 0.03507040813565254, 0.05249195918440819, -0.06585638225078583, 0.032352037727832794, -0.06102529913187027, 0.036641377955675125, -0.026073724031448364, -0.027128715068101883, 0.026328543201088905, -0.041090190410614014, -0.036578431725502014, 0.014284270815551281, 0.0026422764640301466, -0.041119955480098724, -0.009821812622249126, -0.022809602320194244, -0.046662963926792145, 0.08044666051864624, 0.019058413803577423, 0.06756751239299774, 0.003962325863540173, -0.006966607179492712, -0.01819593273103237, 0.06445086002349854, -0.026967745274305344, -0.02523484267294407, 0.055082984268665314, 0.031532563269138336, -0.015220589935779572, -0.011542556807398796, 0.018369121477007866, -0.011557163670659065, -0.06594603508710861, -0.08216733485460281, -0.0010747142368927598, 0.027694320306181908, -0.024515604600310326, -0.004095365293323994, -0.02807752974331379, -0.060030497610569, -0.021435337141156197, -0.012934798374772072, -0.04650431126356125, 0.008180835284292698, 0.05424029007554054, -0.0434388667345047, -0.04718692973256111, 0.04589391127228737, -0.020158424973487854, -0.07017332315444946, -0.041707593947649, -0.016584495082497597, 0.02265007235109806, -0.01127370074391365, -0.0009661599760875106, -0.004428255371749401, 0.07198317348957062, -0.08109958469867706, 0.03760126233100891, -0.00855832640081644, -0.0118580162525177, 0.02238938957452774, -0.03988625109195709, 0.06234085559844971, 0.014659719541668892, 0.09562703967094421, -0.000796182663179934, -0.08923308551311493, 0.000463625299744308, -0.010554308071732521, -0.018457161262631416, -0.03176676109433174, -0.04557280242443085, 0.004884841851890087, 0.07102704048156738, -0.002560514723882079, -0.029377151280641556, -0.04594510793685913, 2.849088787115761e-07, 0.012975550256669521, 0.016956493258476257, -0.075731061398983, -0.06462867558002472, 0.023805204778909683, -0.002272817539051175, 0.006246739067137241, 0.024496030062437057, 0.03217589110136032, 0.037371620535850525, 0.057249024510383606, -0.03185924142599106, -0.009981772862374783, 0.05043136328458786, -0.004811907187104225, -0.02866782620549202, -0.0512680858373642, 0.017796527594327927, -0.06305848807096481, -0.024801034480333328, -0.00914187915623188, 0.07513280212879181, 0.07503649592399597, 0.008573737926781178, -0.025911081582307816, 0.02790537104010582, 0.01999886892735958, -0.06512872874736786, -0.03390708193182945, -0.0581778958439827, 0.06889404356479645, -0.01545734703540802, -0.03303715959191322, 0.010786418803036213, -0.010794946923851967, 0.009542909450829029, 0.0213227029889822, -0.018639041110873222, -0.009520582854747772, -0.013592187315225601, 0.047452569007873535, 0.00854644738137722, 0.027010073885321617, -0.08210552483797073, 0.06475094705820084, 0.06487416476011276, -0.017461735755205154, 0.03934489190578461, -0.06642584502696991, 0.03873230889439583, 0.047314248979091644, 0.014793244190514088, 0.018407870084047318, -0.0020039875525981188, -0.012844942510128021, 0.0037498874589800835, -0.003598002949729562, -0.026954185217618942, 0.03753145411610603, -0.019908880814909935, -0.020449941977858543, -0.035962045192718506, -0.04334546998143196, -0.013826866634190083, 0.0045209783129394054, 0.028185170143842697, 0.030526254326105118, 2.2262361494211942e-34, 0.004767999518662691, 0.038703564554452896, 0.011566775850951672, -0.03253253549337387, 0.019187921658158302, -0.04371068626642227, -0.05783762037754059, 0.004949613939970732, 0.05303517356514931, -0.018234549090266228, 0.009410412982106209]",4,Matrix Factorization Models
Recommender systems survey.pdf,recommender systems survey j bobadilla f ortega a hernando a gutiérrez universidad politécnica de madrid ctra de valencia km madrid spain a r t i c l e i n f o article history received october received in revised form march accepted march available online april keywords recommender systems collaborative ﬁltering similarity measures evaluation metrics prediction recommendation hybrid social internet of things coldstart a b s t r a c t recommender systems have developed in parallel with the web they were initially based on demo graphic contentbased and collaborative ﬁltering currently these systems are incorporating social infor mation in the future they will use implicit local and personal information from the internet of things this article provides an overview of recommender systems as well as collaborative ﬁltering methods and algorithms it also explains their evolution provides an original classiﬁcation for these systems iden tiﬁes areas of future implementation and develops certain areas selected for past present or future importance elsevier bv all rights reserved introduction recommender systems rss collect information on the prefer ences of its users for a set of items eg movies songs books jokes gadgets applications websites travel destinations and elearning material the information can be acquired explicitly typically by collecting users ratings or implicitly typically by monitoring users behavior such as songs heard applications downloaded web sites visited and books read rs may use demo graphic features of users like age nationality gender social information like followers followed twits and posts is commonly used in web there is a growing tend towards the use of infor mation from internet of things eg gps locations rfid realtime health signals rs make use of different sources of information for providing users with predictions and recommendations of items they try to balance factors like accuracy novelty dispersity and stability in the recommendations collaborative filtering cf methods play an important role in the recommendation although they are often used along with other ﬁlterning techniques like contentbased knowledgebased or social ones cf is based on the way in which humans have made decisions throughout history besides on our own experiences we also base our decisions on the experiences and knowledge that reach each of us from a relatively large group of acquaintances recently rs implementation in the internet has increased which has facilitated its use in diverse areas the most com mon research papers are focused on movie recommendation stud ies however a great volume of literature for rs is centered on different topics such as music televi sion books documents e learning ecommerce applications in markets and web search among others the kinds of ﬁltering most used at the beginning of the rs col laborative contentbased and demographic were described in breese et al evaluated the predictive accuracy of differ ent algorithms for cf later the classical paper describes the base for evaluating the collaborative filtering rs the evolution of rs has shown the importance of hybrid tech niques of rs which merge different techniques in order to get the advantages of each of them a survey focused on the hybrid rs has been presented in however it does not deal with the role of socialﬁltering a technique which has become more popular in the recent years through social networks the neighborhoodbased cf has been the recommendation method most popular at the beginning of the rs herlocker et al provides a set of guidelines for designing neighborhoodbased prediction systems adomavicius and tuzhilin present an over view on the rs ﬁeld standing out the most complex areas on which see front matter elsevier bv all rights reserved httpdxdoiorgjknosys corresponding author tel fax email address jesusbobadillaupmes j bobadilla knowledgebased systems contents lists available at sciverse sciencedirect knowledgebased systems journal homepage wwwelseviercomlocateknosys researchers in rs should focus in the next generation of rs lim ited content analysis and overspecialization in contentbased methods coldstart and sparsity in cf methods modelbased tech niques nonintrusiveness ﬂexibility realtime customization etc while researchers have been developing rs different survey papers have been published summarizing the most important is sues in this ﬁeld in view of the impossibility of showing every de tail of all these techniques in just a paper this publication selects those issues the authors have felt most suitable to understand the evolution of rs while the existing surveys focus on the most relevant methods and algorithms of the rs ﬁeld our survey instead tries to enhance the evolution of the rs from a ﬁrst phase based on the tradi tional web to the present second phase based on social web which is presently progressing to a third phase internet of things with the purpose of being useful to the new readers of rs ﬁeld we have included in this survey some traditional topics rs foundations knearest neighbors algorithm coldstart issues similarity measures and evaluation of rs the rest of the paper deals with novel topics that existing surveys do not consider through this survey advanced readers in rs will study in depth concepts classiﬁcations and approaches related to social informa tion social ﬁltering followers followed trust reputation credi bility contentbased ﬁltering of social data social tagging and taxonomies recommending to groups of users and explaining recommendations readers interested in brand new and future applications will ﬁnd this survey useful since it informs about the most recent works in locationaware rs trends and bioin spired approaches they will also discover some important issues such as privacy security pp information and internet of things use rfid data health parameters surveillance data teleopera tion telepresence etc according to the idea that rs tend to make use of different sources of information collaborative social demographic content knowledgebased geographic sensors tags implicit and explicit data acquisition etc this survey emphasizes hybrid architectures based on making recommendations through different known tech nologies each one designed on behalf of a speciﬁc source of information much of the quality of a survey can be measured by an appro priate choice of its references this survey contains references systematically obtained which have been selected taking into ac count factors like the number of recent citations and the impor tance of the journal in which the paper has been published the remainder of this article is structured as follows in sec tion we explain concisely the methodology used to select the most signiﬁcative papers on the rs ﬁeld section describes the rs foundations methods algorithms and models used for provid ing recommendations based from the information of the tradi tional web ratings demographic data and item data cf demographic ﬁltering contentbased ﬁltering and hybrid ﬁltering section describes measures for evaluating the quality of the rs predictions and recommendations section shows the use of so cial information from web for making recomendations through concepts like trust reputation and credibility we will also de scribe techniques based on contentbased for social information eg tags and posts section focusses on two important areas although not very well studied yet recommendation to group of users and explanation of recommendations section focusses on recommender system trends covering bioinspired approaches and web information ﬁltering such as locationaware rs sec tion explains related works and the original contributions of this survey the concluding section summarizes the rs history and focuses on the type of data used as well as the development of algorithms and evaluation measures the conclusions section also indicates seven new areas that we consider likely to be the focus of rs re search in the scientiﬁc community in the near future methodology an initial study was performed to determine the most represen tative topics and terms in the rs ﬁeld first rs papers were se lected from journals with a higher priority for current and for oftencited articles next we extracted from these papers the most signiﬁcant terms we gave the most emphasis to keywords less emphasis to titles and ﬁnally the least emphasis to abstracts we have overlooked common words like articles prepositions and generaluse words from the remaining pool we selected terms represented in the rs ﬁeld from a matrix of arti cles words wherein we stored the importance of each word from each article we generated a tree of relationships between the words fig depicts the most signiﬁcant section of the graph due to space constraints the entire tree is not shown but it is pro vided as additional material in fig additionaldatapng the short distances between words indicate the highest similarities warm colors indicate a greater reliability for the relationships the size of the nodes indicates the importance of the words as a function of the parameters nk nt na number of signiﬁcative words in the keywords title and abstract and nk w nt w na w number of times that the word w appears in the keywords title and abstract the equa tion used to determine the importance of each word w is as follows fw ¼ nk w nk þ nt w nt log na nt þ na w na na nt example we will consider a paper where nk keywords nt words in the title and na words of abstract length we will get the values of ffactorization and fmatrix where the word factorization appears once as a keyword once in the title and three times in the abstract the word matrix does not appear as a keyword but it is contained once in the title and twice in the abstract the importance of these words will be ffactorization ¼ þ log þ ¼ f matrix ¼ þ log þ ¼ the information depicted in fig is used to identify the most relevant aspects of rs they are represented by the most signiﬁcant words in the graph and the related terms the articles referenced herein were chosen based on the following criteria a the tran scendence of the subject according to the importance of the words in fig b its historical contribution a signiﬁcant fraction of the classic reference articles are included c the number of times the article is cited d articles published in journals with an impact factor were preferred over conferences and workshops and e re cent articles were preferred over articles published many years ago fig shows a temporal distribution for the referenced papers we use the clusters of words in fig to structure the explica tions of the survey for each concept explained we have ob tained their keywords and all the words related to them according to fig we have identiﬁed among the set of pa pers those which are more related to the set of words associated to the concept we have selected the subset of papers which deal with the concept giving priority to those with high values in crite ria like importance of the paper and the number of cites and we have tried to balance the number of times a paper is referenced in our survey aiming to reference most of the papers selected j bobadilla et al knowledgebased systems recommender systems foundations this section presents the most relevant concepts on which the traditional rs are based here we provide general descriptions on the classical taxonomies algorithms methods ﬁltering ap proaches databases etc besides we show a graphic depicting the traditional models of recommendations and their relations next we will describe the coldstart problem which will illustrate the difﬁculty of making collaborative recommendation when the rs contains a small amount of data next we will describe the knn algorithm the most used algorithm for implementing rs based on cf finally we will describe different proposed similarity measures for comparing users or items we will show graphics for measuring the quality of these similarity measures fundamentals the process for generating an rs recommendation is based on a combination of the following considerations the type of data available in its database eg ratings user reg istration information features and content for items that can be ranked social relationships among users and locationaware information the ﬁltering algorithm used eg demographic contentbased collaborative socialbased contextaware and hybrid the model chosen eg based on direct use of data memory based or a model generated using such data modelbased the employed techniques are also considered probabilistic approaches bayesian networks nearest neighbors algorithm bioinspired algorithms such as neural networks and genetic algorithms fuzzy models singular value decomposition tech niques to reduce sparsity levels etc sparsity level of the database and the desired scalability performance of the system time and memory consuming the objective sought is considered eg predictions and top n recommendations as well as the desired quality of the results eg novelty coverage and precision research in rs requires using a representative set of public dat abases to facilitate investigations on the techniques methods and algorithms developed by researchers in the ﬁeld through these databases the scientiﬁc community can replicate experiments to validate and improve their techniques table lists the current public databases referenced most often in the literature lastfm and delicious incorporate implicit ratings and social information their data were generated from the versions released in the hetrec data sets hosted by the grouplens research group the internal functions for rs are characterized by the ﬁltering algorithm the most widely used classiﬁcation divides the ﬁltering algorithms into a collaborative ﬁltering b demo graphic ﬁltering c contentbased ﬁltering and d hybrid ﬁltering fig words represented in the recommender systems research ﬁeld short distances indicate higher similarities and a warm color indicates greater reliability the size of the nodes is proportional to the importance of the words fig temporal distribution for the referenced papers j bobadilla et al knowledgebased systems contentbased ﬁltering makes recommendations based on user choices made in the past eg in a webbased ecom merce rs if the user purchased some ﬁction ﬁlms in the past the rs will probably recommend a recent ﬁction ﬁlm that he has not yet purchased on this website contentbased ﬁltering also gener ates recommendations using the content from objects intended for recommendation therefore certain content can be analyzed like text images and sound from this analysis a similarity can be established between objects as the basis for recommending items similar to items that a user has bought visited heard viewed and ranked positively demographic ﬁltering is justiﬁed on the principle that individuals with certain common personal attributes sex age country etc will also have common preferences collaborative filtering allows users to give rat ings about a set of elements eg videos songs ﬁlms etc in a cf based website in such a way that when enough information is stored on the system we can make recommendations to each user based on information provided by those users we consider to have the most in common with them cf is an interesting open research ﬁeld as noted earlier user ratings can also be table most often used memorybased recommender systems public databases without social information with social information hosted by the grouplens movielens m movielens m netﬂix jester eachmovie bookcrossing ml lastfm delicious ratings million million million million million million users items range implicit implicit tags na na na na na na tags assignment na na na na na na friends relations na na na na na na na items movies movies movies jokes movies books movies music urls fig traditional models of recommendations and their relationships j bobadilla et al knowledgebased systems implicitly acquired eg number of times a song is heard informa tion consulted and access to a resource the most widely used algorithm for collaborative ﬁltering is the k nearest neighbors knn in the user to user version knn executes the following three tasks to generate recommenda tions for an active user determine k users neighbors neighbor hood for the active user a implement an aggregation approach with the ratings for the neighborhood in items not rated by a and extract the predictions from in step then select the top n recommendations hybrid ﬁltering commonly uses a combination of cf with demographic ﬁltering or cf with contentbased ﬁltering to exploit merits of each one of these techniques hybrid ﬁltering is usually based on bioinspired or probabilistic methods such as genetic algorithms fuzzy genetic neural net works bayesian networks clustering and latent features a widely accepted taxonomy divides recommendation methods into memorybased and modelbased method categories memorybased methods memorybased methods can be deﬁned as methods that a act only on the matrix of user ratings for items and b use any rating generated before the refer ral process ie its results are always updated memorybased methods usually use similarity metrics to obtain the distance be tween two users or two items based on each of their ratios modelbased methods use rs information to create a model that generates the recommendations herein we consider a method modelbased if new information from any user outdates the model among the most widely used models we have bayesian classiﬁers neural networks fuzzy systems genetic algorithms latent features and matrix factorization among others to reduce the problems from high levels of sparsity in rs dat abases certain studies have used dimensionality reduction tech niques the reduction methods are based on matrix factorization matrix factorization is especially ade quate for processing large rs databases and providing scalable ap proaches the modelbased technique latent semantic index lsi and the reduction method singular value decomposition svd are typically combined svd methods provide good prediction results but are computationally very expensive they can only be deployed in static offline settings where the known preference information does not change with time rs can use clustering techniques to improve the prediction qual ity and reduce the coldstart problem when applied to hybrid ﬁl tering it is typical to form clusters of items in hybrid rs a different common approach uses clustering both for items and users biclustering rs comprising social infor mation have been clustered to improve the following areas tagging explicit social links and explicit trust information the graph in fig shows the most signiﬁcant traditional meth ods techniques and algorithms for the recommendation process as well as their relationships and groupings different sections of this paper provide more detail on the most important aspects involved in the recommendation process as may be seen in fig we can use some of the traditional ﬁl tering methods contentbased demographic and collaborative applied to databases modelbased technologies genetic algo rithms neural networks etc make use of this kind of information typical memorybased approaches are item to item user to user and hybrids of the two previous the main purpose of both mem orybased and modelbased approaches is to get the most accurate predictions in the tastes of users the accuracy of these predictions may be evaluated through the classical information retrieval mea sures like mae precision and recall researchers make use of these measures in order to improve the rs methods and technologies coldstart the coldstart problem occurs when it is not possible to make reliable recommendations due to an initial lack of ratings we can distinguish three kinds of coldstart problems new com munity new item and new user the last kind is the most important in rs that are already in operation the new community problem refers to the difﬁculty when starting up a rs in obtaining a sufﬁcient amount of data ratings for making reliable recommendations two common ways are used for tackling this problem to encourage users to make ratings through different means to take cfbased recom mendations when there are enough users and ratings the new item problem arises because the new items entered in rs do not usually have initial ratings and therefore they are not likely to be recommended in turn an item that is not rec ommended goes unnoticed by a large part of the community of users and as they are unaware of it they do not rate it this way we can enter a vicious circle in which a set of items of the rs are left out of the ratingsrecommendations process the new item problem has less of an impact on rs in which the items can be dis covered via other means eg movies than in rs where this is not the case ie ecommerce blogs photos videos etc a common solution to this problem is to have a set of motivated users who are responsible for rating each new item in the system the new user problem represents one of the great dif ﬁculties faced by the rs in operation since new users in the rs have not yet provided any rating in the rs they cannot receive any personalized recommendations based on memorybased cf when the users enter their ﬁrsts ratings they expect the rs to offer them personalized recommendations but the number of ratings introduced in the rs is usually not yet sufﬁcient to be able to make reliable cfbased recommendations and therefore new users may feel that the rs does not offer the service they expected and they may stop using it the common strategy to tackle the new user problem consists of turning to additional information to the set of ratings in order to be able to make recommendations based on the data available for each user the coldstart problem is often faced using hybrid approaches usually cfcontent based rs cfdemographic based rs cfsocial based rs leung et al propose a no vel contentbased hybrid approach that makes use of crosslevel association rules to integrate content information about domains items kim et al use collaborative tagging employed as an approach in order to grasp and ﬁlter users preferences for items and they explore the advantages of the collaborative tagging for data sparseness and coldstart users they collected the dataset by crawling the collaborative tagging delicious site weng et al combine the implicit relations between users items prefer ences and the additional taxonomic preferences to make better quality recommendations as well as alleviate the coldstart prob lem loh et al represent users proﬁles with information ex tracted from their scientiﬁc publications martinez et al present a hybrid rs which combines a cf algorithm with a knowl edgebased one chen and he propose a number of common terms term frequency ncttf cf algorithm based on demo graphic vector saranya and atsuhiro propose a hybrid rs that utilizes latent features extracted from items represented by a multiattributed record using a probabilistic model park et al propose a new approach they use ﬁlterbots and surrogate users that rate items based only on user or item attributes j bobadilla et al knowledgebased systems the k nearest neighbors recommendation algorithm the k nearest neighbors knn recommendation algorithm is the reference algorithm for the collaborative ﬁltering recommendation process its primary virtues are simplicity and reasonably accurate results its major pitfalls are low scalability and vulnerability to sparsity in the rs databases this section provides a general expla nation of this algorithm function cf based on the knn algorithm is conceptually simple with a straightforward implementation it also generally produces good quality predictions and recommendations however due to the high level of sparsity in rs databases similarity measures often encounter processing problems typically from insufﬁcient mutual ratings for a comparison of users and items and cold start situations users and items with low number of rankings another major problem for the knn algorithm is its low scalabil ity as the databases such as netﬂix increase in size hun dreds of thousands of users tens of thousands of items and hundreds of millions of rankings the process for generating a neighborhood for an active user becomes too slow the similarity measure must be processed as often as new users are registered in the database the item to item version of the knn algorithm sig niﬁcantly reduces the scalability problem to this end neigh bors are calculated for each item their top n similarity values are stored and for a period of time predictions and recommendations are generated using the stored information although the stored information does not include the ratings from previous process ingstorage outdated information for items is less sensitive than for the users a recurrent theme in cf research is generating metrics to calcu late with accuracy and precision the existing similarity for the users or items traditionally a series of statistical metrics have been used such as the pearson correlation cosine constraint pearson correlation and mean squared differences recently metrics have been designed to ﬁt the constraints and peculiarities of rs the relevance signiﬁcance concept was introduced to af ford more importance to more relevant users and items additionally a group of metrics was speciﬁcally designed to ade quately function in coldstart situations the knn algorithm is based on similarity measures next sub section provides further details on the current rs similarity mea sures the similarity approaches typically compute the similarity between two users x and y user to user based on both users item ratings the item to item knn version computes the similarity be tween two items i and j a formal approach of the knn algorithm may be found in in this section we will provide an illustrative example of this algo rithm the method for making recommendations is based on the following three steps a using the selected similarity measure we produce the set of k neighbors for the active user a the k neighbors for a are the nearest k similar users to u b once the set of k users neighbors similar to active a has been calculated in order to obtain the prediction of item i on user a one of the following aggregation approaches is often used the average the weighted sum and the adjusted weighted aggregation deviationfrommean c to obtain the topn recommendations we choose the n items which provide most satisfaction to the active user according to our predictions fig shows a case study using the user to user knn algorithm mechanism in the item to item version of the knn algorithm the following three tasks are executed determine q items neigh bors for each item in the database for each item i not ranked by the active user a calculate its prediction based on the ratings of a from the q neighbors of i and select the top n recommen dations for the active user typically the n major predictions from a step can be executed periodically which facilitates an accel erated recommendation with regard to the user to user version the item to item and user to user versions of the knn algorithm can be combined to take advantage of the positive aspects from each approach these approaches are typically fused by pro cessing the similarity between objects similarity measures a metric or a similarity measure sm determines the similarity between pairs of users user to user cf or the similarity between pairs of items item to item cf for this purpose we compare the ratings of all the items rated by two users user to user or the rat ings of all users who have rated two items item to item the knn algorithm is based essentially on the use of traditional similarity metrics of statistical origin these metrics require as the only source of information the set of votes made by the users on the items memorybased cf among the most commonly used traditional metrics we have pearson correlation corr cosine cos adjusted cosine acos constrained correlation ccorr mean squared differences msd and euclidean euc we will describe and compare a representative group of sm used in the knn algorithm the sm discussed include the following variations a coldstart and general cases b based or not based on models and c using trust information or only ratings table shows a classiﬁcation of the memorybased cf sm which will be tested in this section a new metric jmsd has recently been published which be sides using the numerical information from the ratings via mean squared differences also uses the nonnumerical information pro vided by the arrangement of these via jaccard ortega et al use pareto dominance to perform a preﬁltering process eliminating less representative users from the kneighbur selection process while retaining the most promising ones a specialization of the memorybased cf sm which appeared recently uses the information contained in the votes of all users instead of restricting it to the ratings of the two users com pared user to user or the two items compared item to item we will call this sm sing singularities the possibility exists to create a model modelbased cf from the full set of users ratings in order to later determine the similar ity between pairs of users or pairs of items based on the model cre ated the potential advantages of this focus are an increase in the accuracy obtained in the performance time consuming achieved or in both the drawback is that the model must be regularly up dated in order to consider the most recently entered set of ratings fig user to user knn algorithm example k similarity measure mean squared differences aggregation approach average j bobadilla et al knowledgebased systems bobadilla et al provides a metric based on a model generated using genetic algorithms we will call this sm gen geneticbased as a result of the increase in web websites on the internet a set of metrics has appeared which use the new social information available friends followers followeds etc most of these sm are grouped in papers related to trust reputation and credibility although this situation is also produced in other ﬁelds these metrics could not be considered strictly mem orybased cf as they use additional information which not all rs have in this sense each sm proposed is tailored to a speciﬁc rs or at most to a very small set of rs which share the same structure in their social information there are sm which aim to extract information re lated to trust and reputation by only using the users set of ratings memorybased cf the advantage is that their use can be general ized to all cf rs the drawback is that the social information ex tracted is really poor we will call trust the sm proponed in jeong et al currently two new interesting sm get more cov erage and accuracy fig shows the results from several evaluation measures gen erated by applying the sm discussed in this section the results show that the rstailored sm are superior compared with the tra ditional sm from statistics processing for the memorybased infor mation and results from fig follow the framework schematic published previously there are so far research papers dealing with the coldstart prob lem through the users ratings information ahn presents a heu ristic sm named pip that outperforms the traditional statistical sm table tested collaborative ﬁltering similarity measures not based on models modelbased no trust extraction trust extraction traditional only the ratings of both users or both items not tailored to coldstart users jmsd corr ccorr cos acos msd euc gen tailored to coldstart users pip uerror ncs extended to all the ratings sing trust fig evaluation measures results obtained from current similarities measures movielens database a prediction results b recommendation results c novelty results and d trust results j bobadilla et al knowledgebased systems pearson correlation cosine etc heungnam et al proposes a method uerror that predicts ﬁrst actual ratings and subsequently identiﬁes prediction errors for each user taking into account this er ror information some speciﬁc errorreﬂected models are de signed bobadilla et al presents a metric based on neural learning modelbased cf and adapted for new user coldstart situ ations called ncs fig shows results from several evaluation measures gener ated by applying the coldstart sm presented in this section these results show that the rstailored sm are superior compared with the traditional sm from statistics since the database movielens does not take into account coldstart users we have removed rat ings of this database in order to achieve coldstart users indeed we have removed randomly between and ratings of those users who have rated between and items in this way we will regard those users who now result to rate between and items as coldstart users evaluation of recommender systems results since rs research began evaluation of predictions and recom mendations has become important research in the rs ﬁeld requires quality measures and evaluation metrics to know the quality of the techniques methods and algorithms for predic tions and recommendations evaluation metrics and evalua tion frameworks facilitate comparisons of several solutions for the same problem and selection from different promising lines of research that generate better results because of evaluation measures rs recommendations have gradually been tested and improved a representative set of existing evaluation measures has standard formulations and a group of open rs public databases has been generated these two advances have facilitated quality comparisons for new proposed recommendation methods and previously published methods thus rs methods and algorithms research has progressed continuously the most commonly used quality measures are the following prediction evaluations evaluations for recommen dation as sets and evaluations for recommendations as ranked lists fig shows results from applying several evaluation mea sures to a set of representative similarity measures evaluation metrics can be classiﬁed as a predic tion metrics such as the accuracy ones mean absolute error mae root of mean square error rmse normalized mean average error nmae and the coverage b set recommendation metrics such as precision recall and receiver operating characteristic roc c rank recommendation metrics such as the halflife and the discounted cumulative gain and d diversity met rics such as the diversity and the novelty of the recommended items the validation process is performed by employing the most common cross validation techniques random subsam pling and kfold cross validation for coldstart situations due to the limited number of users or items votes involved the usual method chosen to carry out the experiments is leaveone out cross validation hernández and gaudioso propose an evaluation process based on the distinction between interactive and noninteractive fig evaluation results obtained from current coldstart similarities measures a prediction results b recommendation results c novelty results and d trust results j bobadilla et al knowledgebased systems subsystems general publications and reviews also exist which in clude the most commonly accepted evaluation measures mean absolute error coverage precision recall and derivatives of these mean squared error normalized mean absolute error roc and fallout goldberg et al focuses on the aspects not related to the eval uation breese et al compare the predictive accuracy of vari ous methods in a set of representative problem domains the majority of articles discuss attempted improvements to the accuracy of rs results rmse mae etc it is also common to at tempt an improvement in recommendations precision recall roc etc however additional objectives should be considered for generating greater user satisfaction such as topic diversi ﬁcation and coverage serendipity currently the ﬁeld has a growing interest in generating algo rithms with diverse and innovative recommendations even at the expense of accuracy and precision to evaluate these aspects various metrics have been proposed to measure recommendation novelty and diversity the frameworks aid in deﬁning and standardizing the methods and algorithms employed by rs as well as the mechanisms to eval uate the quality of the results among the most signiﬁcant papers that propose cf frameworks are herlocker et al which evaluates the following similarity weight signiﬁcance weighting variance weighting selecting neighborhood and rating normaliza tion hernández and gaudioso proposes a framework in which any rs is formed by two different subsystems one of them to guide the user and the other to provide usefulinteresting items koutrika et al is a framework which introduces levels of abstraction in cf process making the modiﬁcations in the rs more ﬂexible antunes et al presents an evaluation framework assuming that evaluation is an evolving process during the system lifecicle the majority of rs evaluation frameworks proposed until now present two deﬁciencies the ﬁrst of these is the lack of formal ization although the evaluation metrics are well deﬁned there are a variety of details in the implementation of the methods which in the event they are not speciﬁed can lead to the generation of different results in similar experiments the second deﬁciency is the absence of standardization of the evalu ation measures in aspects such as novelty and trust of the recommendations bobadilla et al provides a complete series of mathematical formalizations based on sets theory authors provide a set of eval uation measures which include the quality analysis of the follow ing aspects predictions recommendations novelty and trust presented next is a representative selection of the rs evaluation quality measures most often used in the bibliography quality of the predictions mean absolute error accuracy and coverage in order to measure the accuracy of the results of an rs it is usual to use the calculation of some of the most common predic tion error metrics amongst which the mean absolute error mae and its related metrics mean squared error root mean squared error and normalized mean absolute error stand out we deﬁne u as the set of the rs users i as the set of the rs items rui the rating of user u on item i the lack of rating rui means user u has not rated item i pui the prediction of item i on user u let ou i ijpui rui set of items rated by user u hav ing prediction values we deﬁne the mae and rmse of the system as the average of the users mae we remark that the absolute dif ference between prediction and real value jpui ruij informs about the error in the prediction mae ¼ u x uu ou x iou jpui ruij ðþ rmse ¼ u x uu ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ ou x iou ðpui ruiþ s ðþ the coverage could be deﬁned as the capacity of predicting from a metric applied to a speciﬁc rs in short it calculates the percent age of situations in which at least one kneighbor of each active user can rate an item that has not been rated yet by that active user we deﬁned kui as the set of neighbors of u which have rated the item i we deﬁne the coverage of the system as the average of the users coverage let cu ¼ fi ijrui ¼ kui g du ¼ fi ijrui ¼ g coverage ¼ u x uu cu du ðþ quality of the set of recommendations precision recall and f the conﬁdence of users for a certain rs does not depend directly on the accuracy for the set of possible predictions a user gains conﬁdence on the rs when this user agrees with a reduced set of recommendations made by the rs in this section we deﬁne the following three most widely used recommendation quality measures precision which indicates the proportion of relevant recommended items from the total number of recommended items recall which indicates the pro portion of relevant recommended items from the number of rele vant items and f which is a combination of precision and recall let xu as the set of recommendations to user u and zu as the set of n recommendations to user u we will represent the evaluation precision recall and f measures for recommendations obtained by making n test recommendations to the user u taking a h rele vancy threshold assuming that all users accept n test recommendations precision ¼ u x uu fi zujrui p hg n ðþ recall ¼ u x uu fi zujrui p hg fi zujrui p hg þ i zc u rui p h ðþ f ¼ precision recall precision þ recall ðþ quality of the list of recommendations rank measures when the number n of recommended items is not small users give greater importance to the ﬁrst items on the list of recommen dations the mistakes incurred in these items are more serious er rors than those in the last items on the list the ranking measures consider this situation among the ranking measures most often used are the following standard information retrieval measures a halflife which assumes an exponential decrease in the interest of users as they move away from the recommenda tions at the top and b discounted cumulative gain wherein decay is logarithmic hl ¼ u x uu x n i¼ maxðrupi d þ ðiþðaþ ðþ dcgk ¼ u x uu rup þ x k i¼ rupi logðiþ ðþ j bobadilla et al knowledgebased systems p pn represents the recommendation list rupi represents the true rating of the user u for the item pi k is the rank of the eval uated item d is the default rating a is the number of the item on the list such that there is a chance the user will review that item novelty and diversity the novelty evaluation measure indicates the degree of differ ence between the items recommended to and known by the user the diversity quality measure indicates the degree of differentia tion among recommended items currently novelty and diversity measures do not have a stan dard therefore different authors propose different metrics certain authors have used the following diversityzu ¼ zuðzu þ x izu x jzuji ½ simði jþ ðþ noveltyi ¼ zu x jzu ½ simði jþ i zu ðþ here simi j indicates item to item memorybased cf similar ity measures zu indicates the set of n recommendations to user u stability the stability in the predictions and recommendations inﬂu ences on the users trust towards the rs a rs is stable if the pre dicitions it provides do not change strongly over a short period of time adomavicius and zhang propose a quality measure of stability mas mean absolute shift this measure is deﬁned through a set of known ratings r and a set of predictions of all un known ratings p for an interval of time users of the rs will have rated a subset s of these unknown ratings and the rs can now make new predictions p mas is deﬁned as follows stability ¼ mas ¼ jpj x ðuiþp jpðu iþ pðu iþj ðþ reliability the reliability of a prediction or a recommendation informs about how seriously we may consider this prediction when rs recommends an item to a user with prediction in a scale this user hopes to be satisﬁed by this item however this value of prediction over does not reﬂect with which certain degree the rs has concluded that the user will like this item with value over indeed this prediction of is much more reli able if it has obtained by means of similar users than if it has obtained by only two similar users in hernando et al a realibility measure is proposed accord ing the usual notion that the more reliable a prediction the less lia ble to be wrong although this reliability measure is not a quality measure used for comparing different techniques of rs through cross validation this can be regarded as a quality measure associ ated to a prediction and a recommendation in this way the rs pro vides a pair of values prediction value reliability value through which users may balance its preference for example users would probably prefer the option to the option conse quently the reliability measure proposed in hernando et al provides a new understandable factor which users may consider for taking its decisions nevertheless the use of this reliability measure is just constrained to those rs based on the knn algorithm the deﬁnition of reliability on the prediction pui is based on two numeric factors sui and vui sui measures the similar ity of the neighbors used for making the prediction pui vui measures the degree of disagreement between these neighbors rating the item i finally the reliablity measure is deﬁned as follows fsðsuiþ ¼ s s þ sui sui ¼ x vkui simðuvþ ðþ where fsðsuiþ ¼ s s þ sui sui ¼ x vkui simðuvþ ðþ fig recommender systems evaluation process j bobadilla et al knowledgebased systems fvðvuiþ ¼ max min vui max min ln lnmax min v max min vui ¼ p vkuisimðuvþðrvi rv pui þ ruþ p vkuisimðuvþ ðþ where s and v are respectively the median of the values of sui and vui in the speciﬁc rs kui is the set of neighbors of u which have rated the item i min max is the discrete range of rating values fig shows the general mechanism for cross validation used to generate quality results form the evaluation measures the data base is divided in training and test areas for both users and items in the ﬁrst phase top on the left side kneighbors are calculated for the active user while the active user is selected from the set of test users the kneighbors are selected from the set of training users in the aggregation phase top on the right side predictions are calculated for the active user from the set of test items final ly evaluation metrics are used to compare the predictions and rec ommendations obtained with the real ratings of the user the more accurate the predictions and recommendations better quality of the proposed recommendation algorithm social information as the web has developed rs have increasingly incorpo rated social information eg trusted and untrusted users fol lowed and followers friends lists posts blogs and tags this new contextual information improves the rs social information improves the sparsity problem inherent in memory based rs because social information reinforces traditional mem orybased information users ratings users connected by a net work of trust exhibit signiﬁcantly higher similarity on items and metadata that nonconnected users social information is used by researchers with three primary objectives a to improve the quality of predictions and recom mendations b propose or generate new rs and c elucidate the most signiﬁcant relationships between social information and collaborative processes trust and reputation is an important area of research in rs this area is closely related to the social information currently in cluded in rs the most common approachs to generating trust and reputation measurements are the following a user trust to calculate the credibility of users through explicit informa tion of the rest of users or to calculate the credibility of users through implicit information obtained in a social network and b item trust to calculate the reputation of items through a feedback of users or to calculate the reputation of items studying how users work with these items in the social rs ﬁeld users can introduce labels associated with items the set of triples huser item tagi form information spaces referred to as folksonomies fundamentally folksonomies are used in the following two ways to create tag recommendation sys tems rs based only on tags and to enrich the recom mendation processes using tags contentbased ﬁltering has recently become more important due to the surge in social networks rs show a clear trend to allow users to introduce content such as comments critiques ratings opinions and labels as well as to establish social relation ship links eg followed followers like user and dislike user this additional information increases the accuracy of predictions and recommendations which has generated a variety of research arti cles kim et al zheng and li and carrerneto et al the rest of this section deal is dealt with the concepts and re search in the two lines considered previously filtering of social information and content ﬁltering social filtering social information can be gathered explicitly or implicitly through identiﬁcation of a community network or afﬁnity network using the individual information that users generate eg communications and web logs even using only the ratings from the users it is possible to improve the rs results creating an implicit social networking both implicit and explicit information sources can be combined to generate recommenda tions the explicit social information can be used via a trustbased cf in order to improve the quality of recommendations trust infor mation can be generated or used through different approaches such as trust propagation mechanisms a follow the leader approach personalitybased similarity measures trust networks distrust analysis and dynamic trust based on the ant colonies metaphor most of the research work that uses social information applied to rs aims to obtain improvements in the recommendations made by referring to the extra information provided by the social infor mation used among the most relevant current work which uses this approach we have woerndl and groh use social net works to enhance collaborative ﬁltering their evaluation shows that the social recommender outperforms traditional collaborative ﬁltering algorithms in the used scenario arazy et al improve accuracy by using data from online social networks and electronic communication tools xin et al propose an approach for improving rs through exploiting the learners note taking activity they maintain that notes features can be exploited by collabora tive learning systems in order to enrich and extend the user proﬁle and improve personalized learning the bonhard and sasse re search has shown that the relationship between adviceseeker and recommender is extremely important so ways of indicating social closeness and taste overlap are required they thus suggest that drawing on similarity and familiarity between the user and the persons who have rated the items can aid judgment and decision making fengkun and hong developed a way to increase rec ommendation effectiveness by incorporating social network infor mation into cf they collected data about users preference ratings and their social network relationships from a social networking web site then they evaluated cf performance with diverse neigh bor groups combining groups of friends and nearest neighbors carmagnola et al state that joining in a network with other people exposes individuals to social dynamics which can inﬂuence their attitudes behaviors and preferences they present sonars an algorithm for recommending content in social rs sonars tar gets users as members of social networks suggesting items that re ﬂect the trend of the network itself based on its structure and on the inﬂuence relationships among users in ramaswamy et al the design of the social network based rs incorporates three features that complement each other to derive highly targeted ads first they analyze information such as customers address books to estimate the level of social afﬁnity among various users this social afﬁnity information is used to identify the recommendations to be sent to an individual user another group of research work uses social information to cre ate or enable rs that is the aim is not to improve the results of a particular rs in operation the aim is to propose or make possible rs which still do not exist or if they do exist they are not based on social information the siersdorfer and sergei objective is to construct social recommender systems that predict the utility of items users or groups based on the multidimensional social environment of a given user they do a mining of the rich set of structures and social relationships that provides the folksonomies in the li and chen study they propose a blog recommenda tion mechanism that combines trust model social relation and j bobadilla et al knowledgebased systems semantic analysis and illustrates how it can be applied to a presti gious online blogging system in the jason research project they have applied a system to discover the social networks be tween mobile users by collecting a dataset from about two millions of users they argue that social network is applicable to generate contextbased recommendation services jyun and chui pa per uses trading relationships to calculate level of recommendation for trusted online auction sellers they demonstrate that network structures formed by transactional histories can be used to expose such underlying opportunistic collusive seller behaviors in dellamico and capra users trustworthiness has been mea sured according to one of the following two criteria taste similar ity ie i trust those who agree with me or social ties ie i trust my friends and the people that my friends trust they argue that in order to be trusted users must be both well intentioned and competent based on this observation they propose a novel approach that they call social ﬁltering a third group of work provides the foundation of the research to discover the most signiﬁcant relationships between social informa tion and collaborative processes without creating proposing or improving any particular rs this research moves at a higher level of abstraction with the aim of establishing bases and general prin ciples bonhard paper explains that qualitative research con ducted to date has shown that the relationship between recommender and recommendee has a signiﬁcant impact on deci sionmaking hossain and fazio present a study exploring the connection between social networks and collaborative process they focus on exploring academics network position and its effect on their collaborative networks by deﬁning network position in this way they develop a social network that uses the academics as nodes within the network instead of each published paper the esslimani et al paper presents a new cf approach based on a behavioral network that uses navigational patterns to model relationships between users and exploits social networks tech niques golbeck and kuter present an experimental study of several types of trust inference algorithms to answer the following questions on trust and change how far does a single change prop agate through the network how large is the impact of that change how does this relate to the type of inference algorithm the experimental results provide insights into which algorithms are most suitable for certain applications research in the ﬁeld of trust and reputation could provide a suitable starting point to create social interaction among users of the rs however the most relevant work on the subject is limited to the use of trust relationships to improve the quality of the rec ommendation services odonovan book chapter examines the diversity of sources from which trust information can be har nessed within social web applications and discusses a high level classiﬁcation of those sources it is shown that harnessing an in creased amount of information upon which to make trust decisions greatly enhances the user experience with the social web applica tion massa and avesani explain that rs making use of trust information are the most effective in term of accuracy while pre serving a good coverage this is especially evident on users who provided few ratings yuan et al choose the trust aware rs as an example to demonstrate the advantages by making use of the veriﬁed smallworld nature of the trust network li and kao present a rs based on the trust of social networks through the trust computing the quality and the veracity of peer produc tion services can be appropriately assessed the experimental re sults show that the proposed rs can signiﬁcantly enhance the quality of peer production services table classiﬁes the current approaches to address user credi bility and item reputation in socialbased rs in the cf ﬁeld the trust of users is used to make predictions weighting trust values that is to say the more trust a user has the more important its ratings are for making predictions in ma et al they propose a probabilistic factor analysis framework combining ratings and trusted friends this framework can be applied to pure useritem rating matrix contentbased ﬁltering contentbased ﬁltering cbf tries to recommend items to the active user similar to those rated positively in the past it is based on the concept that items with similar attributes will be rated sim ilarly for example if a user likes a web page with the words car engine and gasoline the cbf will recommend pages related to the automotive world cbf is becoming especially important as rs incorporate infor mation on items from users working in web environments such as tags posts opinions and multimedia material two challenging problems for contentbased ﬁltering are lim ited content analysis and overspecialization the ﬁrst problem arises from the difﬁculty in extracting reliable automated informa tion from various content eg images video audio and text which can greatly reduce the quality of recommendations the sec ond problem overspecialization refers to the phenomenon in which users only receive recommendations for items that are very similar to items they liked or preferred therefore the users are not receiving recommendations for items that they might like but are unknown eg when a user only receives recommendations about ﬁction ﬁlms recommendations can be evaluated for novelty for cbf to operate attributes of the items you wish to recom mend must be extracted typically a set of attributes is man ually deﬁned for each item depending on its domain in certain instances such as when it is desired to recommend textual infor mation classic information retrieval techniques must be used to automatically deﬁne such attributes eg term frequency inverse document frequency andnormalization to page length fig shows the cbf mechanism which includes the following steps extract the attributes of items for recommendation compare the attributes of items with the preferences of the active table state of the art on trust and reputation user trust item trust explicit trust systems the credibility of users is calculated through explicit information of the rest of users services pp usually implement this technique the reputation of items is calculated by means of a feedback of users who are asked about their opinions ecommerce services often use this technique implicit trust systems the credibility of users is calculated through implicit information obtained in a social network the reputation of items is calculated studying how users work with these items for example the number of times a song is played memory based trust the credibility measure is calculated taking into account the users ratings j bobadilla et al knowledgebased systems user and recommend items with characteristics that ﬁt the users interests when the attributes of the items and the user proﬁles are known the key purpose for cbf is to determine whether a user will like a speciﬁc item this task is resolved traditionally by using heuristic methods or classiﬁcation algorithms such us rule induction nearest neighbors methods rocchios algorithm linear classiﬁers and probabilistic methods the pure cbf has several shortcomings a in certain domains eg music blogs and videos it is a complicated task to generate the attributes for items b cbf suffers from an overspecialization problem because by nature it tends to recommend the same types of items c it is more difﬁcult to acquire feedback from users because with cbf users do not typically rate the items as in cf and therefore it is not possible to determine whether the recommendation is correct because of these shortcomings it is rare to ﬁnd a pure cbf implementation it is more common to use the hybrid cbfcf burke cf solves cbfs problems because it can function in any domain it is less affected by overspecialization and it ac quires feedback from users cbf adds the following qualities to cf improvement to the quality of the predictions because they are calculated with more information and reduced impact from the coldstart and sparsity problems cbf and cf can be combined in different ways fig shows the different alternatives fig a shows the methods that calculate cbf and cf recom mendations separately and subsequently combine them claypool et al propose to use a weighted average for combining cbf and cf predictions depending on the type of prediction in another study pazzani proposes combining the cbf and cf recom mendation lists by assigning the items scores according to their position on the lists additionally billsus and pazzani and tran and cohen propose to select the cbf or cf prediction in accordance with the quality fig b depicts the methods that incorporate cbf characteristics into the cf approach balabanovic and shoham maintain user proﬁles based on content analysis and directly compare the pro ﬁles to determine similar users for cf recommendations good et al construct specialized ﬁlterbots using cbf techniques which later act as neighbors in the cf stage melville et al propose to add predictions from the cbf into the ratting matrix employed by the cf li modiﬁes the ratting matrix which is input for the cf by combining it with another matrix generated from clustering the items according to their attributes in hu and pu authors incorporate personality characteristics in the cf similarity measure to minimize the newuser problem fig c illustrates the methods to construct a uniﬁed model with both cbf and cf characteristics basu et al propose using cbf and cf characteristics in a single rulebased classiﬁer popescul et al and schein et al propose using prob ability models to combine cbf and cf recommendations in an other studies the authors employ bayesian networks to combine cbf and cf characteristics and generate more accu rate recommendations burke and middleton et al propose using knowledgebased techniques to solve the cold start problem fig d shows the methods that incorporate cf characteristics into a cbf approach in soboroff and nicholas the authors use lsi to create the user proﬁles used in cbf recommendations beginning with the cf ratting matrix mooney and roy use cf system predictions as input for cbf the current trend in cbf is to add social information to the items attributes such as tags comments opinion and social net work sharing social tagging systems are the most popular because they allow users to annotate online resources with arbitrary labels which produces rich information spaces folksonomies these new components have opened novel lines of rs research that can be di vided into two categories tag recommendation systems and use of tags in the recommendation process rs tags attempt to provide personalized item recommenda tions to users through the most representative tags in jächke et al the authors compare different mecha nisms for tags recommendations marinho and schmidtthi eme improve tags recommendations by applying classic recommendation methods additionally landia and anand propose a method that combines clustering based cbf with cf to suggest new tags to users the methods using tags in the recommendation process increase the capacity of traditional rs tsosutter et al propose a generic method that allows tags to be incor porated to standard cf algorithms bogers and van den bosh examine how to incorporate the tags and other metada ta into a hybrid cbfcf algorithm by replacing the tradi tional userbased and itembased similarity measures by tag overlap gemmell et al propose a weighted hybrid recommender wherein they combine the graphbased tag recommendations with userbased cf and itembased cf gedikli and jannach propose to use tags as a means to express which features of an item users particularly like or dislike in gemmell et al the authors offer a hybrid rs wherein they predict the user preferences for items by only consulting the users tagging history additional recommender systems objectives commercial rs compete in the market by offering the best con tent and quality in recommendations as well as greatest variety of services recommendations to user groups facilitate joint recommendations to user groups eg a group of four friends who wish to choose a movie for cf four design approaches offer an opportunity for action acting into the similarity measures stage acquiring neighbors acquiring predictions and generating recommendations research results indicate that the quality of the recommendations does not vary greatly between the different approaches but the execution time is dramatically reduced as we advance when it is used when the design of a similarity measure for groups is the most efﬁcient solution for the rs generated recommendations to be valuable for users they must be explained well in a simple compelling and accurate manner the recommendation explanation ﬁeld has been investi gated with new developments in rs until now tradi tionally the explanation type is divided into the following categories a human style user to user approach b item style item to item approach c feature styleitems features and d hybrid it also employs the use of conversational techniques and incorporates geosocial information recommending to groups of users rs that consider groups of users are starting to expand and to be used in different areas tourism music tv web given the speciﬁc characteristics of the recommendation to groups it is appropriate to establish a consensus for different j bobadilla et al knowledgebased systems group semantics that formalize the agreements and disagreements among users with the aim of presenting the work carried out to date in a structured way we provide a classiﬁcation of the recommendation to groups in cf rs fig graphically illustrates the four basic lev els on which we can act in order to unify the groups users data with the objective of obtaining the data of the group of users sim ilarity metric establishing the neighborhood prediction phase determination of recommended items in fig the individual members of a group are represented on the left in grey each graticule represents the matrix of ratings by the users horizontal on the items vertical the graph shows the four representative cases of tackling the solution to recommenda tion by groups one case for each matrix on the left of the ﬁgure the circles show key information they indicate the cf process phase where the uniﬁcation is performed n users group in the ﬁrst case at the top of the graph the data uniﬁcation is performed in the prediction phase of the cf process n individual predictions of n users of the group are combined in one prediction of the group predictions aggregation this approach has been used by berkovsky and freyne garcía et al and christen sen and schiafﬁno the second case acts on the sets of neighbors of the groups users by unifying them in one neighborhood for the whole group this approach has been studied by bobadilla et al proposing the intersection of a large number k of neighbors of each user of the group in the third case the recommendations obtained for each indi vidual user of the group are merged into one recommendation for the group baltrunas et al use rank aggregation of individual lists of recommendations the fourth case uses a similarity metric that acts directly on the set of ratings of the group of users this solution is the only one that directly provides a set of neighbors for the group of users a study exists which prior to any of the previous cases pro poses as a frontend the incorporation of a process of estimation of missing information when dealing with incomplete fuzzy lin guistic preference relations explaining recommendations an important research subject in the rs ﬁeld focuses on provid ing explanations that justify the recommendations the user has re ceived this is an important aspect of an rs because it aids in maintaining a higher degree of user conﬁdence in the results gen erated by the system the type of explanations used thus far can be classiﬁed as fol lows human style explanations user to user approach for example we recommend movie i because it was liked by the users who rated movies j k m very positively j k m are movies rated well by the active user item style explanations item to item approach for example we recommend the vacation destination i because you liked the vacation destinations g c r g c r are vacation destina tions similar to i and rated well by the active user feature style explanations it is recommended based on items features for example we recommend movie i because it was directed by director d it features actors a b and it belongs to genre g d a b g are features the active user is interested in hybrid methods this category primarily includes the following humanitem humanfeature featureitem and humanfeature item additionally in geosocial rs foursquare google latitude etc location information exists that must be used in the recommenda tion explanation mechanism geosocial rs typically adopt a hybrid humanitem explanation method based on social location and memorybased information a reference publication that is a helpful introduction to the rs explanations research ﬁeld has been published previously they explore the utility of explanations in cf rs and they stated three key research questions what models and techniques are effective in supporting explanations can explanation facil ities increase the acceptance of cf rs can explanation facilities increase the ﬁltering performance of the cf rs users to answer to the ﬁrst question they propose using rating histograms indica tions of past performance comparisons to similar rated items and use of domain speciﬁc content features the results from the experiments conducted with rs users support an afﬁrmative re sponse to the second question the third question is unanswered fig contentbased ﬁltering mechanism fig different alternatives for combining cf and cbf j bobadilla et al knowledgebased systems because users perform ﬁltering based on many different channels of input a dynamic approach that favors the mechanisms for rs expla nations includes using conversational techniques such as the ccbr conversational casebase reasoning explained into mcsherry as ccbr they use an incremental nearest neighbor process based on the pareto case dominance approach in a different study a dynamic approach is also adopted but it employs a differ ent perspective instead of attempting to justify a particular recom mendation they focus on how explanations can help users to understand the recommendation opportunities that remain if the current recommendation should not meet their requirements they generate compound critiques as explanations users have the opportunity to accept or critique recommendations if they cri tique a recommendation the critique acts as a ﬁlter over the remaining recommendations in a separate study authors differentiate between the con cepts promotion increasing of the acceptance of the recommended item and satisfaction user satisfaction with the recommended item they also produced better results by using the keyword style explanation based on content data compared with the neighbor style explanation human style explanation authors propose a new classiﬁcation of the recommendation justiﬁcations keyword style explanation for contentbased rs neighbor style explana tion for collaborative ﬁltering rs and inﬂuence style explanation tells the user how their interactions with the rs inﬂuences the recommendation tintarev and masthoff describe the advantages of making justiﬁcations in recommendations trans parency scutability trustworthiness effectiveness persuasive ness efﬁciency and satisfaction billus and pazzani propose a recommendation system on news which provides keyword style justiﬁcations of the recom mendations through the weights used for obtaining these recom mendations wang et al describe a system of justiﬁcations based on the features of users preference tintarnev and masthoff design a recommedation system on ﬁlms whose recommen dations are justiﬁed through the features vig et al propose a mechanism for justifying recommendations called tagsplanations which is based on community tags trangsplanations have two key components tag relevance the degree to which a tag describes an item and tag preference the users sentiment toward a tag fahri provides a framework for organizing justiﬁcations used to categorize explanations they propose the categorization of the discourse explicative theoretical pragmatic ethical moral legal aesthetic and personal although this theoretical framework has not been used into the research literature it can be used to de sign new types of explanations hernando et al present a no vel explanation technique based on the visualization of trees of items these trees provide valuable information about the reliabil ity of recommendations and the importance of the ratings the user has made the most relevant investigations that produce justiﬁcations in recommender systems include a study wherein the authors design a new organization interface where results are grouped according to their tradeoff properties they have developed a trust model for recommender agents based on the pareto algorithm excluding dominated categories symeonidis et al ﬁrst con struct a feature proﬁle for the users to reveal their favorite features later they group users into biclusters to exploit partial matching between de preferences of groups of users over groups of items additionally they propose a metric to measure the quality of justi ﬁcations the explain coverage ratio in symeonidis et al they use a prototype moviexplain to put into the test the research showed into symeonidis et al in hu et al they use im plicit feedback to derive an estimate of the user preference like or dislike an item and user conﬁdence for each useritem pair recommender systems trends from the evolution of existing rs and research papers in the ﬁeld there is a clear tendency to collect and integrate more and different types of data this trend is parallel to the evolution of the web which we can deﬁne through the following three primary stages at the genesis of the web rs used only the explicit rat ings from users as well as their demographic information and con tentbased information included by the rs owners for the web in addition to the above information rs collect and use social fig classiﬁcation of the recommendations to groups in cf rs the ﬁgure represents the four representative cases for approaching the solution to group recommendations j bobadilla et al knowledgebased systems information such as friends followers followed both trusted and untrusted simultaneously users aid in the collaborative inclusion of such information blogs tags comments photos and videos for the web and the internet of things contextaware informa tion from a variety of devices and sensors will be incorporated with the above information currently geographic information is included and the expected trend is gradual incorporation of information such as radio frequency identiﬁcation rfid data sur veillancedata online health parameters and food and shopping habits as well as teleoperation and telepresence contextaware recommender systems focus on additional contextual information such as time location and wireless sensor networks the contextual information can be obtained explic itly implicitly using data mining or with a mixture of these meth ods hybrid currently mobile applications increasingly use geographic information this information enables geographic rs that can be considered as locationaware rs for geographic rs recommendations are typically generated by consider ing the geographical position of the user that receives the recommendation this section provides an introduction of concepts which are gaining popularity in the rs research ﬁeld internet of things pri vacy preservation shilling attacks new frameworks etc in this introduction we provide a novel classiﬁcation for analyzing these rs concepts next we will deal with the research on the loca tionaware rs which may be regarded as the ﬁrst steps for future rs based on web finally we will describe the most signiﬁca tive results on a promising research ﬁeld the rs based on bioin spired models introduction there is a clear trend towards collection of implicit information instead of a traditional explicit evaluation of items by ratings lastfm is a good example of this situation the user ratings are in ferred by the number of times they have heard each song the same can be applied in a number of everyday situations such as for access to web addresses use of various public transport sys tems food purchased access to sports facilities and access to learn ing resources incorporation of implicit information on the daily habits of users allows rs to use a variety of data these data will be used in future cf processes which are increasingly useful and accurate privacy and security considerations will be increasingly important with the widespread trend in using with consent devices and sen sors for the internet of things privacy is an important issue for rs because the systems contain information on large numbers of registered users for pri vacy preservation in rs a certain level of uncertainty must be intro duced into the predictions primarily through tradeoffs between accuracy and privacy furthermore privacy can be preserved when different rs companies share information com bining their data privacy becomes more important as rs increasingly incorporate social information because rs are often used in electronic commerce unscrupulous producers may ﬁnd proﬁtable to shill rs by lying to the systems in order to have their products recommended more often than those of their competitors rs can experience shilling attacks which generate many positive ratings for a product while products from competitors receive negative ratings rs are still highly vul nerable to such attacks knowledgebased ﬁltering is emerging as an important ﬁeld of rs knowledge rs use knowledge about users and products to pursue a knowledgebased approach to generating recommenda tions reasoning about what products meet the users requeri ments recommendations are based on inferences about users needs and preferences user models are based on knowledge struc tures such as querys preferred features por products cases casebased reasoning constraints constraintbased reason ing ontologies matching metrics and knowledge vec tors and social knowledge workﬂow is a current knowledge ﬁeld where the user model is based on usersrolestasks reference information that describes which member plays which roles or fulﬁlls which tasks peertopeer pp networks are other current knowl edge ﬁeld where user information is based on the distributed information existing from each peer and the set of peers who may need her gradual incorporation of different types of information eg ex plicit ratings social relations user contents locations use trends knowledgebased information has forced rs to use hybrid ap proaches once the memorybased social and locationaware methods and algorithms are consolidated the evolution of rs dem onstrates a clear trend toward combining existing collaborative methods the latest research in the cf ﬁeld has generated only modest improvements for predictions and recommendations from a single type of information eg when the only information used is user ratings information from social relations or item content the re sults improve further when several algorithms are combined with their respective data types a growing number of publications ad dress hybrid approaches that use current databases to simulta neously incorporate memorybased social and contentbased information to unify the above concepts fig provides an original taxon omy for rs the taxonomy is classiﬁed depending on the nature of the data rather than according to the methods and algorithms used the core of the taxonomy focuses on data classiﬁcation by three factors the target of the data user or item mode of acquisition explicit ie ratings to items made by users or impli cit eg number of times a user has heard a song and informa tion level memory content or social context fig shows the recommender methods and algorithms la beled as collaborative ﬁltering algorithms depending on the information type in each rs database it adopts a hybrid ﬁltering approach each hybrid approach will use an appropriate subset of algorithms to consider processing of existing information in a coor dinated manner future developments will include different rec ommendation frameworks that address the most common situations these frameworks allow rs to incorporate the cf kernel with the most appropriate recommendations methods based on the available information in a simple and straightforward manner at higher levels prediction and recommendation fig incorporates current evaluation quality measures such as those for diversity and novelty the importance of such measures and measures developed in the future will grow as users demand novel stable and less predictable recommendations locationaware recommender systems due to the increasing use of mobile devices locationaware sys tems are becoming more widespread these systems show a ten dency towards their consolidation as web services and this naturally leads to locationaware cf and locationaware rs which can be called geographic cf and geographic rs we introduce a classiﬁcation for geographic cf rs and focus on the most relevant section of the classiﬁcation obtained table establishes the different possibilities of tackling a geographic rs according to the nature of the ratings made rating stage and the recommendation process followed recommendation stage user indicates that the rating andor recommendation are made without having or using the users geographic information gi j bobadilla et al knowledgebased systems similarly item indicates that the rating andor recommendation are made without having or using the items gi in the cases la beled as userg and itemg the gi is used the cases identiﬁed are rs traditional rs in which ratings and recommendations are made without using geographical information rs g traditional rs which also contributes the items geo graphical position these rs cannot be regarded as geographic rs as the gi does not play a part in the recommendation process grs this group of geographic rs is most likely to become pop ular in the near future in these ratings are made in a traditional way whilst recommendations are made by considering the geo graphical position of the user to whom the recommendation is to be made a representative example is that of a rs for restau rants the users rate a restaurant using very diverse concepts which do not include the distance at the time of voting between the user and the restaurant however users of a geographic rs expects a restaurant to be recommended to them not only because of good ratings from similar users kneighbors but also according to the distance between their current position and that of the restaurant other possible examples are rs for cinemas pubs supermarkets cultural activities in a city lan guage learning centers gyms and sports clubs etc grs in this case users establish ratings on items by weighting the distance between them and the items rated in this type of geographic rs two possibilities can be established hybrid cfdemographic ﬁltering each item accepts a max imum of one vote per user to which the geographical posi tion from which it has been issued is associated geographic rs where each item accepts more than one rat ing for each user depending on the geographical position from which each rating is made the hybrid rs in case respond to regional or national geo graphical approaches in which recommendations can be established according to weighting between the similarity of the votes cf and their origin this type of grs may be regarded as an extended case of hybrid cfdemographic ﬁltering in which the gi is given for each vote instead of for each user from a theoretical point of view type grs are the most com plete however from a practical point of view they involve a semantic difﬁculty in the item rating process which makes their use very difﬁcult rating items in this grs involves that each user can rate items according to the relative distances between the user and the items in this way a user can rate a restaurant from their home differently to how they would rate it from their workplace and when the distances are very different the ratings are also likely to be so the mental process would be something like this i am km from the restaurant and i rate very positively travelling km to go to that restaurant which i think is good but after some time the same user who is at work km away from the restau rant could cast a vote indicating they do not consider it to be po sitive to travel km to go to the restaurant even if they think it is good in summary grs have the advantage that they accept a wider variety of ratings and that these also contain the relative impor tance that each user gives to the items according to the distance re quired to access them the disadvantage is that it is difﬁcult to involve users in a particularly complex and demanding ratings process this subsection focuses on the grstype geographic cf rs at present there are few publications regarding gibased rs this is due to a great extent to the lack of public databases that include ratings and geographic positions capable of being combined in an rs some of the publications that focus more closely on the ﬁeld are as follows martinez et al and biukaghai et al are examples of the rs g group in schlieder they propose a novel approach for modeling the collaborative semantics of geographic folksono mies this approach is based on multiobject tagging that is the analysis of tags that users assign to composite objects this paper is based on the concept of groups of people who share a common geospatial feature data dictionary including deﬁnitions of feature relationships and a common metadata schema wanshiou et al can be considered as a hybrid content basedgeographic rs the core of the system is a hybrid content basedgeographic recommendation mechanism that analyzes a customers history and position so that vendor information can be ranked according to the match with the preferences of a customer matyas and schlieder show a collaborative system that we could situate between a rs and a grs in this case the users ratings are taken based on the photos they have downloaded from a web and the photos they have uploaded to the same web the photos have a gps address associated to them after this a search of kneighborhoods based on this data is carried out the recommendation process does not take into account the users position it is possible to collect travel gps traces from users and use the database to generate recommendations the travel gps traces can be reinforced with social information based on friends both papers can be classiﬁed as grs bioinspired approaches much of the proposed modelbased rs are based on bioin spired approaches which primarily use genetic algorithms gas and neural networks nns models have also been proposed based on artiﬁcial immune networks ains ga are heuristic approaches based on evolutionary principles such as natural selection and survival of the ﬁtest ga have mainly been used in two aspects of rs clustering and hybrid user models a common technique to improve the fea tures of rs consists of initially carrying out a clustering on all of the users in such a way that a group of classes of similar users is obtained after this the desired cf techniques can be applied to each of the clusters obtaining similar results but in much shorter calculation times it is usual to use common genetic clustering algorithms such as gabased kmeans the rs hybrid user models commonly use a combination of cf with demographic ﬁltering or cf with content based ﬁltering to exploit merits of each one of these techniques in these cases the chromosome structure can easily contain the demographic charac teristics andor those related to contentbased ﬁltering in order to tackle locationbased advertisement dao et al propose a modelbased cf using ga they combine both users preferences and interaction context bobadilla et al use ga to create a similarity metric weighting a set of very simple similar ity measures hwang et al employ a ga to learn personal preferences of customers nn is a model based on the observed behavior of biological neu rons this model intended to simulate the way the brain processes information enables the computer to learn to a certain degree a nn typically consists of a number of interconnected nodes each handles a designated sphere of knowledge and has several inputs from the network based on the inputs it gets a node can learn about the relationships between sets of data pattern and based upon operational feedback are molded into the pattern required to generate the required results j bobadilla et al knowledgebased systems the rs most relevant research available in which nn usually fo cuses is hybrid rs in which nn are used for learn users proﬁles nn have also been used in the clustering processes of some rs the hybrid approaches enable nn to act on the additional infor mation to the ratings in ren et al they propose a hybrid rec ommender approach that employs widrowhoff algorithm to learn each users proﬁle from the contents of rated items this improves the granularity of the user proﬁling in christakou and stafylopatis they use a combination of contentbased and cf in order to construct a system that provides more precise recom mendations concerning movies in lee and woo ﬁrst all users are segmented by demographic characteristics and users in fig recommender systems taxonomy j bobadilla et al knowledgebased systems each segment are clustered according to the preference of items using the selforganizing map som nn kohonons soms are a type of unsupervised learning their goal is to discover some underlying structure of the data two alternative nn uses are presented in huang et al and roh et al in the ﬁrst case paper authors use a training back propagation nn for generating association rules that are mined from a transactional database in the second paper authors pro pose a model that combines a cf algorithm with two machine learning processes som and case based reasoning cbr by changing an unsupervised clustering problem into a supervised user preference reasoning problem neurofuzzy inference has been used in sevarac et al to create pedagogical rules in elearning a new coldstart similarity measure has been perfected in bobadilla et al using optimiza tion based on neural learning artiﬁcial immune systems are distributed and adaptive systems using the models and principles derived form the human immune system they model the defence system which can protect our body against infections in order to tackle the rs sparsity problem and to make algorithms more scalable acilar and arslan pres ent a new cf model based on the ain algorithm ainet ain were previously proposed to general recommendations and to rec ommend web sites related works and original contributions of the paper as cf has become more complex different survey papers have been published in this area schafer et al introduces the core concepts of cf the theory and practice the rating systems and their acquisition evaluation interaction interfaces and privacy is sues candillier et al review the main cf ﬁltering methods and compare their results su and khoshgoftaar presents a survey of cf techniques authors introduce the theory on cf and concisely deal with the main challenges sparsity scalability synonymy gray sheep shil ling attacks privacy etc they also expose an overview table of cf techniques park et al review papers on rs and classiﬁes them by the year and journal of the publication their application ﬁelds and their data mining techniques additionaly they categorized the pa pers into eight application ﬁelds ﬁlms music etc a review in rs algorithms is presented in this paper fo cuses on explaining carefully how the most used algorithms in rs work the paper presents also the basic concepts of cf and their evaluation metrics dimensionality reduction techniques diffu sionbased methods social ﬁltering and meta approaches our survey tries to include the most novel issues that have not been dealt carefully in the previous papers next we will stand out the most outstanding features of this survey uses a methodology for selecting the most suitable papers in the rs standing out the latest and most cited papers in the area of rs provides an updated overview table of the most used rs public databases including tags and friend relations information studies the coldstart problem inherent to all the rs presents a novel overview table informing both the classical similarity measure and those which have recently been pro posed it includes both the tailored metrics for coldstart users and the generalpurpose metrics besides we show the quality measures obtained when evaluating such metrics includes the recent quality measurements beyond accuracy to evaluate rs novelty diversity and stability additionaly we include a reliability measure associated to predictions and recommendations provides a comprehensive survey on social ﬁltering presenting a novel overview table on trust reputation and credibility introduces the contentbased ﬁltering from a modern perspec tive standing out its application for dealing with social informa tion such as social tagging presents a summary of the most relevant contributions in the rs for group of users we will show a novel classiﬁcation for the existing methods deals with a fast growing rs ﬁeld the locationaware rs based on geographic information this section is estructured with the help of a novel geographic rs classiﬁcation table summarizes the most relevant contributions on the use of bio inspired approaches describes the rs trends to implicitally collect data specially those derived from the use of internet of things provides an rs taxonomy for classifying the rs through three factors source of data traditional web social web internet of thingsweb target of data users items method for extracting data explicit implicit conclusions recommender systems are proving to be a useful tool for addressing a portion of the information overload phenomenon from the internet its evolution has accompanied the evolution of the web the ﬁrst generation of recommender systems used tradi tional websites to collect information from the following three sources a contentbased data from purchased or used products b demographic data collected in users records and c mem orybased data collected from users item preferences the second generation of recommender systems extensively use the web by gathering social information eg friends followers followed trusted users untrusted users the third generation of recom mender systems will use the web through information pro vided by the integrated devices on the internet the use of location information already incorporated in many recommender systems will be followed by data from devices and sensors which will be widely used eg realtime health signals rfid food habits online local weather parameters such as temperature and pressure the ﬁrsts recommender systems were focused on improving recommendation accuracy through ﬁltering most memorybased methods and algorithms were developed and optimized in this context eg knn metrics aggregation approaches singular value decomposition diffusionbased methods etc at this stage hybrid approaches primarily collaborativedemographic and collabora tivecontent ﬁltering improved the quality of the recommenda tions in the second stage algorithms that included social information with previous hybrid approaches were adapted and developed eg trustaware algorithms social adaptive ap proaches social networks analysis etc currently the hybrid ensemble algorithms incorporate location information into exist ing recommendation algorithms evaluation of the predictions and recommendations has evolved since the origins of recommender systems which weighted prediction errors accuracy heavily they also recognized the table geographic collaborative ﬁltering recommender systems classiﬁcation rating stage recommendation stage user gi item itemg item itemg user rsgrs rs rs g not userg grs grsgrs yes item gi not yes not yes j bobadilla et al knowledgebased systems convenience of evaluating the quality of the top n recommenda tions as a set evaluation of the top n recommendations as a ranked list was then incorporated currently there is a tendency to assess new evaluation measures such as diversity and novelty future research will concentrate on advancing the existing methods and algorithms to improve the quality of recommender systems predictions and recommendations simultaneously new lines of research will be developed for ﬁelds and aims such as on proper combination of existing recommendation methods that use different types of available information to get the maximum use of the individual potential of various sensors and devices on the internet of things acquisition and integration of trends related to the habits consumption and tastes of individ ual users in the recommendation process data mining from rs databases for nonrecommendation uses eg market research general trends visualization of differential characteristics of demo graphic groups enabling security and privacy for recom mender systems processes new evaluation measures and developing a standard for nonstandardized evaluation measures and designing ﬂexible frameworks for automated analysis of heterogeneous data references s abbar m bouzeghoub s lopez contextaware recommender systems a service oriented approach in proceedings of the rd international workshop on personalized access proﬁle management and context awareness in databases am acilar a arslan a collaborative ﬁltering method based on artiﬁcial immune network expert systems with applications g adomavicius a tuzhilin toward the next generation of recommender systems a survey of the stateoftheart and possible extensions ieee transactions on knowledge and data engineering g adomavicius j zhang on the stability of recommendations algorithms in acm conference on recommender systems pp g adomavicius a tuzhilin contextaware recommender systems in f ricci et al ed recommender systems handbook pp hj ahn a new similarity measure for collaborative ﬁltering to alleviate the new user coldstarting problem information sciences myh alshamri kk bharadwaj fuzzygenetic approach to recommender systems based on a novel hybrid user model expert systems with applications j alsharawneh ma williams credibilityaware webbased social network recommender follow the leader in proceedings of the acm conference on recommender systems pp s alonso fj cabrerizo f chiclana f herrera e herreraviedma group decision making with incomplete fuzzy linguistic preference relations international journal of intelligent systems a ansari s essegaier r kohli internet recommendation systems journal of marketing research n antonopoulus j salter cinema screen recommender agent combining collaborative and contentbased ﬁltering ieee intelligent systems p antunes v herskovic sf ochoa ja pino structuring dimensions for collaborative systems evaluation acm computing surveys article o arazy n kumar b shapira improving social recommender systems journal it professional l ardissono a goy g petrone m segnan p torasso intrigue personalized recommendation of tourist attractions for desktop and handset devices applied artiﬁcial intelligence r baezayates b ribeironeto modern information retrieval addison wesley m balabanovic y shoham contentbased collaborative recommendation communications of the acm l baltrunas t makcinskas f ricci group recommendation with rank aggregation and collaborative ﬁltering in proceedings of the acm conference on recommender systems pp ab barragánsmartınez e costamontenegro jc burguillo m reylópez fa mikicfonte a peleteiro a hybrid contentbased and itembased collaborative ﬁltering approach to recommend tv programs enhanced with singular value decomposition information sciences c basu h hirsh w cohen recommendation as classiﬁcation using social and contentbased information in recommendation in proceedings of the fifteenth national conference on artiﬁcial intelligence pp p bedi r sharma trust based recommender system using ant colony for trust computation expert systems with applications y bengio y grandvalet no umbiased estimator of the variance of kfold crossvalidation journal of machine learning research s berkovsky j freyne groupbased recipe recommendations analysis of data aggregation strategies in proceedings of the acm conference on recommender systems pp a bilge h polat an improved privacypreserving dwtbased collaborative ﬁltering scheme experts systems with applications m bilgic r mooney explanation for recommender systems satisfaction vs promotion in next stage of recommender systems research workshop iui conference pp d billsus m pazzani a personal news agent that talks learns and explains in proc auton agents conf pp d billsus m pazzani user modeling for adaptive news access user modeling and useradapted interaction d billsus m pazzani j chen a learning agent for wireless news access in proceedings of the international conference on intelligent user interfaces pp rp biukaghai s fong s yainwhar design of a recommender system for mobile tourism multimedia selection in nd international conference on internet multimedia services architecture and applications imsaa pp j bobadilla f serradilla the effect of sparsity on collaborative ﬁltering metrics in australian database conference pp j bobadilla f serradilla a hernando collaborative ﬁltering adapted to recommender systems of elearning knowledge based systems j bobadilla f serradilla j bernal a new collaborative ﬁltering metric that improves the behavior of recommender systems knowledge based systems j bobadilla a hernando f ortega j bernal a framework for collaborative ﬁltering recommender systems expert systems with applications j bobadilla f ortega a hernando j alcalá improving collaborative ﬁltering recommender systems results and performance using genetic algorithms knowledge based systems j bobadilla a hernando f ortega a gutiérrez collaborative ﬁltering based on signiﬁcances information sciences j bobadilla f ortega a hernando a collaborative ﬁltering similarity measure based on singularities information processing and management j bobadilla f ortega a hernando j bernal a collaborative ﬁltering approach to mitigate the new user cold start problem knowledge based systems j bobadilla f ortega a hernando j bernal generalization of recommender systems collaborative ﬁltering extended to groups of users and restricted to groups of items expert systems with applications j bobadilla f ortega a hernando a arroyo a balanced memorybased collaborative ﬁltering similarity measure international journal of intelligent systems t bogers a van den bosch collaborative and contentbased ﬁltering for item recommendation on social bookmarking websites in proceedings of the acm conference on recommender systems pp p bonhard who do trust combining recommender systems and social networking for better advice in international conference on intelligent user interfaces p bonhard ma sasse knowing me knowing youusing proﬁles and social networking to improve recommender systems bt technology journal p borzymek m sydow a wierbicki enriching trust prediction model in social network with user rating similarity in proceedings of the international conference on computational aspects of social network pp js breese d heckerman c kadie empirical analysis of predictive algorithms for collaborative ﬁltering in th conference on uncertainty in artiﬁcial intelligence pp d bridge mh goker l mcginty b smyth casebased recommender systems the knowledge engineering review r burke encyclopedia of library and information systems in a kent ed vol suppl marcel dekker chapter knowledgebased recommender systems r burke a casebased reasoning approach to collaborative ﬁltering in ewcbr pp r burke hybrid recommender systems survey and experiments user modeling and useradapted interaction f cacheda v carneiro d fernández v formoso comparison of collaborative ﬁltering algorithms limitations of current techniques and proposals for scalable highperformance recommender systems acm transactions on the web article s caizer u aickelin a recommender system based on idiotypic artiﬁcial immune networks journal of mathematics models and algorithms j bobadilla et al knowledgebased systems lm campos jm fernándezluna jf huete ma ruedamorales combining contentbased and collaborative recommendations a hybrid approach based on bayesian networks international journal of approximate reasoning l candillier f meyer m boullé comparing stateoftheart collaborative ﬁltering systems lecture notes in computer sciece f carmagnola f vernero p grillo sonars a social networksbased algorithm for social recommender systems in proceedings of the th international conference on user modeling adaptation and personalization formerly um and ah pp w carrerneto ml hernándezalcaraz r valenciagarcıa f garcıa sánchez social knowledgebased recommender system application to the movies domain expert systems with applications jj castrosanchez r miguel d vallejo lm lópezlópez a highly adaptive recommender system based on fuzzy logic for bc ecommerce portals expert systems with applications d chao j balthrop s forrest adaptive radio achieving consensus using negative preferences in international acm siggroup conference on supporting group work pp t chen l he collaborative ﬁltering based on demographic attribute vector in proceedings of the international conference on future computer and communication pp pa chirita w nejdl c zamﬁr preventing shilling attacks in online recommender systems in workshop on web information and data management pp j cho k kwon y park qrater a collaborative reputation system based on source credibility theory expert systems with applications sb cho jh hong mh park locationbased recommendation system using bayesian users preference model in mobile devices lecture notes in computer science k choi d yoo g kim y suh a hybrid onlineproduct recommendation system combining implicit ratingbased collaborative ﬁltering and sequential pattern analysis electronic commerce research and applications in press doi jelerap k choi y suh a new similarity fuction for selecting neighbors for each target item in collaborative ﬁltering knowledge based systems c christakou a stafylopatis a hybrid movie recommender system based on neural networks in international conference on intelligent systems design and applications pp ia christensen s schiafﬁno entertainment recommender systems for group of users expert systems with applications m claypool a gokhale t miranda p murnikov d netes m sartin combining contentbased and collaborative ﬁlters in an online newspaper in proceedings of acm sigir workshop on recommender systems pp w cohen fast effective rule induction in proceedings of the twelfth international conference on machine learning pp m condliff d lewis d madigan c posse bayesian mixedeffects models for recommender systems in acm sigir workshop on recommender systems algorithms and evaluation pp e costamontenegro ab barragánsmartı nez m reylópez which app a recommender system of applications in markets implementation of the service for monitoring users interaction expert systems with applications th dao sr jeong h ahn a novel recommendation model of locationbased advertising contextaware collaborative ﬁltering using ga approach expert systems with applications m dellamico l capra sofia social ﬁltering for robust recommendation ifip advances in information and communication technology t dubois j golbeck j kleint a srinivasan improving recommendation accuracy by clustering social networks with trust in proceedings of the acm conference on recommender systems pp m ekström h björnsson c nass a reputation mechanism for businessto business electronic commerce that accounts for rater credibility journal of organizational computing and electronic commerce i esslimani a brun a boyer from social networks to behavioral networks in recommender systems in proceedings of the international conference on advances in social network analysis and mining pp y fahri a framework for organizing justiﬁcations for strategic use in adaptive iteraction contexts ecis article a felfernig r burke constraintbased recommender systems technologies and research issues in th international conference on electronic commerce article no l fengkun jl hong use of social network information to enhance collaborative ﬁltering performance expert systems with applications lq gao c li hybrid personalizad recommended model based on genetic algorithm in international conference on wireless communication networks and mobile computing pp m gao z wu f jiang userrank for itembased collaborative ﬁltering recommendation information processing letters i garcı a l sebastia e onaindia on the design of individual and group recommender systems for tourism expert systems with applications r garcıa x amatriain weighted content based methods for recommending connections in online social networks in proceedings of the acm conference on recommender systems pp d gavalas m kenteris a webbased pervasive recommendation system for mobile tourist guides personal and ubiquitous computing f gedikli d jannach rating items by rating tags in proceedings of the acm conference on recommender systems pp j gemmell t schimoler b mobasher r burke resource recommendation for social tagging a multichannel hybrid approach in proceedings of the acm conference on recommender systems pp j gemmell t schimoler m ramezani l christiansen b mobasher improving folkrank with itembased collaborative ﬁltering in proceedings of the acm conference on recommender systems pp m gemmis p lops g semeraro p basile integrating tags in a semantic contentbased recommender in proceedings of the acm conference on recommender systems pp t george s meregu a scalable collaborative ﬁltering framework base don coclustering in ieee international conference on data mining icdm pp j golbeck u kuter the ripple effect change in trust and its impact over a social network in computing with social trust humancomputer interaction series part ii pp chapter k goldberg t roeder d gupta c perkins eigentaste a constant time collaborative ﬁltering algorithm information retrieval r gonzálezcrespo o sanjuánmartınez j manuelcueva b cristinapelayo je labragayo p ordoñez recommendation system based on user interaction data applied to intelligent electronic books computers in human behavior n good jb schafer ja konstan a borchers b sarwar jl herlocker j riedl in proceedings of the sixteenth national conference on artiﬁcial intelligence and the eleventh innovative applications of artiﬁcial intelligence conference innovative applications of artiﬁcial intelligence pp a gunawardana g shani a survey of accuracy evaluation metrics of recommender tasks journal of machine learning reearch jl herlocker ja konstan j riedl explaining collaborative ﬁltering recommendations in acm conference on computer supported cooperative work cscw pp jl herlocker ja konstan al borchers jt riedl an algorithmic framework for performing collaborative ﬁltering in proceedings of the nd annual international acm sigir conference on research and development in information retrieval pp jl herlocker ja konstan jt riedl an empirical analysis of design choices in neighborhoodbased collaborative ﬁltering algorithms information retrieval jl herlocker ja konstan jt riedl lg terveen evaluating collaborative ﬁltering recommender systems acm transactions on information systems f hernández e gaudioso evaluation of recommender systems a new approach expert systems with applications a hernando j bobadilla f ortega j tejedor incorporating reliability measurements into the predictions of a recommender systems information sciences in press doi jins a hernando j bobadilla f ortega a gutiérrez trees for explaining recommendations made through collaborative ﬁltering information sciences k heungnam es abdulmotaleb j geunsik collaborative errorreﬂected models for coldstart recommender systems decision support systems y ho s fong z yan a hybrid gabased collaborative ﬁltering model for online recommenders in international conference on ebusiness pp l hossain d fazio the social networks of collaborative process the journal of high technology management research hr hu p pu using personality information in collaborative ﬁltering for new users in proceedings of the acm conference on recommender systems pp y hu y koren ch volinsky collaborative ﬁltering for implicit feedback datasets in ieee international conference on data mining icdm pp yp huang wp chuang yh ke fe sandnes using backpropagation to learn association rules for service personalization expert systems with applications z huang d zeng h chen a comparison of collaborative ﬁltering recommendation algorithms for ecommerce ieee intelligent systems n hurley m zhang novelty and diversity in topn recommendations analysis and evaluation acm transactions on internet technology j bobadilla et al knowledgebased systems chs hwang ych su kch tseng using genetic algorithms for personalized recommendation lecture notes in computer science h ingoo jo kyong hr tae the collaborative ﬁltering recommendation based on som clusterindexing cbr expert systems with applications a jameson b smyth recommendation to groups in p brusilovsky a kobsa w nejdl eds the adaptive web pp chapter d jannach fast computation of query relaxations for knowledgebased recommenders ai communications r jäschke l marinho a hotho l schmidtthieme g stumme tag recommendations in folksonomies in proceedings of the th european conference on principles and practice of knowledge discovery in databases pp jj jason contextualized mobile recommendation service based on interactive social network discovered from mobile users expert systems with applications b jeong j lee h cho user credit based collaborative ﬁltering expert systems with applications t joachims text categorization with support vector machines learning with many relevant features in european conference on machine learning pp a jøsang r ismail c boyd a survey of trust and reputation systems for online service provision decision support systems chw jyun chch chui recommending trusted online auction sellers using social network analysis expert systems with applications c kaleli h polat privacypreserving sombased recommendations on horizontally distributed data knowledge based systems hn kim a alkhaldi ae saddik gs jo collaborative user modeling with usergenerated tags for social recommender systems expert systems with applications hn kim at ji i ha gs jo collaborative ﬁltering based on collaborative tagging for enhancing the quality of recommendations electronic commerce research and applications j kim b lee m shaw h chang w nelson application of decisiontree induction techniques to personalized advertisements on internet storefronts international journal of electronic commerce k kim h ahn using a clustering genetic algorithm to support customer segmentation for personalizad recommender systems in proceedings of the th international conference on ai simulation and planning in high autonomy systems pp k kim h ahn a recommender system using ga kmeans clustering in an online shopping market expert systems with applications s kitisin c neuman reputationbased trustaware recommender system in securecomm and workshops pp f kong x sun s ye a comparison of several algorithms for collaborative ﬁltering in startup stage ieee transactions on networks sensing and control y koren r bell ch volinsky matrix factorization techniques dor recommender systems ieee computer g koutrika b bercovitz h garcia flexrecs expressing and combining ﬂexible recommendations in proceedings of the th sigmod international conference on management of data pp b krulwich lifestyle ﬁnder intelligent user proﬁling using largescale demographic data artiﬁcial intelligence magazine k kwon j cho y park multidimensional credibility model for neighbor selection in collaborative recommendation expert systems with applications sk lam j riedl shilling recommender systems for fun and proﬁt in international conference on world wide web pp xn lam t vu td le ad duong addressing coldstart problem in recommendation systems in conference on ubiquitous information management and communication pp n landia ss anand personalised tag recommendation in proceedings of the acm conference on recommender systems pp k lang newsweeder learning to ﬁlter netnews in proceedings th international conference on machine learning pp dh lee p brusilovsky does trust inﬂuence information similarity in proceedings of the acm conference on recommender systems pp m lee y woo a hybrid recommender system combining collaborative ﬁltering with neural network lecture notes on computer sciences sk lee yh cho sh kim collaborative ﬁltering with ordinal scalebased implicit ratings for mobile music recommendations information sciences cw leung sc chan fl chung an empirical study of a crosslevel association rule mining approach to coldstart recommendations knowledge based systems q li clustering approach for hybrid recommender system in proceedings of the ieeewic international conference on web intelligence pp ym li chw chen a synthetical approach for blog recommendation combining trust social relation and semantic análisis expert systems with applications ym li chp kao trepps a trustbased recommender system for peer production services expert systems with applications ym li tf liao chy lai a social recommender mechanism for improving knowledge sharing in online forums information processing and management in press doi jipm s loh f lorenzi r granada d lichtnow lk wives jp oliveira identifying similar users by their scientiﬁc publications to reduce cold start in recommender systems in proceedings of the th international conference on web information systems and technologies webist pp l lü m medo chh yeung ych zhang zk zhang t zhou recommender systems physics reports x luo y xia q zhu incremental collaborative ﬁltering recommender based on regularizad matrix factorization knowledgebased systems x luo y xia q zhu applying the learning rate adaptation to the matrix factorization based collaborative ﬁltering knowledge based systems h ma i king mr lyu learning to recommend with explicit and implicit social relations acm transactions on intelligent systems and technology article h ma t ch zhou mr lyu i king improving recommender systems by incorporating social contextual information acm transactions on information systems article a machanavajjhala a korolova ad sharma personalized social recommendations accurate or private in proceedings of the vldb endowment vol issue pp lb marinho l schmidtthieme collaborative tag recommendations in proceedings of the st annual conference of the german classiﬁcation society pp l martinez lg perez mj barranco incomplete preference relations to smooth out the coldstart in collaborative recommender systems in proceedings of the th north american fuzzy information processing society annual conference nafips a pp l martinez rm rodriguez m espinilla reja a georeferenced hybrid recommender system for restaurants in ieeewicacm international joint conference on web intelligence and intelligent agent technonolgy wiiat b pp p massa p avesani trustaware collaborative ﬁltering for recommender systems lecture notes in computer science p massa p avesani trustaware recommender systems in proceedings of the acm conference on recommender systems pp c matyas c schlieder a spatial user similarity measure for geographic recommender systems in proceedings of the rd international conference on geospatial semantics pp k mccarthy j reilly l mcginty b smyth thinking positivelyexplanatory feedback for conversational recommender systems in european conference on casebased reasoning eccbr pp k mcnally mp omahony m coyle p briggs b smyth a case study of collaboration and reputation in social web search acm transactions on intelligent systems and technology article d mcsherry explanation in recommender systems artiﬁcial intelligence review f mcsherry i mironov differentially private recommender systems building privacy into the netﬂix prize contenders in proceedings of the th acm sigkdd international conference on knowledge discovery and data mining kdd pp p melville rj mooney r nagarajan contentboosted collaborative ﬁltering for improved recommendations in proceeding eighteenth national conference on artiﬁcial intelligence pp r meteren m someren using contentbased ﬁltering for recommendation in proceedings of ecml workshop maching learning in information age pp se middleton nr shadbolt dc de roure ontological user proﬁling in recommender systems acm transactions on information systems tois rj mooney l roy contentbased book recommending using learning for text categorization in proceedings of the fifth acm conference on digital libraries pp t morrison u aickelin an artiﬁcial immune system as a recommender for web sites in international conference on artiﬁcial immune systems pp a nanolopoulus d rafailidis p symeonidis y manolopoulus music box personalizad music recommendation based on cubic analysis of social tags ieee transactions on audio speech and language processing k nehring c puppe a theory of diversity econometrica er núñezvaldéz jm cuevalovelle o sanjuánmartınez v garcı adıaz p ordoñez ce montenegromarı n implicit feedback techniques on recommender systems applied to electronic books computers in human behavior j bobadilla et al knowledgebased systems j odonovan capturing trust in social web applications in j golbeck ed computing with social trust pp j odonovan b smyth trust in recommender systems in international conference on intelligent user interfaces pp k oku r kotera k sumiya geographical recommender system based on interaction between map operation and category selection in workshop on information heterogeneity and fusion in recommender systems pp j ortega j bobadilla a hernando a gutiérrez incorporating group recommendations to recommender systems alternatives and performance information processing and management httpdxdoiorg jipm j ortega jl sánchez j bobadilla a gutiérrez improving collaborative ﬁlteringbased recommender systems results using pareto dominance information sciences httpdxdoiorgjins a papadimitriou p symeonidid y manolopoulus a generalized taxonomy of explanations styles for traditional and social recommender systems data minning knowledge discovery dh park hk kim iy choi jk kim a literature review and classiﬁcation of recommender systems research expert systems with applications st park w chu pairwise preference regression for coldstart recommendation in proceedings of the acm conference on recommender systems pp st park dm pennock o madani n good d coste naıve ﬁlterbots for robust coldstart recommendations in proceedings of knowledge discovery and data mining kdd pp yj park a tuzhilin the long tail of recommender systems and how to leverage it in proceedings of the acm conference on recommender systems pp m pazzani d billsus learning and revising user proﬁles the identiﬁcation of interesting web sites machine learning mj pazzani d billsus contentbased recommender systems in p brusilovsky a kobsa w nejdl eds the adaptive web pp chapter m pazzani a framework for collaborative contentbased and demographic ﬁltering artiﬁcial intelligence reviewspecial issue on data mining on the internet s perugini ma gonçalves ea fox recomender systems research a connectioncentric surrey journal of intelligen information systems mc pham y cao r klamma m jarke a clustering approach for collaborative ﬁltering recommendation using social network analysis journal of universal computer science g pitsilis sj knapskog socila trust as a solution to address sparsityinherent problems of recommender systems in proceedings of the acm conference on recommender systems pp g pitsilis x zhang w wang clustering recommenders in collaborative ﬁltering using explicit trust information advances in information and communication technology a popescul lh ungar dm pennock s lawrence probabilistic models for uniﬁed collaborative and contentbased recommendation in sparsedata environments in proceeding uai proceedings of the th conference in uncertainty in artiﬁcial intelligence pp c porcel e herreraviedma dealing with incomplete information in a fuzzy linguistic recommender system to disseminate information in university digital libraries knowledgebased systems c porcel jm moreno e herreraviedma a multidisciplinar recommender system to advice research resources in university digital libraries expert systems with applications c porcel a tejedalorente ma martı nez e herreraviedma a hybrid recommender system for the selective dissemination of research resources in a technology transfer ofﬁce information sciences j preece b shneiderman the reader to leader framework motivating technologymediated social participation ais transactions on human computer interaction p pu l chen trustinspiring explanation interfaces for recommender systems knowledge based systems w qin l xin h liang unifying userbased and itembased algorithm to improve collaborative ﬁltering accuracy energy procedia l ramaswamy p deepak r polavarapu k gunasekera d garg k visweswariah s kalyanaraman caesar a contextaware social recommender system for lowend mobile devices in international conference on mobile data management systems services and middleware pp am rashid g karypis j riedl learning preferences of new users in recommender systems an information theoretic approach in acm sigkdd explorations newsletter vol issue pp s ray a mahanti strategies for effective shilling attacks against recommender systems lecture notes in computer science l ren l he j gu w xia f wu a hybrid recommender approach based on widrowhoff learning in international conference on future generation communication and networking pp th roh kj oh i han the collaborative ﬁltering recommendation based on som clusterindexing cbr expert systems with applications ja rodrigues lf cardoso j moreira g xexeo bringing knowledge into recommender systems the journal of systems and software in press http dxdoiorgjjss sb roy s ameryahia a chala g das c yu space efﬁciency in group recommendation the international journal on very large data bases g ruffo r schifanella a peertopeer recommender system base don spontaneous afﬁnities acm transactions on internet technology pb ryan d bridge collaborative recommending using formal concept analysis knowledge based systems g salton automatic text processing the transformation analysis and retrieval of information by computer addisonwesley reading ma m saranya t atsuhiro hybrid recommender systems using latent features in proceedings of the international conference on advanced information networking and applications workshops pp b sarwar g karypis ja konstan j riedl itembased collaborative ﬁltering recommendation algorithms in th international conference on world wide web pp b sarwar g karypis j konstan j riedl analysis of recommendation algorithms for ecommerce in acm conference on electronic commerce a pp b sarwar g karypis j konstan j riedl application of dimensionality reduction in recommender system a case study in acm webkdd workshop b pp jb schafer d frankowski j herlocker s sen collaborative ﬁlltering recommender systems in p brusilovsky a kobsa w nejdl eds the adaptive web pp chapter ai schein a popescul lh ungar dm pennock methods and metrics for coldstart recommendations in proceeding sigir proceedings of the th annual international acm sigir conference on research and development in information retrieval pp c schlieder modeling collaborative semantics with a geographic recommender in workshop on semantic and conceptual issues in geographic information systems pp j serranoguerrero e herreraviedma ja olivas a cerezo fp romero a google wavebased fuzzy recommender system to disseminate information in university digital libraries information sciences z severac v devedzic j jovanovic adaptive neurofuzzy pedagogical recommender expert systems with applications a shepitsen j gemmell b mobasher r burke personalized recommendation in social tagging systems using hierarchical clustering in proceedings of the acm conference on recommender systems pp sk shinde u kulkami hybrid personalizad recommender system using centeringbunching based clustering algorithm expert systems with applications s siersdorfer s sergei social recommender systems for web folksonomies in th acm conference on hypertext and hipermedia pp i soboroff c nicholas combining content and collaboration in text ﬁltering in proceedings of the ijcai workshop on machine learning for information filtering pp x su tm khoshgoftaar a survey of collaborative ﬁltering techniques advance in artiﬁcial intelligence p symeonidis a nanopoulus y manolopoulus providing justiﬁcations in recommender systems ieee transactions on systems man and cybernet p symeonidis a nanopoulus y manolopoulus movieexplain a recommender system with explanations in proceedings of the acm conference on recommender systems pp g takács i pilászy b németh d tikk scalable collaborative ﬁltering approaches for large recommender systems journal of machine learning research s tan j bu ch chen x he using rich social media information for music recommendation via hypergraph model acm transactions on multimedia computing communications and applications article n tintarev j masthoff a survey of explanations in recommender systems in ieee rd international conference on data engineering workshop t tran r cohen hybrid recommender systems for electronic commerce in proceedings of the th national conference on artiﬁcial intelligence aaai pp khl tsosutter lb marinho l schmidtthieme tagaware recommender systems by fusion of collaborative ﬁltering algorithms in proceedings of the acm symposium on applied computing pp s vargas p castells rank and relevance in novelty and diversity metrics for recommender systems in proceedings of the acm conference on recommender systems pp p victor ch cornelis m decock trust networks for recommender systems antalis press j bobadilla et al knowledgebased systems j vig s sen j riedle tagsplanations explaining recommendations using tags proceedings of the th international conference on intelligent user interfaces pp p victor ch cornelis m decock pp dasilva gradual tust and distrust in recommender systems fuzzy sets and systems mg vozalis kg margaritis using svd and demographic data for the enhancement of generalized collaborative ﬁltering information sciences y wanshiou ch hungchi d jiaben a locationaware recommender system for mobile shopping environments expert systems with applications j wang a vries m reinders unifying userbased and itembased collaborative ﬁltering approaches by similarity fusion in proc sigir conf pp j wang ap vries mj reinders uniﬁed relevance models for rating prediction in collaborative ﬁltering acm transactions in information systems lt weng y xu y li r nayak exploiting item taxonomy for solving cold start problem in recommendation making in proceedings of the th ieee international conference on tools with artiﬁcial intelligence ictai pp b widrow me hoff adaptive switching circuits in convention record ire wescon pp p winoto ty tang the role of user mood in movie recommendations expert systems with applications w woerndl g groh utilizing physical and social context to improve recommender systems in ieeewicacm international conferences on web intelligence and intelligent agent technology pp b xie p han f yang rm shen hj zeng z chen dcfla a distributed collaborativeﬁltering neighborlocating algorithm information sciences w xin q jamaliding t okamoto discovering social network to improve recommender system for group learning support in international conference on computational intelligence and software engineering pp rr yager fuzzy logic methods in recommender systems fuzzy sets and systems ws yang hch cheng jb dia a locationaware recommender system for mobile shopping environments expert systems with applications y yang an evaluation of statistical approaches to text categorization information retrieval z yao q zhang itembased clustering collaborative ﬁltering algorithm under high dimensional sparse data in international joint confeence on computational sciences and optimization pp z yu x zhou y hao j gu tv program recommendation for multiple viewers based on user proﬁle merging user modeling and useradapted interaction w yuan d guan yk lee s lee sj hur improved trustaware recommender system using smallworldness of trust networks knowledge based systems g zacharia a moukas p maes collaborative reputation mechanisms for electronic marketplaces decision support systems o zaiane building a recommender agent for elearning systems in proceedings of the international conference on computers education icce vol pp j zhan privacypreserving collaborative recommender systems ieee transactions on systems man and cybernetics f zhang hy chang a collaborative ﬁltering algorithm employing genetic clustering to ameliorate the scalability issue in ieee international conference on ebusiness engineering pp s zhang w wang j ford f makedon using singular value decomposition approximation for collaborative ﬁltering in ieee international conference on ecommerce technology pp l zhen gq huang z jiang recommender systems based on workﬂow decision support systems l zhen gq huang z jiang collaborative ﬁltering based on workﬂow space expert systems with applications l zhen z jiang h song distributed recommender for peertopeer knowledge sharing information sciences n zheng q li a recommender system based on tag and time information for social tagging systems expert systems with applications y zheng x xie learning travel recommendations from usergenerated gps traces acm transactions on intelligent systems and technology article y zheng l zhang z ma x xie wy ma recommending friends and locations based on individual location history acm transactions on the web article j zhong x li uniﬁed collaborative ﬁltering model based on combination of latent features expert systems with applications rl zhu sj gong analyzing of collaborative ﬁltering using clustering technology international colloquium on computing in isecs international colloquium on computing communication control and management pp cn ziegler sm mcnee ja konstan g lausen improving recommendation lists through topic diversiﬁcation in proceedings of the th international conference on world wide web pp j bobadilla et al knowledgebased systems,"[0.010387231595814228, -0.028208009898662567, -0.027821922674775124, -0.01994139887392521, -0.024704033508896828, -0.028099145740270615, 0.011491086333990097, 0.022706780582666397, 0.05560768023133278, 0.004101363476365805, -0.04470595344901085, 0.01853746920824051, 0.001798535231500864, 0.02950938418507576, -0.029114006087183952, -0.026860307902097702, -0.00706653343513608, 0.024403857067227364, -0.032444775104522705, 0.008698848076164722, 0.016948645934462547, 0.014015094377100468, 0.06673205643892288, 0.015831461176276207, 0.030502695590257645, 0.04102329537272453, 0.03206682950258255, -0.018738290295004845, 0.0013357066782191396, -0.04746187478303909, 0.01565592549741268, -0.026194045320153236, 0.015373200178146362, -0.006896815728396177, 2.0984130060242023e-06, 0.004868895281106234, -0.048639751970767975, -0.02075388841331005, 0.0761958658695221, -0.08431965112686157, 0.033664241433143616, 0.08806761354207993, 0.04210660234093666, 0.03152009844779968, -0.05665876343846321, 0.021587781608104706, 0.02732028439640999, 0.036979421973228455, -0.008838213048875332, -0.03582068160176277, -0.033962737768888474, 0.002739738905802369, -0.03662659600377083, 0.020244339480996132, 0.02487565018236637, 0.030217047780752182, -0.01603197492659092, -0.012404111213982105, 0.045170754194259644, -0.0019245276926085353, 0.03177948296070099, -0.048485029488801956, -0.009212039411067963, 0.032854028046131134, 0.05297109857201576, 0.011720546521246433, -0.01743372716009617, -0.03613850101828575, -0.04478055611252785, 0.028580473735928535, 0.03001374565064907, -0.027147307991981506, 0.015507861971855164, 0.03562846779823303, -0.03119121678173542, 0.045610323548316956, -0.05084747448563576, -0.03421487659215927, 0.001754406257532537, 0.060234908014535904, -0.020055921748280525, 0.043281253427267075, 0.008528516627848148, 0.019363950937986374, 0.06670371443033218, 0.08301027119159698, 0.007316415198147297, -0.008538001216948032, 0.0005434899940155447, -0.0074212136678397655, 0.03289811685681343, -0.053702618926763535, 0.06193963438272476, 0.05202208831906319, -0.005896827206015587, -0.05917694792151451, -0.0025997261982411146, 0.03397210314869881, 0.001788584515452385, -0.02443726919591427, 0.031110107898712158, -0.0046572936698794365, 0.010433144867420197, 0.043304651975631714, 0.055039115250110626, -0.01842069998383522, 0.017849508672952652, -0.02271772362291813, -0.018722858279943466, 0.002111708978191018, -0.07234187424182892, 0.014224336482584476, 0.015504124574363232, 0.06613621860742569, 0.00483262725174427, -0.03699009120464325, -0.026084275916218758, 0.013143617659807205, -0.0296262726187706, 0.03514299541711807, 0.015445895493030548, 0.0826256275177002, 0.03132748231291771, 0.03723001852631569, -0.03895309567451477, -0.01620583049952984, -0.05168769508600235, 0.003740687621757388, -0.009059385396540165, 0.044089846312999725, 0.07651887089014053, 0.015114809386432171, 0.06029226630926132, -0.026892678812146187, -0.004046994261443615, -0.011036972515285015, 0.059144362807273865, -0.03366059064865112, -0.01890651509165764, -0.0333537794649601, 0.041267700493335724, -0.03025696985423565, -0.05076034739613533, -0.0440438948571682, 0.018760748207569122, 0.028184305876493454, 0.024372873827815056, 0.019504649564623833, 0.007274417672306299, -0.01614447496831417, -0.001418973202817142, 0.04230654612183571, 0.014698422513902187, 0.0036615040153265, 0.03105934150516987, 0.03322303295135498, 0.016720067709684372, -0.04677565395832062, -0.02002340741455555, 0.03476349636912346, 0.0930052101612091, 0.015424232929944992, 0.0038334447890520096, 0.004787738900631666, -0.03037235140800476, 0.009097985923290253, 0.0030131812673062086, 0.01619482785463333, -0.0448489710688591, -0.02816757559776306, -0.07044991850852966, 0.03826053813099861, -0.046321969479322433, 0.016735171899199486, 0.04139798879623413, -0.01661735586822033, 0.05117366462945938, 0.0388805978000164, 0.012141290120780468, 0.05599886551499367, -0.005835844203829765, -0.009023545309901237, 0.04374007508158684, 0.0738796666264534, -0.06646030396223068, -0.07995028793811798, -0.013579522259533405, 0.01071844156831503, -0.052201006561517715, -0.014386684633791447, 0.051324211061000824, -0.034071266651153564, 0.07563266158103943, 0.0077811433002352715, 0.015598397701978683, -0.03183886036276817, 0.014222188852727413, -0.0483032651245594, 0.01694522611796856, -0.02537183277308941, 0.004513309337198734, -0.008129702880978584, 0.09163814038038254, 0.08035885542631149, 0.04459881782531738, -0.029707245528697968, 0.03421866148710251, 0.009385278448462486, -0.03451590612530708, -0.12046153843402863, 0.04307115077972412, -0.03130776807665825, -0.017495766282081604, -0.009574543684720993, -0.06105266883969307, 0.0786057710647583, 0.0009579545585438609, -0.057109933346509933, -0.017423611134290695, 0.06137198954820633, -0.0058728656731545925, 0.028462858870625496, -0.006844738032668829, -0.037641339004039764, 0.00740620493888855, 0.024017300456762314, 0.03632238507270813, 0.04172405228018761, 0.03446986526250839, 0.03594880923628807, 0.06952496618032455, -0.011803491972386837, 0.02167581580579281, -0.02381196618080139, -0.04346216842532158, 0.04144778102636337, 0.025539474561810493, 0.06744668632745743, 0.03880029544234276, -0.010965242050588131, 0.0809725970029831, 0.06374683231115341, 0.045089855790138245, -0.022886715829372406, 0.01664726436138153, -0.018403656780719757, 0.014094693586230278, 0.03577182814478874, 0.018140878528356552, -0.039270009845495224, 0.014865211211144924, 0.005233549978584051, -0.004492594860494137, -0.0027796421200037003, -0.020725777372717857, -0.02341511659324169, -0.05027472972869873, 0.03622286021709442, -0.04127999022603035, -0.009148821234703064, 0.004401316400617361, 0.03604560345411301, 0.015078775584697723, 0.01977173425257206, -0.0036526506301015615, -0.011859187856316566, -0.004353644326329231, -0.03517370671033859, 0.03420337662100792, -0.003638677764683962, -0.006924109533429146, -0.015033649280667305, 0.03568705543875694, 0.02614445984363556, -0.02056037448346615, -0.03732934594154358, 0.06256517767906189, -0.04939517751336098, -0.014900170266628265, -0.0022688466124236584, 0.04834757000207901, -0.004149982705712318, -0.012098885141313076, -0.006569584831595421, -0.01279448065906763, 0.052094969898462296, 0.012713702395558357, -0.004577788524329662, -0.009691853076219559, -0.042816828936338425, -0.06601528078317642, -0.03655168414115906, 0.01766214333474636, 0.0045548384077847, 0.001142248511314392, 0.014405223540961742, 0.0023925055284053087, -0.06419119238853455, 0.006174319889396429, 0.015826664865016937, 0.037035081535577774, -0.006932325195521116, -0.04844995588064194, -0.023476507514715195, -0.03344821184873581, 0.03827156499028206, 0.0012514725094661117, -0.005075779743492603, -0.0012258555507287383, -0.06116044521331787, 0.0006764829740859568, -0.02313821390271187, -0.03676016628742218, 0.07802122086286545, -0.001374338986352086, 0.02689097262918949, -0.04773763194680214, -0.019644495099782944, 0.0214933380484581, 0.05281657725572586, 0.03266029432415962, -0.020307645201683044, 0.02759326621890068, 0.006648701149970293, 0.03664691746234894, -0.01546051912009716, -0.09652356058359146, -0.025893157348036766, -0.010480368509888649, 0.00672216946259141, 0.0027636259328573942, -0.027649404481053352, 0.034828126430511475, 0.013844242319464684, -0.0013159399386495352, 0.04214099422097206, -0.03089791163802147, -0.08828040957450867, 0.06264716386795044, -0.0755983293056488, 0.013789176009595394, -0.047892387956380844, 0.00469557847827673, -0.031915802508592606, -0.032020650804042816, -0.012748101726174355, -0.042840007692575455, -0.02548239193856716, 0.032212406396865845, -0.021765591576695442, -0.016631877049803734, 0.021149130538105965, -0.0007821574108675122, -0.02566314861178398, 0.04131406545639038, 0.029225237667560577, 0.009821170940995216, -0.049448177218437195, -0.02044258639216423, 0.05280687287449837, -0.006239145528525114, 0.02866964414715767, 0.02280019223690033, -0.08159908652305603, -0.0697273313999176, 0.02175847440958023, 0.06029990315437317, 0.03573403134942055, -0.033022958785295486, 0.04929855465888977, 0.0006727079162374139, 0.02372124418616295, 0.06615670025348663, 0.03722512722015381, 0.03321226313710213, -0.08218252658843994, -0.0008556218817830086, -0.0123987328261137, -0.01570417359471321, 0.03635518625378609, 0.03218189999461174, -0.017967967316508293, 0.030327798798680305, -0.022348253056406975, 0.02454022504389286, 0.014675728976726532, -0.035082194954156876, -0.010232392698526382, 0.0059848446398973465, 0.04470701515674591, -0.003571338951587677, -0.017331354320049286, -0.012106871232390404, -0.04525172710418701, 0.005492492113262415, 0.0072921630926430225, -0.05038123577833176, -0.040516309440135956, -0.02085653506219387, -0.0001839757023844868, -0.012590435333549976, -0.0770488977432251, -0.00429542688652873, 0.021558549255132675, -0.057399969547986984, -0.001131169032305479, -0.006674098316580057, 0.07726792246103287, 0.0005686227814294398, -0.04425628483295441, -0.063141368329525, 0.014879807829856873, 0.0008673190604895353, -0.045326586812734604, -0.0017185726901516318, 0.0033757134806364775, 0.034080490469932556, -0.050838761031627655, 0.02736779674887657, 0.011683949269354343, -0.007510335184633732, 0.02091016061604023, 0.060122910887002945, -0.049214888364076614, -0.05954756960272789, -0.04969160258769989, 0.03708447515964508, 0.045536331832408905, 0.03402618691325188, 0.0012050159275531769, -0.05486899986863136, 0.014750204980373383, 0.013274089433252811, 0.008321555331349373, 0.04754515737295151, -0.022325465455651283, -0.025971494615077972, 0.03043287806212902, -0.04850705340504646, -0.05974432826042175, 0.021069712936878204, -0.035131752490997314, 0.023545222356915474, 0.0006177922477945685, 0.023717666044831276, 0.03642138093709946, -0.0609433688223362, 0.019465375691652298, -0.028952518478035927, 0.03941328451037407, 0.01550204772502184, -0.015111683867871761, 0.016863567754626274, -0.024415025487542152, -0.043813545256853104, 0.0077730948105454445, -0.04451591894030571, -0.038066934794187546, 0.011981096118688583, -0.02115372009575367, 0.06527175009250641, 0.016942894086241722, 0.02456597238779068, -0.034764017909765244, -0.05145811289548874, 0.019442837685346603, 0.005679251626133919, -0.03915497660636902, -0.0580051988363266, 0.007079881615936756, 0.016832858324050903, -0.0061940159648656845, 0.042618513107299805, -0.009143455885350704, -0.01571018621325493, 0.0008278840687125921, -0.05522414296865463, -0.04168291389942169, -0.01632462441921234, -0.009873978793621063, -0.008542382158339024, 0.01946515217423439, 0.0018640407361090183, 0.03058970347046852, 0.019319385290145874, -0.009771758690476418, 0.020387103781104088, -0.024176456034183502, -0.043775029480457306, -0.028144586831331253, 0.021561114117503166, 0.001994330668821931, -0.03592365235090256, -0.014959963038563728, 0.017503727227449417, 0.00022175873164087534, -0.02988838031888008, 0.06077711284160614, 0.020281022414565086, 0.026342526078224182, 0.005937868729233742, 0.013857291080057621, 0.03428154066205025, -0.03378329053521156, 0.021817829459905624, 0.006025460083037615, -0.046393368393182755, 0.012485919520258904, -0.023171953856945038, -0.04962780326604843, 0.002296963706612587, 0.08358180522918701, 0.024813299998641014, -0.024147043004631996, 0.02288416400551796, 0.04102146625518799, 0.008543065749108791, -0.05703933537006378, -0.020353391766548157, -0.010054532438516617, -0.0017922166734933853, -0.03919968754053116, 0.012892266735434532, -0.05458259582519531, -0.016626417636871338, 0.0023931756149977446, 0.019897300750017166, -0.0032959727104753256, 0.09340374171733856, 0.0481712631881237, -0.029614249244332314, -0.07541767507791519, 0.005846631247550249, -0.09713714569807053, -0.027571232989430428, 0.06151512265205383, 0.009502844884991646, 0.06002234295010567, -0.041451435536146164, 0.01089845597743988, -0.014900344423949718, -0.009596602991223335, 0.05657538026571274, -0.029133006930351257, 0.013841009698808193, -0.0006529674865305424, 0.035720668733119965, 0.02398649789392948, -0.0360499806702137, -0.003047176403924823, -0.030150705948472023, -0.019169695675373077, -0.029563380405306816, 0.007547994609922171, -0.0398106575012207, -6.473977831804146e-33, 0.04866873100399971, -0.04038460925221443, 0.002136183436959982, 0.06433521211147308, 0.01014774851500988, -0.027259085327386856, 0.02328684739768505, -0.0011121119605377316, 0.06321684271097183, -0.017392132431268692, -0.013479599729180336, -0.008527451194822788, -0.0022583669051527977, -0.015109074302017689, -0.025497177615761757, -0.03549986705183983, 0.02558598853647709, 0.0612560473382473, 0.002410345012322068, -0.018081538379192352, 0.022858237847685814, 0.036982808262109756, 0.006394098978489637, -0.10890736430883408, -0.03059089370071888, -0.017561526969075203, -0.01297131460160017, -0.004583828616887331, 0.03491612523794174, 0.04901767522096634, -0.0011819879291579127, 0.022594090551137924, -0.006157332565635443, 0.02209971286356449, 0.016565218567848206, 0.016981780529022217, -0.08037625253200531, -0.019022244960069656, -0.002459664363414049, 0.04558613523840904, -0.010062970221042633, 0.0005634836270473897, 0.0018361426191404462, -0.003669603029266, -0.036592863500118256, 0.0225314199924469, 0.025571295991539955, -0.03111608326435089, -0.04084019735455513, 0.019020788371562958, 0.051661018282175064, 0.010237820446491241, -0.006222642492502928, 0.02420654520392418, -0.02518453635275364, 0.033338602632284164, -0.022876372560858727, 0.04805959016084671, -0.06978588551282883, 0.030509237200021744, -0.0744035467505455, -0.028475400060415268, -0.04792988300323486, -0.07412567734718323, -0.0034049497917294502, 0.03786008432507515, -0.02826499380171299, -0.019984113052487373, -0.0004904972156509757, 0.010597935877740383, -0.043828126043081284, 0.07435519248247147, -0.013317917473614216, 0.035882316529750824, -0.011589291505515575, -0.06272853910923004, -0.027509693056344986, 0.0659099593758583, 0.013697680085897446, -0.03078213706612587, 0.014504844322800636, 0.041744671761989594, -0.012355903163552284, -0.0010426166700199246, 0.0813688263297081, -0.030637279152870178, -0.03994559496641159, -0.039641834795475006, -0.015101042576134205, 0.05345657467842102, -0.025869086384773254, 0.020351087674498558, -0.049297090619802475, -0.05726772919297218, -0.027586819604039192, -0.019998058676719666, -0.011595972813665867, -0.02059105411171913, 0.019689615815877914, -0.0009828000329434872, -0.003554734867066145, -0.0094029251486063, -0.03160097077488899, -0.045336365699768066, -0.026829924434423447, -0.015285791829228401, 0.05837082117795944, 0.04071393236517906, -0.0003145765222143382, -0.022596070542931557, 0.05488400533795357, -0.053989458829164505, -0.02404532954096794, -0.032276298850774765, 0.00018939972505904734, 0.03752131760120392, -0.03424626216292381, 0.053967565298080444, -0.016983848065137863, 0.06919088214635849, -0.018848415464162827, -0.09963175654411316, 0.016847817227244377, -0.03295276314020157, -0.013614222407341003, -0.054796572774648666, -0.04099287837743759, 0.003612932749092579, 0.05486011505126953, -0.01956317387521267, -0.03827071189880371, -0.06489678472280502, 2.8325067091827805e-07, -0.02427743375301361, 0.02085692621767521, -0.06322718411684036, -0.06935057789087296, 0.01261019054800272, 0.019053518772125244, 0.0012537589063867927, 0.030232679098844528, -8.604230242781341e-05, 0.08174387365579605, 0.031221700832247734, -0.011559272184967995, 0.009371091611683369, 0.051419731229543686, -0.009764819405972958, -0.02125134877860546, -0.042214151471853256, -0.03650698810815811, -0.03470054641366005, -0.003097217995673418, -0.01672152616083622, 0.03811018913984299, 0.07940031588077545, 0.007589952554553747, -0.004103079903870821, 0.013596149161458015, 0.008586278185248375, -0.04461744427680969, -0.014206808991730213, -0.08120688796043396, 0.05694115534424782, 0.022103644907474518, -0.027874348685145378, -0.017822664231061935, -0.045368339866399765, 0.006647674832493067, 0.018134774640202522, -0.03813131898641586, -0.010985526256263256, 0.012356894090771675, 0.009028041735291481, -0.003439873456954956, 0.003970211371779442, -0.040125686675310135, 0.06587804108858109, 0.054589834064245224, -0.0353698804974556, -0.006995783187448978, -0.0008852049941197038, -0.00821065716445446, 0.03308425471186638, 0.019845347851514816, -0.03693679720163345, 0.001992064993828535, 0.01466990914195776, -0.009180956520140171, -0.0194611344486475, -0.003383927745744586, 0.02036263793706894, -0.025259297341108322, 0.013861525803804398, -0.014024305157363415, -0.046075161546468735, 0.04090484604239464, 0.02913476899266243, 0.01564711704850197, 0.03480913117527962, 1.9389331618769862e-34, -0.01789412461221218, 0.06229133531451225, -0.01441046129912138, -0.09597881138324738, 0.012423744425177574, -0.04751678928732872, -0.02726837433874607, -0.012497755698859692, 0.041135527193546295, 0.027647322043776512, -0.01409580186009407]",0,Recommender Systems
Creating synthetic datasets for collaborative filtering recommender systems using generative adversarial networks.pdf,knowledgebased systems available online september the authors published by elsevier bv this is an open access article under the cc by license httpcreativecommonsorglicensesby contents lists available at sciencedirect knowledgebased systems journal homepage wwwelseviercomlocateknosys creating synthetic datasets for collaborative filtering recommender systems using generative adversarial networks jesús bobadilla a abraham gutiérrez a raciel yera b luis martínez b a departamento de sistemas informáticos etsi sistemas informáticos universidad politécnica de madrid c alan turing sn madrid spain b departamento de informática universidad of jaén jaén spain a r t i c l e i n f o keywords recommender systems generative adversarial networks deep learning collaborative filtering a b s t r a c t research and education in machine learning requires diverse representative and open datasets that contain sufficient samples to handle the necessary training validation and testing tasks currently the recommender systems area includes a large number of subfields in which accuracy and beyondaccuracy quality measures are continuously being improved to feed this research variety it is both necessary and convenient to reinforce the existing datasets with synthetic ones this paper proposes a generative adversarial network ganbased method to generate collaborative filtering datasets in a parameterized way by selecting their preferred number of users items samples and stochastic variability this parameterization cannot be performed using regular gans our gan model is fed with dense short and continuous embedding representations of items and users instead of sparse large and discrete vectors to ensure fast and accurate learning as compared to the traditional approach based on large and sparse input vectors the proposed architecture includes a deepmf model to extract the dense user and item embeddings and a clustering process to convert the dense gan generated samples to the discrete and sparse samples necessary to create each required synthetic dataset the results from three different source datasets show adequate distributions and expected quality values and evolutions in the generated datasets compared to the source datasets synthetic datasets and source codes are available to researchers introduction recommender systems rs are a relevant area in artificial intel ligence due to the growing popularity of social networks the big companies that extensively use rss are tripadvisor netflix spotify youtube music tiktok youtube and amazon these companies make use of the rs models to recommend to users similar items music videos trips news to those that they have already consumed some other companies such as facebook work hard to collect customer activity to provide personalized advertising rather than personalized products or services rss are usually classified according to their filter ing approach contentbased rss select the recommended items by looking for similar content since most item contents is text natural language processing models are used reviews and tweets are two common types of contentbased filtered data product images can also be processed to make recommendations convolutional neural networks are the most commonly used models to perform this task social filtering has been extensively used to improve socialbased rec ommendations this type of filtering uses data such as tags followers corresponding author email addresses jesusbobadillaupmes j bobadilla abrahamgutierrezupmes a gutiérrez ryeraujaenes r yera martinujaenes l martínez and being followed and makes use of the concepts of reputation and trust geographic information such as gps coordinates and poi is mainly used to support contextaware filtering demographic filtering age gender country etc is commonly combined with other types of filtering implementing recommendation ensembles be yond the previous filtering strategies collaborative filtering cf is the most important approach for implementing rss since it provides superior accuracy particularly when combined with some other types of filtering effective rs research makes use of innovative models adequate quality measures and representative datasets the historical evolution of cf begins with the use of memorybased models mainly the knearest neighbors algorithm memory based approaches were replaced by modelbased machine learning approaches due to their overall performance they are superior in accu racy of results also in time to obtain predictions once the model has learned and their output is capable of being explained through post hoc techniques matrix factorization mf is the most widely used machine learning model to implement collaborative filtering it performs a dimensional reduction of users and items capturing the httpsdoiorgjknosys received december received in revised form september accepted september knowledgebased systems j bobadilla et al main patterns that relate them to the votes cast additionally by using nonnegative matrix factorization nfm semantic meanings can be assigned to latent factors bayesian nmf allows clustering users and making predictions simultaneously which opens the door to effective recommendations to user groups and social clustering appli cations nowadays cf research is mainly developed by deep learning models where deepmf is the basis for modern approaches deepmf is the model that we use in this paper in which users are coded in a latent space by means of an embedding layer whereas items are coded in a different latent space by means of a second embedding layer finally predictions are made by making the dot product of both item and user embeddings deepmf improves mf due to the inherent competence of neural networks to capture the nonlinear relations hips between samples neural collaborative filtering ncf is extensively used to implement cf this model replaces the deepmf dot layer with a multilayer perceptron mlp and outperforms deepmf when applied to large and complex datasets beyond accuracy deep learning models are emerging to perform some innovative tasks such as improving fairness where the deepfair model achieves a tradeoff between equity and precision green computing results explanation via latent space visualization and efficient neighborhood identifica tion the adversarial networkbased recommendation has recently been introduced in the rs area and we will focus on it in the related work section generative adversarial networks gan are responsible for the popular fake faces and fake videos that flood social networks their architecture has two separate neural networks that compete against each other adversarial such as an art forger competing against an art expert ensuring that both improve their work the gan forger is a generator model that creates fake samples from random noise vectors while the gan expert is a discriminator model implemented as a simple binary classifier fake nonfake however while rs research is mainly focused on proposing novel recommendation models this paper tries to make progress in cf datasets in this respect it is essential to identify quality measures as a key element to carry out adequate research since they allow the baselines of the state of the art to be compared with the proposed algorithms methods and models beyond the usual prediction and recommendation quality measures mae msd precision recall f ndcg etc some other measures such as novelty and diversity have recently acquired growing importance of these diversity is cur rently the main focus of researchers attention due to the risks of inappropriate recommendations in social networks such as those that exhibit a lack of variability and promote prefixed ideas and behaviors diversity and reliability in rs have been improved by introducing diversityenhancing constraints in the mf model additionally a deep learning classification model is proposed to obtain the recommendation reliability values from the softmax output layer of the neural network quality values are obtained when a model or method is tested on balanced cf datasets to obtain balanced training and testing sets with respect to their user and item distributions deterministic strategies are proposed in most of the rs research makes use of popular cf datasets such as movielens filmtrust myanimelist or citeseer cf datasets include different domains such as music movies pois tourism news research papers tagged data etc some of these datasets have been filled with explicit votes from users while others contain implicit interactions between users and systems there are also datasets filled with crawled web pages or academic pdfs and some others are enriched with social tags that researchers add to the ar ticles a selection of relevant social cf datasets is provided in and related to some articles using them recently an educational news dataset was released which included contextualized information time and location finally an rs dataset has also been provided that contains artificial intelligence research data to obtain segmented information clustering and geographical locations beyond these works it is particularly relevant that parameterized synthetic datasets have not yet been used so consequently the cf research does not benefit from the flexibility that parameterization provides in the experiment design different dataset sizes number of users and items and so on this paper aims to fill the gap by proposing a procedure coined as ganrs which focuses on the use of gans to generate collaborative filtering recommender systems datasets in a parameterized way please note that current rs ganbased models cannot simultaneously set the number of generated users items and rating distributions regarding our contribution two main overall approaches can be identified in the stateofart statistical and generative the main ad vantage of the statistical approach is that several relevant parameters can be simultaneously set number of users number of items dataset size etc the main drawback of this approach is its poor accuracy on the other hand current modelbased generative approaches improve accuracy compared to statistical frameworks but they lack flexibility since parameterization is very limited in fact current gan designs are focused on user profiles and they can generate as many new fake users as required but other relevant parameters cannot be set such as the number of items that is fixed in the source set of user vectors and then also in the fake generated set of user vectors this can be explained with an example when we run a regular gan to generate fake images the synthetic images have the same shape resolution and number of channels as the source images in the rs field the synthetic user vectors contain the same number of items as the real user vectors following the example there are some specific gan designs that return superresolution images they can increase resolution but to our knowledge there are no rs gans designed to generate fake users containing more items or fewer items our proposed method is designed to simultaneously set some cf relevant parameters such as the number of users and items the rest of the paper has been structured as follows related work is introduced in section focusing on the most recent uses of the gan models applied to rs section explains the proposed model and its formalization section presents the design result and discussion of the experiments finally section contains the main conclusions of the article and discusses future work background basics on generative adversarial networks gans are designed to generate data from scratch they have been commonly used to create fake images although their use has been spreading to many other domains music medicine financial data etc the gan architecture composes of two deep network models generator and discriminator the generator model learns to create samples as similar as possible to those in a dataset eg a dataset with human faces images whereas the discriminator model learns to detect fake samples those samples created by the generator to better understand the gans we can consider the example of a painting forger and a forgery expert the more imitations the forger paints the better their results and the better the experts ability to detect fake paintings both people successively improve their abilities when the learning begins the gan discriminator the forgery expert in our example has an easy job since the generator does not have the painting patterns after thousands of learning epochs the generator has learnt the patterns well enough to confuse the discriminator who is forced to tune their weights if the learning loop iterates enough times both the generator and the discriminator models are well designed and the painting in the dataset contains suitable patterns the generator will be able to create synthetic fake samples that are difficult to distinguish from the originals fig shows the gan architecture the discriminator model makes a binary classification between fake and real samples the generator model updates its weights learns when the discriminator correctly classifies a fake sample the discriminator model updates its weights when it incorrectly classifies a sample note that the generator takes a random noise distribution as input to generate samples then knowledgebased systems j bobadilla et al fig generative adversarial networks architecture once it has learnt for each input random noise vector that feeds the generator a sample is created with the patterns of the dataset samples for this reason by providing random noise vectors we can create as many samples as required which means that in our context we can create fake cf datasets of any size by creating fake profiles to measure gan loss we use crossentropy the discriminator 𝐷 loss can be expressed as the sum of the expectations 𝑚𝑎𝑥𝐷𝑉𝐷 𝐸𝑥𝑝𝑑𝑎𝑡𝑎𝑥𝑙𝑜𝑔𝐷𝑥 𝐸𝑧𝑝𝑧𝑧𝑙𝑜𝑔 𝐷𝐺𝑧 where the first term of the equation is used to recognize real images and the second term recognizes generated images 𝑍represents the noisy vector 𝐺is the generator and 𝐺𝑍 is the generated sample 𝐷𝐺𝑧 is the classification result of the discriminator when its input is a fake sample 𝐷𝑥 is the classification result of the discriminator when its input is a real sample the generator loss is designed to learn when the discriminator correctly classifies the true label is and the fake label is its equation is 𝑚𝑖𝑛𝐺𝑉𝐺 𝐸𝑥𝑝𝑑𝑎𝑡𝑎𝑥𝑙𝑜𝑔 𝐷𝐺𝑧 the gan is a minimax in which 𝐺wants to minimize 𝑉while 𝐷 wants to maximize it 𝑚𝑖𝑛𝐺𝑚𝑎𝑥𝐷𝑉𝐷 𝐺 𝐸𝑥𝑝𝑑𝑎𝑡𝑎𝑥𝑙𝑜𝑔𝐷𝑥 𝐸𝑧𝑝𝑧𝑧𝑙𝑜𝑔 𝐷𝐺𝑧 as in the previous example gan models act on non sparse values eg pixels in a picture but they are not designed to work with sparse vectors or matrices our problem here is that cf datasets contain extraordinarily sparse matrices of ratings users only vote or consume a very limited number of the available items using the regular gan architecture is not an adequate approach to addressing cfbased rs this paper proposes an extended gan architecture where embeddings are introduced to code the sparse and discrete vectors of votes to dense and continuous vectors this innovation makes it possible to use a regular gan to generate dense and continuous vectors efficiently and accurately this compression stage forces us to design the corre sponding stage to decompress the generated dense vectors the adopted solution makes it possible to set both the number of users and items in the generated dataset which is a relevant innovation in the stateofart related works generative deep learning is an innovative field in the cf rs area although some variational autoencoder approaches have been pub lished current research is mainly focused on gan models a cf subfield where gans are used is the attackdefense strate gies where these models can reinforce security in rs neverthe less the most extended uses of cf gans are a to solve the issue of noisy data and b to tackle the data sparsity problem and implement a data augmentation framework by capturing the distribution of real data cfgan is a model that generates purchase vectors rather than the ids of items and then uses the generated fake purchase vectors to augment the real vectors the wasserstein version of cfgan is the unified gan ugan and reports improvements compared to cfgan to prioritize long and shortterm rs information inter actions between users and items that change quickly or slowly the plastic model trains a generator and uses it as a reinforcement learning agent the recurrent gan recgan learns temporal patterns in ratings combining gan and recurrent neural networks rnns models to capture negative sampling information in the cf datasets ipgan implements two different generative models one for positive instances and another for negative instances ipgan considers the relations between the positive ratings sampled and the negative ones selected currently the dcgan model combines gan and reinforcement learning models to catch the information of the rs sessions rather than the traditional historical matrices of votes from users to items session information includes the responses of users to current recommenda tions the users immediate feedback is managed by the reinforcement learning model combined with the gan the ncgan incorporates a neural network to extract nonlinear features from users and a gan to guide the recommendation training the generator model makes user recommendations whereas the discriminator model measures distances between real and generated distributions an innovative method to improve the information flow from generator to discriminator reduces the discrepancies between both models in the cf gan a regularization wasserstein gan model is used in combined with an autoencoder acting as a generator reporting accuracy improvement when applied to highdimensional and sparse cf matrices a cgan conditional gan is used to improve cf recommendations and the sizes of the rating vectors can be set simplifying the generator and discriminator tasks additionally it allows conditional rating gen eration to be established for datasets that do not follow standard gaussian distributions a missing data imputation based on gan is proposed results show improved quality in several representative clas sification data sets trust information is used in to make effective recommendations they propose a gan where the discriminator is an mlp model and the generator is a longshort term memory network lstm model finally cf datasets are usually imbalanced due to their social data collection eg more young people than old people to address this limitation proposes a wasserstein gan model in the generator and the pacgan concept in the discriminator to minimize the mode collapse problem a platform for multiagent rs simulation is the probabilisticbased recsim which generates synthetic profiles of users and items and uses markov chains and recurrent neural networks the virtual taobao is a multiagent reinforcement learning system designed to improve search in the social taobao website it makes use of a knowledgebased systems j bobadilla et al gan to simulate internal distributions a simple matrix factorization is used to inject topic diversification into the recommendation pro cess the datagencars is a javabased generator of rs synthetic data it contains a statistical basement that provides flexibility but it returns low accuracy compared to deep learning generative models finally the synevarec framework provides the generation of synthetic rs datasets using the synthetic data vault svd library this library models multivariate distributions using copula functions its ctgan sublibrary includes gan models the main advantage of synevarec compared to previous frameworks is that it can use different rss as a source its main drawbacks are the poor quality of the results in most of the cases and the excessive time it takes to perform the training stage previous research mainly focuses on improving different objectives such as noise reduction recommendation quality prediction values defense against attacks or balancing data to make this happen many different approaches and information sources have been combined the use of gan cgan wasserstein gan etc gan models have been combined with recurrent neural networks and lstm net works and reinforcement learning has been introduced in the ganbased architectures long and short data have been introduced to the proposed models in addition to trust information session logs including responses of the users to previous recommendations and inferred negative votes the pure generation of synthetic datasets does not seem to be a goal in this novel field of gan applied to cf rs which is currently focused on improving prediction and recommendation quality results by means of data augmentation based on the inherent ability of the gan model to capture the complex nonlinear patterns of highdimensional and sparse cf datasets the innovation of our proposal is to generate representative and useful cf synthetic datasets rather than to improve the existing results that are of varying quality additionally it allows representative parameters to be set and a whole family of synthetic datasets to be obtained taking real datasets as a source such as movielens netflix or myanimelist these parameters are the number of users the number of items the number of samples and the variability of the generated data by varying the parameter values we can generate different versions of the same cf pattern such as a movielensbased dataset containing users and items or another that contains users and items among others in this way we can test the accuracy and performance impact of the dataset size its sparsity its number of users and items as well as check the improvement of the mae when the number of users increases as far as we know there are no published methods or models for creating in a parameterized deep learning model accurate and scalable synthetic datasets from diverse sources the generative adversarial networksbased approach for data sets building in collaborative filtering as previously mentioned in the introduction section our research problem is defined as obtaining a larger scalable synthetic dataset from an original rs dataset that synthesizes similar user behavior and valuation patterns in relation to the original dataset in addition it is desirable that such generation be parameterized allowing the number of users items samples and variability of the distribution to be controlled next this section proposes the ganrs method which uses a gan network to generate synthetic cf datasets the gan is fed with a real cf dataset and the model learns its internal patterns the most innovative contribution is to feed the gan with dense and small embedding representations of users and items instead of the traditional approach where the gan inputs are large and comprise sparse vectors containing the votes cast for each user the main advantage of the ganrs method is that it greatly reduces the complexity of the gan architecture its convergence speed and its performance the traditional and sparsebased gan architectures deal with very large input vectors as large as the number of items in the dataset which can be in the tens of thousands and require a very large dense layer in the model to hold this huge amount of data what is more between to of the data is usually missing since users only vote for or consume a tiny proportion of the available products or services hence the extraordinary sparsity in the cf datasets following the huge dense layer in classical gan architectures it is necessary to stack a large multilayer perceptron to reduce dimensionality by comparison the proposed model replaces the large dense layer with two embeddings one to code users and the other to code items bor rowed from the deepmf model in the first stage of the proposed method embedding layers are specifically designed to deal with sparse data they receive integer values user and item ids in our case and they provide small embedding representations typically to float values in the cf scenarios related users or items share similar embedding representations and this feature allows for extraordinarily simplification of the model overall the proposed architecture is much smaller than traditional architectures it contains far fewer parameters and consequently learns faster additionally it better captures the complex nonlinear relations between items and users in the same way that nongan rs models do to improve predictions the formalization of the ganrs method is presented and structured according to the following seven stages also illustrated in fig stage cf definitions let 𝑈be the set of users who make use of a cf rs let 𝐼be the set of items available for voting in the cf rs let 𝑉be the range of allowed votes usually 𝑉 let 𝑆be the set of samples contained in the cf dataset in which 𝑁 𝑆 𝑡ℎ𝑒𝑡𝑜𝑡𝑎𝑙𝑛𝑢𝑚𝑏𝑒𝑟𝑜𝑓𝑣𝑜𝑡𝑒𝑠𝑐𝑎𝑠𝑡 𝑆 𝑢 𝑖 𝑣 𝑢 𝑖 𝑣 𝑢 𝑖 𝑣𝑁 where each 𝑢 𝑈 each 𝑖 𝐼 and each 𝑣 𝑉 stage deepmf training let e be the size of two neural layer embeddings used to vectorize each user and each item belonging to 𝑈and 𝐼 respectively let 𝑓𝑒𝑢𝑢 𝑒𝑢 𝑒𝑢 𝑒𝑢 𝐸 where 𝑓𝑒𝑢is the embedding layer output of the users where 𝑢 𝑈 let 𝑓𝑒𝑖𝑖 𝑒𝑖 𝑒𝑖 𝑒𝑖 𝐸 where 𝑓𝑒𝑖is the embedding layer output of the items where 𝑖 𝐼 by com bining both dense vectors of user and item embeddings 𝑒𝑢 𝑒𝑢 𝑒𝑢 𝐸 and 𝑒𝑖 𝑒𝑖 𝑒𝑖 𝐸 we can make rating pre dictions in the deepmf training stage the dot product of the user embedding and the item embedding in each 𝑢 𝑖 𝑣𝑗𝑆provides its rating prediction 𝑦𝑗 𝑓𝑒𝑢𝑢 𝑓𝑒𝑖𝑖 𝑒𝑢 𝑒𝑢 𝑒𝑢 𝐸 𝑒𝑖 𝑒𝑖 𝑒𝑖 𝐸 𝑦𝑗𝑦𝑗 is the output error used in the deepmf neural network to start the backpropagation algorithm where the neural weights are iteratively improved from the 𝛿𝑗values 𝑤𝑗𝑖 𝛼𝑦𝑗𝑓𝑁𝑒𝑡𝑖 𝑘𝑤𝑖𝑘𝛿𝑘 when 𝑘is a hidden layer and 𝑤𝑗𝑖 𝛼𝑦𝑖𝑓𝑁𝑒𝑡𝑖 𝑦𝑘𝑦𝑘 if 𝑘is the output layer i j and k are successive sequential layers 𝑁𝑒𝑡𝑖 represents the cumulative input received for an artificial neuron 𝑁𝑒𝑡𝑖 𝑗𝑦𝑗𝑤𝑗 where 𝑗is the index of the neurons in the layer preceding the current neuron stage deepfm feedforward once the deepmf has learned we can collect the embedding representation of each user and each item in the cf rs let 𝐸 𝑢 𝑒𝑢 𝑒𝑢 𝑒𝑢 𝐸 𝑢 𝑈 be the set of embeddings for all the rs users 𝑢𝑈 one to u let 𝐸𝑢 𝑒𝑢 𝑒𝑢 𝑒𝑢 𝐸 knowledgebased systems j bobadilla et al fig the stages of the proposed ganrs method let 𝐸 𝑖 𝑒𝑖 𝑒𝑖 𝑒𝑖 𝐸 𝑖𝐼 be the set of embed dings for all the rs items 𝑖𝐼 one to i let 𝐸𝑖 𝑒𝑖 𝑒𝑖 𝑒𝑖 𝐸 stage setting the dataset of embeddings let 𝑅 𝐸𝑢 𝐸𝑖 𝑣 𝑢 𝑖 𝑣𝑗𝑆be the embedding based dataset of real samples stage gan training let 𝑓𝐷be the discriminator d model belonging to a gan model let 𝑓𝐺be the generator g model belonging to a gan model let 𝑓𝐺𝐷be the optimization function of the gan model 𝑓𝐺𝐷 𝑀𝑖𝑛𝐺𝑀𝑎𝑥𝐷𝑓𝐷 𝐺 𝐸𝑅𝑙𝑜𝑔𝐷𝑅 𝐸𝑧𝑙𝑜𝑔 𝐷𝐺𝑧 where 𝐸𝑅is the expected value for real samples 𝑧is the random noise that feeds the generator 𝐺 and 𝐸𝑧 is the expected value for the generated fake profiles 𝐺𝑧 note that 𝑅refers to stage gan generation let 𝐹 𝑓𝐺𝑧 be the generated dataset of fake samples from different random noise vectors 𝑧 stage clustering of items and users let 𝐾be the number of clusters used to group the embed dings of the users let 𝐾be the number of clusters used to group the embeddings of the items let ℎ𝑢 𝑐𝑐 𝐾 be the clustering operation that assigns a centroid to each user let ℎ𝑖 𝑐𝑐 𝐾 be the clustering operation that assigns a centroid to each item stage setting dataset of item ids and user ids let h be the item ids and users ids discrete dataset ob tained from the embeddingbased dataset f of fake sam ples 𝐻 ℎ𝑢 ℎ𝑖 𝑣𝐸𝑢 𝐸𝑖 𝑣𝐹 let 𝑆 𝐻 be the synthetic generated dataset version of h where duplicated samples are removed let 𝐺 ℎ𝑢 ℎ𝑖 𝑣𝐻ℎ𝑢 ℎ𝑖 𝑣𝐻 where ℎ𝑢 ℎ𝑢 ℎ𝑖 ℎ𝑖 𝑣𝑣 fig shows the seven designed stages to generate different syn thetic datasets from real datasets movielens netflix etc stage top left graph in fig shows the training of a deepmf model used to set both the embedding layer of users and the embedding layer of items basically embedding layers in a neural network efficiently convert an input from a sparse representation into an output dense representation for each input sample 𝑢𝑠𝑒𝑟 𝑖𝑡𝑒𝑚 𝑟𝑎𝑡𝑖𝑛𝑔in the training set the output dot layer combines the embedding layer values to predict the rating value and to obtain the output error rating prediction that will we backpropagated to update the learning parameters steps to formalize these concepts once the deepmf model has learned stage top right graph in fig shows the deepmf feedforward process where each item id from one to the number of items in the dataset range 𝐼 feeds the item embedding which outputs the item id dense representation usually cf embedding vectors have a size from to the same applies to user ids as input and their output dense representations please note that the number of items in the dataset will be different from the number of users steps to explain this second stage the purpose of the third stage is to convert the source sparse cf dataset into its dense representation to accomplish the task for each source 𝑢𝑠𝑒𝑟 𝑖𝑡𝑒𝑚 𝑟𝑎𝑡𝑖𝑛𝑔sample in the dataset eg we replace the user id in this example with its related dense representation the same applies for the item id using embeddings of size the result in the example could be such as knowledgebased systems j bobadilla et al table example of samples representation sparse dense stage in fig shows an illustrative example step formalizes the operation the dense dataset obtained will be used in stage to train a gan capable of generating fake user and item profiles as well as their associated rating values which will be even at this stage the ratings that will be in the dataset generated at the end of the proposal our gan will use the stage dense dataset to train the discriminator by providing it with the necessary real samples the gan generator takes gaussian random noise as input and iteratively learns how to generate increasingly good fake profiles capable of cheating the discriminator model once the generator and the discriminator have learnt the generator can convert input noise vectors into dense samples that mimic the patterns of the real dataset provided in stage stage is formalized in steps to the last stage in fig bottom left graph uses the trained gan generator model stage to generate as many fake samples as desired we feed the generator with successive vectors of random noise values following a gaussian distribution and the generator outputs successive fake dense samples following the patterns of the real dataset obtained in stage the higher the standard deviation of the gaussian distribu tion the higher the variety of individual values in the generated dense fake samples as an example a low standard deviation value in the ran dom noise gaussian distribution leads to a higher proportion of votes ranging from to while choosing a high standard deviation value will produce a higher density of votes and ratings are generated in the same way as items and users they are coded in the dense embedding generated by the gan synthetic ratings are continuous values whereas real ratings are discrete usually in the range to make this conversion a function assigns the maximum value in the range usually to the synthetic continuous values greater than it analogously the function assigns the minimum value usually to the continuous values lower than it finally a round function is performed to ensure discrete values step formalizes the generation of fake samples although the ganrs method could be considered complete this is not the case because our goal is to generate fake datasets of sparse samples such as movielens or netflix it is then necessary to convert from the obtained dense representation in stage to the usual sparse representation seen in stage the process is not straightforward since all the dense representations of the fake samples are different from each other this will be better explained using the example in table it can be observed that user two first rows has very similar dense embedding values but there are not identical since the gan generator is not able to create the same exact values from the noise input vectors the same situation occurs in table for the item with id consequently the ganrs method provides a way to group similar dense embeddings into a unique id that is to convert the dense bold vectors of the user in table into a unique user id need not be and the dense bold vectors of the item into a unique item id need not be either to group similar dense embeddings into a unique id a kmeans clustering has been chosen this algorithm has the relevant feature that a number k of clusters must be chosen a priori and it is very con venient in this context since in this way we will have the opportunity to establish the number of users and the number of items in the ganrs synthetic generated dataset stage of fig shows this concept where table main parameter values of the tested datasets dataset users items ratings scores sparsity movielens k to netflix to myanimelist to 𝐾has been selected as number of users and 𝐾has been selected as number of items two separate kmeans processes are run one to group user embeddings and the other to group item embeddings steps to formalize these two clustering processes to better understand this stage we can consider an example where one million fake samples have been generated and we want to create a synthetic dataset containing two thousand fake users and one thousand fake items to accomplish this task we should obtain two thousand groups collected from the one million user vectors the same for the one thousand item groups on average five hundred user vectors could be assigned to each user group and analogously one thousand item vectors to each item group but we know that this depends on the user and item vector patterns to adequately accomplish the grouping task machine learning provides us with clustering algorithms of which the kmeans allow us to set the number of desired groups two thousand for users and one thousand for items in our example running both clustering processes one for users and the other for items we can assign a fake user id to all the fake user vectors in each cluster please note that the id number can be assigned at random to each of the two thousand clusters the same for the one thousand item ids fig illustrates the concept where graphs at the top show the two kmeans clustering processing performed in the proposed model one to group item vectors yellow circles and the other one to group user vectors orange circles gray ellipses represent the kmeans clustering groups all the fake user vectors in each cluster collapse into the same user vector which codes a sample representative of its group and is different from the samples in the rest of the clusters same for items in this way we obtain the selected representative k users and k items the graphs at the bottom in fig show the final stages of the proposed method stage draws the k clusters of users and the k clusters of items from the previous clustering with blue circles each of the k clusters of users groups a set of user vectors columns of orange squares and each of the k clusters of items groups a set of item vectors columns of yellow squares each cluster of user vectors collapses into a representative user at the bottom of stage graph the same for items once the representative users and items are set we can generate the fake dataset of embeddings by translating each generated embedding sample bottomright graph to its equivalent representative concatenated embedding of representative collapsed users and items at the bottom of the stage graph previously we illustrated a case where a generated sample collapses its item vector in the item representative code vector of red squares and it collapses its user vector in the user representative code vector of brown squares in stage the complete embedding and the translation to the sparse tuple codification can be seem this is also true for the following fake embedding which collapses in the item green and user blue generating the sparse tuple note that the gan generated profiles bottomright in fig are not limited to a fixed number of users and items whereas their stage version bottomleft in fig are limited to the ranges 𝐾 and 𝐾 making it possible to preset the number of users and items of the synthetic dataset the seventh stage in fig converts dense fake samples coming from stage into sparse samples 𝑢𝑠𝑒𝑟 𝑖𝑡𝑒𝑚 𝑟𝑎𝑡𝑖𝑛𝑔 to accomplish this task for each sample in the dense representation we replace its user vector with its centroid number from to 𝐾 and its item vector with its centroid number from to 𝐾 the rating value remains the same as that already generated by the framework in stages knowledgebased systems j bobadilla et al fig top graphs clustering process to collapse user and item similar vectors into their representative user and item representations bottom graphs translation from unlimited fake limited profiles to profiles in the range 𝐾 𝐾 𝑟𝑎𝑡𝑖𝑛𝑔 fig shows an example of this operation formalized in step please note that repeated samples will appear in the previous discretization process since the gan generator can create very similar dense samples that will be converted to the same discrete encoding there are several factors that modulate the number of repeated samples such as the number of generated samples the embedding size the size of the noise vector and the standard deviation of the gaussian distribution but the most relevant factor is the number of chosen users or items 𝐾and 𝐾 the lower the 𝐾 the higher the number of repeated samples when the number of users or items is low the average number of samples grouped in each cluster is high step formalizes the process of removing repeated discrete samples finally the ganrs method can generate a small proportion of samples in which different votes are cast from the same user to the same item eg this could be considered as a convenient behavior code a higher range of votes in the example or express a change in the users opinion these cases can be unchanged changed or removed step formalizes their removal operation overall it is important to keep in mind that new rating values are initially calculated in the context of stage of the proposal where gan is used for generating the fake samples of pairs 𝑢𝑠𝑒𝑟 𝑖𝑡𝑒𝑚 𝑟𝑎𝑡𝑖𝑛𝑔 using the user and item embeddings obtained in the previous stages as a base afterward our methodology refines the obtained data to assure consistency stages appendix a table shows the main parameter and hyperparam eter values used to design both the models deepmf and gan involved in the proposed ganrs method experiments and results evaluating the quality of the generated datasets and comparing them with stateofart synthetic datasets is not straightforward since the traditional measures only cover distribution probabilities this is the case of the kullbackleibler kl divergence 𝐷𝐾𝐿𝑃𝑄 where 𝑃and 𝑄are two probability distributions in our context we face two main drawbacks to applying the kl divergence or any similar divergence measure 𝑃and 𝑄are not distribution probabilities they are datasets and a low 𝐷𝐾𝐿value does not mean that 𝑄the generated dataset is a good synthetic dataset obtained from 𝑃the source dataset in fact if 𝐷𝐾𝐿 usually 𝑃 𝑄 which is not a useful result of course each cf dataset contains a reduced number of representative distribution probabilities including rating user and item distributions 𝑄𝑢 𝑄𝑖 𝑄𝑟 but comparing each distribution of the generated dataset with the corresponding distribution of the source dataset has the same intrinsic problem as explained above 𝐷𝐾𝐿𝑃𝑢 𝑄𝑢 𝐷𝐾𝐿𝑃𝑖𝑄𝑖 𝐷𝐾𝐿𝑃𝑟𝑄𝑟 does not mean that 𝑄is a suitable synthetic dataset with regard to 𝑃 indeed 𝑄must have a certain degree of variability regard to 𝑃 a common alternative approach that is used to deal with these situations is testing the quality results in the specific domain in our case mae precision recall etc results should be interpreted according to graph trends rather than absolute values since better results just mean that 𝑄patterns are less complicated than 𝑃ones and worse results tell us that 𝑄 patterns are more complicated than 𝑃ones which scenario is better it depends on the objectives of the scientist that generates the synthetic datasets addressing the concerns explained we provide a complete set of comparative graphs between the source 𝑃 and generated datasets 𝑄 including probability distributions of the user item rating and precision and recall trends designing specific quality measures that maximize each scientists objectives required distribution variability required complexity in the resulting patterns etc is challenging re search and would help compare stateofart generative approaches but this is out of the scope of this paper in this paper we evaluate the suitability of the presented procedure focused on building synthetic datasets first the traditional data sets to be used as a starting point for the present procedure are presented as well as a description of the experiments to be performed subsequently the obtained results are presented and discussed experiments to test the behavior of the proposed ganrs method we will use three representative and open datasets in the cf field movielens netflix and myanimelist we have chosen the k version of movie lens and a reduced version of the complete netflix dataset netflix available in table shows the main parameter values for these datasets a complete set of experiments has been run using netflix whereas only a subset of these experiments is shown for movielens and myanimelist to reduce the size of the paper results from the movielens and myanimelist tests are summarized at the end of this section each of the three source datasets is used to generate its corre sponding synthetic version setting different numbers of users items and samples and changing the standard deviation of the gaussian random noise knowledgebased systems j bobadilla et al table parameter values of the synthetic datasets generated by gan source netflix std users items std users items std users items samples m k k m m experiments have been carried out using the neural deepmf model training validation and testing sets have been obtained for all the real datasets netflix myanimelist and movielens k and their corresponding synthetic datasets the source code to train the model and test the results is the same for both the real and generated datasets ensuring the consistency of the graphs in the comparative figures figs a b b e b and e table shows the gan generated synthetic datasets used to test the proposed ganrs method using netflix as source data the columns show the number of the generated datasets std is the stan dard deviation used in the random noise gaussian distribution users and items are the total number of users and items chosen to generate each dataset samples is the number of fake samples created by the gan generator please note that the final number of samples contained in each of the datasets is lower than samples due to the removing process of repeated samples cases to in table are used to test the effect of changing standard deviation and number of users cases and test the consequences of increasing the number of items finally cases and test the behavior of the synthetic datasets when they have different sizes number of samples all generated datasets and the source code of the proposed ganrs method are fully available in httpsuleimanujaenesgitlabinstanceccc ganrs additionally appendix b fig shows an example of the dis tribution graphs obtained for each of the synthetic datasets following the link provided each generated dataset is located in its specific directory where a readmetxt file is provided along the synthetic dataset distribution graphs using the parameter values of table a variety of experiments have been conducted the classification of the experiments is as follows number of users a distribution of users versus ratings b distribution of the user ratings c number of repeated samples d proportion of samples with the same user and item e mae and accuracy of the data set f users precision and recall number of items a mae and accuracy of the dataset b items precision and recall number of samples a number of samples generated b precision and recall these experiments refer to wellknown metrics in collaborative filtering precision is focused on measuring the proportion of relevant rec ommendations ie the user rated the item with a rating value equal or greater than a threshold 𝜃 among the top 𝑁items recommended to the user 𝑢 collected in the list 𝑇𝑁 𝑢 eq on the other hand recall mea sures the proportion of correctly predicted relevant recommendations among the total number of relevant votes of each user therefore recall is sensitive to the existing proportions of relevant ratings eq 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 𝑈 𝑢𝑈 𝑖𝑇𝑁 𝑢𝑟𝑢𝑖𝜃 𝑁 𝑅𝑒𝑐𝑎𝑙𝑙 𝑈 𝑢𝑈 𝑖𝑇𝑁 𝑢𝑟𝑢𝑖𝜃 𝑖𝑇𝑁 𝑢𝑟𝑢𝑖𝜃 𝑖𝑇𝑁 𝑢𝑟𝑢𝑖𝜃 where 𝑈is the set of training users 𝑟𝑢𝑖is the rating of the training user 𝑢for the item 𝑖 𝑁is the number of recommendations and 𝑇𝑁 𝑢 is the set of 𝑁recommendations for the test user 𝑢 𝑁highest predictions of the user 𝑢above the relevancy threshold 𝜃 please note that precision measures the proportion of recommenda tion hits hits with respect to number of recommendations whereas recall measures the proportion of recommendation hits with respect to the total number of relevant items precision takes into consideration the number of true positives whereas recall combines both the true positives and the false negatives the importance of the precision and the recall quality measures largely depends on the scenario in which they are applied eg recall seems to be crucial in medicine where a false negative is a serious mistake ie not detecting cancer nevertheless recall is less important in rs since missing a relevant film false negative is not serious the objective is to maximize a correctly recommended film true positives the f quality measure combines both precision and recall eq 𝐹 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛𝑅𝑒𝑐𝑎𝑙𝑙 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 𝑅𝑒𝑐𝑎𝑙𝑙 finally this paper also tests accuracy eq where true negatives are also considered in this case both the positive and the negative hits contribute to the results to positively recommend relevant items and to negatively recommend non relevant items 𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦 𝑖𝑆𝑡𝑝𝑢𝑖𝜃𝑟𝑢𝑖𝜃 𝑖𝑆𝑡𝑝𝑢𝑖 𝜃𝑟𝑢𝑖 𝜃 𝑆𝑡 where 𝑆𝑡is the set of test samples and each sample is the tuple 𝑢 𝑖 𝑟containing the user id item id and rating of the user u for the item 𝑖𝑟𝑢𝑖 the model prediction of the rating is 𝑝𝑢𝑖 two values of the threshold 𝜃will be explored across the experimen tal scenario when precision recall f and accuracy quality measures are tested note that the accuracy quality measure does not use the term 𝑇𝑁 𝑢 since the typical rs does not include negative recommendations accordingly this accuracy formulation does not average users results and acts on the entire training data such as we have done with the mean absolute error eq 𝑀𝐴𝐸 𝑆𝑡 𝑠𝑆𝑡 𝑝𝑢𝑖𝑟𝑢𝑖 𝑢 𝑖𝑆 knowledgebased systems j bobadilla et al fig a distribution of users versus ratings number of items datasets and in table b distribution of user ratings number of users number of items datasets and in table c number of samples remaining after removing the repeated ones items datasets to in table d proportion of samples in which the same user has cast different votes for the same item items datasets to in table e mae and accuracy number of users number of items std is the standard deviation of the gaussian random noise distribution datasets to in table f precision recall and f standard deviation of the random noise gaussian distribution number of recommendations 𝑁 datasets to in table results this subsection shows the graphs obtained when the designed ex periments previous subsection are run the synthetic datasets de scribed in table are used to obtain results that allow us to compare the distributions of users items and ratings belonging to the source datasets in relation to those obtained using the synthetic datasets to measure the number of repeated samples returned in the clustering stage and to test the prediction and recommendation qualities and trends obtained by running the proposed rsgan method and comparing them to those shown by the source datasets experiment a number of users distribution of users versus ratings fig a shows the density of users yaxis that have cast different numbers of votes xaxis selected datasets and in table as expected for a fixed number of ratings in the dataset we can observe that the higher the number of users the lower the number of ratings if the fixed number of samples in the dataset is distributed among a high number of users each user centroid in the clustering stage receives a lower number of samples please note that netflix contains around users experiment b distribution of the user ratings fig b shows the proportion of each rating xaxis when different random noise gaussian distributions are applied selected datasets and it can be observed that the standard deviation generates a more similar distribution of votes compared to the netflix original than the adjacent standard distributions and fig b also shows the impact of the gaussian standard deviation in the layout of the individual values of the gangenerated samples experiment c number of repeated samples as explained in the method section the trained gan generator predicts from random noise vectors as many dense samples as we want all these samples are then converted from continuous dense values to discrete sparse ones in the discretization process repeated samples will appear that must be removed table contains an example fig c shows the number of samples remaining in the dataset after the removal process the lower the number of users the higher the number of samples assigned to each user to its centroid in the clustering process and therefore the higher the probability of repeating discrete samples overall the smaller the number of users the smaller the number of remaining samples selected datasets to in table experiment d proportion of samples with the same user and item the ganrs generated datasets possess one attribute that does not exist in the source datasets movielens etc they contain a proportion of samples where the same user has cast different votes for the same item eg as explained in the method section this can be seen as a mechanism to allow intermediate votes in the example or to allow users to change their minds this makes sense if the number of repeated votes is two or three the rare cases of four or five repeated votes should be removed just as we have done in all the generated datasets from the standard quality metrics to measure the accuracy of predictions mean absolute error mae and root mean square error rmse we have chosen the former since it is the most widely used in rs stateofart research some papers provide both measures but experimental research shows that in the cf field results for rmse and mae are very similar this is because the distribution of the errors in the cf field usually has little variance the mae returns the absolute difference between the predicted values and the real values in the testing set 𝑀𝐴𝐸 𝑛 𝑖𝑦𝑖𝑦𝑖 the lower the mae the better the model fits a dataset the rmse uses the square of the error instead of the absolute value 𝑀𝐴𝐸 𝑛 𝑖𝑦𝑖𝑦𝑖 therefore the rmse is more sensitive to observations that are further from the mean and this is not the case in cf fig d shows that for regular cf rs or more users the proportion of four or five repetitions is not significant and as the number of users increases the proportion of repetitions drops very fast experiment e mae and accuracy of the dataset whereas the previous experiments analyze the internal composition and distribution of the synthetic datasets this experiment and the knowledgebased systems j bobadilla et al following experiment test the behavior of the generated datasets on the prediction and recommendation tasks fig e shows the prediction quality mae and the accuracy of the recommendation obtained from each set of individual samples in datasets to in table please note that these measures are not obtained by analyzing and averaging the results of users the graphs in fig e show an improvement in accuracy and its corresponding decrease in mae error as the number of users increases this behavior is expected in the cf rs where a high number of users leads to better predictions and it tells us that the gan generated samples follow a cf convenient pattern the mae values in the top graph of fig e are closely related to the distribution of ratings for each of the standard deviations and maeaccuracy results can be used to select the most appropriate standard deviation in this case std experiment f users precision and recall this experiment provides the most significant results to test the generated datasets we extract the values and evolutions of two repre sentative recommendation quality measures precision and recall the top graphs in fig f show the quality values obtained testing several numbers of recommendations n xaxis two different relevancy thresholds 𝜃 and two number of users green lines and blue lines the standard deviation of the gaussian random noise has been set to selected datasets to in table the values and evolutions obtained from the synthetic datasets fit with the source dataset netflix black lines additionally as expected the overall results of the dataset generated by users outperform those of the users and are closer to the netflix reference please note that netflix contains around users the two bottom graphs in fig f represent the f combination of precision and recall they clearly show the similarity in the behavior of the generated datasets compared to the source dataset experiment a mae and accuracy when the number of items varies experiment e tested mae and accuracy quality measures on datasets with different numbers of users now we will test both quality measures on datasets with different numbers of items k k k k the results in fig show adequate values for both mae and accuracy and consistent evolutions where accuracy increases and mae decreases as the number of items xaxis increases thus the higher the number of items the better the accuracy this shows that the gan generator can enrich the data the netflix source dataset contains items and we can observe in fig a how the improvement slows down around this value xaxis selected datasets and in table and the user versions not included in table experiment b items precision and recall experiment b is similar to experiment f now we will test the behavior of datasets that contain different numbers of items instead of different numbers of users fig b shows the performance of netflix items represented using black lines and compares it with the item dataset green lines and the item dataset blue lines we can observe that evolutions and values are consistent with the source datasets black lines furthermore both the k and k items versions perform well the first one conveniently captures the neflix patterns of items since both contain a similar number of items the dataset generated second k items can enrich the data and show better accuracy than the k items version selected datasets and in table and the user versions not included in table experiment a number of samples generated in datasets with differ ent sizes here we will test the number of samples that the ganrs method obtains when different numbers of generated samples and different numbers of users have been set for this purpose we define four different numbers of samples k k m and m datasets to in table and their equivalent datasets for and users in the gan generation process the number of items is fixed at k for all experiments in fig a we can observe that the smaller the number of users the smaller the number of generated samples this is due to the fact that the smaller the number of users the higher the number of samples assigned to each user to each centroid in the clustering stage and therefore the higher the probability of repeated samples that will be removed as an example fig shows that the k user dataset preserves approximately m samples from the gan generated version m and k in version m experiment b precision and recall on datasets with different sizes this experiment shows the impact of increasing the number of samples in datasets with fixed parameters in this case users items and a standard deviation of table datasets and it is important to realize that we are using the same source dataset netflix to generate the three cases shown in fig b k samples yellow lines k samples magenta lines and m samples red lines please note that k k and m samples refer to the dense and continuously generated samples prior to the removal stage to convert them into their sparse discrete version fig a shows the final sizes of the datasets in the user data xaxis fig b compares the precision and recall values obtained in the netflix dataset black lines with the generated values overall precision increases and recall decreases the bigger the generated dataset the better its precision the higher the dataset the lower its recall precision results improve when using large datasets as there are more relevant samples to choose from and therefore it is easier to succeed in the fixed number 𝑁of recommended predictions on the other hand recall gets worse using large datasets because they contain more variability in the samples particularly when large standard devi ations have been chosen for the random noise gaussian distribution unlike precision whose denominator is the constant 𝑁number of recommendations the recall quality measure depends on the variable number of relevant votes in the set of test items for each user tested as the number of samples increases the number of user votes also increases and from them the number of relevant votes this is the reason why recall is lower in the m synthetic dataset in fig b and higher in the k version figs and show respectively the results obtained from the myanimelist and movielens k test datasets graph a compares the rating distribution of each source dataset in blue with the gen erated rating distributions obtained by setting different values of the gaussian random noise standard deviation we have chosen the stan dard deviation value of for myanimelist and the standard devia tion value of for movielens k since the obtained distributions of ratings are closest to their respective baselines results b c and e are obtained using the selected standard deviation values graph b shows the distribution of users according to their number of casted ratings xaxis as expected they follow the same pattern as the one in netflix to compare results please note that myanimelist dataset contains users and movielens k contains users graph c shows the number of samples left after removing repeated instances the higher the number of users the lower the probability of generating samples containing the same user id item id and rating in the myanimelist case we started with million generated samples whereas for movielens we selected million generated samples graph d refers to mae error and accuracy values obtained by processing the individual samples contained in each dataset as usual in the cf context the higher the number of users the lower the error and the higher the accuracy finally graphs e tests the recommendations obtained by processing the users in each dataset as is with netflix compared to baselines precision improves and recall gets worse knowledgebased systems j bobadilla et al fig a mae and accuracy obtained from the dataset samples when the number of items varies number of users standard deviation of the gaussian random noise datasets and in table b precision recall and f when the number of items varies standard deviation of the random noise gaussian distribution number of recommendations 𝑁 datasets and in table fig a number of generated samples using different number of users x axis and different number of gan generated samples legend standard deviation of the random noise gaussian distribution number of items datasets to in table b precision and recall using a different number of recommendations x axis and a different number of gan generated samples legend standard deviation of the random noise gaussian distribution datasets and in table the results obtained in this section highlight the importance of those that test the performance of the synthetic datasets against the source datasets particularly when specific rs metrics are used to check the consistency between synthetic and real data two types of knowledgebased systems j bobadilla et al fig myanimelist million generated samples a distribution of the myanimelist ratings to b distribution of users according to their number of casted ratings c number of samples after the removing process of the repeated ones d error and accuracy by processing the samples of the dataset e cf precision and recall by testing the dataset users the ganrs std value has been set to test experiments b to e experiments have been conducted direct and indirect in direct com parisons rating distributions have been obtained and compared from both source datasets and their synthetic versions figs b and c show the netflix results by varying the number of generated users and the standard deviation of the random gaussian distribution used to feed the proposed gan figs b and b show respectively comparison of the myanimelist and the movielens k datasets in this case by varying the number of users in the synthetic datasets versus their equivalent source counterparts indirect experiments tested and compared the recommendation performance on both the synthetic and the source datasets we have chosen the recommendation quality measures of pre cision recall and f obtained using the classical neural model deepmf results can be found in fig f netflix vs its synthetic version fig e myanimelist vs its synthetic version and fig e movielens k vs its synthetic version overall as expected the results show that synthetic datasets behave like their source datasets the more similar the results are the more suitable the generated datasets will be as this means that the original datasets can be effectively replaced by synthetic ones comparison of the proposed framework with previous work the related works section identifies some previous work focused on data generation methods for recommender systems in this subsection a brief analysis will be performed which will focus on showing how this previous work is not truly comparable with our current proposal in a fair way since it is focused on different objectives and also generates data of a different nature mladenov et al presented recsim ng an architecture cen tered on the generation of synthetic profiles of users and items as part of the recommendation environment overall the goal of the work is the development of a configurable platform for both authoring and learning rs simulation environments the aim of this simulation is to evaluate existing rs policies or generate data to train new policies in either a tightly coupled online fashion or in batch mode furthermore this paper lacks information about the presented method and therefore does not allow reproducibility shi et al introduce a multiagent reinforcement learning architecture tailored to taobaospecific website search improve ment and uses a gan to simulate the internal rating distribu tion therefore considering that it is focused on data generation for a specific context it is not comparable with the framework proposed in the current paper del carmen et al introduce datagencars a javabased generator of rs synthetic data here it is important to remark that this work is specifically focused on the contextaware recom mendation scenario in this sense even though the proposed tool supports the generation of synthetic datasets of users items con texts and ratings this generation always relies on contextrelated characteristics through criteria introduced throughout the work such as the uncertainty of the content the users expectations or the items attributes as result this work is not comparable with the methodology presented in our current paper which mainly uses rating values as input and does not consider datasets with contextual information knowledgebased systems j bobadilla et al fig movielens k results million generated samples a distribution of the movielens k ratings to b distribution of users according to their number of casted ratings c number of samples after the removal process of the repeated ones d error and accuracy by processing the samples of the dataset e cf precision and recall by testing the dataset users the ganrs std value has been set to test experiments b to e provalov et al introduce the synevarec framework focused on the presentation of a novel paradigm for evaluating recom mendations based on the generation of synthetic rs datasets in contrast to our current paper this approach is mainly focused on generating synthetic user and item profiles that are internally used by synevarec to guarantee user privacy protection mitigate the data insufficiency problem and measure the effect of the nofreelunch problem regarding the aim of the architecture proposed in provalov et al is not the proper retrieval of the whole synthetic rating datasets to be used in further evaluations ie an evaluation protocol is presented rather than a dataset generation method a major transformation of their work is needed to make it comparable with this paper a fair comparison is then not possible at this stage overall discussion a large number of synthetic datasets have been generated to test the performance of the proposed ganrs method these datasets have been created setting different values for the main parameters of the method number of users number of items gaussian random noise variation and number of generated samples to generalize the conclusions of this paper three open and representative cf datasets have been used as sources for the generative process finally a variety of quality measures have been tested on the generated datasets of these precision and recall are the most relevant a key issue is that we are not able to visually test the quality of the generated samples as can be done for example with the popular fake faces in fact in the cf context we only can adequately test the generated datasets by comparing their cf quality results with those typically obtained in real cf datasets for this reason we have focused on the designed experiments in which the quality measures of precision and recall are tested using datasets containing different numbers of users different numbers of items and different numbers of samples sizes in all cases comparatively we obtain excellent precision results and moderate recall values overall it can be considered positive in the cf context where precision errors are serious and recall errors are less important it is worse to recommend a trip you will not like sorry no refunds than not to recommend a trip that you probably would enjoy please note that it is the opposite for a deep learning model detecting malignant tumors it is worse to make precision errors no early detection of the tumor than making recall errors to erroneously detect a tumor additionally experiments show the relevant impact of the standard deviation on the quality of the results the gan network learning has been based on a vector containing noise values that serves as a seed to generate the different samples in the synthetic dataset each fake sample is generated from the list of random values in the noise vector as usual in the gan context random values have been created from knowledgebased systems j bobadilla et al a gaussian distribution with a mean of and a standard deviation of each generated sample contains a dense item representation a dense user representation and an individual value that codes the users rating of the item once the gan has learned its generative model can be used in a feedforward process to generate as many samples as we want starting from a different random noise vector for each sample generated experimental results show that using a gaussian distribution with a standard deviation of leads to many ratings in the middle of the voting range rating and closest in the to voting range movielens and netflix and rating and closests in to voting range myanimelist several experiments in this section demonstrate that we can modulate the standard deviation of the gaussian distribution of random noise to generate a wider range of ratings using feedforward as expected when the standard deviation increases the range of ratings also increases proportionally finally the experiments presented include the existing relationship between the number of fake samples generated for the gan and the number of samples that the dataset will eventually contain as explained in the method section the conversion from dense and continuous values to sparse and discrete values leads to a probability of sample repetitions results show that as expected the larger the number of users and items in the synthetic dataset the lower the number of repeated samples it has also been shown that for a typical number of users say or more the probability of more than two different ratings from one user for the same item can be considered negligible conclusions this paper provides an innovative method for generating synthetic parameterized collaborative filtering datasets from real datasets syn thetic datasets can be generated by selecting different numbers of users items samples and distribution variability this means that comparative experiments can be designed on the basis of a whole family of generated datasets for example to test the accuracy of a new matrix factorization model when the number of users increases a gan is used to obtain fake samples from real samples benefitting from the inherent capacity of gan networks to capture complex patterns in the source datasets the gan learns from dense and continuous embedding representations of items and users rather than the sparse and discrete representations of the collaborative filtering datasets the effect is a fast and accurate learning process the proposed ganrs method contains a clustering stage to convert from the dense generated fake samples to the sparse and discrete values necessary to fill the generated dataset this clustering stage implements a kmeans algorithm to group items and another kmeans to group users in a natural way both k parameters set the chosen num ber of users and items in the dataset a drawback of the discretization process is the generation of identical samples that our method merely removes a complete set of experiments have been made using three representative source datasets we have tested the distribution values and evolutions of the results as well as prediction and recommendation qualities although precision tends to improve while recall tends to worsen overall accuracy can be considered correct since precision is more relevant than recall in the rs context the results show that the generated datasets conveniently mimic the behavior of the source datasets movielens myanimelist etc the source code for the proposed ganrs method is available to ensure the reproducibility of the experiments similarly a complete set of generated datasets has been made available for research this paper and its related documentation open the door to address some future work such as designing alternative options to the clustering stage implementing the pacgan concept in the gan discriminator testing generated datasets using a complete range of machine learning and deep learning collaborative filtering models replacing the gan model with a cgan one generating demographically balanced datasets and performing an indepth study of the impact of the random noise vector variations in the generated set of samples credit authorship contribution statement jesús bobadilla conceptualization validation formal analysis investigation software writing original draft writing review editing visualization abraham gutiérrez conceptualization valida tion formal analysis investigation software writing original draft visualization raciel yera methodology validation formal analysis writing original draft visualization luis martínez methodology validation writing original draft declaration of competing interest the authors declare that they have no known competing finan cial interests or personal relationships that could have appeared to influence the work reported in this paper data availability the link to the data and code has been shared in the manuscript acknowledgments this work was partially supported by ministerio de ciencia e inno vación of spain under the project pidrbi dlcemg the comunidad de madrid spain under convenio plurianual with the universidad politécnica de madrid spain in the actuation line of programa de excelencia para el profesorado universitario and the plan andaluz de investigación desarrollo e innovación paidi spain under the project proyexcel_ appendix a see table table main parameter and hyperparameter values set for the neural models involved in the rsgan method deepmf values embedding size both for users an items optimizer adam loss function mean squared error epochs gan generator input shape noise vector size block dense layer neurons block activation function leakyrelu alpha block normalization batchnormalization momentum block dense layer neurons block activation function leakyrelu alpha block regularization dropout block dense layer neurons 𝑒𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔𝑠𝑖𝑧𝑒 block activation function linear gan discriminator input shape 𝑒𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔𝑠𝑖𝑧𝑒 block dense layer neurons block activation function leakyrelu alpha block dense layer block activation function sigmoid gan train epochs batch size stochastic noise gaussian loss function 𝑟𝑒𝑎𝑙𝑠𝑎𝑚𝑝𝑙𝑒𝑠𝑙𝑜𝑠𝑠 𝑓𝑎𝑘𝑒𝑠𝑎𝑚𝑝𝑙𝑒𝑠𝑙𝑜𝑠𝑠 knowledgebased systems j bobadilla et al appendix b see fig fig main distributions of the data in the synthetic dataset generated from movielens k compared to the distributions of the data in the source dataset number of users number of items initial number of samples standard deviation of the gaussian noise graph a shows the distribution of the fake users y axis versus the number of ratings belonging to each of the users x axis graph b shows the distribution of the fake items y axis versus the number of ratings belonging to each of the items x axis graph c shows the percentage of ratings y axis for each of the available vote values x axis in the dataset references z fang l zhang k chen a behavior mining based hybrid recommender system in ieee international conference on big data analysis icbda ieee pp r yera l martínez fuzzy tools in recommender systems a survey int j comput intell syst r yera aa alzahrani l martínez a fuzzy contentbased group recommender system with dynamic selection of the aggregation functions internat j approx reason l zheng v noroozi ps yu joint deep modeling of users and items using reviews for recommendation in proceedings of the tenth acm international conference on web search and data mining pp y gong q zhang hashtag recommendation using attentionbased convolutional neural network in ijcai pp h kanwal m assam a jabbar s khan et al convolutional neural network and topic modeling based hybrid recommender system int j adv comput sci appl k mcnally mp omahony b smyth a comparative study of collaboration based reputation models for social recommender systems user model useradapt interact nm villegas c sánchez j díazcely g tamura characterizing contextaware recommender systems a systematic literature review knowlbased syst m moradi j hamidzadeh ensemblebased topk recommender system considering incomplete data j ai data min m jalili s ahmadian m izadi p moradi m salehi evaluating collaborative filtering recommender algorithms a survey ieee access b zhu r hurtado j bobadilla f ortega an efficient recommender system method based on the numerical relevances and the nonnumerical structures of the ratings ieee access r yera aa alzahrani l martínez exploring posthoc agnostic models for explainable cooking recipe recommendations knowlbased syst e damico g gabbolini c bernardis p cremonesi analyzing and improving stability of matrix factorization for recommender systems j intell inf syst mh aghdam a novel constrained nonnegative matrix factorization method based on users and items pairwise relationship for recommender systems expert syst appl g ayci a köksal mm mutlu b suyunu at cemgil active learning with bayesian nonnegative matrix factorization for recommender systems in th signal processing and communications applications conference siu ieee pp j bobadilla r bojorque ah esteban r hurtado recommender systems clustering using bayesian non negative matrix factorization ieee access hj xue x dai j zhang s huang j chen deep matrix factorization models for recommender systems in ijcai vol melbourne australia pp x he l liao h zhang l nie x hu ts chua neural collaborative filtering in proceedings of the th international conference on world wide web pp j bobadilla r laracabrera a gonzalezprieto f ortega deepfair deep learning for improving fairness in recommender systems int j interact multimed artif intell y himeur a alsalemi a alkababji f bensaali a amira c sardianos g dimitrakopoulos i varlamis a survey of recommender systems for energy efficiency in buildings principles challenges and prospects inf fusion j bobadilla j dueñas a gutiérrez f ortega deep variational embedding representation on neural collaborative filtering recommender systems appl sci j bobadilla á gonzálezprieto f ortega r laracabrera deep learning approach to obtain collaborative filtering neighborhoods neural comput appl s zhang l yao a sun y tay deep learning based recommender system a survey and new perspectives acm comput surv i goodfellow j pougetabadie m mirza b xu d wardefarley s ozair a courville y bengio generative adversarial networks commun acm d sacharidis diversity and novelty in socialbased collaborative filtering in proceedings of the th acm conference on user modeling adaptation and personalization pp a gogna a majumdar diablo optimization based design for improving diversity in recommender system inform sci j bobadilla a gutierrez s alonso á gonzálezprieto neural collaborative filtering classification model to obtain prediction reliabilities int j interact multimed artif intell knowledgebased systems j bobadilla et al f pajueloholguera ja gómezpulido f ortega evaluating strategies for selecting test datasets in recommender systems in international conference on hybrid artificial intelligence systems springer pp kd bollacker s lawrence cl giles citeseer an autonomous web agent for automatic retrieval and identification of interesting publications in proceedings of the second international conference on autonomous agents pp w choochaiwattana usage of tagging for research paper recommendation in rd international conference on advanced computer theory and engineering vol icacte ieee pp v j shokeen c rana social recommender systems techniques domains metrics datasets and future scope j intell inf syst y xing i mohallick ja gulla ö özgöbek l zhang an educational news dataset for recommender systems in joint european conference on machine learning and knowledge discovery in databases springer pp f ortega j bobadilla a gutiérrez r hurtado x li artificial intelligence scientific documentation dataset for recommender systems ieee access d liang rg krishnan md hoffman t jebara variational autoencoders for collaborative filtering in proceedings of the world wide web conference pp s zamany d li h fei p li towards deeper understanding of variational autoencoders for binary collaborative filtering in proceedings of the acm sigir international conference on theory of information retrieval pp m gao j zhang j yu j li j wen q xiong recommender systems based on generative adversarial networks a problemdriven perspective inform sci y deldjoo td noia fa merra a survey on adversarial recommender systems from attackdefense strategies to generative adversarial networks acm comput surv dk chae js kang sw kim jt lee cfgan a generic collaborative filtering framework based on generative adversarial networks in proceedings of the th acm international conference on information and knowledge management pp z wang m gao x wang j yu j wen q xiong a minimax game for generative and discriminative sample models for recommendation in pacific asia conference on knowledge discovery and data mining springer pp w zhao b wang j ye y gao m yang x chen plastic prioritize long and shortterm information in topn recommendation using adversarial training in ijcai pp h bharadhwaj h park by lim recgan recurrent generative adversarial net works for recommendation systems in proceedings of the th acm conference on recommender systems pp g guo h zhou b chen z liu x xu x chen z dong x he ipgan generating informative item pairs by adversarial sampling ieee trans neural netw learn syst j zhao h li l qu q zhang q sun h huo m gong dcfgan an adver sarial deep reinforcement learning framework with improved negative sampling for sessionbased recommender systems inform sci j sun b liu h ren w huang ncgan a neural adversarial collaborative filtering for recommender system j intell fuzzy systems y lin z xie b xu k xu h lin infoflow enhanced gans for recommender in proceedings of the th international acm sigir conference on research and development in information retrieval pp q wang q huang k ma x zhang a recommender system based on model regularization wasserstein generative adversarial network in ieee international conference on systems man and cybernetics smc ieee pp j wen xr zhu cd wang z tian a framework for personalized recom mendation with conditional generative adversarial networks knowl inf syst g deng c han ds matteson extended missing data imputation via gans for ranking applications data min knowl discov h chen s wang n jiang z li n yan l shi trustaware generative adversarial network with recurrent neural network for recommender systems int j intell syst g van houdt c mosquera g nápoles a review on the long shortterm memory model artif intell rev w shafqat yc byun a hybrid ganbased approach to solve imbalanced data problem in recommendation systems ieee access z lin a khetan g fanti s oh pacgan the power of two samples in generative adversarial networks in proceedings of the nd international conference on neural information processing systems pp m mladenov cw hsu v jain e ie c colby n mayoraz h pham d tran i vendrov c boutilier demonstrating principled uncertainty modeling for recommender ecosystems with recsim ng in fourteenth acm conference on recommender systems pp jc shi y yu q da sy chen ax zeng virtualtaobao virtualizing real world online retail environment for reinforcement learning in proceedings of the aaai conference on artificial intelligence vol pp cn ziegler sm mcnee ja konstan g lausen improving recommendation lists through topic diversification in proceedings of the th international conference on world wide web pp m del carmen rodríguezhernández s ilarri r hermoso r trillolado datagencars a generator of synthetic data for the evaluation of contextaware recommendation systems pervasive mob comput v provalov e stavinova p chunaev synevarec a framework for evalu ating recommender systems on synthetic data classes in international conference on data mining workshops icdmw ieee pp a cossu a carta v lomonaco d bacciu continual learning for recurrent neural networks an empirical evaluation neural netw m ahmed r seraj sms islam the kmeans algorithm a comprehensive survey and performance evaluation electronics fm harper ja konstan the movielens datasets history and context acm trans interact intell syst tiis f ortega b zhu j bobadilla a hernando cfj collaborative filtering for java knowlbased syst,"[0.030278699472546577, 0.03421425819396973, -0.031546760350465775, 0.032258566468954086, 0.029434680938720703, -0.02079756185412407, 0.042635802179574966, 0.018496036529541016, 0.025780195370316505, 0.03464062511920929, -0.06661487370729446, -0.024937007576227188, -0.061086416244506836, 0.06657420098781586, 0.02587963454425335, -0.04361790418624878, 0.019952723756432533, 0.031028123572468758, -0.02360404096543789, -0.043628353625535965, 0.008483543992042542, 0.03097258135676384, 0.03109654039144516, 0.021335337311029434, 0.024601420387625694, -0.006234948523342609, -0.022657377645373344, -0.033638522028923035, 0.01815149560570717, -0.014750934205949306, -0.001087682438082993, 0.0067779747769236565, -0.011603867635130882, 0.009130981750786304, 2.223836872872198e-06, -0.0029530080500990152, -0.005551386624574661, -0.0376197025179863, -0.028229188174009323, 0.018281083554029465, 0.022738737985491753, 0.10206229239702225, -0.004545651376247406, 0.029452092945575714, -0.04310329258441925, -0.06341982632875443, -0.014850206673145294, 0.04091775417327881, -0.0128586795181036, 0.011453786864876747, -0.023108527064323425, -0.007814042270183563, 0.014033588580787182, -0.06854470819234848, 0.0005459525273181498, -0.017321795225143433, 0.004268423654139042, 0.013189439661800861, 0.00740369176492095, 0.012537642382085323, -0.018143223598599434, -0.026232024654746056, 0.0060059791430830956, -0.013640946708619595, 0.09317705035209656, 0.040448252111673355, -0.0036348451394587755, -0.007341098040342331, 0.015160305425524712, 0.10330582410097122, -0.0332956425845623, 0.013809937052428722, 0.0014484715647995472, 0.0023976198863238096, 0.010850360617041588, 0.019732628017663956, -0.03109067864716053, -0.04924501106142998, -0.04530474916100502, 0.016413168981671333, -0.03902725875377655, -0.0076775322668254375, 0.04888192191720009, -0.009055768139660358, 0.010121732950210571, 0.03462815284729004, 0.04291609302163124, -0.006911024916917086, 0.0019219544483348727, -0.03489462658762932, -0.05131768435239792, -0.06666421890258789, 0.04354070499539375, -0.005552875343710184, -0.0019460159819573164, -0.03073587268590927, -0.00623258575797081, 0.02762152999639511, 0.004775153007358313, 0.00882683414965868, 0.04794918745756149, -0.04191672056913376, 0.01837250217795372, 0.05875028669834137, 0.009764058515429497, -0.007847676984965801, -0.023849163204431534, -0.01364115346223116, -0.02508632279932499, -0.008888505399227142, -0.014910786412656307, -0.016767427325248718, 0.004606141708791256, 0.02274237386882305, -0.041807323694229126, -0.009498360566794872, -0.061304353177547455, 0.019485747441649437, -0.016155313700437546, 0.06884729862213135, 0.03613123297691345, 0.10200811177492142, -0.00824646558612585, 0.002429076237604022, -0.06803065538406372, -0.02315536141395569, -0.07204114645719528, 0.037450529634952545, 0.001697604893706739, 0.021420715376734734, 0.05993499234318733, 0.01803814247250557, 0.02379121072590351, -0.0003034606052096933, -0.001283506746403873, 0.04215066879987717, 0.023614712059497833, 0.02328224666416645, 0.003639036323875189, -0.03191206231713295, 0.001509939320385456, -0.05721725896000862, -0.023239541798830032, -0.04837975651025772, 0.051016464829444885, -0.008578157983720303, 0.003830730216577649, -0.05539735034108162, -0.02175133302807808, -0.037501271814107895, 0.021850958466529846, 0.06780248880386353, 0.012475295923650265, -0.03619300574064255, 0.012108429335057735, 0.01726675033569336, -0.008108971640467644, -0.053091295063495636, 0.022574273869395256, 0.09274911880493164, 0.06747158616781235, 0.005488721188157797, 0.006457147188484669, -0.01457801554352045, -0.000670074310619384, 0.009394990280270576, -0.008488837629556656, 0.009877113625407219, -0.05985774099826813, 0.022673625499010086, 0.012551907449960709, 0.061656706035137177, -0.07903196662664413, -0.021857673302292824, 0.024022376164793968, -0.009071022272109985, 0.07519625872373581, 0.10492143034934998, 0.04042983055114746, 0.022236814722418785, -0.03846636414527893, -0.02244679071009159, 0.032065458595752716, 0.06244749575853348, 0.022353505715727806, -0.05869753286242485, 0.045814186334609985, 0.04689458757638931, -0.05210625007748604, -0.031442128121852875, 0.052101634442806244, -0.004830476362258196, 0.00693798903375864, 0.0029044977854937315, 0.0489848330616951, -0.012929536402225494, -0.013666253536939621, -0.08726053684949875, -0.002080224920064211, -0.029229171574115753, 0.04648870602250099, -0.012446618638932705, 0.07505735009908676, 0.08600026369094849, 0.07981431484222412, 0.004956560675054789, 0.03709256276488304, -0.021149080246686935, -0.04805987700819969, -0.08123558759689331, 0.0256376750767231, -0.07184174656867981, -0.0240662582218647, -0.0442657433450222, -0.056548960506916046, 0.0064085256308317184, -0.009819074533879757, 0.05353754013776779, -0.03732457384467125, 0.0325167179107666, 0.010168549604713917, 0.016701392829418182, 0.006906939670443535, -0.01050762552767992, -0.014872330240905285, -0.022872867062687874, 0.05780651420354843, 0.0010887535754591227, 0.06256018579006195, 0.022315697744488716, 0.027524016797542572, -0.02806088700890541, 0.03958766907453537, -0.013524632900953293, -0.036661483347415924, -0.027866508811712265, 0.005952836945652962, -0.03565743938088417, 0.0070879231207072735, -0.0569886788725853, 0.061704590916633606, 0.04474148899316788, -0.01651385985314846, -0.03594573214650154, -0.00034448131918907166, 0.040785741060972214, -0.006954850163310766, -0.038926102221012115, 0.013454988598823547, 0.03647725284099579, 0.026650121435523033, -0.005710008554160595, 0.04447014257311821, -0.00748206302523613, 0.001640566042624414, -0.01124816294759512, 0.02752668224275112, 0.03780369460582733, -0.044704634696245193, -0.03743521124124527, 0.02047576755285263, 0.009143488481640816, 0.004473999608308077, 0.004544341936707497, -0.03881444036960602, -0.016544828191399574, 0.02637096494436264, -0.03773704916238785, 0.041363395750522614, 0.019926827400922775, -0.016131751239299774, -0.007514896336942911, 0.01729714125394821, 0.0019941204227507114, -0.008430941961705685, -0.08268314599990845, 0.07391513139009476, -0.01475773099809885, -0.048699554055929184, 0.006660389713943005, 0.025398224592208862, 0.029559975489974022, -0.008675041608512402, -0.01867886632680893, 0.004133731126785278, 0.026951495558023453, -0.008516065776348114, 0.03153517097234726, -0.028921740129590034, -0.02794102020561695, -0.02794760651886463, 0.0022919580806046724, -0.029823748394846916, -0.0014834706671535969, -0.019157463684678078, 0.0009371372289024293, 0.019628696143627167, 0.005808615125715733, -8.591174992034212e-05, 0.02669893018901348, 0.04895078018307686, 0.009274454787373543, -0.04210115969181061, 0.012909820303320885, -0.03091585263609886, 0.01656208001077175, 0.004840640351176262, 0.002041828352957964, -0.03163202479481697, -0.019856832921504974, 0.03618955984711647, -0.008289472199976444, -0.044594693928956985, 0.058291878551244736, 0.027031762525439262, -0.020281752571463585, -0.054778605699539185, 0.0021077629644423723, 0.00027310047880746424, 0.021751508116722107, -0.013638738542795181, -0.022166026756167412, 0.05445079877972603, 0.019955681636929512, -0.0029413674492388964, -0.012132328003644943, -0.035705290734767914, -0.00394402164965868, -0.03726726770401001, 0.012911660596728325, 0.0026724126655608416, -0.011032258160412312, 0.03131996840238571, -0.06088302657008171, 0.056402113288640976, 0.027687326073646545, -0.05887807533144951, -0.01140244584530592, 0.04545831307768822, -0.04866252467036247, 0.006105809472501278, -0.012484581209719181, -0.06696266680955887, -0.005771213211119175, 0.0394846647977829, -0.01609249971807003, 0.06980093568563461, -0.014795646071434021, 0.01211108174175024, -0.0193882305175066, -0.04570598900318146, 0.04332639276981354, 0.002524909796193242, -0.010385865345597267, 0.020821241661906242, 0.08096488565206528, 0.030482271686196327, -0.07841908931732178, -0.020584426820278168, 0.032125938683748245, 0.015005754306912422, 0.03256605565547943, -0.009879105724394321, -0.03203997015953064, -0.049301087856292725, -0.006685481872409582, 0.018956439569592476, 0.018586086109280586, 0.009890864603221416, 0.014449244365096092, -0.01613406278192997, 0.04191696643829346, 0.024988533928990364, 0.023972710594534874, 0.03149932622909546, -0.104636050760746, 0.009339573793113232, 0.02533707022666931, 0.018241403624415398, 0.033953581005334854, 0.05184387043118477, -0.06416495889425278, 0.04044410586357117, -0.0036033084616065025, 0.05946413427591324, 0.017840368673205376, -0.021251363679766655, -0.012614311650395393, -0.06739884614944458, 0.07311700284481049, -0.005312475375831127, 0.029432442039251328, -0.008325918577611446, -0.02445274218916893, -0.010015105828642845, -0.042105745524168015, 0.0003801773127634078, -0.009004446677863598, 0.03341911733150482, 0.01329288724809885, 0.004010616801679134, 0.0017766206292435527, -0.04964017495512962, 0.01694997400045395, -0.03762955591082573, 0.05877206102013588, 0.011274207383394241, 0.055003467947244644, 0.02688228152692318, -0.017050424590706825, -0.07337810099124908, -0.006676465272903442, -0.024180885404348373, -0.006568452809005976, 0.0736381858587265, -0.006972300820052624, 0.017659101635217667, -0.0015950296074151993, 0.04978825896978378, -0.022823797538876534, 0.026705188676714897, 0.028179338201880455, 0.033204179257154465, -0.032101742923259735, -0.014741174876689911, -0.043718647211790085, -0.006026918068528175, 0.025622479617595673, 0.018708351999521255, -0.00609169714152813, -0.02209809236228466, 0.04970387741923332, -0.02230060286819935, -0.004521205555647612, -0.02916058525443077, -0.020872579887509346, 0.010220621712505817, -0.005314479116350412, 0.0080063221976161, -0.06827826052904129, -0.031456392258405685, 0.0331370048224926, 0.024211211130023003, 0.015975233167409897, 0.035183507949113846, -0.05330473184585571, -0.030040038749575615, 0.0164939071983099, -0.009726402349770069, 0.04637300595641136, 0.0038013376761227846, -0.031402524560689926, -0.016369575634598732, -0.0003245219122618437, -0.047187499701976776, -0.017780859023332596, -0.030102968215942383, -0.008116635493934155, -0.009117107838392258, -0.02161157689988613, 0.07871372252702713, 0.006856902502477169, 0.028757471591234207, -0.0562819205224514, -0.0727342888712883, 0.08205529302358627, 0.0126537149772048, -0.02465982921421528, -0.0790335014462471, -0.016341008245944977, 0.03692786768078804, -0.010786720551550388, 0.02874014899134636, -0.03871766850352287, 0.015355482697486877, -0.009464161470532417, -0.021160820499062538, -0.02876206673681736, -0.010726286098361015, 0.011442464776337147, 0.003845233703032136, 0.019022537395358086, -0.021256515756249428, 0.03319305554032326, -0.04687407240271568, 0.029491985216736794, -0.005116137210279703, -0.030552202835679054, -0.03758857026696205, -0.024707529693841934, 0.05238046869635582, -0.015973679721355438, -0.03857521712779999, 0.0007937278714962304, 0.01316634751856327, 0.030299322679638863, -0.054915595799684525, 0.019945811480283737, 0.03176594153046608, 0.024314086884260178, 0.007701345719397068, 0.05125666782259941, 0.034823354333639145, -0.02127045951783657, 0.020254744216799736, 0.03537963330745697, -0.025850163772702217, 0.026021862402558327, -0.00559166120365262, 0.004324024543166161, -0.047561369836330414, 0.06363209336996078, 0.006591541692614555, -0.04164156690239906, -0.03211735561490059, 0.025481054559350014, 0.052095845341682434, -0.0380382277071476, -0.023144681006669998, -0.04229307547211647, -0.009521769359707832, -0.05980486795306206, 0.00835864245891571, -0.04628485068678856, -0.024394644424319267, 0.005915396846830845, 0.047934018075466156, -0.005459966138005257, 0.02398691326379776, 0.08784741908311844, 0.02100221812725067, -0.007271979469805956, -0.021899936720728874, -0.06703423708677292, -0.05426592379808426, 0.02032197080552578, 0.029905667528510094, 0.03865810111165047, -0.051538825035095215, -0.0027601567562669516, 0.0029715662822127342, -0.059738755226135254, -0.021242203190922737, -0.02080410346388817, 0.04660701006650925, -0.017443593591451645, 0.0554826483130455, 0.029125221073627472, -0.021166402846574783, 0.014272385276854038, -0.04185551404953003, 0.0006271876045502722, -0.013756556436419487, -0.00918296817690134, -0.010897881351411343, -6.17970898412311e-33, 0.03349809721112251, -0.02104092389345169, 0.004598945379257202, -0.018996896222233772, -0.01727181114256382, -0.03243093565106392, -0.00528678996488452, -0.019388778135180473, 0.05096636712551117, 0.00775446742773056, -0.04027814045548439, -0.005627386271953583, 0.000991365872323513, 0.01618891768157482, -0.001092932652682066, -0.0037099088076502085, 0.07594741135835648, 0.005450558848679066, 0.006304644513875246, 0.038803745061159134, 0.05323753133416176, 0.06518880277872086, -0.005863850004971027, -0.0531405471265316, -0.011158555746078491, -0.012275799177587032, 0.007881363853812218, -0.035354048013687134, -0.00902659259736538, 0.06054858863353729, -0.02661152556538582, 0.057709455490112305, -0.009623847901821136, -0.02000752091407776, 0.026159336790442467, -0.027981998398900032, -0.08728881180286407, 0.020315902307629585, -0.014667600393295288, -0.0027368254959583282, -0.05552232265472412, -0.016487915068864822, 0.008717836812138557, 0.003923530224710703, 0.017993882298469543, 0.019203761592507362, 0.049607425928115845, -0.028604546561837196, -0.07900948822498322, -0.05414480343461037, 0.02985915169119835, 4.3768501200247556e-05, -0.001616545720025897, 0.011848214082419872, 0.00022367725614458323, 0.02846776321530342, -0.00609669229015708, 0.025364628061652184, -0.0513526052236557, 0.004349681083112955, -0.017334559932351112, 0.04321778938174248, 0.0044538178481161594, 0.01000103447586298, -0.0008935177465900779, 0.037697456777095795, -0.020811932161450386, -0.06582804024219513, -0.03421854227781296, 0.02693937160074711, -0.021409209817647934, 0.06141849607229233, 0.011172308586537838, 0.1064654290676117, 0.06848961114883423, -0.04853013902902603, -0.05541842430830002, 0.05993709713220596, -0.0013132982421666384, 0.01591932401061058, 0.010298690758645535, 0.036518242210149765, -0.010618242435157299, -0.026414496824145317, 0.008812027052044868, -0.08822743594646454, -0.03763756528496742, -0.07431779056787491, 0.015253525227308273, 0.02396179735660553, -0.06016286835074425, -0.018813228234648705, -0.002138293581083417, -0.0665993019938469, -0.02351044863462448, 0.01146344281733036, -0.004074896685779095, -0.03411862999200821, 0.02754923887550831, 0.002964786486700177, -0.05796697735786438, 0.01071937195956707, 0.012586712837219238, -0.06676194071769714, -0.04671496897935867, 0.012276503257453442, 0.03819963335990906, 0.007637552451342344, 0.017471354454755783, 0.015844052657485008, 0.028292125090956688, -0.049171097576618195, -0.003535971511155367, 0.056819695979356766, -0.011356227099895477, 0.0402587354183197, -0.01860065758228302, 0.03410477563738823, 0.036061909049749374, 0.06137023866176605, 0.0016864349599927664, -0.0885673239827156, 0.011500511318445206, -0.0289787445217371, -0.03848985955119133, -0.031074106693267822, -0.061021558940410614, -0.03320873901247978, 0.09312272816896439, -0.08196783065795898, -0.01510973647236824, -0.051837336272001266, 2.8322861567176005e-07, -0.009106164798140526, -0.007325358223170042, -0.003278621006757021, -0.0308891162276268, 0.001153646851889789, -0.015317434445023537, 0.00659955944865942, 0.06894641369581223, -0.018345031887292862, 0.022288836538791656, 0.062235843390226364, 0.014044367708265781, -0.004031242802739143, 0.03629611060023308, -0.043779123574495316, 0.01207504328340292, -0.03125659376382828, 0.00416514603421092, -0.039430681616067886, -0.04203123226761818, -0.010756551288068295, 0.08081081509590149, 0.06515219062566757, -0.019110074266791344, 0.05050632730126381, 0.043130140751600266, 0.020101213827729225, -0.02643764391541481, 0.0010958127677440643, -0.021138425916433334, 0.08908414095640182, 0.03741508349776268, -0.046455662697553635, 0.011290989816188812, -0.04237421974539757, 0.009145336225628853, 0.017042724415659904, -0.011367053724825382, -0.009602135978639126, -0.03847363591194153, -0.0042622326873242855, -0.022747695446014404, 0.02170538902282715, -0.05194322392344475, 0.06485126912593842, -0.008223718032240868, 0.004851530306041241, 0.061468880623579025, -0.07106512784957886, 0.018161043524742126, 0.012933662161231041, -0.02948480285704136, -0.003314717672765255, -0.033133212476968765, 0.024971680715680122, -0.01568230427801609, -0.004047130700200796, -0.04672682285308838, 0.06638304889202118, -0.01496055070310831, -0.041791170835494995, -0.03974774852395058, -0.01960347592830658, 0.007761920336633921, 0.012421912513673306, 0.019961204379796982, 0.041337866336107254, 2.3695560022577977e-34, -0.0047295731492340565, 0.06321501731872559, -0.018920505419373512, -0.08183646202087402, -0.010238501243293285, -0.037415605038404465, -0.027441462501883507, -0.0011275828583166003, 0.0504816435277462, -0.035361867398023605, -0.05921749770641327]",2,Synthetic Datasets & GANs
Deep variational models for collaborative filtering-based recommender systems.pdf,original article deep variational models for collaborative filteringbased recommender systems jesus bobadilla fernando ortega abraham gutierrez a ngel gonzalezprieto received september accepted november published online december the authors abstract deep learning provides accurate collaborative ﬁltering models to improve recommender system results deep matrix factorization and their related collaborative neural networks are the state of the art in the ﬁeld nevertheless both models lack the necessary stochasticity to create the robust continuous and structured latent spaces that variational autoencoders exhibit on the other hand data augmentation through variational autoencoder does not provide accurate results in the collaborative ﬁltering ﬁeld due to the high sparsity of recommender systems our proposed models apply the variational concept to inject stochasticity in the latent space of the deep architecture introducing the variational technique in the neural collaborative ﬁltering ﬁeld this method does not depend on the particular model used to generate the latent representation in this way this approach can be applied as a plugin to any current and future speciﬁc models the proposed models have been tested using four representative open datasets three different quality measures and stateoftheart baselines the results show the superiority of the proposed approach in scenarios where the variational enrichment exceeds the injected noise effect additionally a framework is provided to enable the reproducibility of the conducted experiments keywords recommender systems collaborative ﬁltering variational enrichment deep learning introduction recommender systems rss are an artiﬁcial intelligence ﬁeld that provides methods and models to predict and recommend items to users eg ﬁlms to persons ecom merce products to costumers services to companies quality of service qos to internet of things iot devices etc current popular rss are spotify netﬂix tripadvisor amazon etc rss are usually categorized attending to their ﬁltering strategy mainly demo graphic contentbased contextaware social collaborative filtering cf and ﬁltering ensembles cf is the most accurate and widely used ﬁltering approach to implement rss cf models have evolved from the knearest neighbors knn algorithm to the probabilistic matrix factorization pmf the non negative matrix factorization nmf and the baye sian nonnegative matrix factorization bnmf currently deep learning research approaches are growing in strength they provide improvement in accuracy com pared to the machine learning mlbased matrix fac torization mf models additionally deep learning architectures are usually more ﬂexible than the mfbased ones introducing combined deep and shallow learn ing integrated contentbased ensembles gener ative approaches among others deep matrix factorization deepmf is a neural network model that implements the popular mf concept deepmf was designed to take as input a useritem matrix with explicit ratings and nonpreference implicit feedback a ngel gonzalezprieto angelgonzalezprietoucmes departamento de sistemas informaticos etsi sistemas informaticos universidad politecnica de madrid c de alan turing sn madrid madrid spain knodis research group universidad politecnica de madrid c de alan turing sn madrid madrid spain departamento de a lgebra geometrıa y topologıa universidad complutense de madrid plaza ciencias madrid madrid spain instituto de ciencias matematicas csicuamucm ucm c nicolas cabrera madrid madrid spain neural computing and applications httpsdoiorgs volv volv although current implementations use two embedding layers whose inputs are respectively user and items the experimental results evidence the deepmf superiority over the traditional approaches based on mlfocused rs par ticularly the most used mf models pmf nmf and bnmf currently deepmf is a popular model that is rapidly replacing the traditional mf models based on classical ml additionally deepmf has been used in the rs ﬁeld to combine social behaviors clicks ratings with images and a social trustaware rs has been implemented by using deepmf to extract features from the useritem rating matrix for improving the initialization accuracy qos predictions have also been addressed by using deepmf to learn attribute representations a deepmf model has been used that creates a lowdimen sional representation of a dataset that lends itself to a clustering interpretation finally the classical matrix completion task has been addressed by using the deepmf approach the not so widely spread neural collaborative filtering ncf model may be seen as an augmented deepmf model where deeper layers are added to the dot one additionally the dot layer can be replaced by a concatenate layer figure shows the explained concepts ncf slightly outperforms the deepmf accuracy results but it increases the required runtime to train the model and to run the forward process it is necessary to execute the extra multilayer perceptron mlp on top of the dot or concatenate layers moreover compared to deepmf the ncf architecture adds new hyperparameters to set mainly the number of hidden layers depth and their size number of neurons in each layer of the mlp architecture the hypothesis of the paper is that we can improve the existing cf neural models by adding a variational stage that borrows its operative from the variational autoen coders vae vaes not only improve latent factorbased models but they also manage nonlinear probabilistic latentvariable models while vaes have been extensively used in the imagegenerative area they have rarely been covered in the cf ﬁeld autoencoders perform a nonlinear pca and vaes improve their results by performing a nonlinear factor analysis unfortunately regular autoen coders do not ensure the regularity of the latent space this is the reason why in image processing they do not perform ﬁne producing new content from random encodings without explicit regularization some combinations of the latent space are meaningless once decoded the vaes superiority comes from their variational behavior which allows to make suitable regularizations such as in the statistic variational method using vaes inputs are encoded as distributions instead of single points making it possible to naturally express latent space regularization the cf improvement using vaes is because the item and the user latent factor distributions are regularized in the training stage ensuring that their latent spaces have good properties and conveniently generalize rs predictions the vaes regularization has two main properties com pleteness points sampled in the latent space give mean ingful content once decoded and continuity close points in the latent space provide similar contents when they are decoded to accomplish these properties usually regularization is done by enforcing distributions to be close to a centered and reduced standard normal distribution regularization involves a higher reconstruction error that can be balanced using the kullbackleibler divergence the use of vae in the cf ﬁeld provides a better fig deep matrix factorization deepmf versus neural collaborative filtering ncf neural computing and applications generalization it not only can improve recommendations but it also makes easier to use the latent codiﬁcations of items and users to make clustering to explain recommen dations and to generate augmented datasets the com pleteness and continuity properties make possible these additional beneﬁts of the vaes in the cf area the rest of the paper has been structured as follows in sect we describe the main ideas involved in our pro posal as well as its differences with the related work in variational cfbased recommender systems in sect the proposed model is explained section shows the experi ments design results and their discussions finally sect contains the main conclusions of the paper and the future works fundamentals and related work vaes as generative models variational autoencoders vaes act as regular autoen coders they aim to compress the input raw values into a latent space representation by means of an encoder neural network whereas the decoder neural network makes the opposite operation seeking to decompress from latent space to output raw values the main difference between clas sical autoencoders and vaes is the latent space design meaning and operation classical autoencoders do not generate structured latent spaces whereas vaes introduce a statistical process that forces them to learn continuous and structured latent spaces in this way vaes turn the samples into parameters of a statistical distribution usually the means and variance of a gaussian distribution from the parameters in the multivariate distribution we draw a random sample and a latent space sample is obtained for each training input this operation procedure is represented in fig the stochasticity of the random sampling improves the robustness and forces the encoding of continuous and meaningful latent space representations as it can be seen in fig where it is shown the vae latent space represen tation and its cumulative normal distribution due to their properties vaes have been used as gen erative deep learning models in the image processing ﬁeld reconstruction of a multispectral image has been per formed by means of a vae that parameterizes the latent space of gaussian distribution parameters vaes have been also used to create superresolution images as in where a model is proposed to encode lowresolution images in a dense latent space vector that can be decoded for target high resolution image denoising the blur image problem using vae is tackled in by adding a condi tional sampling mechanism that narrows down the latent space making it possible to reconstruct high resolution images moreover in the authors propose a ﬂexible autoencoder model able to adapt to varying data patterns with time by importing the vae concept from image processing several papers have used these models to improve rs results for instance denoising and variational autoencoders are tested in where the authors reported the superiority of the vae option against other models or in where variational autoencoders are combined with social information to improve the quality of the recommendations our proposal deep variational models the aim of this paper is to propose a neural architecture that joins the best of the deepmf and ncf models with the vae concept this novel models will be called respec tively variational deep matrix factorization vdeepmf and variational neural collaborative filtering vncf in contrast with the autoencoder and generative adversarial network gan approaches in the cf ﬁeld we shall not use the generative decoder stage and we maintain the regression output layer presented in the deepmf and the ncf models the main advantage in the use of the vae operation is the robustness that it confers to the latent representation this robustness can be seen by observing fig if we consider each dot drawn as a train sample representation in the latent space then test samples are most likely to be correctly classiﬁed in the vae model right graph in fig than being correctly classiﬁed in the regular autoencoder model left graph in fig in short the variational approach stochastically spreads the sam ples in the latent space improving the chances of classi fying correctly the training samples in our proposed rs cf scenario we expect that rating values can be better predicted when a variational latent space has been learnt because this space covers a wider more robust and more representative latent area whereas with a traditional autoencoders each sample would be coded as a value in the latent space white circle in fig the vae encodes the parameters of a multivariate distri bution eg mean and variance of both the blue and the orange gaussian distributions in fig from the learnt distribution parameters random sampling is carried out to generate stochastic latent space values gray circles in fig each epoch in the learning process generates a new set of latent space values once the proposed model has been trained when a huser itemi tuple is presented to the model the obtained latent space value green circle in fig can be better predicted in the vae scenario than in the regular autoencoder scenario the random sampled values gray circles of the enriched latent space will help to associate the predicted sample green circle with their neural computing and applications associated training samples white circle making the prediction process much more robust and accurate from the above explanations the vae operation can be deﬁned following fig in its variational layers stage ﬁrst two dense layers code the normal distribution parameters that set the mean and variance of the latent factors in the cf scenario two dense layers are arranged to code the normal distribution parameters of the items and two other different dense layers are used to code the normal distribution parameters of the users this variational approach regularizes the latent factors and makes it pos sible to reach the explained completeness and continuity goals once the distribution parameter layers are regular ized it is necessary to obtain a single latent factor point to code each user or item in the dataset that is for each user and item in the input of the model we need to combine its mean and variance a normal random function is used to generate the latent factor point coding the item or the user in the model input then each latent factor point is obtained by combining the normal random value its item mean or its user mean and its item variance or its user variance this operation is usually performed using a neural lambda layer each lambda layer result can be seen as a regularized version of the deepmf nonvariational fig operation of a trained variational autoencoder vae model when a new sample is presented to the encoder stage the handwritten digit in this example the model produces in the latent space a probability distribution typically this distribution belongs to a known family a multivariate normal distribution in this example so its shape is determined by some numerical parameters mean and standard deviation in our case with this information the decoder stage generates an instance by sampling this distribution getting a slightly different digit in this example this introduces a stochastic component in the generation procedure that enriches the latent space and variability of the generative model fig representation of a vae latent space for the mnist dataset left side and its cumulative normal distribution right side neural computing and applications approach finally we obtain the prediction of the rating of the user to the item by combining the lambda user and item factors using a dot product in short our variational approach incorporates the following substages con verting the input embedding factors to normal distribution values and thus making a regularization to generate continuous and complete latent factor codes combin ing the normal distribution latent factor codes to obtain single latent factor values and predicting ratings by making the dot product of the regularized latent factor values vaes for recommender systems current cfbased variational autoencoders usually obtain raw augmented data one strategy is to synthetize ratings from user to items or generated relevant versus not relevant votes from users to items and another approach is to pretrain a vae model to map data vectors into the latent space an idea that has been intensively studied in several variants in any case these strategies force practitioners to sequentially run two separated models the generative model gan or vae that provides augmented data and the regression cf model that makes predictions and rec ommendations this approach presents three main draw backs complexity as two separate models are necessary large time consumption and sparsity management as we will explain deeper in the following section our proposed model does not generate raw aug mented data on the contrary its innovation is based on the use of a single model to internally manage both augmen tation and prediction aims particularly signiﬁcant is the way in which the proposed model addresses the sparsity problem we do not make augmentation on the sparse raw data ratings cast from users to item but an internal augmentation process in the dense latent space of the model figs and each sample that is randomly gen erated from the latent space feeds the model regression layers thereby we propose a model that ﬁrst generates stochastic variational samples in a dense latent space and then these generated samples act as inputs of the regres sion stage of the model to test these ideas the hypothesis considered in this paper is that the augmented samples will be more accurate and effective if they are generated in an inner and dense latent space rather than in a very sparse input space it is important to realize that enriching the inner latent space can improve the recommendation results but it also injects noise to the latent space that may potentially worsen the results it is expected that the proposed approach will work better with poor latent spaces whereas when it is applied to rich spaces the spurious entropy added by the variational stage could worsen recommendations thus mediumsize cf datasets or large and complex ones are better candi dates to improve their results when the variational proposal is applied whereas large datasets with predictable data distributions will probably not beneﬁt from the noise injection of the variational architecture proposed model the proposed neural architecture will mix the vae and the deepmf or the ncf models from the vae we take the encoder stage and its variational process and from the deepmf or the ncf model we use its regression layers this is an innovative approach in the rs ﬁeld since the vae and gan neural networks have only been used as a posteriori stage to make data augmentation ie to obtain enriched input datasets to feed the cf deepmf or ncf models hence the traditional approach needs to separately train two models ﬁrst the vae and then the deepmfncf networks as discussed in sect these combined solu tions present important disadvantages in terms of model complexity time consumption and poor sparsity management in sharp contrast our proposed approach efﬁciently joins the vae and the deep cf regression concepts to obtain improved predictions with a single training process in the learning stage the training samples feed the model left hand side of fig each training sample consists of the tuple huser item ratingi rating casted by the user to the item in the deepmfncf architecture each user is represented by hisher vector of voted ratings and each item is represented by its vector of received ratings the model learns the ratings third element in the tuples casted by the users to the items ﬁrst and second elements in the fig latent space representation of the proposed variational model from the learnt means and variances of the multivariate gaussian distribution a random sampling process is run to spread the latent space sample values gray circles that will help to accurately predict the unknown sample rating values green circle neural computing and applications tuples in other words the ratings are outputs of the neural network right hand side of fig thanks to this architecture the variational stage is nat urally embedded into the model so it can be ﬂexibly used to inject variability into the samples it is worth mentioning that this stage is also trained simultaneously to the pre dictive part of the model mutually inﬂuencing each other which we expect will lead to better results than a simple separate learning formalization of the model the architectural details of the proposed models are shown in fig for simplicity only the variational deep matrix factorization vdeepmf architecture is shown in this ﬁgure the corresponding model for ncf named varia tional neural collaborative filtering vncf is analogous to the vdeepmf one it has the same embedding and variational layers and we should only replace the dot layer of deepmf by a concatenate layer fol lowed by a mlp to ﬁx the notation let us suppose that our dataset contains u users and i items in general the aim of any deep learning model for cfbased prediction is to train a stochastic neural network that implements a function h ru ri r this function h operates as follows let us codify the uth user of the dataset resp the ith item using onehoten coding as the uth canonical basis vector eu resp the ith canonical basis vector ei then we have that the outcome of the model is the following hðeu eiþ r ¼ prediction of the score that the uth user would assign to theith item to train this function h in the learning phase the neural network is fed with a set x ¼ hu i ri f g of training tuples hu i ri of a user u that rated item i with a score r the function h is trained to minimize the error eðhþ ¼ x huirix dðhðeu eiþ rþ ðþ here d r r r is any metric on r typical choices are the socalled mean squared error mse and mean absolute error mae respectively given by dmseðx yþ ¼ ðx yþ dmaeðx yþ ¼ jx yj our proposal for the vdeepmf consist on decomposing h has a combination of a embedding followed by a variational stage and a ﬁnal dot layer as shown in fig that is h ¼ dot variational embedding notice that at the end of the day h is a deep leaning model with novel customary layers designed for the rs problem in this way h can be trained to reduce the error eðhþ of eq with the standard deep learning dl methods such as the backpropagation algorithm the embedding layer the ﬁrst embedding layer left hand side of fig is borrowed from the natural language processing nlp the idea is that this layers provides a fast translation of users and items into their respective fig proposed vdeepmf ncf approach cf samples are encoded in the latent space by means of a variational process and then predictions are obtained by using a regression neural network neural computing and applications representations in the latent spaces to be precise this layer implements a linear map embedding ru ri rl rl that maps a pair ðeu eiþ into a pair of dense vectors ðvu wiþ rl rl that represents the uth user and the ith item being l the dimension of the representations for our purpose we implement the embedding layer as a regular mlp dense layer in sharp contrast with other approaches in nlp such as wordvec glove or elmo among others the reason is that these later approaches seek to ﬁnd an embedding preserving some metric information of the words typically the likelihood of ﬁnding two words together or their semantic similarity however in our case since we perform contextfree cf prediction no a priori information about the similarity between users or items is available indeed this is precisely the ultimate goal of the rs to ﬁnd an appropriate repre sentations of these users and items in the latent space for this reason we decided not to add any extra mechanism that could bias this training process so the embedding layer will act as a regular dense layer to be trained in parallel during the learning process finally we would like to point out that even though from a conceptual point of view the embedding layer is just a dense layer to save time and space these embedding layers are typically implemented through lookup tables in this way instead of feeding the network with the onehot encoding of the user u resp the item i we input it via its id as user resp as item the lookup table efﬁciently recovers the uth resp ith column of the embedding matrix that contains vu resp wi so that the translation can be conducted in a more efﬁcient way than with a standard mlp layer by exploiting the sparsity of the input the variational layer the variational process is carried out by the varia tional stage labeled as variational layers at the middle of fig this is the core of our proposed model from the latent space representation ðvu wiþ rl rl of the uth user and the ith item two separated dense layers return the mean and variance parameters of two gaussian multivariate distribution in this way if ﬁx a latent space dimension k the ﬁrst part of this variational stage left part of the middle rectangle of fig computes a map sðvu wiþ ¼ ðlðvuþ r ðvuþ lðwiþ rðwiþþ rk the outputs lðvuþ lðwiþ of s will be interpreted as the means of two gaussian distributions to the user and the item respectively whereas r ðvuþ rðwiþ will represent variance the second part of the variational stage left right of the middle rectangle of fig is ruled by a pair of random vectors ðplðvuþr ðvuþ qlðwiþrðwiþþ where p n ðlðvuþ diag r ðvuþþ q n ðlðwuþ diag r ðwiþþ here n ðl rþ denotes a kdimensional multivariate nor mal distribution of mean vector l and diagonal covariance matrix r ie whose probability density function is fig proposed vdeepmf architecture the ncf architecture will have identical embedding and variational layers to the vdeepmf one it will just replace the dot layer for a concatenate layer followed by an mlp neural computing and applications fðsþ ¼ ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ ðpþk det r q exp ðs lþtrðs lþ notice that in our case the covariance matrix is always diagonal in this setting the task of the variational stage is just to sample p and q in this manner variationalðvu wiþ ¼ ðp qþ rk rk where p is a sample of p ¼ pðsðvu wiþþ n ðlðvuþ diag r ðvuþþ and q is a sample of q ¼ qðsðvu wiþþ n ðlðwuþ diag r ðwiþþ this pair represents the stochastic latent representations associated with ðvu wiþ the join layer this is the only layer that depends on the particular choice of the architecture in the case of the variational deep matrix factorization vdeepmf architecture this ﬁnal layer is a dot layer labeled as regression layer at right hand side of fig it is just a linear layer that simply computes the dot product of the latent vectors p and q therefore dotðp qþ ¼ p q in the case of vncf this simple layer is replaced by a fully connected mlp h rk rk r that extracts the nonlinear relations from p and q therefore summarizing the process the proposed vdeepmf model h computes hðeu eiþ ¼ dot variational embeddingðeu eiþ ¼ plðvuþr ðvuþ qlðwiþrðwiþ analogously the vncf model returns the proposed vdeepmf model h computes hðeu eiþ ¼ h variational embeddingðeu eiþ ¼ hðplðvuþr ðvuþ qlðwiþrðwiþþ in both cases hðeu eiþ is a random variable that when sampled returns a natural number that should be inter preted as the predicted rating by h for the user u regarding item i empirical evaluation in this section we describe the empirical experiments carried out to evaluate the performance of the variational approach in the deepmf and ncf models experimental setup the experimental evaluation has been performed over four different datasets to measure the performance of the pro posed method over different environments the selected datasets are filmtrust an small dataset that contains the ratings of thousands of items to movies movielens m the gold standard dataset in cfbased rs myanimelist a dataset extracted from kaggle that contains the ratings of thousands of users to anime comics and netﬂix a popular dataset with hundred of millions ratings used in the netﬂix prize competition table shows the main parameters of these datasets the corpus of these datasets has been randomly splitted into training ratings of the ratings and test ratings of the ratings the evaluation of the proposed method has been ana lyzed from three different points of view the quality of the predictions the quality of the recommendations and the quality of the recommendation lists to measure the quality of the predictions we have compared the real rating rui of an user u to an item i of the test split rtest with the predicted one rui these compar isons have been carried out in three ways using the mae as in eq using the mse as in eq and computing the proportion of the explained variance r as in eq notice that in eq r denotes the mean of the ratings contained in the test split mae ¼ rtest x huiirtest j rui rui j ðþ mse ¼ rtest x huiirtest rui rui ðþ r ¼ x huiirtest rui rui x huiirtest rui r ðþ to measure the quality of the recommendations we have analyzed the impact of the top n recommended items to the user u collected in the list tn u using precision eq we measure the proportion of relevant recommendations ie the user rated the item with a rated equal or greater than a threshold h among the top n here u denotes the set of user in the test split in a similar vein using recall eq we measure the proportion of the test items rated by the user u rtest u that were relevant to him or her and were included into the recommended items tn u for the con ducted experiments the used thresholds are h ¼ for filmtrust h ¼ for movielens and netﬂix and h ¼ for myanimelist these thresholds were chosen in agreement wwwkagglecom neural computing and applications with the results of where it was shown that these values represent a fair tradeoff between provided coverage of the dataset and prediction accuracy precision ¼ u x uu fi tn u j rui hg n ðþ recall ¼ u x uu fi tn u j rui hg fi rtest u j rui hg ðþ additionally we have measure the quality of the recom mendations using the harmonic mean of the precision and the recall using f score eq f ¼ precision recall precision þ recall ðþ however evaluating the quality of recommendations based solely on user ratings provides a biased view of the rec ommenders performance therefore we have also deter mined the novelty eq of the recommendations novelty is calculated by assigning more weight to those items that have received fewer ratings in other words the nov elty of an item is inversely proportional to the number of ratings received for an item ri with respect to the total number of votes in the recommender system r novelty ¼ u x uu p itnu log ri r n ðþ finally to measure the quality of the recommendation lists we use the normalized discounted cumulative gain ndcg suppose that the recommendation list of the user u tn u is sorted decreasingly so that the items predicted as more relevant are placed in the ﬁrst positions given i tn u let postnu ðiþ be the position of the item i in the recommendation list analogously suppose that the real top n recommendations to user u rn u as sorted decreas ingly and denote by posrnu ðiþ the position of the item i rn u in the list in this setting the discounted cumulative gain dcg and the ideal cumulative gain idcg of the user u u are deﬁned as in eq dcgu ¼ x itnu rui log postnu ðiþ þ idcgu ¼ x irnu rui log posrnu ðiþ þ ðþ in this way ndcg is given by the mean of the ratio between dcg and idcg as in eq ndcg ¼ u x uu dcgu idcgu ðþ due to the stochastic nature of the variational embedded space of the proposed method the test predictions used to evaluate the proposed method have been computed as the average of the predictions performed for each pair of user u and item i overall the proposed variational architecture ade quately improves simple models such as the deepmf one approaching their results to larger models such as the ncf this tendency can be observed in both predictions and recommendation quality measures additionally shorter running times are needed to train the proposed variational approach compared to baselines this is the expected behavior in the hypothesis of the paper but a remarkable constraint must be considered the variational stage works particularly well when applied to not too large datasets whereas using large datasets the variational approach could not be necessary the key idea is the ability of the table main parameters of the datasets used in the experiments dataset n users n items n ratings scores sparsity filmtrust to movielens to myanimelist to netﬂix to table quality of the predictions filmtrust movielens myanimelist netﬂix a mean absolute error the lower the better vdeepmf deepmf vncf ncf b mean squared error the lower the better vdeepmf deepmf vncf ncf c r score the higher the better vdeepmf deepmf vncf ncf the best results for each quality measure are highlighted in bold neural computing and applications proposed model to deal with entropy the variational stage increases entropy by generating stochastic latent factors and then enriching the latent space and making it more robust to the input sample variability the intrinsic com pleteness and continuity properties of the vae are the foundations on which the variational approach gets robust continuous and structured latent spaces these enriched spaces provide the improved results obtained in the experiments experimental results table includes the quality of the predictions performed by the proposed model best values for each dataset are highlighted in bold table a contains the mae eq table b contains the mse eq and table c contains the r score eq we can observe that the proposed variational approach improves the prediction capability of deepmf in all datasets except of netﬂix and reports worse predictions when it is applied to ncf we justify these results by taking into account the fea tures of the deep learning models used and the properties of each dataset on the one hand the larger the size of the dataset the less necessary it is to enrich the votes with the proposed variational approach in other words when the dataset is small the amount of shannon entropy that it contains might be quite limited by using a variational method to generate new samples we add some extra entropy that enriches the dataset giving the chance to the regressive part of exploiting this extra data however large datasets usually present a large entropy in such a way that the regressive models can effectively extract very subtle information from them in this setting if we add a varia tional stage instead of adding new relevant variability to the dataset we only add noise that muddies the underlying patterns for this reason the variational approach is of no beneﬁt in huge datasets like netﬂix on the other hand the ncf model is more complex than the deepmf one so data enrichment has less impact for complex models that are able to ﬁnd more sophisticated relationships between data than simpler models in fact fig quality of the recommendations measured by precision and recall the higher the better neural computing and applications based on these results we can assert that including the variational approach into a simple model such as deepmf is equivalent to using a more complex model such as ncf furthermore figs and show the quality of the recommendations using precision eq recall eq and f eq quality measures in filmtrust figs a and a movielens figs b and b and myanimelist figs c and c we can observe that the proposed variational approach reports a beneﬁt for the deepmf model and it worsens the results of the ncf model in addition vdeepmf model is the model that computes the best recommendations for these datasets in contrast in netﬂix figs d and d the proposed variational approach does not improve the quality of the recommen dations with ncf being the model that provides the best recommendations for this dataset these results are con sistent with those analyzed when measuring the quality of the predictions consequently it is evident that the pro posed variational approach works adequately when the dataset is not too large and the model used is not too complex fig contains the quality of recommendations regard ing novelty eq it is observed that when the variational stage is added to the deepmf model a signiﬁcant improvement of the novelty of the recommendations in small datasets is achieved as the dataset becomes larger the impact of the variational step is detrimental to the model thus the variational stage has a positive impact on the filmtrust fig a and movielens fig b datasets and a negative impact on the myanimelist fig c and netﬂix fig d datasets on the contrary when a varia tional stage is added to the ncf model its impact on novelty is practically zero regardless of the dataset size this experiment like the previous ones reafﬁrms the conclusion that a variational step improves the results of simple models on small datasets in addition fig contains the ndcg results from it we can observe the same trends as those shown in previous experiments in filmtrust fig a the quality of the recommendation lists do not vary independently of whether the variational approach is used or not in movielens fig b and myanimelist fig c the combination of the variational approach with simple modeling such as deepmf provides the best results and in netﬂix fig d the variational approach signiﬁcantly worsens the quality of the recommendation lists fig quality of the recommendations measured by f the higher the better neural computing and applications conclusions in the latest trends accuracy of rss is being improved by using deep learning models such as deep matrix factor ization and neural collaborative ﬁltering however these models do not incorporate stochasticity in their design unlike variational autoencoders do variational random sampling has been used to create augmented input raw data in the collaborative ﬁltering context but the inherent col laborative ﬁltering data sparsity makes it difﬁcult to get accurate results this paper applies the variational concept not to generate augmented sparse data but to create aug mented samples in the latent space codiﬁed at the dense inner layers of the proposed neural network this is an innovative approach trying to combine the potential of the variational stochasticity with the augmentation concept augmented samples are generated in the dense latent space of the neural network model in this way we avoid the sparse scenario in the variational process observe that the proposed model in this paper also encodes the intrinsic locality of the users and items in the latent space recall that regular mf models capture the similarity of users and items in the latent space since pre dictions are constructed via inner product a continuous function in the same spirit our variational models also preserve this locality since the output is still computed through a continuous function the feedforward neural network a much more complicated function but eventu ally continuous moreover since the probability distribu tions representing each user and item in the latent space depend on continuous parameters the mean and standard deviation of a gaussian distribution small variations in these parameters corresponding to similar items or users are also encoded as almost equal distributions and thus their samples tend to be also close in the distributional sense thanks to these ideas the results of the experimental analyses conducted in this paper show an important improvement when the proposed models are applied to middlesize representative collaborative ﬁltering datasets compared to the stateoftheart baselines testing both prediction and recommendation quality measures in sharp contrast testing on the huge netﬂix dataset not only leads to no improvement but the recommendation quality fig quality of the recommendations measured by novelty the higher the better neural computing and applications actually gets worse in this manner increasing the shannon entropy in rich latent spaces causes that the negative effect of the introduced noise exceeds its beneﬁt therefore the proposed deep variational models should be applied to seek to a fair balance between their positive enrichment and their negative noise injection to emphasize this idea in table we show the total time and epochs required by each model to be ﬁtted to each dataset using a quadro rtx gpu best time for each dataset is in bold we can observe that including a varia tional layer to the model signiﬁcantly reduces the required time for ﬁtting variational models are able to generate shannon entropy that is transferred to the regression stage leading to a more effective training that requires fewer epochs to be ﬁtted therefore the ﬁtting time needed to reach acceptable results is substantially lower the results presented in this work can be considered as generalizable since they were analyzed in four represen tative and open cf datasets researchers can reproduce our experiments and easily create their own models by using the provided framework referenced in sect the authors of this work are committed to reproducible science so the code used in these experiments is publicly available among the most promising future works we propose the following introducing the variational process in the alternative inner layers of the relevant architectures in the collaborative ﬁltering area screening the learning evolution in the training process since it is faster than the classical models but it also requires early stopping in the fig quality of the recommendations lists measured by ndcg the higher the better table fitting time using a quadro rtx filmtrust movielens myanimelist netﬂix vdeepmf s epochs s epochs s epochs s epochs deepmf s epochs s epochs s epochs s epochs vncf s epochs s epochs s epochs s epochs ncf s epochs s epochs s epochs s epochs best ﬁtting times for each datased in bold neural computing and applications training stage providing further theoretical explana tions of the properties of the cf datasets in terms of shannon entropy or other statistical features that ensure a good performance of the proposed models applying probabilistic deep learning models in the cf ﬁeld to cap ture complex nonlinear stochastic relationships between random variables and testing the impact of the pro posed concept when recommendations are made to groups of users acknowledgements a gp acknowledges the hospitality of the department of mathematics at universidad autonoma de madrid where part of this work was developed this work was partially supported by ministerio de ciencia e innovacion of spain under the project pidrbi dlcemg and the comunidad de madrid under convenio plurianual with the universidad politecnica de madrid in the actuation line of programa de excelencia para el profesorado universitario the forth author has been partially sup ported by the madrid government comunidad de madrid spain under the multiannual agreement with the universidad complutense de madrid in the line research incentive for young phds in the context of the v pricit regional programme of research and technological innovation through the project pr funding open access funding provided thanks to the cruecsic agreement with springer nature data availability the datasets analyzed during the current study are available in the repositories referred in the references declarations conflict of interest the authors declare that they have no conflict of interest open access this article is licensed under a creative commons attribution international license which permits use sharing adaptation distribution and reproduction in any medium or format as long as you give appropriate credit to the original authors and the source provide a link to the creative commons licence and indicate if changes were made the images or other third party material in this article are included in the articles creative commons licence unless indicated otherwise in a credit line to the material if material is not included in the articles creative commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use you will need to obtain permission directly from the copyright holder to view a copy of this licence visit httpcreativecommons orglicensesby references beel j langer s genzmehr m gipp b breitinger c nurnberger a research paper recommender system evaluation a quantitative literature survey in proceedings of the international workshop on reproducibility and replication in recommender systems evaluation pp bobadilla j gonzalezprieto a ortega f laracabrera r deep learning feature selection to unhide demographic recom mender systems factors neural comput appl deldjoo y schedl m cremonesi p pasi g recommender systems leveraging multimedia content acm comput surveys csur kulkarni s rodd sf context aware recommendation systems a review of the state of the art techniques comput sci rev shokeen j rana c a study on features of social recom mender systems artif intell rev bobadilla j alonso s hernando a deep learning archi tecture for collaborative ﬁltering recommender systems appl sci forouzandeh s berahmand k rostami m presentation of a recommender system with ensemble learning and graph embedding a case on movielens multimed tools appl c ano e morisio m hybrid recommender systems a systematic literature review intell data anal mnih a salakhutdinov rr probabilistic matrix factor ization adv neural inf process syst fevotte c idier j algorithms for nonnegative matrix factorization with the bdivergence neural comput hernando a bobadilla j ortega f a non negative matrix factorization for collaborative ﬁltering recommender systems based on a bayesian probabilistic model knowlbased syst rendle s krichene w zhang l anderson j neural collaborative ﬁltering vs matrix factorization revisited in fourteenth acm conference on recommender systems pp he x liao l zhang h nie l hu x chua ts neural collaborative ﬁltering in proceedings of the th international conference on world wide web pp narang s taneja n deep contentcollaborative recom mender system dccrs in international conference on advances in computing communication control and networking icacccn pp ieee bobadilla j laracabrera r gonzalezprieto a ortega f deepfair deep learning for improving fairness in recommender systems int j interact multimed artif intell gao m zhang j yu j li j wen j xiong q recom mender systems based on generative adversarial networks a problemdriven perspective inf sci xue hj dai x zhang j huang s chen j deep matrix factorization models for recommender systems in ijcai mel bourne australia vol pp wen j she j li x mao h visual background recom mendation for dance performances using deep matrix factoriza tion acm trans multimed comput commun appl tomm wan l xia f kong x hsu ch huang r ma j deep matrix factorization for trustaware recommendation in social networks ieee trans network sci eng zou g chen j he q li kc zhang b gan y ndmf neighborhoodintegrated deep matrix factorization for service qos prediction ieee trans netw serv manage trigeorgis g bousmalis k zafeiriou s schuller bw a deep matrix factorization method for learning attribute repre sentations ieee trans pattern anal mach intell fan j cheng j matrix completion by deep matrix fac torization neural netw liu x gherbi a wei z li w cheriet m multispectral image reconstruction from color images using enhanced varia tional autoencoder and generative adversarial network ieee access neural computing and applications liu zs siu wc wang lw li ct cani mp unsupervised real image superresolution via generative varia tional autoencoder in proceedings of the ieeecvf conference on computer vision and pattern recognition workshops pp liu zs siu wc chan yl photorealistic image super resolution via variational autoencoders ieee trans circ syst video technol zhang ss liu jw zuo x lu rk lian sm online deep learning based on autoencoder appl intell liang d krishnan rg hoffman md jebara t varia tional autoencoders for collaborative ﬁltering in proceedings of the world wide web conference pp nisha c mohan a a social recommender system using deep architecture and network embedding appl intell rama k kumar p bhasker b deep autoencoders for feature learning with embeddings for recommendations a novel recommender system solution neural comput appl tahmasebi h ravanmehr r mohamadrezaei r social movie recommender system based on deep autoencoder network using twitter data neural comput appl li x she j collaborative variational autoencoder for recommender systems in proceedings of the rd acm sigkdd international conference on knowledge discovery and data mining pp he m meng q zhang s collaborative additional varia tional autoencoder for topn recommender systems ieee access nahta r meena yk gopalani d chauhan gs twostep hybrid collaborative ﬁltering using deep variational bayesian autoencoders inf sci shenbin i alekseev a tutubalina e malykh v nikolenko si recvae a new variational autoencoder for topn recom mendations with implicit feedback in proceedings of the th international conference on web search and data mining pp wang k xu l huang l wang cd lai jh sddrs stacked discriminative denoising autoencoder based recom mender system cogn syst res liu y wang s khan ms he j a novel deep hybrid recommender system based on autoencoder with neural collab orative ﬁltering big data mining anal mikolov t sutskever i chen k corrado gs dean j distributed representations of words and phrases and their com positionality adv neural inform process syst mikolov t chen k corrado g dean j efﬁcient esti mation of word representations in vector space arxiv preprint arxiv pennington j socher r manning cd glove global vectors for word representation in proceedings of the conference on empirical methods in natural language processing emnlp pp peters m neumann m iyyer m gardner m clark c lee k zettlemoyer l deep contextualized word representations arxiv preprint arxiv guo g zhang j yorkesmith n a novel bayesian simi larity measure for recommender systems in proceedings of the rd international joint conference on artiﬁcial intelligence ijcai pp harper fm konstan ja the movielens datasets history and context acm trans interact intell syst tiis azathoth myanimelist dataset httpswwwkagglecomaza thothmyanimelist online accessed july bennett j lanning s et al the netﬂix prize in pro ceedings of kdd cup and workshop new york ny usa vol p bobadilla j hernando a ortega f bernal j a framework for collaborative ﬁltering recommender systems expert syst appl herlocker jl konstan ja terveen lg riedl jt evaluating collaborative ﬁltering recommender systems acm trans inf syst gunawardana a shani g evaluating recommender sys tems handbook boston ma ortega f laracabrera r gonzalezprieto a bobadilla j providing reliability in recommender systems through bernoulli matrix factorization inf sci castells p vargas s wang j novelty and diversity metrics for recommender systems choice discovery and rele vance in proceedings of the rd european conference on information retrieval ecir shannon ce weaver w the mathematical theory of communication university of illinois press urbana publishers note springer nature remains neutral with regard to jurisdictional claims in published maps and institutional afﬁliations neural computing and applications,"[0.021635670214891434, 0.07120244204998016, -0.01991306059062481, 0.0032793288119137287, 0.0013616065261885524, -0.008203945122659206, 0.03456254303455353, -0.019589172676205635, -0.007471803110092878, 0.03709975257515907, -0.035440295934677124, -0.028098231181502342, -0.018959304317831993, 0.10136227309703827, -0.010352816432714462, -0.04890919104218483, -0.0102360425516963, 0.01874757558107376, -0.032366424798965454, -0.02719695493578911, 0.011990657076239586, -0.028750881552696228, 0.04555816203355789, -0.0047419387847185135, 0.024533599615097046, 0.032039374113082886, -0.036678675562143326, -0.03242997080087662, -0.0029911159072071314, 0.009799659252166748, 0.00022522764629684389, -0.007266777101904154, 0.020772943273186684, -0.02334030345082283, 2.245335736006382e-06, 0.024155866354703903, -0.01791904866695404, -0.04277992993593216, 5.183219036553055e-05, -0.036928534507751465, 0.03649556636810303, 0.07564331591129303, 0.006644994020462036, 0.004551812540739775, -0.036806605756282806, -0.0204787477850914, 0.013452290557324886, 0.06313273310661316, 0.010943935252726078, -0.006423348560929298, -0.026895124465227127, 0.004822487011551857, 0.038511086255311966, -0.04988827556371689, 0.031045960262417793, -0.011629375629127026, 0.025453077629208565, -0.01024849433451891, 0.02566480077803135, 0.009335119277238846, -0.022621093317866325, -0.005702471360564232, 0.0446307547390461, -0.01944224163889885, 0.07436984032392502, 0.009123334661126137, 0.04014817252755165, -0.03176335617899895, -0.0194803886115551, 0.0710565447807312, -0.005366160999983549, 0.002521006390452385, -0.0443042553961277, -0.02214585430920124, -0.009367522783577442, 0.055812202394008636, -0.02235235832631588, -0.016922691836953163, 0.01685846783220768, 0.009053817018866539, -0.008590875193476677, 0.038593839854002, 0.05225689709186554, 0.01214680541306734, 0.03407222777605057, 0.05899680405855179, 0.05001593008637428, -0.0435512512922287, 0.002637856872752309, -0.01538616418838501, -0.010759175755083561, -0.03107491508126259, 0.05883282050490379, -0.012045299634337425, -0.018621617928147316, -0.035893023014068604, -0.0026087353471666574, -0.026899700984358788, -0.03762615844607353, 0.021516529843211174, 0.011555109173059464, -0.004495513159781694, -0.009896118193864822, 0.0456317737698555, 0.010739118792116642, -0.011130483821034431, -0.018193110823631287, -0.03545694798231125, -0.04280107095837593, 0.00696934387087822, 0.00958267878741026, -0.005577367264777422, 0.03215815871953964, 0.05317949503660202, -0.04115454852581024, -0.05287976562976837, -0.04667351767420769, 0.03764214366674423, -0.02282905764877796, 0.02917622961103916, 0.005809923633933067, 0.12090914696455002, -0.0035188121255487204, 0.04286280274391174, -0.045591775327920914, -0.004816997796297073, -0.05903179198503494, 0.04224543645977974, 0.013505236245691776, 0.04471568018198013, 0.0558137372136116, 0.02893616072833538, 0.05171942338347435, -0.027126185595989227, 0.023378532379865646, -0.007443212438374758, 0.03145051747560501, 0.016536545008420944, 0.004090185277163982, 0.00462657306343317, 0.00159975525457412, -0.02225525677204132, -0.021897481754422188, -0.040279265493154526, 0.022997546941041946, -0.0063935574144124985, 0.011657294817268848, -0.017633933573961258, -0.025419676676392555, -0.042703576385974884, -0.020423218607902527, 0.0722418874502182, 0.011408822610974312, -0.036318954080343246, 0.04551149532198906, -0.0074649592861533165, 0.014510701410472393, -0.03330562263727188, 0.009323704987764359, 0.057224515825510025, 0.04063166305422783, 0.004918139427900314, -0.012601235881447792, -0.001207973575219512, -0.022405683994293213, -0.005381700582802296, -0.029694337397813797, -0.02067340910434723, -0.08540572226047516, 0.01874842494726181, 0.03351462632417679, 0.05443126708269119, -0.06104578450322151, -0.01235931646078825, 0.03567684069275856, -0.0063233221881091595, 0.07304338365793228, 0.09000523388385773, 0.038817450404167175, -0.01679193042218685, -0.03562726452946663, -0.0078866733238101, 0.021364374086260796, 0.07332926243543625, 0.020342905074357986, -0.032207708805799484, 0.016116678714752197, 0.007529027760028839, -0.04586247354745865, -0.03623894229531288, 0.046414174139499664, -0.03671688213944435, 0.07006463408470154, -0.0029982130508869886, 0.06654952466487885, -0.036606524139642715, -0.030891528353095055, -0.042664963752031326, 0.013678948394954205, -0.011247212067246437, 0.024485286325216293, 0.007164750713855028, 0.09416120499372482, 0.07929204404354095, 0.04271936044096947, 0.013403148390352726, 0.04688645154237747, -0.03963927924633026, -0.02345987595617771, -0.07002443075180054, 0.021790117025375366, -0.04227627441287041, -0.02497568167746067, -0.028566518798470497, -0.06211457401514053, -0.009839242324233055, 0.002016953192651272, 0.044970862567424774, -0.04792233929038048, 0.03626987710595131, 0.010407213121652603, 0.04753263294696808, 0.019480518996715546, -0.028738848865032196, -0.018251704052090645, 0.02399935945868492, 0.04898519814014435, 0.027439355850219727, 0.04348254203796387, 0.03234882280230522, 0.0305352620780468, 0.0005326146492734551, 0.026788892224431038, -0.0589429996907711, -0.049503739923238754, -0.02088930457830429, -0.01740683615207672, 0.007592775393277407, 0.029209228232502937, -0.05020434409379959, 0.06840864568948746, 0.04520994424819946, 0.013622035272419453, -0.04580551013350487, 0.05371740832924843, 0.010262448340654373, -0.03304343298077583, -0.005384908057749271, -0.015090527944266796, 0.0013495743041858077, 0.026220308616757393, -0.0004060029168613255, 0.015536745078861713, -0.03912777453660965, 0.023128919303417206, -0.0088672349229455, 0.05365614593029022, 0.04382696747779846, -0.02466455101966858, -0.03976942226290703, 0.006896147038787603, 0.014776456169784069, 0.002447170903906226, 0.03682462126016617, -0.0014756208984181285, -0.01911020092666149, -0.017027322202920914, -0.029929811134934425, 0.014211062341928482, -0.007422301918268204, -0.03585870936512947, -0.013779813423752785, 0.05448002740740776, 0.03334314376115799, 0.023674167692661285, -0.035947635769844055, 0.06079144775867462, -0.005352568347007036, 0.007985817268490791, -0.005112368613481522, 0.038714878261089325, 0.024631889536976814, -0.025693105533719063, -0.061297670006752014, 0.00381233892403543, 0.01944664493203163, -0.004801072180271149, 0.01757916808128357, 0.0009293335024267435, -0.03833235800266266, -0.02151237055659294, -0.005768655799329281, -0.01150630321353674, -0.016034554690122604, -0.008008738048374653, -0.011995959095656872, 0.04383836314082146, 0.009535606019198895, -0.0052389781922101974, 0.032760586589574814, 0.05315356329083443, 0.007002019789069891, -0.03461447358131409, 0.028011435642838478, -0.05309378728270531, 0.007192255463451147, 0.02308446355164051, 0.013135244138538837, -0.03872412443161011, -0.025394722819328308, 0.0021313007455319166, 0.0063017746433615685, -0.06060652434825897, 0.05144185572862625, 0.017387783154845238, -0.012416527606546879, -0.021395236253738403, -0.05937708169221878, -0.03833913803100586, 0.03356955945491791, 0.002330014482140541, -0.008848450146615505, 0.04982367157936096, 0.04550803452730179, 0.00626293895766139, -0.026364248245954514, -0.05074262246489525, -0.007277838885784149, -0.08322910219430923, 0.017339741811156273, -0.009732134640216827, -0.0743606686592102, -0.009066053666174412, -0.037467531859874725, 0.05153670161962509, 0.022167466580867767, -0.033351656049489975, -0.01290817093104124, 0.06779717653989792, -0.05549293011426926, 0.01520234439522028, -0.013674077577888966, -0.06033073738217354, -0.011885233223438263, 0.021204456686973572, 0.008889072574675083, 0.038548778742551804, -0.009121150709688663, 0.0038248684722930193, -0.022653507068753242, -0.041768744587898254, 0.01726597733795643, -0.022457998245954514, -0.018389666453003883, 0.015405897051095963, 0.0515022948384285, 0.05752258375287056, -0.04465072602033615, 0.016594260931015015, 0.014921775087714195, 0.013930926099419594, 0.004410454537719488, 0.0078879464417696, -0.043213628232479095, -0.06838861107826233, 0.05007559061050415, 0.030187541618943214, 0.045913804322481155, 0.010425654239952564, 0.04072941839694977, -0.02285595051944256, 0.04281889647245407, 0.01797800324857235, 0.0514695830643177, 0.0023664424661546946, -0.1209488958120346, -0.008145486004650593, -0.03593309596180916, 0.018869662657380104, 0.028582768514752388, 0.027617665007710457, -0.009291885420680046, 0.0350881963968277, 0.004879721440374851, 0.023206297308206558, 0.021725991740822792, -0.03644096106290817, 0.00945719238370657, -0.025792578235268593, 0.05499012768268585, 0.010994389653205872, 0.009821338579058647, -0.012322932481765747, -0.046826332807540894, -0.014057737775146961, -0.03913269191980362, 0.02948675863444805, -0.028580665588378906, 0.030822493135929108, 0.00820900872349739, 0.018211929127573967, 0.010356518439948559, -0.04860306158661842, -0.004057307727634907, -0.06664939969778061, 0.03224194794893265, 0.03976960480213165, 0.008810869418084621, -0.029496559873223305, -0.01962336152791977, -0.033858522772789, -0.03607732802629471, -0.01607472449541092, 0.00213421368971467, 0.044826604425907135, -0.026763545349240303, 0.012689928524196148, -0.02766728401184082, 0.03659510612487793, -0.03302345797419548, 0.004581541288644075, -0.04391133412718773, 0.03755555674433708, -0.014224667102098465, -0.033639095723629, -0.052245136350393295, -0.008542600087821484, 0.02426440641283989, 0.013707241974771023, 0.020746659487485886, -0.050114452838897705, 0.041157808154821396, -0.025395676493644714, 0.02071753703057766, 0.005105023737996817, 0.0009405873133800924, -0.013786589726805687, 0.03643069788813591, -0.05946021527051926, -0.040904127061367035, -0.03774355351924896, -0.020170029252767563, 0.008062414824962616, 0.00774095905944705, 0.03116374835371971, 0.006031558383256197, -0.048609547317028046, 0.020390404388308525, -0.008572953753173351, 0.06628873944282532, 0.027019577100872993, -0.01579730212688446, 0.03497081622481346, -0.044439807534217834, -0.07105442881584167, 0.0034981879871338606, -0.0767388716340065, -0.0648333951830864, -0.0156375914812088, -0.020691152662038803, 0.08065585792064667, 0.009850963950157166, 0.03584552928805351, -0.052628226578235626, -0.12018125504255295, 0.04233170300722122, -0.012208924628794193, -0.018424393609166145, -0.042153939604759216, 0.006955354008823633, 0.008762247860431671, -0.006294250953942537, 0.021087544038891792, -0.04409831762313843, -0.028426721692085266, -0.02378726564347744, -8.130491914926097e-05, 0.0011465833522379398, -0.051292773336172104, -0.003113302169367671, -0.04336521029472351, 0.007282749749720097, -0.0008370005525648594, 0.026857728138566017, -0.05152405798435211, -0.00452779745683074, 0.016765914857387543, -0.008101318962872028, -0.03469933569431305, -0.0003832592919934541, 0.05848217383027077, -0.021043842658400536, -0.04076078534126282, -0.013774865306913853, 0.03508360683917999, 0.026634257286787033, -0.027459416538476944, 0.057596322149038315, 0.037936873733997345, -0.012171855196356773, 0.010643934831023216, 0.06082785874605179, 0.038433145731687546, -0.018041320145130157, 0.021649712696671486, 0.014385052025318146, -0.01839105598628521, 0.03473673760890961, 0.00047044051461853087, -0.011326487176120281, -0.03178714960813522, 0.04407382756471634, -0.0006064106128178537, -0.04378015175461769, -0.05405711755156517, 0.012141208164393902, 0.01832558400928974, -0.04598918929696083, 0.012432463467121124, -0.015459771268069744, -0.005295543000102043, -0.07265809923410416, -0.01431124098598957, -0.03441169485449791, -0.003407688345760107, 0.04189605638384819, 0.04002253711223602, -0.0026886763516813517, 0.05499809607863426, 0.04614797979593277, -0.002205175580456853, -0.023548822849988937, -0.03166633099317551, -0.043462853878736496, -0.033040449023246765, 0.04792774096131325, 0.004327691160142422, 0.1080053523182869, -0.06195345148444176, 0.016342084854841232, 0.03662030026316643, -0.041151296347379684, 0.007148746866732836, -0.017135173082351685, 0.024955250322818756, -0.022215358912944794, 0.0021859919652342796, 0.04222983494400978, -0.017289066687226295, 0.04023708775639534, -0.023687100037932396, 0.0008501325501129031, 0.016814418137073517, -0.013632277958095074, -0.057160064578056335, -6.624214826046865e-33, 0.044887177646160126, -0.0329543873667717, -0.02126457914710045, 0.0036783250980079174, -0.009214877150952816, -0.024405507370829582, -0.012616516090929508, 0.005980838090181351, 0.02938305400311947, 0.010912459343671799, -0.005218219943344593, -0.00203009438700974, 0.0010785380145534873, 0.008744364604353905, 0.051470767706632614, -0.036318033933639526, 0.05264391750097275, 0.021595966070890427, 0.0358041487634182, 0.02847559191286564, -0.005706432741135359, 0.07452195137739182, 0.006225151009857655, -0.09586550295352936, -0.015614724718034267, -0.00913818646222353, 0.0008129934431053698, -0.028847862035036087, 0.03204713761806488, 0.05069560557603836, -0.04392590373754501, 0.02165871486067772, -0.005460127256810665, -0.01803705282509327, 0.00686987629160285, -0.03285329416394234, -0.08334518224000931, -0.019861983135342598, -0.01796291209757328, 0.016308093443512917, -0.04698290303349495, -0.014602359384298325, 0.04646487534046173, 0.03496790677309036, 0.024113265797495842, 0.005343997851014137, 0.036483630537986755, -0.006572231650352478, -0.0502227358520031, -0.05658753216266632, 0.032511159777641296, 0.011239893734455109, -0.012135905213654041, 0.014577031135559082, 0.01589386537671089, 0.0062554278410971165, -0.015447181649506092, 0.06831713765859604, -0.07856445759534836, 0.015255743637681007, -0.040123265236616135, 0.005089204292744398, 0.007039837539196014, -0.027418196201324463, -0.03313033655285835, 0.015705380588769913, -0.008761420845985413, -0.037613388150930405, -0.010665479116141796, 0.02838316559791565, 0.004776808898895979, 0.08652195334434509, 0.0007910035201348364, 0.06313267350196838, 0.0437600314617157, -0.02897491306066513, -0.04282344877719879, 0.0666290745139122, -0.00850952509790659, 0.0243002288043499, 0.026262963190674782, 0.056266799569129944, -0.02047412283718586, -0.021630022674798965, 0.017253227531909943, -0.0753929391503334, -0.05866056680679321, -0.06898559629917145, 0.002335970290005207, 0.03572286665439606, -0.01550048403441906, -0.03342393413186073, 0.018748607486486435, -0.07115823775529861, -0.02037820778787136, 0.034337159246206284, -0.037580713629722595, -0.018924564123153687, 0.03063241019845009, 0.009231921285390854, -0.06234946474432945, 0.014047462493181229, -0.008276472799479961, -0.06401695311069489, -0.04576994106173515, -0.0007235265802592039, 0.023341914638876915, 0.04852115362882614, 0.021301643922924995, -0.01714235357940197, 0.024640273302793503, -0.08463648706674576, 0.019060146063566208, 0.057948723435401917, 0.009086653590202332, 0.026318423449993134, -0.026907766237854958, 0.09849637001752853, 0.03162700682878494, 0.09464667737483978, -0.01646345667541027, -0.10499794036149979, 0.06150425225496292, -0.013872780837118626, -0.06254167854785919, -0.049478400498628616, -0.03655080869793892, 0.0010676212841644883, 0.0791623592376709, -0.054680123925209045, -0.010321035049855709, -0.04253632202744484, 2.9311982530089153e-07, 0.003486320609226823, -0.002471338491886854, -0.015020715072751045, -0.03472232073545456, 0.03722567856311798, 0.03222917020320892, 0.006829370744526386, 0.032429132610559464, 0.018377231433987617, 0.003662463976070285, 0.05249623954296112, -0.027224009856581688, -0.01320433709770441, -0.0005417432985268533, -0.00010527986887609586, -0.01690870150923729, -0.04975005239248276, 0.010502815246582031, -0.012295905500650406, -0.04838709160685539, 0.020687807351350784, 0.097575344145298, 0.08858160674571991, -0.02957073226571083, 0.013303833082318306, 0.04257923737168312, 0.04577484354376793, -0.027246877551078796, -0.03644656017422676, -0.04869695007801056, 0.08168886601924896, 0.01214616745710373, -0.040605489164590836, -0.006353565491735935, -0.0340229794383049, 0.03529301658272743, 0.024357948452234268, -0.014983734115958214, -0.023918112739920616, -0.05598036199808121, 0.00014846413978375494, -0.006056714802980423, 0.001000135438516736, -0.02791220135986805, 0.053997550159692764, 0.017450833693146706, -0.027015499770641327, 0.01334267295897007, -0.06614161282777786, 0.021321188658475876, 0.0541982427239418, -0.027159927412867546, 0.001839529606513679, -0.04825199767947197, 0.004900207277387381, 0.005885837599635124, -0.01524625439196825, -0.07040739059448242, 0.06383665651082993, -0.02220749296247959, -0.03729581832885742, -0.011740495450794697, -0.04021938890218735, 0.01687130704522133, 0.05208967253565788, 0.03571831062436104, 0.016869423910975456, 2.4437230377212126e-34, 0.00895357970148325, 0.0532863475382328, 0.004353353288024664, -0.025204570963978767, -0.007271905429661274, -0.04450129717588425, -0.04403303191065788, -0.004561217501759529, 0.02378741279244423, -0.04176969453692436, -0.05944536626338959]",1,Deep Learning Models
Neural group recommendation based on a probabilistic semantic aggregation.pdf,original article neural group recommendation based on a probabilistic semantic aggregation jorge duenaslerın raul laracabrera fernando ortega jesus bobadilla received july accepted february published online march the authors under exclusive licence to springerverlag london ltd part of springer nature abstract recommendation to groups of users is a challenging subﬁeld of recommendation systems its key concept is how and where to make the aggregation of each set of user information into an individual entity such as a ranked recommendation list a virtual user or a multihot input vector encoding this paper proposes an innovative strategy where aggregation is made in the multihot vector that feeds the neural network model the aggregation provides a probabilistic semantic and the resulting input vectors feed a model that is able to conveniently generalize the group recommendation from the individual predictions furthermore using the proposed architecture group recommendations can be obtained by simply feedforwarding the pretrained model with individual ratings that is without the need to obtain datasets containing group of user information and without the need of running two separate trainings individual and group this approach also avoids maintaining two different models to support both individual and group learning experiments have tested the proposed architecture using three representative collaborative ﬁltering datasets and a series of baselines results show suitable accuracy improvements compared to the state of the art keywords group recommender system collaborative ﬁltering aggregation models deep learning introduction personalization is one of the ﬁelds of artiﬁcial intelligence ai that has a greater impact on the lives of individuals we can ﬁnd a multitude of services that provide us with a personalized choice of news videos songs restaurants clothes travels etc the most relevant tech companies make extensive use of personalization services amazon netﬂix spotify tripadvisor google tiktok etc these companies generate their personalized recommendations using recommender system rs applications rec ommender system rs provides to their users personal ized products or services items by ﬁltering the most relevant information regarding the logs of items consumed by the users the time and place that took place as well as the existing information about users their social networks and the content of items texts pictures videos etc we can classify recommender system rs attending to their ﬁltering strategy as demographic contentbased contextaware social collaborative filtering cf and ﬁltering ensembles currently the matrix factorization mf machine learning model is used to obtain accurate and fast recommendations between input data votes matrix factorization mf translates the very sparse and huge matrix of discrete votes from users to items into two dense and relatively small matrices of real values one of the matrices contains the set of short and dense vectors representing users whereas the second matrix vectors represent items each vector element real jorge duenaslerın raul laracabrera fernando ortega and jesus bobadilla have contributed equally to this work jorge duenaslerın jorgedlalumnosupmes raul laracabrera raullaraupmes fernando ortega fernandoortegaupmes jesus bobadilla jesusbobadillaupmes departamento de sistemas informaticos universidad politecnica de madrid alan turing sn madrid spain knodis research group universidad politecnica de madrid madrid spain universidad politecnica de madrid madrid spain neural computing and applications httpsdoiorgs volv volv value is called the hidden factor value since it represents some complex and unknown relationship between the input data votes however matrix factorization mf machine learning models are fast and accurate and they also present a remarkable drawback they cannot detect in their hidden factors the complex nonlinear relationships between the input data neural network nn can solve this problem through their nonlinear activation functions neural net work nnbased recommender system rs makes a compression of information by coding the patterns of the rating matrix in their embeddings and hidden lay ers these embeddings play the role of the matrix factorization mf hidden factors enriching the result by incorporating nonlinear relations the most wellknown neural network nn base recommender system rs approaches are generalized matrix factorization gmf and multilayer perceptron mlp group recommendation gr is a subﬁeld of the recommender system rs area where recommendations are made to sets of users instead of to individual users eg to recommend a movie to a group of three friends as in the regular recommender system rs the goal is to make accurate recommendations to the group in this case sev eral policies can be followed the most popular are a to minimize the mean accuracy error to recommend the items that on average most like to all the group members and b to minimize the maximum accuracy error to recom mend the items that does not excessively dislike to any of the group members it is important to state that there are not open datasets containing group information to be used by group recommendation models for this reason gener ally randomly generated groups are used for training and testing research models regardless of the machine learning approach used to implement group recommendation gr recommender system rs the most notable design concept is to estab lish where to locate the aggregation stage to convert indi vidual information to group information the general rule is the sooner the aggregation stage the better the perfor mance of group recommendation gr there are three different locations where group information can be aggregated into a uniﬁed group entity a before the model b in the model and c after the model the most intuitive approach is to combine individual recommenda tions into a uniﬁed group recommendation option c this approach is known as individual preference aggre gation ipa and requires processing several individual recommendations followed by rank aggregation however the process is slow and not particularly accurate on the other hand to consider the entire group for the recom mendation we should work before or inside the model options a or b these approaches are known as group preference aggregation gpa aggregating group infor mation before the model requires working with the user item interaction matrix in a higherdimensional space which can lead to misinformation problems to aggregate group information in the model we need to work with the users hidden vector in the lowdimensional space aggregating several hidden vectors from individual users into a uniﬁed virtual user hidden vector avoids compute the model predictions several times and makes the rank aggregation stage unnecessary in addition it takes advantage of operating with condensed information com ing from the matrix factorization mf compression of information the virtual user can be obtained simply by averaging the representative short and dense vectors of the users group this is efﬁcient and accurate an interesting question is can neural network nn operate the same way that matrix factorization mf does to obtain virtual users and generate recommendations first note that many neural network nnbased recommender system rs models compress the user embedding in a different latent space than the item embedding and it can be a problem then the neural network nn nonlinear ensemble repre sentations are more complex than the matrix factorization mf hidden factor representations consequently simply averaging the ensembles of the users in the group does not automatically ensure a representative virtual user embed ding furthermore modelbased aggregations option b in the previous paragraph are model dependent and then it is necessary to design and test different solutions for dif ferent neural network nnbased recommender system rs models whereas the neural network nn latent spaces are the state of the art to catch users and items relations some other machine learning approaches have been designed such as the use of the random walk with restart method providing a framework to relate users items and groups and to exploit the item content and the proﬁles of the users a threestage method is proposed to increase the precision and fairness of group recom mendation gr where binary matrix factorization mf graphs and the dynamic consensus model are processed sequentially some relevant and current gr research aims to make use of the concept of member preference inﬂu ence or expertise concept based on similarity and trust the key idea is to detect the group leaders as group members that are trusted more than others and have more inﬂuence than others in fuzzy clustering and an implicit trust metric are combined to ﬁnd neighborhoods group recommendation gr based on an average strategy applied to user preference differences has been com bined with trusted social networks to correct recommen dations an aggregation approach for gr mimics crowd sourcing concepts to estimate the level of expertise of group members it is implemented using parameters of neural computing and applications sensitivity and speciﬁcity the impact of social factors on a group recommendation gr computational model is evaluated in using the expertise factor the inﬂuences of personality preference similarities and interpersonal relationships in this paper we present how we can generate group recommendation gr using neural network nnbased recommender system rs by training the model using raw collaborative filtering cf data ie the ratings of individual users to the items without any additional infor mation the group recommendation gr have been tested using the two most popular implementations of neural network nnbased recommender system rs generalized matrix factorization gmf and multilayer perceptron mlp as stated previously to make recom mendations to groups using neural network nnbased recommender system rs information of the individual users must be aggregated the chosen information aggre gation design is to merge the users of the group in the input vector that feeds the user embedding of the neural net work nn this aggregation design is not novel since it has been used by applied to a multilayer perceptron mlp architecture however our approach combines several innovative aspects in comparison with the state of the art on the one hand the aggregation of the users in the group is a probabilistic function rather than a simple multi hot encoding this better captures the relative impor tance of users in the input vector that feeds the neural network nn moreover this aggregation approach serves as frontend for any neural network nn group recommendation gr model on the other hand we propose the use of a simple recommender system rs neural network nn model generalized matrix factor ization gmf instead of the deepest multilayer per ceptron mlp one the hypothesis is that complex models overﬁt group recommendation gr scenarios since they are designed to accurately predict individual predictions whereas group recommendation gr must satisfy an average of the tastes in the group of users that is group recommendation gr should be designed to gen eralize the set of individual tastes in the group further more the proposed architecture just needs a single training to provide both individual recommendations and group recommendations particularly the model is trained by only using individual recommendations as in regular recommender system rs once the model is trained to return individual predictions we can ﬁll the input vector by aggregating all the users in the group then feedforward the trained model and ﬁnally obtain the recommendation for the group of users anyway the impact of these innovative aspects can be evaluated in sect where we empirically compare the proposed aggregation designs with respect to the main baseline in summary the group recommendation gr state of the art presents the following drawbacks a some research relies on additional data to the collaborative fil tering cf ratings such as trust or reputation information that is not available on the majority of datasets b differ ent proposals make the aggregation of individual users before individual preference aggregation ipa or after ranking the model making it impossible to beneﬁt from the machine learning model inner representations group preference aggregation gpa and c the proposed gr neural model solutions tend to apply architectures designed to make individual recommendations rather than group ones this leads to the model overﬁtting and to a low scalability referred to the number of users in a group to ﬁll the gap our proposed model a acts exclusively on collaborative filtering cf ratings b makes user aggregation in the model and c its model depth and design enable adequate learning generalizations addi tionally the provided experiments test the proposed model according to different aggregation strategies to set the group labels used in the learning stage in contrast a notable limitation of our architecture and the experiments is the lack of testing on particularly demanding scenarios such as cold start in groups users extremely sparse data sets impact of popular item bias and fear group recom mendation gr the rest of the paper is structured as follows sect introduces the tested models and aggregation functions sect describes the experiment design the selected quality measures the chosen datasets and shows the results obtained sect provides their explanations and sect highlights the main conclusions of the article and the suggested future work proposed model in collaborative filtering cf interactions purchase viewing rating etc between users and items are stored in a sparse matrix since it is common for users to interact only with a small proportion of the available items and in the same way only a small percentage of existing users interact with the items the sparsity levels of this matrix are around as shown in table to handle this sparsity current collaborative filtering cf models based on neural network nn work with a projection of users and items into a lowdimensional latent space using embedding layers embedding layers are a very popular type of layer used in neural network nn that receive as input any entity and return a vector with a lowdimensional representation of the entity in a latent space these vectors are commonly named latent factors in order to transform the entity into its lowdimensional representation the neural computing and applications embedding layer ﬁrst transforms the entity into a one hot encoding representation typically using a hash function figure summarizes this process in the context of collaborative filtering cf two embedding layers are required one for the users and the other for the items later both embedding layers are combined using a neural network nn architecture see fig for example the models generalized matrix factorization gmf and multilayer perceptron mlp use a dot layer and a concatenate layer followed by some fully connected dense layers as architectures respectively formally we deﬁne a neural network nn model u that predicts the rating that a user u will give to an item i rui combining the latent factors provided by the embed ding layer embl of the user u lu and the item i li emblðuþ ¼ lu emblðiþ ¼ li uðlu liþ ¼ rui ðþ as stated in sect when working with group recom mendation gr a straightforward strategy is individual preference aggregation ipa this strategy makes a prediction for each member of the group and then performs an aggregation this strategy does not treat the group as a whole if we have a group of users g ¼ fu u ung the prediction of the rating of this group g to an item i rgi is computed as the average value of the individual predictions rgi ¼ kgk x ug rui ¼ kgk x ug uðlu liþ ðþ on the other hand the group preference aggregation gpa strategies take into account the group as a whole it should be noted that the order of users within the group and the length of it should not affect the aggregation thus the aggregations should meet the constraints of permutation invariant and ﬁxed result length our goal with the group preference aggregation gpa strategy is to be able to obtain a prediction rgi with a single forward propagation and to treat the group as a whole entity we can achieve this by aggregating the latent factors of each user that belongs to the group to obtain the latent factor of the group lg once the latent factors of the group are aggregated the model u can be used to compute the predictions emblðgþ ¼ lg rgi ¼ uðlg liþ ðþ the aggregation of group latent factors in embedding layers can be achieved by modifying the input of the neural network nn as mentioned previously embed ding layers have as input a one hot representation of the entities this approach is adequate when performing indi vidual predictions however for group recommendations we need to apply a multihot representation to the users embedding layer ie we encode the group by setting multiple inputs of the user embedding layer the inputs related with the users that belong to the group to a value higher than this encoding allows us to take into account all group users at the same time for the extraction of latent factors of the group lg the simplest aggregation which is used by the deepgroup model is to use as input for embedding a constant value proportional to the size of the group we deﬁne the input of the users embedding layer for the user u as embeddinginputaverageðuþ ¼ kgk if u g if u g ðþ we call this aggregation average since the embedding layer will generate the group latent factor equal to the average of the latent factors of all users in the group recommender system rs can give better predictions the more information they have about users so to take advantage of this fact we have tested the expertise aggregation in which we give a weight to the users pro portional to the number of votes they have entered into the system let kruk the number of ratings of the user u the input of the users embedding layer for the user u is deﬁned as fig embedding layer schema fig collaborative ﬁlteringbased neural network model neural computing and applications embeddinginputexpertiseðuþ ¼ kruk p gg krgk if u g if u g ðþ in addition to the expertise aggregation we also pro posed the softmax aggregation as a smooth version of the expertise aggregation in this case the input of the users embedding layer for the user u is deﬁned as embeddinginputsoftmaxðuþ ¼ ekruk p gg ekrgk if u g if u g ðþ in fig we can see where the equations ﬁt in the group recommendation process the ﬁrst step is to generate the multihot vector with some of the described aggregation eqs this vector multihot representation of the group is fed into the embedding layer to obtain a vector of the latent factors of the groups lg eq once the latent fig graphical representation of the proposed model table complete aggregation example a rating count user u u u u rating b input values to the users embedding layer strategy user u u u u average expertise softmax users latent factors assuming a latent space of size userfactor l l l u u u u group latent factors using different aggregations agg factor lg lg lg average expertise softmax neural computing and applications factors of the group and the item are obtained they are used to feed the model u generalized matrix factoriza tion gmf or multilayer perceptron mlp and produce the rating prediction for the group g on the item i eq in table we can ﬁnd an example with some users and with different rating counts table a their input values to the users embedding layer in a multihot fashion table b their individual latent factors table c and the ﬁnal group latent factors with different aggregations table d experimental evaluation in this section we show the experiments carried out to validate the aggregation proposed in this manuscript as previously stated the experiments have been performed using the most popular neural network nnbased rec ommender system rs architectures generalized matrix factorization gmf and multilayer perceptron mlp we have chosen these two architectures because they are the best known and offer the best results for individual predictions however the aggregation strategies proposed can be applied to any neural network nn architecture based on embedding layers the choice of datasets has been made considering that a there are no open datasets containing information on group voting and b generalized matrix factorization gmf and multilayer perceptron mlp models should be trained using individual voting since the proposed aggregations allow computing predictions for groups on already trained models for these reasons we have chosen the following gold standard datasets in the ﬁeld of rec ommender system rs movielensm the most popular dataset in the research of recommender system rs filmtrust a dataset smaller than movielensm to measure the performance of the aggregation in datasets with a lower number of users items and ratings and myanimelist a dataset with a range of votes higher than the movielensm other popular datasets such as netﬂix prize or movielensm have not been selected due to the high computational time required to train and test the models the main parameters of the selected datasets can be found in table the generation of synthetic groups has been carried out in such a way that all groups have voted at least ﬁve items in test in this way it is possible to evaluate both the quality of the predictions and the quality of the recom mendations to the groups as detailed below groups of different sizes from to users have been generated for each group size synthetic groups have been generated the generation of a group has been carried out following the following algorithm deﬁne the size of the group s random select items rated in test by at least s users find all users who have rated the items selected in if we found fewer than s users go back to otherwise random select s users and create a group to measure the quality of the predictions for the group we have calculated the mean absolute error mae ¼ groups x g kgk kigk x ug x iig j rgi rui j ðþ the mean squared error mse ¼ groups x g kgk kgk kigk x ug x iig rgi rui ðþ and mean maximum group error max ¼ groups x g max ug max iig j rgi rui j ðþ where ig denotes the items rated by the group g to measure the quality of the recommendations for the group we have calculated the normalized discounted cumulative gain ndcg score ndcgn ¼ groups x g dcggn idcggn ðþ dcggn ¼ x ixn g rgi logðposgðiþ þ þ ðþ idcggn ¼ x itn g rgi logðiposgðiþ þ þ ðþ where n is the number of items recommended to the group in our experiments n ¼ according to the generation of synthetic groups xn g is the set of n items recommended to the group g posgðiþ is the position of the item i in the groups g recommendation list tn g is the set of the top n items for the group g iposgðiþ is the ideal rank of the item table main parameters of the datasets used in the experiments dataset users items ratings scores sparsity movie lensm filmtrust my anime list neural computing and applications table mean absolute error model group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax a movielensm model group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax b filmtrust model group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax c myanimelist neural computing and applications table mean squared error model group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax a movielensm model group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax b filmtrust model group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax c myanimelist neural computing and applications table mean max error model group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax a movielensm model group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax b filmtrust model group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax c myanimelist neural computing and applications i for the group g and rgi is the average rating of the users belonging to the group g for the item i we can see the results of the experiment executed with these scores in table mae table mse table max and table ndcg the cells with the best results table discounted cumulative gain model group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax a movielensm model group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax b filmtrust model group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax c myanimelist neural computing and applications have been highlighted gray background and bold while the standard deviation of each metric is in parentheses all results are analyzed in sect all experiments have been run using an nvidia quadro rtx gpu with gb gddr of memory nvidia tensor cores and a performance of tflops we are committed to reproducible science so the source code of all experiments with the values of the parameters used and their random seeds have been shared on github discussion the main goal of this research is to evaluate different aggregation techniques to make recommendations to groups as shown in sect we can see different trends according to a the models used b the way group information is aggregated c the datasets on which they act and d the size of the groups focusing on the models we can see how multilayer perceptron mlp which has several hidden layers obtains a lower mae however generalized matrix factorization gmf a simpler model obtains a lower mse although the multilayer perceptron mlp model has great power in these types of problem it seems to overﬁt generating very good recommendations for some users in the group but bad ones for the rest hence achieving higher mse values on the other hand the generalized matrix fac torization gmf model can obtain smaller maximum errors in each group which means that no user in the group is badly affected by the recommendation in the results we can also observe how the models with higher maximum errors lead to a poorer order of items according to user preferences and obtain worse performance in the normal izaed discounted cumulative gain ndcg metric looking at the aggregation of users we can see that the best performing user aggregation is the average followed by a very similar performance by the softmax however the use of expert user weighting without softmax produces worse results based on the results we can observe that in models that do not use a deep architecture with several hidden layers the individual preference aggregation ipa and group preference aggregation gpa strategies pro duce similar results when the aggregation function is a linear transformation of latent factors generalized matrix factorization gmf however we can see how the nonlinearity of multilayer perceptron mlp produces different results between both two strategies regarding the different datasets we can see that there is a clear trend in the models that achieve the best results in complex datasets with a large number of users items and votes such as movilens or myanimelist while in the filmtrust dataset with a smaller number of votes there is no clear trend in terms of group size as more users have the group the probability of ﬁnding discrepancies between user prefer ences increases therefore we can see how a larger group size leads to higher values in all error metrics conclusions and future work with the irruption of neural network nn in the world of collaborative filtering cf the possibilities of their ability to ﬁnd nonlinear patterns within user preferences to generate better predictions are opening up to use these systems to generate a recommendation for a group of users we need to aggregate their preferences as we have seen in this research there are several key points at which aggre gation can be performed group preference aggregation gpa strategies do the aggregation before or inside the model so they have the advantage of taking into account the preferences of the entire group and that a single feed forward step generates the prediction in contrast the individual preference aggregation ipa strategy requires multiple predictions for each user and performs the aggregations after the model in this study we have tested how different approaches to perform group preference aggregation gpa work in different datasets comparing different metrics as future work there are two key factors to consider first in this research the researchers have designed user aggregation techniques presented to the models in future work these functions will be explored by different machine learning models the second key point is that in this work models perform a knowledge transfer from the model trained for individuals to make group predictions it is shown that although the models have high performance mae improvement they tend to overﬁt when working in groups larger errors in group prediction leading to worse mse to solve this problem future work will try to per form a specialization training stage for groups after indi vidual training funding this work has been cofunded by the ministerio de ciencia e innovacion of spain and the european regional development fund feder under grants pidrbi dlcemg and the comunidad de madrid under convenio plurianual with the uni versidad politecnica de madrid in the actuation line of programa de excelencia para el profesorado universitario data availability the movielensm filmtrust and myani melist dataset along with the source code of the experiments that support the ﬁndings of this study is available in neuralcffor httpsgithubcomknodisresearchgroupneuralcfforgroups neural computing and applications groups githubs repository httpsgithubcomknodis researchgroupneuralcfforgroups declarations conflict of interest the authors of this paper declare that they have no conflict of interest references batmaz z yurekli a bilge a kaleli c a review on deep learning for recommender systems challenges and remedies artif intell rev httpsdoiorgs y bobadilla j gonzalezprieto a ortega f laracabrera r deep learning feature selection to unhide demographic recom mender systems factors neural comput appl httpsdoiorgs deldjoo y schedl m cremonesi p pasi g recommender systems leveraging multimedia content acm comput surv httpsdoiorg kulkarni s rodd sf context aware recommendation systems a review of the state of the art techniques comput sci rev httpsdoiorgjcosrev shokeen j rana c a study on features of social recom mender systems artif intell rev httpsdoiorg sw bobadilla j alonso s hernando a deep learning archi tecture for collaborative ﬁltering recommender systems appl sci httpsdoiorgapp dara s chowdary cr kumar c a survey on group recommender systems j intell inf syst https doiorgs forouzandeh s berahmand k rostami m presentation of a recommender system with ensemble learning and graph embedding a case on movielens multimed tools appl httpsdoiorgs c ano e morisio m hybrid recommender systems a systematic literature review intell data anal httpsdoiorgida salakhutdinov r mnih a probabilistic matrix factoriza tion in proceedings of the th international conference on neural information processing systems nips pp curran associates inc red hook ny usa httpsdoiorg bobadilla j gonzalezprieto a ortega f laracabrera r deep learning approach to obtain collaborative ﬁltering neigh borhoods neural comput appl httpsdoiorg s huang t zhang df bi l neural embedding collabora tive ﬁltering for recommender systems neural comput appl httpsdoiorgs he x liao l zhang h nie l hu x chua ts neural collaborative ﬁltering in proceedings of the th international conference on world wide web www pp inter national world wide web conferences steering committee republic and canton of geneva che httpsdoiorg ortega f bobadilla j hernando a gutierrez a incor porating group recommendations to recommender systems alternatives and performance inf process manage httpsdoiorgjipm baltrunas l makcinskas t ricci f group recommen dations with rank aggregation and collaborative ﬁltering in proceedings of the fourth acm conference on recommender sys tems recsys pp association for computing machinery new york ny usa httpsdoiorg ortega f hernando a bobadilla j kang jh recom mending items to group of users using matrix factorization based collaborative ﬁltering inf sci httpsdoiorg jins feng s zhang h wang l liu l xu y detecting the latent associations hidden in multisource information for better group recommendation knowbased syst httpsdoi orgjknosys abolghasemi r engelstad p herreraviedma e yazidi a a personalityaware group recommendation system based on pairwise preferences inf sci httpsdoiorgj ins barzegar nozari r koohi h a novel group recommender system based on members inﬂuence and leader impact know based syst httpsdoiorgjknosys wang x su l zhou q wu l zhang y group recom mender systems based on members preference for trusted social networks sec commun netw httpsdoiorg ismailoglu f aggregating user preferences in group rec ommender systems a crowdsourcing approach decis support syst httpsdoiorgjdss guo j zhu y li a wang q han w a social inﬂuence approach for group user modeling in group recommendation systems ieee intell syst httpsdoiorg mis sajjadi ghaemmaghami s salehiabari a deepgroup group recommendation with implicit feedback association for computing machinery new york pp hu l cao j xu g cao l gu z cao w deep modeling of group preferences for groupbased recommendation in pro ceedings of the twentyeighth aaai conference on artiﬁcial intelligence aaai pp aaai press palo alto california httpsdoiorgaaaivi harper fm konstan ja the movielens datasets history and context acm trans interact intell syst https doiorg guo g zhang j yorkesmith n a novel bayesian simi larity measure for recommender systems in proceedings of the twentythird international joint conference on artiﬁcial intelli gence ijcai pp aaai press menlo park california httpsdoiorg publishers note springer nature remains neutral with regard to jurisdictional claims in published maps and institutional afﬁliations springer nature or its licensor eg a society or other partner holds exclusive rights to this article under a publishing agreement with the authors or other rightsholders author selfarchiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law neural computing and applications,"[0.021458489820361137, 0.02807997539639473, 0.007775427773594856, -0.022423796355724335, 0.0035858743358403444, -0.019972408190369606, 0.049557335674762726, -0.026428550481796265, -0.005966355092823505, -0.019043205305933952, -0.035020217299461365, -0.0391073040664196, -0.005768942646682262, 0.03877652809023857, 0.015229006297886372, -0.032292090356349945, 0.03789962828159332, 0.039221178740262985, 0.0028371987864375114, -0.022136395797133446, 0.024925829842686653, 0.05212630704045296, 0.011029690504074097, 0.03407752886414528, 0.001590408501215279, 0.02324177511036396, 0.02402096800506115, -0.023986808955669403, 0.002301422180607915, -0.0045861913822591305, 0.01888861693441868, -0.004910213872790337, -0.020024491474032402, -0.02078952081501484, 2.053284106295905e-06, -0.028703313320875168, -0.05851041153073311, -0.03972167894244194, 0.024413952603936195, -0.04803568869829178, 0.016803991049528122, 0.08756323158740997, -0.0025108351837843657, 0.028243450447916985, -0.037855517119169235, 0.01812300831079483, 0.030475275591015816, 0.029009969905018806, 0.035581253468990326, 0.006969985086470842, -0.02977551333606243, -0.05044885352253914, 0.02407965250313282, -0.02757081389427185, 0.009236537851393223, -0.032841701060533524, 0.009652122855186462, -0.021754655987024307, 0.014172641560435295, -0.027478808537125587, 0.04311680421233177, -0.03883684054017067, 0.025253919884562492, 0.0017884864937514067, 0.07614951580762863, 0.037702448666095734, -0.017593253403902054, -0.022622110322117805, -0.058907195925712585, 0.07133419811725616, -0.04000197350978851, 0.015259653329849243, -0.027116097509860992, 0.009398723021149635, 0.012811601161956787, -0.0026369013357907534, -0.00027539621805772185, -0.006232668645679951, -0.012291152030229568, 0.02110384590923786, -0.037029143422842026, 0.08236448466777802, 0.007650274783372879, 0.02992532216012478, -0.0010154499905183911, 0.08093351125717163, 0.01506249513477087, 0.004136892035603523, 0.02004055678844452, -0.010984092019498348, -0.004451051354408264, -0.026696879416704178, 0.04008108749985695, 0.007509288843721151, -0.008717243559658527, -0.00033208567765541375, -0.022142091765999794, 0.026417655870318413, 0.007066225167363882, -0.04055746644735336, 0.06430316716432571, 0.014802063815295696, 0.002076262142509222, 0.05798625946044922, 0.024506310001015663, -0.01738443784415722, -0.0029990144539624453, -0.0041029565036296844, -0.043609779328107834, -0.007718835957348347, -0.05028815194964409, 0.01880129612982273, -0.00077412388054654, 0.09803169220685959, -0.007148801814764738, -0.017943967133760452, -0.05934587121009827, 0.04301303252577782, -0.018968908116221428, 0.0017528036842122674, 0.00027434685034677386, 0.10009043663740158, 0.028618941083550453, 0.006489147432148457, -0.04967470467090607, -0.00031665185815654695, -0.0410761684179306, 0.016927769407629967, 0.01048990897834301, 0.009273047558963299, 0.09575727581977844, -0.007175861392170191, 0.015215129591524601, -0.006693253759294748, -0.006121860817074776, -0.0026624046731740236, -0.004828629549592733, 0.0005690681864507496, -0.0034232959151268005, -0.04564860835671425, 0.006155482493340969, -0.03904053568840027, -0.02615792490541935, -0.061753518879413605, 0.07569484412670135, -0.020836299285292625, -0.020743081346154213, -0.010867560282349586, -0.008207695558667183, -0.002236024709418416, -0.023923031985759735, 0.06779684126377106, 0.032908279448747635, -0.048021309077739716, 0.07962276041507721, 0.01755921170115471, 0.00693069864064455, -0.017366528511047363, -0.006006506737321615, 0.0777776911854744, 0.021180180832743645, 0.026988347992300987, -0.007887423038482666, 0.0006188861443661153, -0.02054520510137081, -0.016876788809895515, -0.006503324024379253, -0.014887974597513676, -0.06326816231012344, -0.026241356506943703, -0.02058868110179901, 0.08601787686347961, -0.06652615964412689, -0.011440924368798733, 0.028793420642614365, 0.016920246183872223, 0.03629809245467186, 0.0807756707072258, 0.021067190915346146, 0.024837268516421318, -0.01158601138740778, -0.0324731171131134, 0.016348721459507942, 0.08541706949472427, -0.022944670170545578, -0.025922633707523346, 0.04285924881696701, 0.02687005139887333, -0.04704160615801811, -0.040273506194353104, 0.03360634297132492, -0.028143083676695824, 0.04200532287359238, 0.03062865324318409, 0.05077574402093887, -0.05133659020066261, -0.03962508589029312, -0.005612754728645086, 0.03532405570149422, -0.0497104749083519, 0.013569400645792484, -0.008738075383007526, 0.07198962569236755, 0.054855115711688995, 0.049511563032865524, 0.005087296478450298, 0.017152460291981697, -0.0155837032943964, -0.0653543695807457, -0.09682828933000565, 0.05374740809202194, -0.04122621566057205, -0.014561405405402184, -0.045023903250694275, -0.06754732877016068, 0.04853596165776253, -0.023097297176718712, 0.04310696944594383, -0.025489477440714836, 0.0019087584223598242, 0.008909990079700947, 0.11809982359409332, 0.011060493066906929, -0.01769174635410309, 0.020581165328621864, 0.028861481696367264, 0.053304046392440796, 0.027362488210201263, 0.06049344688653946, 0.05030756816267967, 0.01851382479071617, 0.007101396098732948, 0.05033581331372261, -0.04637644439935684, -0.05505929887294769, -0.017642304301261902, -0.01902443915605545, 0.012943916954100132, 0.025486838072538376, -0.013017832301557064, 0.06363292783498764, 0.026377981528639793, 0.018001258373260498, -0.04020721837878227, 0.005246818996965885, 0.015875494107604027, 0.02414686419069767, -0.022252889350056648, -0.01009264774620533, 0.011071930639445782, 0.03150006756186485, -0.03129308670759201, 0.06381554901599884, -0.01711241528391838, -0.003956807777285576, -0.07749031484127045, 0.01654641330242157, 0.00015286017151083797, -0.044703710824251175, -0.051277272403240204, 0.014295591041445732, 0.01535483542829752, 0.009165795519948006, 0.04083770141005516, -0.03169433772563934, -0.03344780579209328, 0.012266983278095722, -0.04907674714922905, 0.03683074191212654, 0.022359667345881462, 0.0012159553589299321, -0.0514119528234005, 0.0297638401389122, 0.016584182158112526, -0.0376252718269825, -0.052811916917562485, 0.057095449417829514, -0.02410460263490677, -0.00560808228328824, 0.009647950530052185, 0.04524470865726471, -0.0019841392058879137, -0.02765345387160778, -0.030508020892739296, -0.0342712327837944, 0.003959048539400101, 0.00690606702119112, -0.04263736680150032, -0.008629652671515942, -0.05755335092544556, -0.09216687828302383, -0.015267020091414452, 1.0944478162855376e-05, -0.016431152820587158, -0.005464036483317614, -0.01543579250574112, 0.01827559992671013, -0.006375259719789028, 0.015431561507284641, -0.014914018101990223, 0.03639475628733635, 0.026245903223752975, -0.03133692964911461, 0.027532396838068962, -0.031765177845954895, -0.004314800258725882, 0.04068050533533096, 0.019893761724233627, -0.017848487943410873, -0.027672911062836647, 0.012546995654702187, -0.010793791152536869, -0.044769901782274246, 0.04990466684103012, 0.010261560790240765, 0.013877411372959614, -0.04906115680932999, -0.06773870438337326, -0.0016466877423226833, 0.04245281592011452, -0.0017851475859060884, -0.031203029677271843, 0.05861079320311546, 0.050776343792676926, -0.016555877402424812, -0.034952521324157715, -0.06283364444971085, -0.044484686106443405, -0.026822427287697792, -0.0002632512478157878, 0.02743143029510975, -0.04686228930950165, 0.016991930082440376, -0.00668449467048049, 0.011087136343121529, 0.0036764824762940407, -0.05828719213604927, 0.026846786960959435, 0.021970003843307495, -0.007111737504601479, -0.002457141410559416, -0.030252650380134583, -0.036535486578941345, -0.04909844696521759, -0.020431028679013252, -0.006340596824884415, 0.00906546600162983, 0.0006357867387123406, -0.037362560629844666, -0.019412878900766373, -0.03135751187801361, -0.01954641006886959, 0.006153321824967861, -0.027326393872499466, 0.03305273875594139, 0.012367836199700832, 0.0010831208201125264, -0.05739123374223709, -0.013619265519082546, 0.010915067978203297, 0.023292770609259605, 0.04913138970732689, 0.05480263754725456, -0.008134158328175545, -0.05888424813747406, 0.0011200711596757174, 0.04879317432641983, -0.009741502813994884, -0.013405297882854939, 0.043313879519701004, -0.04167849197983742, 0.028529338538646698, 0.09376875311136246, 0.04180731996893883, 0.03162377327680588, -0.12359503656625748, -0.029259009286761284, 0.047832734882831573, -0.0031253222841769457, 0.02195993810892105, 0.04821067675948143, -0.03956287354230881, 0.03713686391711235, -0.005707056261599064, 0.0005533006624318659, 0.03872271999716759, -0.033018093556165695, -0.05375300347805023, -0.06156596913933754, 0.013435081578791142, 0.033113688230514526, -0.004138466436415911, 0.0507580041885376, -0.02676818147301674, 0.005740651860833168, -0.031003208830952644, 0.01226694043725729, -0.029488904401659966, 0.015956856310367584, -0.011710519902408123, 0.010307984426617622, -0.025551481172442436, -0.0008045427384786308, 0.016756365075707436, -0.06664703041315079, 0.02646663971245289, 0.06698659062385559, 0.01851220615208149, -0.004517326131463051, -0.046632539480924606, -0.018901221454143524, -0.01213090494275093, -0.008263973519206047, -0.013316748663783073, 0.05724022537469864, -0.027993502095341682, 0.03815877437591553, 0.003028186736628413, 0.017553849145770073, -0.027503857389092445, 0.023559655994176865, -0.04180057719349861, 0.009156238287687302, -0.02737676352262497, 0.008216280490159988, -0.06003794074058533, 0.015603452920913696, -0.007828177884221077, 0.03079266846179962, -0.044130414724349976, -0.039099372923374176, 0.06211138516664505, -0.020688507705926895, -0.008687623776495457, 0.031569067388772964, -0.02502279542386532, 0.026406392455101013, -0.048788320273160934, -0.03617500886321068, -0.05567866191267967, -0.018463917076587677, 0.010257398709654808, 0.03943074122071266, -0.02505476213991642, 0.04950355365872383, 0.03500836342573166, -0.0217679925262928, 0.022416986525058746, -0.014352336525917053, 0.053576815873384476, 0.04596073925495148, -0.050524767488241196, 0.018135754391551018, 0.019939318299293518, -0.03468957170844078, -0.005365670192986727, -0.06424534320831299, -0.022907679900527, -0.04499243199825287, -0.020720794796943665, 0.06620312482118607, 0.015677805989980698, 0.02118692360818386, -0.049851588904857635, -0.10803361237049103, 0.08205346018075943, 0.004004298709332943, -0.02064470574259758, -0.04169554263353348, -0.03358026593923569, 0.03496815264225006, -0.028050946071743965, 0.035711005330085754, -0.04764896258711815, 0.03354113921523094, -0.03869708627462387, -0.0743231400847435, -0.03906365483999252, -0.04052980616688728, 0.004705721512436867, -0.028462225571274757, 0.008537673391401768, -0.02143999934196472, 0.05601824074983597, -0.015409366227686405, -0.005547566805034876, 0.011656587943434715, -0.02325120009481907, -0.043527573347091675, -0.02295570634305477, 0.03773396089673042, -0.07364838570356369, -0.010278230533003807, -0.039791181683540344, 0.03574152663350105, -0.02505945973098278, -0.03314608335494995, 0.03324951231479645, -0.013280498795211315, -0.01482526957988739, -0.022291259840130806, 0.05208800733089447, 0.02452109381556511, -0.010416061617434025, -0.00872763805091381, 0.02049380913376808, -0.033575501292943954, 0.010996484197676182, -0.00988000724464655, -0.004801230505108833, -0.04902049899101257, 0.06451498717069626, -0.00874967873096466, -0.044882941991090775, 0.011476824060082436, 0.014144966378808022, 0.02563309855759144, -0.04580714926123619, -0.003218826139345765, 0.002182924887165427, -0.0017095364164561033, -0.05427451804280281, -0.011242080479860306, -0.05927624925971031, 0.0012909586075693369, 0.015361321158707142, 0.038442086428403854, -0.0029690053779631853, 0.027537614107131958, 0.06474827975034714, -0.020253073424100876, -0.07205058634281158, 0.002580787753686309, -0.034268517047166824, -0.04131649434566498, 0.0582670234143734, 0.0030011688359081745, 0.08607066422700882, -0.05691752955317497, -0.013495681807398796, -0.00512629933655262, -0.01288305502384901, -0.007692100014537573, -0.006310827098786831, 0.03926389291882515, -0.0020212498493492603, 0.041437700390815735, 0.021629486232995987, -0.029491126537322998, -0.0029286344069987535, -0.04464497044682503, -0.0335640087723732, -0.03038961812853813, 0.020859066396951675, -0.002235832391306758, -6.1193873894847104e-33, 0.020886490121483803, -0.02274997904896736, -0.010550596751272678, 0.03557265177369118, -0.01718483306467533, -0.006981962826102972, 0.03276894614100456, -0.00608991552144289, 0.042918749153614044, -0.012675768695771694, -0.028937846422195435, -0.0030356745701283216, 0.025472279638051987, 0.017646050080657005, 0.03449574485421181, -0.01596190221607685, 0.03275083005428314, 0.020486773923039436, 0.0437963530421257, 0.018875977024435997, 0.028842873871326447, 0.05945008248090744, 0.02139744535088539, -0.08780033141374588, 0.019672084599733353, 0.0036218909081071615, -0.020177142694592476, -0.02041834406554699, 0.011535855010151863, 0.07931864261627197, 0.006207878235727549, 0.0193987637758255, 0.003657590365037322, -0.0250093936920166, 0.007166130933910608, 0.03113132156431675, -0.06937504559755325, -0.007028988562524319, -0.0035777634475380182, 0.00880532804876566, -0.03992312029004097, 0.011342736892402172, 0.03321196138858795, -0.006028688047081232, 0.041677553206682205, 0.008921841159462929, 0.03256162628531456, 0.004195480141788721, -0.06278259307146072, -0.051288627088069916, 0.04971608147025108, 0.021792838349938393, 0.014583302661776543, 0.004486510995775461, 0.00792587362229824, -0.00929151102900505, -0.008240967988967896, 0.0414639450609684, -0.06685101240873337, 0.014457298442721367, -0.07093839347362518, -0.021197305992245674, -0.010488518513739109, -0.004226690623909235, -0.039079006761312485, 0.041739482432603836, 0.032887257635593414, -0.02439531311392784, -0.017355797812342644, 0.0041257054544985294, -0.029577746987342834, 0.09063787013292313, 0.01484194491058588, 0.02696404792368412, 0.0757041722536087, -0.023131033405661583, -0.014127780683338642, 0.07639174163341522, 0.0635208711028099, -0.010323205962777138, -0.007575048599392176, 0.07393300533294678, -0.04213596507906914, -0.014941702596843243, 0.015504823997616768, -0.055334094911813736, -0.054663851857185364, -0.06955453753471375, -0.03170761093497276, 0.04047105461359024, -0.024200737476348877, 0.028875049203634262, -0.012393219396471977, -0.059240251779556274, -0.012512220069766045, -0.014698523096740246, 0.022036435082554817, -0.006654088851064444, 0.005329425912350416, -0.023714441806077957, -0.06667234003543854, 0.023027803748846054, -0.03266091272234917, -0.04862162470817566, -0.04130074381828308, 0.005937212612479925, 0.04219087213277817, 0.010711436159908772, 0.002217302331700921, -0.0022872411645948887, 0.04582950100302696, -0.05555479973554611, 0.006851117592304945, 0.03506025671958923, 0.06273866444826126, 0.04296695441007614, -0.013712580315768719, 0.048544980585575104, 0.011660494841635227, 0.0414273627102375, -0.006258347537368536, -0.04714668542146683, 0.01742558740079403, -0.02653234638273716, -0.009504425339400768, -0.03338701277971268, -0.024950411170721054, -0.022289564833045006, 0.11262820661067963, -0.00636629480868578, -0.020834872499108315, -0.023766612634062767, 2.818193536313629e-07, -0.002793789841234684, -0.013781318441033363, 0.01335317362099886, -0.032903607934713364, 0.002669291803613305, 0.02192721888422966, 0.039451923221349716, 0.04710334911942482, 0.020795036107301712, 0.04795209690928459, 0.03613749518990517, 0.011614937335252762, -0.014002453535795212, 0.034888483583927155, -0.04137903079390526, -0.04647010192275047, -0.05651379004120827, 0.03844822943210602, -0.054757870733737946, 0.007552792318165302, 0.022290058434009552, 0.09617104381322861, 0.09918911010026932, -0.04150573909282684, -0.025917617604136467, 0.027878209948539734, 0.02532273158431053, -0.027775844559073448, -0.04487227648496628, -0.0046474626287817955, 0.07307456433773041, 0.0233945120126009, -0.060389380902051926, 0.02934849075973034, -0.0514712855219841, 0.04298555850982666, 0.017836719751358032, -0.025313401594758034, -0.041856251657009125, -0.046059105545282364, 0.02814832516014576, -0.005755029618740082, 0.008637990802526474, -0.013640913181006908, 0.06887322664260864, -0.013261045329272747, 0.0014262065524235368, 0.029531333595514297, -0.02706090360879898, 0.03277556225657463, 0.047720205038785934, 0.02104274556040764, -0.01841641403734684, 0.02922145649790764, 0.01198577880859375, -0.04338569566607475, -0.0005138105480000377, -0.08391021937131882, 0.023629674687981606, 0.01421738788485527, 0.0017340527847409248, 0.0018148653907701373, -0.02413751184940338, 0.024115510284900665, 0.011488586664199829, -0.021296046674251556, -0.003728414885699749, 1.9342658523734967e-34, -0.006305074319243431, 0.026101229712367058, -0.014807431027293205, -0.02842704765498638, -0.0017136394744738936, -0.03941746801137924, -0.06665351241827011, 0.0013548159040510654, 0.031441498547792435, -0.03342469781637192, -0.03442448377609253]",3,Neural Network-based Models

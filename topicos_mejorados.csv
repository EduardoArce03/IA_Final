Documento,Titulos_Extraidos,Keywords_Extraidas,Texto_Original,Texto_Procesado,Titulos_Procesados,Keywords_Procesadas,Texto_Final,T√≥pico_Descubierto,Nombre_Topico
Wasserstein GAN based architecture to generate collaborative filtering synthetic datasets.pdf,Wasserstein GAN‚Äëbased architecture to¬†generate collaborative | filtering synthetic datasets,WGANRS¬†¬∑ Generative Adversarial Networks¬†¬∑ Recommender Systems¬†¬∑ Wasserstein distance¬†¬∑ Synthetic,"https://doi.org/10.1007/s10489-024-05313-4 Wasserstein GAN‚Äëbased architecture to¬†generate collaborative filtering synthetic datasets Jes√∫s¬†Bobadilla 1,2 ¬∑ Abraham¬†Guti√©rrez 1,2 Accepted: 1 February 2024 ¬© The Author(s) 2024 Abstract Currently, generative applications are reshaping different fields, such as art, computer vision, speech processing, and natural language. The computer science personalization area is increasingly relevant since large companies such as Spotify, Netflix, TripAdvisor, Amazon, and Google use recommender systems. Then, it is rational to expect that generative learning will increasingly be used to improve current recommender systems. In this paper, a method is proposed to generate synthetic recommender system datasets that can be used to test the recommendation performance and accuracy of a company on dif- ferent simulated scenarios, such as large increases in their dataset sizes, number of users, or number of items. Specifically, an improvement in the state-of-the-art method is proposed by applying the Wasserstein concept to the generative adversarial network for recommender systems (GANRS) seminal method to generate synthetic datasets. The results show that our pro- posed method reduces the mode collapse, increases the sizes of the synthetic datasets, improves their ratings distributions, and maintains the potential to choose the desired number of users, number of items, and starting size of the dataset. Both the baseline GANRS and the proposed Wasserstein-based WGANRS deep learning architectures generate fake profiles from dense, short, and continuous embeddings in the latent space instead of the sparse, large, and discrete raw samples that previ- ous GAN models used as a source. To enable reproducibility, the Python and Keras codes are provided in open repositories along with the synthetic datasets generated to test the proposed architecture ( https://‚Äãgithub.‚Äãcom/‚Äãjesus‚Äãbobad‚Äãilla/‚Äãganrs.‚Äãgit ). Keywords WGANRS¬†¬∑ Generative Adversarial Networks¬†¬∑ Recommender Systems¬†¬∑ Wasserstein distance¬†¬∑ Synthetic datasets¬†¬∑ Collaborative Filtering 1‚ÄÇ Introduction Recommender systems (RSs) are used to provide personali- zation facilities to users of internet services. Large compa- nies that use RSs are Spotify, TripAdvisor, Netflix, Google Music, etc. RSs are becoming increasingly important due to its capacity to provide both accurate recommendations and recommendations designed to retain people using the service. Recommendations are provided by suggesting the products or services that have a higher probability of being liked by the user. Consequently, it is necessary to filter the available items (products or services) in the RS. For this reason, RSs are usually classified according to their filtering approach. Social [ 1 , 2 ], content-based [ 3 ], demographic [ 4 , 5 ], context-aware [ 6 ], collaborative filtering (CF) [ 7 ] and their ensembles [ 8 ] are the most commonly used strategies. Social filtering recommends to the active users items that their followed, group of friends, contacts, etc., like. Content-based recommendations include items with similar content to those the active user liked. It is usual to compare descriptions or even item images. Demographic filtering selects users having demographic features such as those of the active user (similar age, same sex, same zip code or near zip code, etc.) and then extracts those item preferences. Context-aware filtering usually relies on geographic information, such as GPS coordinates. The most accurate and relevant filtering strategy is the * Jes√∫s Bobadilla jesus.bobadilla@upm.es Abraham Guti√©rrez abraham.gutierrez@upm.es 1 Universidad Polit√©cnica de Madrid, ETSISI, Ctra. de Valencia Km. 7, Madrid, Spain 2 Technical University of¬†Madrid, ETSISI, Ctra. de Valencia Km. 7, Madrid, Spain / Published online: 17 February 2024 Applied Intelligence (2024) 54:2472‚Äì2490 collaborative strategy. In this strategy, recommendations are based on the preferences of the most similar users. The machine learning method that best fits the CF concept is the K-nearest neighbours algorithm (KNN) [ 9 ]. It is simple and directly implements the CF concept, where the neigh- bours are the most similar users to the active users. The main drawbacks of the KNN are that it is a memory-based method, it runs slowly, and it is not sufficiently accurate. The model-based matrix factorization (MF) [ 10 ] solves the KNN limitations. Moreover, it contains two vectors of hidden factors. The first vector is used to code (compress) the relevant information of users, whereas the second vec- tor is used to code the relevant information of items. Both vectors belong to the same latent space, and they are com- bined using a dot product. Additionally, the hidden factors are optimized by minimizing the prediction errors. Non- negative matrix factorization (NMF) [ 11 ] ensures that the hidden factors are non-negative to enable some semantic interpretations of predictions. Deep learning [ 12 ] can currently be implemented to obtain improved MF results. The simplest deep learn- ing architecture is similar to that of MF. In this method, the hidden factors of the user are replaced by neural user embedding, and analogously, the hidden factors of items are replaced by neural item embedding. This model is called deep matrix factorization (DeepMF) [ 13 ], and it is better than MF due to the ability of its neural networks to remove complex non-linear patterns in raw data. DeepMF combines the embeddings using a dot layer. An improved DeepMF model is the variational deep matrix factorization (VDeepMF) [ 14 ], where an intermediate layer codes the parameters of a chosen distribution (usually Gaussian), and from it, a stochastic-based sampling process spreads samples in the latent space. The DeepMF (or VDeepMF) dot layer can be improved by replacing it with a multilayer perceptron (MLP) that combines the hidden factors of users and item embeddings and generates a manifold. This approach is called neural collaborative filtering (NCF) [ 15 ]. Our proposed architecture combines a DeepMF model and a Wasserstein generative adversarial network (GAN). GAN [ 16 ] networks can generate fake samples fol- lowing the distribution of a source set of real data samples. The most common use of GAN networks is to generate realistic fake faces from a dataset of real human faces. Similarly, our objective is to generate synthetic (fake) CF samples from an existing dataset of CF samples, such as MovieLens [ 17 ]. Then, by collecting many fake samples, a synthetic CF dataset can be created. Generating synthetic CF datasets makes it possible to simulate the stress situation in the RS, as it can be gener- ated ‚Äòfamilies‚Äô of datasets where gradually some of the parameters can be selected. For example, we can gener- ate a family of CF datasets where the number of users grows from several thousands to millions, and then test in advance the performance of our system in different scenarios where the number of users gradually, or sud- denly, grows (e.g. due to a marketing campaign or an influ- encer action). This simulation can avoid system failures in extreme situations. Similarly, a family of datasets can be generated with a growing number of items. It leads to more sparse scenarios where the RS accuracy could decrease. This type of simulation gives us the conveni- ence of incorporating many products or services in a short period of time. Additionally, the generation of synthetic datasets makes possible that researchers test their machine learning models in bounded scenarios, difficult to find in real datasets, such as increasingly sparse data matrices, different cold start situations, or extreme pattern variations in the user profiles. The state-of-the-art methods in CF generation include statistical methods that are not able to adequately determine the patterns of complex datasets. Therefore, adversarial approaches [ 18 ], and GAN-based approaches have been proposed. Preventing shilling attacks is a relevant objective in the RS field, and some GAN-based approaches act as a defence against them [ 19 ]. Data augmentation is an obvi- ous field where GANs can be applied. Purchase profiles are used in the collaborative filtering generative adversarial net- work model (CFGAN) [ 20 ] model to increase the number of training samples in a dataset of commercial products. The identity-preservation generative adversarial network model (IPGAN) [ 21 ] incorporates negative sampling information to improve accuracy results. It allows two separate generative models to be incorporated, with one method managing posi- tive data and the other method processing negative samples. Session information is used in the deep collaborative filter- ing generative adversarial network (DCFGAN) model [ 22 ] instead of matrices of votes combining GAN and reinforce- ment learning. To run recommendation training, the neural collaborative generative adversarial network (NCGAN) [ 23 ] incorporates a regular GAN that processes the intermediate CF results provided by a neural network stage. The recurrent generative adversarial network (RecGAN) [ 24 ] combines a recurrent neural network (RNN) and a GAN to process temporal patterns. Unbalanced datasets are managed using a Wasserstein GAN acting as a generator and the packing generative adversarial network (PacGAN) as a discriminator [ 25 ]. Finally, a conditional generative adversarial network (CGAN) performs a conditional generation of ratings [ 26 ]. The RS state-of-the-art method that generates synthetic CF datasets is divided into statistical and machine learning approaches. Solutions in the first group allow us to param- eterize the results (to change the number of items, users, etc.), but they do not adequately capture the complex non- linear relations between users and items. Consequently, the accuracy of this method is poor. The second group makes Wasserstein GAN-based architecture to generate collaborative filtering synthetic datasets 2473 use of deep learning generative adversarial networks to cre- ate fake profiles or fake samples. The accuracy is improved, but the GAN architectures in this group take discrete and heavily sparse CF datasets as a source, leading to results that are obtained slowly and the subject-to-mode collapse prob- lem. In addition, the number of items cannot be changed. Nevertheless, the existing generative adversarial network for recommender systems (GANRS) method makes its GAN generation start from dense and continuous latent space embeddings, obtaining more accurate results and enabling us to choose the number of users and the number of items in the synthetic datasets. The method proposed in this paper borrows the GANRS architecture, making the necessary changes to introduce the Wasserstein concept. Wasserstein generative adversarial networks (WGANs) are designed to reduce the inherent ‚Äòmode collapse‚Äô of the GAN architecture. In the model regularization Wasserstein generative adver- sarial network (MRWGAN) [ 27 ], an RS is implemented. Moreover, an autoencoder is used to implement the genera- tive model, and a model-Wasserstein regularized distance is used as the function loss. It achieves better accuracy with missing data than the state-of-the-art methods. Analogously, an L1 regularized Wasserstein loss function has been used for autoencoder-based CF [ 28 ] to learn a low-rank repre- sentation of variables in the latent space. The Wasserstein distance has also been implemented to tackle the cold-start issue in CF, minimizing it under user embedding constraints. GAN approaches also have their own drawbacks, particu- larly: a) a long training time, b) a long inference time when the GAN model is very deep, c) difficulty to set relevant CF parameters such as the number of items and the number of users in the dataset, d) possibility of suffering from the ‚Äòmode collapse‚Äô behaviour, e) difficulty to adequately learn from the sparse data sets of CF, and e) lack of fine tuning the variation of the results in successive executions. No standard machine learning quality measures are defined to compare synthetic datasets created or gener- ated using different statistical or generative models. This is because these models are designed to catch the complex nonlinear patterns of the source data, and there are no simple comparations able to discriminate the quality of the gen- erated results, such as in regression (MAE, MSD, etc.) or classification (accuracy, precision, recall, etc.). To better understand this drawback, we can analyse the face image quality assessment strategies [ 29 ], which are based on the character, fidelity, and utility features of facial biometrics. In the RS field we do not have such type of information to make a similar process, since what we are generating are user/ item vector profiles. In addition, face image quality makes a distinction between approaches that require a reference, a reduced reference, and no reference of faces, where only the two first cases have some accurate quality measure; pre- cisely those situations that RS cannot manage as they do not have the equivalent ‚Äòreference‚Äô to the face image quality field. Finally, the conceptual problem of the ‚Äòquality para- dox‚Äô inherent in these quality measures is heavily present in the RS scenario, where a generated dataset should not be too similar to the source, otherwise it would not be useful, and should not be too different from the source, otherwise it would not be representative. Therefore, research papers that generate synthetic datasets [ 23 ‚Äì 25 ] test them by run- ning several CF Machine Learning models and comparing the results obtained on different instances of the generated datasets from the same source data. This is the strategy that our paper follows in its ‚ÄòResults‚Äô section. In the seminal GANRS paper [ 30 ], relevant innovations are incorporated, and the previous RS GAN architectures are compared to generate synthetic datasets. However, a signifi- cant drawback occurs. The process to convert from the latent space generated samples (dense, small, and continuous) to the raw samples (sparse, large, and discrete) that form the synthetic dataset generates duplicated samples that must be removed. This is a common drawback in a discretization task, but if the number of duplicated samples is high, a ‚Äòcol- lapse‚Äô in the GAN generation can occur. The innovation of our proposed Wasserstein GAN approach (WGANRS) is the introduction of the Wasserstein design (function loss, weight constraints, etc.) to the existing GANRS method in the hope that the mode collapse situations are reduced. The proposed method borrows the stages defined in [ 30 ] and replaces the regular GAN generation kernel by a Wasserstein approach (WGAN). The WGAN provides four relevant improvements: 1) it incorporates a new loss function that is interpretable and has clear stopping criteria, 2) it empirically returns better results, 3) the GAN mode collapse is significantly reduced, and 4) it provides a clear theoretical backing. The WGAN loss function is based on the earth mover‚Äôs distance, and it incorporates an f w function that acts as a discrimina- tor model, called the ‚Äòcritic‚Äô. The critic estimates the earth mover‚Äôs distance, processing the highest difference between the generated distribution and the real distribution under sev- eral parameterizations of the f w function. The critic makes the generator work harder by looking at different projec- tions. Our most relevant predictor that measures the mode collapse mitigation will reduce the removed samples and consequently increase the number of samples of the syn- thetic files (their sizes). We will also test some other quality measures such as the precision, recall, and the distribution of the ratings, users, and items. Figure 1 shows the innovation of the proposed method com- pared to SOTA, particularly with the most currently published baseline (GANRS) on which our method is based. As shown in a) (top of Fig. 1 ), SOTA methods that generate CF datasets take only raw profiles and generate synthetic RS datasets. This is an analogous process to fake face creation, which can be generated by GANs from datasets of real faces. It is known J. Bobadilla, A. Guti√©rrez 2474 that a recurrent problem in these processes is mode collapse [ 30 ], which leads to a lack of balanced generation of samples. Some categories are overrepresented, whereas other categories are underrepresented. As an example, we could obtain an enor- mous quantity of fake samples of Number 7 by using the Modi- fied National Institute of Standards and Technology (MNIST) dataset. However, some other numbers are rarely generated. Notably, in Fig. 1 a (SOTA methods), the GAN module is fed with RAW data, such as image pixels or in our case, user pro- files. These RAW data are large, discrete, and sparse, leading to the mode collapse problem. The most current research in the area is the GANRS method (our baseline). Its high-level architecture is shown in Fig. 1 b, where the GAN model is not fed with RAW data. Instead, it is fed with deep learning embedded data. These embedded data are short, continuous, and dense vectors. The embedded data contain compressed information on the items and users in the RS. As a result, both the performance and the accuracy of the GANRS are improved compared to the previous SOTA models and methods. In the GANRS baseline [ 30 ], the mode collapse problem is reduced, and the RS datasets generated are less biased than those created using SOTA methods. Regardless, the mode collapse remains, and it produces a certain degree of redundant samples. To reduce mode collapse even further, our proposed WGANRS method introduces the Wasserstein concept into the GAN kernel (Fig. 1 c). The Wasserstein approach has been shown to yield better results by reducing mode collapse when applied to GANs [ 27 ]. This approach requires the introduction of a new loss function and benefits from a theoretical backing and a defined stopping criterion. The hypothesis of the paper claims that incorporating the Wasserstein concept into the generative kernel of the GANRS method will lead to a decrease in the mode collapse problem inherent to the GAN when applied to CF scenarios. Consequently, the proposed WGANRS is expected to gener- ate more accurate CF datasets. The structure of the paper is as follows: In Section 2 , the proposed WGANRS method (from the existing GANRS infor- mation) is explained and formalized. In Section 3 , the design of the experimental executions of code is introduced, and the results are shown and analysed using the MovieLens and Net- flix* datasets as a source. Moreover, the most relevant results are provided. In Section 4 , the most remarkable conclusions are presented, and some future work is proposed. Additionally, the references section includes current representative papers in the main RS area and in the specific GAN generation of CF datasets. 2‚ÄÇ Method This section is divided into two subsections. In the first subsection, the proposed method concepts, its architecture, and the sequence of processes and stages to both train the model and generate the synthetic datasets in a feedforward prediction are explained. The second subsection contains the necessary equations to formalize the method, grouped into the main stages of the architecture. The Python and Keras codes of the proposed method is available in ( https://‚Äãgithub.‚Äã com/‚Äãjesus‚Äãbobad‚Äãilla/‚Äãganrs.‚Äãgit ). 2.1‚ÄÇ Concepts and¬†architecture The proposed deep learning architecture is based on five sequential stages in which a neural CF, a WGAN model, and a clustering process are involved. Moreover, a CF dataset is used as the source, and a synthetic dataset that has the same format as the source dataset and similar data distributions is generated. The key issue involving both the GANRS [ 30 ] seminal baseline and the WGANRS proposed architecture is that the GAN or WGAN stages are fed with dense, short, and continuous embeddings in the latent space instead of sparse, large, and discrete raw data. It makes the work of both the generator and the discriminator models easier, faster, and more accurate. The obvious drawback of the proposed design is the theoretical loss of quality involved in the com- pression stage (coder) and, particularly, in the subsequent decompression (decoder). However, when converting from embedded to raw samples, a significant benefit emerges: we can choose the target number of users and items, mak- ing the GANRS and WGANRS models more flexible and useful than the state-of-the-art methods. Figure 2 shows an overview of the proposed WGANRS architecture. From an existing source dataset (most-left side in Fig. 2 ), such as MovieLens, a synthetic dataset (most-right side in Fig. 2 ) is generated with the same format (to be useful to researchers) and similar patterns and distributions of the users, items, and ratings. This dataset can be generated by choosing the desired number of users, items, and starting number of sam- ples to be useful for companies and researchers as a base for simulations, anticipating diverse future scenarios, or as ground data for new machine learning models. The proposed WGANRS first converts (compresses) the input sparse dataset to its embedding-based representation and converts (decompresses) the generated (fake) embed- ding-based dataset to its raw and sparse representation. A DeepMF model (left side in Fig. 2 ) was chosen to perform the compression stage due to its simplicity and performance, and K -means clustering (right side in Fig. 2 ) was used to run the necessary decompression. In this scenario, the K -means algorithm has the advantage of setting the K * number of users and K ** number of items we want the generated dataset to hold. Finally, our architecture kernel is based on a WGAN model (centre of Fig. 2 ) to generate fake embedding samples from real embedding samples. The DeepMF model used for the compression task has a previous learning stage (top-left draw in Fig. 3 ) where the Wasserstein GAN-based architecture to generate collaborative filtering synthetic datasets 2475 embedding weights are set by means of backpropagation optimization. The DeepMF model contains two separate embedding layers: one layer for users and the other layer for items. These embeddings must have the same size, which usually ranges from 5 to 15 neurons. It is expected that similar users will be coded with similar embedding maps (codes), and the same applies for items. Once the DeepMF model has been trained, we can feedforward each existing user ID to obtain its embedding representation (top-right draw in Fig. 3 ). The same process is performed with all existing item IDs. Thus, we obtain a matrix I x E containing the embedding representations of the items, where I is the number of items in the source dataset and E is the embed- ding size. Analogously, we obtain a matrix U x E containing the embedding representations of the users, where U is the number of users in the source dataset. By combining the source dataset (left side of Fig. 2 ), the compressed item matrix, and the compressed user matrix (top right draw in Fig. 3 ), we can obtain the embedding rep- resentation of the source dataset, as shown in the ‚Äúembed- ding-based CF dataset‚Äù in the bottom left graph of Fig. 3 and in Fig. 2 . Starting from the embedding-based CF dataset as a source, the proposed WGANRS architecture generates the ‚Äúfake embedding-based CF dataset‚Äù (centre of Fig. 2 ), and it is performed by means of a Wasserstein GAN. The first stage of this generative task is the WGAN training (bottom-left in Fig. 3 ), where the generator model creates synthetic samples from Gaussian stochastic vectors containing random noise. Then, the Wasserstein critic (discriminator) performs the necessary binary classification to label samples as ‚Äòreal‚Äô or ‚Äòfake‚Äô. Notably, the ‚Äòfake‚Äô samples come from the generator model, whereas the ‚Äòreal‚Äô samples are randomly taken from the previously generated ‚Äòreal embedding-based CF data- set‚Äô. Once the training process has finished, we can forget the critic model and take the generator model to create as many fake embedding samples as needed. The whole pro- cess (training and feedforward generation) is expected to be fast due to the compressed embedding representation and accurate due to the Wasserstein restrictions to avoid mode collapse. In the last stage of the proposed architecture, it is neces- sary to decompress the ‚Äòfake embedding-based CF dataset‚Äô (right side in Fig. 2 and bottom right draw in Fig. 3 ). In this stage, we have generated a very large number of fake samples, consisting of tuples‚Äâ< user_embedding,item_ embedding,rating >‚Äâ, where both the user and the item embeddings produce vectors of real numbers. We have to convert this set of tuples to a discretized version‚Äâ< user_ ID,item_ID,rating >‚Äâ, where user_IDs are integers in the range [1..number of users], and analogously item_IDs are integers in the range [1..number of items]. Once the neural network has been trained, the user embedding assigns simi- lar codes to similar users (same with the embedding layer). This inherent property of the embedding layers makes it possible to incorporate a clustering process to the proposed Fig.‚ÄØ1 Innovation of the proposed method and its expected impact in solving the GAN mode collapse. Figure 1 a shows the traditional GAN approach in the CF context, Fig. 1 b shows the improvement introduced in the baseline method to adequately process sparse data, and Fig. 1 c details the proposed introduction of the Wasserstein ker- nel to reduce the mode collapse problem J. Bobadilla, A. Guti√©rrez 2476 method, in charge of grouping similar users and items to the desired number of users and items in each synthetic dataset. This is a discretization process in which the WGANRS has been designed to set the desired number of users and items in the generated dataset. To implement it, K-Means clustering [ 31 ] was performed, since it allows us to set the K* number of users and the K** number of items. Figure 4 shows the follow- ing concept: a K-means is used to cluster K* users, whereas another K-Means process is used to cluster K** items. Since similar users should have similar embeddings, it is expected that they will be grouped in the same clusters, analogously with items. Each user number in the generated dataset corre- sponds to the cluster number in the K-Means where the fake user embedding has been grouped. For example, the left-most sample in the fake embedding-based CF dataset (left side of Fig. 4 ) was grouped with its user (green colour) in the K* group and its item (blue colour) in Group 3. Consequently, the generated fake sample in the synthetic dataset is‚Äâ<‚ÄâK*, 3, rating‚Äâ>‚Äâ. In this example, the ‚Äòrating‚Äô is the value of the first sample of the source dataset (left side of Fig. 2 ). Finally, due to the discretization process, duplicated sam- ples can be found. This happens when two different generated samples share the same user ID and the same item ID. When the chosen number of users and items is high, it is more diffi- cult to find duplicated samples since there is a wider variety of clusters, and it is expected that the users and the items will be assigned to the groups in a balanced way. Duplicated samples can be managed by simply removing the spare samples. The expected balance in the clustering groups could be ‚Äòbroken‚Äô if the mode collapse is happening in the GAN. Indeed, the Was- serstein concept is used in this paper to avoid mode collapse, and the number of removed samples will be used as a quality measure in the results section. The lower the removed samples are, the better the method is. Since two of the hyperparameters in the proposed model are the number of users and the number of items, the cluster- ing method that better fits this information is K-Means, where directly we can set K* as the number of users and K** as the number of items. In fact, this is one of the unusual situations where the K value is known before the clustering process. Thus, other relevant clustering methods such as hierarchical, distribution, density or fuzzy-based ones are not adequate in this scenario. In the following subsection, the WGANRS approach is for- malized. Moreover, equations have been provided. 2.2‚ÄÇ Formalization 2.2.1‚ÄÇ CF definitions First, we define the main sets in the RS: set of users U , items I , range of ratings V , and existing samples S . (1) We let U be the set of users who make use of a CF RS (2) We let I be the set of items available to vote on in the CF RS (3) We let V be the range of allowed votes , where V = { 1, 2, 3, 4, 5 } (4) We let S be the set of samples contained in the CF dataset , where N = | S | = the total number of cast votes (5) S = { < u , i , v > 1 , < u , i , v > 2 , ‚Ä¶ , < u , i , v > N } , where each u ‚àà{ 1, ‚Ä¶ , | U | }each i ‚àà{ 1, ‚Ä¶ , | I | } , and each v ‚àà{ 1, ‚Ä¶ , | V | } Fig.‚ÄØ2 Overview of the proposed WGANRS architecture Wasserstein GAN-based architecture to generate collaborative filtering synthetic datasets 2477 The formalization of the defined CF dataset consists of a set of tuples <userID, itemID, rating (number of stars)>, where the ‚Äòrating‚Äô is the vote assigned for the ‚ÄòuserID‚Äô to the ‚ÄòitemID‚Äô. 2.2.2‚ÄÇ DeepMF training (6) The Deep MF training ( top ‚àíleft graph in Figure 3 )is conducted to create a model that can embed each user ID and each item ID . These two embeddings feed the WGANRS generative stage . Each embedding is a compressed representation of the user or the item . The embeddings are unidimensional vectors of size E + 1. We define f eu ( u ) as the function that compresses the user u information and analogously f ei ( i ) as the function that compresses the item i information (7) We let E + 1 be the size of the two neural layer embeddings used to vectorize each user and each item belonging to U and I , respectively . We let f eu ( u ) = ‚Éó e u = [ e u 0 , e u 1 , ‚Ä¶ , e u E ] , where f eu is the embedding layer output of the users and u ‚àà{ 1, ‚Ä¶ , | U | } (8) We let f ei ( i ) = ‚Éó e i = [ e i 0 , e i 1 , ‚Ä¶ , e i E ] , where f ei is the embedding layer output of the items and i ‚àà{ 1, ‚Ä¶ , | I | } Fig.‚ÄØ3 DeepMF and WGAN models involved in the WGANRS architecture Below, the most relevant equations in the back propaga- tion algorithm are defined, and we set the output error as the mean squared differences metric. These equations are not distinctive of the proposed method. 2.2.3‚ÄÇ DeepMF feedforward Once DeepMF has learned, we can collect the embedding representation of each user and each item in the CF RS. Therefore, all the existing itemID and userID in the RS (9) By combining the dense vectors of the user and item embeddings ( ‚Éó e u = [ e u 0 , e u 1 , ‚Ä¶ , e u E ] and ‚Éó e i = [ e i 0 , e i 1 , ‚Ä¶ , e i E ]) , we can make rating predictions in the DeepMF training stage . The dot product of the user embedding and the item embedding in each < u , i , v > j ‚àà S provides its rating prediction .  y j = f eu ( u ) ‚àô f ei ( i ) = ‚Éó e iu ‚àô ‚Éó e i = [ e u 0 , e u 1 , ‚Ä¶ , e u E ] ‚àô[ e i 0 , e i 1 , ‚Ä¶ , e i E ] (10) 1 2 ( y j ‚àí ÃÇ y j ) 2 is the output error used in the DeepMF neural network to start the back propagation algorithm , where the neural weights are iteratively improved from the Ìõø j values , Œî w ji = Ìõº y j f  ( Net i ) ‚àë k w ik Ìõø k , where k is a hidden layer , and Œî w ji = Ìõº y j f  ( Net i ) 1 2 ( y k ‚àí ÃÇ y k ) 2 if k is the output layer. i , j , and k are successive sequential layers . J. Bobadilla, A. Guti√©rrez 2478 dataset feed the trained DeepMF model, and their embed- ded representations can then be obtained. It can be done by making the feedforward prediction operation (top-right graph in Figure 3 ) on the trained DeepMF model. (11) We let E ‚àó = { < u , ‚Éó e u = [ e u 0 , e u 1 , ‚Ä¶ , e u E ] > , ‚àÄ u ‚àà U } be the set of embeddings for all the RS users (12) We let E ‚àó ( u ) = ‚Éó e u = [ e u 0 , e u 1 , ‚Ä¶ , e u E ] (13) Let E ‚àó‚àó = { < i , ‚Éó e u = [ e u 0 , e u 1 , ‚Ä¶ , e u E ] , ‚Éó e i = [ e i 0 , e i 1 , ‚Ä¶ , e i E ] > , ‚àÄ i ‚àà I } be the set of embeddings for all the RS items . (14) We let E ‚àó‚àó ( i ) = ‚Éó e i = [ e i 0 , e i 1 , ‚Ä¶ , e i E ] 2.2.4‚ÄÇ Setting the¬†dataset of¬†the¬†embeddings Now, we collect the above embedding representations of all the itemID and userID in the RS to translate the set ‚ÄòS‚Äô (5) to the set ‚ÄòR‚Äô (15). The set ‚ÄòR‚Äô is the embedding-based dataset version of the original RAW dataset. We let (15) R = [ < E ‚àó ( u ) , E ‚àó‚àó ( i ) , v > ] , ‚àÄ < u , i , v > j ‚àà S be the embedding ‚àíbased dataset of real samples 2.2.5‚ÄÇ WGAN training The core concept of the GAN methodology is to jointly train a generator model and a discriminator model. Once the architecture has been trained, the generator model creates new samples that follow the distribution of the training samples. The discriminator model attempts to differentiate between real samples and generated ones. This is a min-max optimization problem of the form: Min G Max D ( Ìîº x ‚àΩ p data [ log D ( x ) ] + Ìîº z ‚àΩ p latent [ log ( 1 ‚àí D ( G ( z )) ] ) , w h e r e G ‚à∂ Z ‚Üí X is the generator model, which maps from the latent space Z to the input space X ; D ‚à∂ X ‚Üí ‚Ñù is the dis- criminator model, which maps from the input space X to a clas- sification value (real/fake). ‚Ñù ‚Üí ‚Ñù is a concave function. The above formula is the optimization function, the expression that both networks (generator and discriminator) try to optimize. G aims to minimize it, whereas D wants to maximize it. The bottom-left graph in Fig. 3 shows the generative learning. The GAN architecture consists of a discriminator classifier (16) and a generator model (17). The generator creates fake samples (RS profiles, in our case), whereas the discriminator tries to detect fake samples. In generative adversarial training, the discriminator progressively learns to accurately differentiate fake profiles from real profiles. At the same time, the generator learns to make fake sam- ples difficult to distinguish from real profiles. We call f D (16) the discriminator model and f G (17) the generator Fig.‚ÄØ4 Clustering stage in the WGANRS architecture Wasserstein GAN-based architecture to generate collaborative filtering synthetic datasets 2479 model. Both f D and f G will iteratively learn and improve themselves by minimizing a loss function (18) f GD . f GD = Min G Max D f ( D , G ) = E R [ f w ( R )] + E z [ f w ( G ( z )] , where E R is the expected value for real samples, z is the random noise that feeds generator G , and E z is the expected value for the generated fake profiles G(z). f w is the Wasserstein function based on the earth mover‚Äôs distance . This function satisfies the 1 ‚Äì Lipschitz constraint: | || f ( x 1 ) ‚àíf ( x 2 )||| ‚â§ || x 1 ‚àí x 2 || , ‚àÄ x 1 , x 2 . R refers (16) We let f D be the discriminator D model belonging to a GAN model (17) We let f G be the generator G model belonging to a GAN model (18) We let f GD be the cost function of the GAN model to (15). Notably, the Wasserstein concept has been introduced in Eq.¬†( 18 ). Mainly, it is implemented in the loss function code of the generative model. The Wasserstein approach has been designed to reduce the mode collapse problem inherent to the GAN. We implement it to reduce the mode collapse in our WGANRS proposed method and to consequently reduce the number of excessively generated similar profiles in the RS. 2.2.6‚ÄÇ WGAN generation Once the GAN has been trained, we can generate as many samples as needed. We can introduce batches of random Gaussian noise vectors ‚Äòz‚Äô and implement the feedforward process ( model.predict ). The result are batches of fake embedded prof i les (bottom-right graph in Figure 3 ). (19) We let F = f G be the generated dataset of fake samples from different random noise vectors z 2.2.7‚ÄÇ Clustering of¬†items and¬†users Figure 4 shows the clustering process, where we set K* (20) as the number of users in the generated dataset and K** (21) as the number of items on it. The N gen- erated fake profiles will contain both fake user embed- dings and fake item embeddings (where N >> K* and N >> K** ). (20) We let K ‚àó be the number of clusters used to group the embeddings of the users (21) We let K ‚àó‚àó be the number of clusters used to group the embeddings of the items For each generated fake user (each user of N), we must select the nearest user from the K* existing users (22). The h ‚àó ( u ) function makes this group. The same process is used for items. For each generated fake item (each one of the N), we must select the nearest item from the K** existing items (23). The h ‚àó‚àó ( i ) function makes this group. (22) We let h ‚àó ( u ) = c | c ‚àà{ 1, ‚Ä¶ , K ‚àó } be the clustering operation that assigns a centroid to each user . (23) We let h ‚àó‚àó ( i ) = c | c ‚àà{ 1, ‚Ä¶ , K ‚àó‚àó } be the clustering operation that assigns a centroid to each item 2.2.8‚ÄÇ Setting the¬†dataset of¬†the¬†item IDs and¬†user IDs To create the synthetic dataset, the generated set of embed- dings F (19) is converted to its discretized version H (24). We let H be the item ID and user ID discrete dataset obtained from the embedding-based dataset F of fake samples. Sometimes, different generated samples in Set F will be discretized to the same user and item: < h ‚àó ( u ) , h ‚àó‚àó ( i ) , v > = < h ‚àó( u ) , h ‚àó‚àó( i ) , v > . (24) H = [ < h ‚àó ( u ) , h ‚àó‚àó ( i ) , v > | ‚àÄ < E ‚àó ( u ) , E ‚àó‚àó ( i ) , v > ‚àà F ] This particularly happens if the GAN suffers from mode collapse. In these cases, there are samples with identical information, and we create the set H where duplicated sam- ples are removed (25). We let S = { H } be the synthetic generated dataset version of H where duplicated samples are removed. (25) The last transformation removes samples when a fake user casts different votes ( v, v ) to the same item . (26) We let G  = { < h ‚àó ( u ) , h ‚àó‚àó ( i ) , v > ‚àà H | ‚àÑ < h ‚àó ( u  ) , h ‚àó‚àó ( i  ) , v  > ‚àà H , where h ‚àó ( u ) = h ‚àó ( u  ) ‚àß h ‚àó ( i ) = h ‚àó‚àó ( i ) ‚àß v ‚â† v  } J. Bobadilla, A. Guti√©rrez 2480 3‚ÄÇ Results The proposed method has been tested using two open-source representative CF datasets: MovieLens 1¬†M ( https://‚Äãgroup‚Äãlens.‚Äã org/‚Äãdatas‚Äãets/‚Äãmovie‚Äãlens/‚Äã1m/ ) and a subset of Netflix that we call Netflix* [ 32 ]. These two datasets were chosen because they are representative in the CF field. MovieLens is probably the most tested dataset family over the years in CF research. The results obtained in MovieLens are very informative for RS researchers. On the other hand, Netflix is not widely used due to its enor- mous size and because it is no longer available. We utilized the open version of Netflix* that is randomly shortened [ 33 ]. Net- flix* has been selected as the dataset for this research because its internal patterns are different from those of MovieLens. MovieLens has been created in a relatively short time in an academic environment, whereas Netflix is an enormous com- mercial dataset that has been growing for a long period. Since this research involves catching the internal patterns of a source dataset and parameterizing and translating those patterns to a generated dataset, it is convenient to use such different sources. Table 1 shows their main parameter values. The results of both datasets follow the same trends. Therefore, to ensure that the length of this paper is appropriate, we only explain the Mov- ieLens results and group the Netflix* results (Figs. 10 , 11 , 12 and 13 ) in Appendix A. To test the WGANRS method, two sets of synthetic datasets have been created. The first set has a varied number of users, whereas the second set has a varied number of items. Each row in Table 2 shows the values of each set. The first row indicates that five synthetic datasets have been generated. The first dataset contains 500 users and 1000 items, the second dataset holds 1000 users and 1000 items, and so on until the last dataset has 8000 users and 1000 items. All the generated datasets were created starting from 400 thousand samples. This set of data allows us to test the impact of changing the number of users. Analogously, the second row in Table 2 shows that four synthetic datasets have been created. All four datasets have 4000 users. However, the number of items varies from 500 in the first dataset to 4000 in the last set. This allows us to measure the impact of changing the number of items. Since we will use the GANRS method [ 29 ] as the baseline, all datasets have also been created using GANRS. Thirty-six datasets were generated, 5‚Äâ+‚Äâ4 using MovieLens as a source and 5‚Äâ+‚Äâ4 using Netflix*, both for GANRS and for WGANRS. To test these datasets, four different exections were conducted: ‚Ä¢ Number of generated samples : The number of samples returned by GANRS and WGANRS was compared. The WGANRS method is expected to perform better, as it focuses particularly on avoiding the typical ‚Äòmode collapse‚Äô in GANs. The better managed the mode col- lapse is, the more varied the embedding samples that the WGANRS generates, the better the performance of the clustering process to create the raw samples, and finally, the lesser the number of sample collisions, increasing the sizes of the synthetic datasets. ‚Ä¢ Rating distributions : It is important that the rating distri- bution of the generated datasets be as similar as possible to that of the source, particularly on the relevant ratings (usually 4 and 5 stars). This is an indication that the pat- terns of the fake profiles are correct, and they contain an adequate proportion of relevant and nonrelevant votes. ‚Ä¢ User and item distributions : It is interesting to test the user and item distributions as the number of users and items var- ies, comparing them to the source dataset. It is expected that the Gaussian random noise used to create the stochastic vector that feeds the WGANRS generator will force the dif- ferent Gaussian distributions of users and items. ‚Ä¢ Precision and recall : Regarding the ground distributions, balanced votes, and high number of samples, the gen- erated datasets are used to adequately analyse them on the CF task, and their recommendation quality measures return suitable values and trends. The above executions cover the potential comparatives avail- able on the generative creation of synthetic datasets in the CF area. Figure 5 shows the concept. Figure 5 a (top graph) shows the traditional CF analysis. Different state-of-the-art methods or models are applied to one or several existing CF datasets, and the recommendation results can be measured using traditional quality prediction and recommendation quality metrics, such as the precision, recall, F1, and mean absolute error (MAE). However, the field of synthetic CF dataset generation is com- pletely different. From a source dataset (Fig. 5 b), we create one or several synthetic datasets. We can set different numbers of users, items, samples, etc., and each generated dataset will hold. To compare the proposed generative method with the selected state-of-the-art baseline, we must create a synthetic dataset or group of synthetic datasets using the proposed method (orange datasets in Fig. 5 b) and a different dataset or group of datasets using the SOTA baseline (blue datasets in Fig. 5 b). Now, we need to determine which of these datasets (or groups) are bet- ter. Comparing generated datasets (Fig. 5 b) is a very different task than comparing methods or models applied to an existing dataset (Fig. 5 a). Figure 5 b shows three types of code execution that we can perform to decide whether the generated datasets using the proposed method (orange datasets) are better than the generated datasets using the baseline method (blue datasets): Table‚ÄØ1 Main parameter values of the tested datasets Dataset #users #items #ratings scores sparsity Movielens 1¬†M 6,040 3,706 911,031 1 to 5 95,94 Netflix* 23,012 1,750 535,421 1 to 5 98.68 Wasserstein GAN-based architecture to generate collaborative filtering synthetic datasets 2481 1)	 The mode collapse impact can be measured in the CF field by removing very similar user profiles. The GAN can collapse to a reduced number of source profiles. The higher the number of deleted profiles is, the higher the mode collapse impact. The higher the deleted profiles are, the lower the number of samples in the generated dataset. Figure 5 b1 shows a comparison where the y -axis represents the number of samples. The proposed method (orange colour) improves the SOTA baseline. 2)	 The generated datasets should have probability distribu- tions that are similar to that of the source dataset. The user, item, and rating distributions of the synthetic data- sets can be compared. Figure 5 b2 shows the distribu- tion of the ratings from the source dataset (green colour) compared to the ‚Äòbaseline‚Äô dataset (orange colour, in this graph) and the ‚Äòproposed method‚Äô dataset (blue colour). Notably, the synthetic datasets are not expected to have the same distributions as the source dataset. The genera- tive process should create similar datasets, not identical datasets. Identical datasets have no value, just as rep- licating real faces is not valuable in field of computer vision. Therefore, there is no absolute metric to measure this type of quality. Extreme distribution similarities and large distribution differences must be avoided. 3)	 The quality of the generated datasets can be indirectly meas- ured by running state-of-the-art CF methods and models on them. We expect similar behaviours to those obtained when we apply these methods to the source dataset. Very different trends or absolute values in the generated dataset graphs, compared to those in the source dataset, will tell us that the generated dataset does not contain the main patterns of the source dataset. Figure 5 b3 shows the precision and recall results on the source dataset (left graph) and the generated dataset (right graph) when measured with several SOTA CF deep learning models. Both trends and values are similar. As explained above, we do not expect identical behaviours and values since synthetic datasets should mimic the source pat- terns and not copy them. For this reason, there is no standard quality measure to compare the graphs in Fig. 5 b3. Taking into account the above considerations, several experiments have been performed on the three explained approaches, as shown in b1, b2, and b3 of Fig. 5 . Individual executions and their explained results have been structured in SubSects. 3.1 to 3.4 , followed by the Discussion Subsection. 3.1‚ÄÇ Number of¬†generated samples As explained in the previous section, the proposed method uses a WGAN to generate synthetic embedding samples. These dense and continuous samples are then converted to their sparse and discrete versions by means of the clustering process and their translation to the raw tuples in the synthetic dataset. This discretization stage causes a proportion of ‚Äòcollisions‚Äô where identical or similar generated samples must be removed. The smaller the number of samples removed, the more accu- rate the generative model, and the richer the synthetic dataset. The Wasserstein GAN is expected to improve the results, as it is designed to prevent mode collapse inherent to the GAN models. Please note that the hypothesis is that by reducing the mode collapse, the variability of the generated embedded samples will increase, and then the clustering process will be able to spread users and item IDs in a more homogeneous way. Consequently, the number of discretized samples that are repeated (and deleted) will decrease. Overall, the total size of the generated datasets will increase as the GAN mode collapse is reduced using the Wasserstein approach. The final number of samples generated is a relevant qual- ity measure since it is directly related to the impact of mode collapse in the generative process. The baseline GANRS method suffers from the mode collapse problem, leading to the generation of repeated fake profiles. The method han- dles this situation by removing spare profiles, but it does not provide the necessary diversity of samples. The proposed WGANRS is expected to improve the results due to the Wasserstein ability to reduce the mode collapse and then to improve diversity and increase the synthetic dataset size. Figure 6 shows the comparison of GANRS (gan) versus WGANRS (wgan) both for synthetic datasets where the number of users varies (left graph) and for synthetic datasets where the number of items varies (right graph). Overall, the proposed approach (wgan) significantly improves the base- line (gan). Specifically, it duplicates the number of gener- ated samples. A 213% improvement in the left graph and a 191% improvement in the right graph are achieved. This is a relevant predictor of the superiority of the proposed method. Additionally, as expected, the higher the number of users or items there are, the higher the number of generated sam- ples. This is because the clustering process can better spread the samples in the latent space as the number of centroids increases. Then, the number of duplicated samples decreases. The results show a relevant improvement when the pro- posed method is applied compared to the baseline. This con- firms that the paper hypothesis is fulfilled. Moreover, incor- porating the Wasserstein concept into the generative kernel of the GANRS method will lead to a decrease in the mode collapse problem inherent to the GAN when applied to CF scenarios. Generated datasets have less redundant profiles. Accordingly, they are more diverse, and they contain more Table‚ÄØ2 Parameter values initial #samples #users #items 400,000 {500, 1000, 2000, 4000, 8000} 1,000 400,000 4,000 {500, 1000, 2000, 4000} J. Bobadilla, A. Guti√©rrez 2482 samples. Overall, the proposed WGANRS method generates richer, unbiased, and longer synthetic datasets. 3.2‚ÄÇ Rating distributions The distribution of the ratings (one star, two stars, ‚Ä¶, five stars) is an important quality measure in the CF synthetic dataset generation process. Recommendation models are very sensitive to the relevant versus non-relevant thresh- old, which is usually set to four or five stars in CF datasets containing five possible ratings. It is not enough that the Gaussian distribution of ratings in the generated dataset has a similar mean to the Gaussian distribution in the source dataset. It is also necessary that their standard deviation be analogous. Figure 7 shows that the proposed WGANRS generates a Gaussian distribution more similar to the Mov- ieLens distribution than the baseline GANRS. Specifically, it achieves a 271.21% improvement. The improvement aver- age obtained using the synthetic datasets in the first row of Table 2 (the number of users varies) is 304% (541% in Net- flix*), whereas the second row (the number of items varies) returns a 357% improvement on average (399% in Netflix*). It is expected that these positive results will contribute to providing adequate recommendation quality results in the next subsection. Beyond the numeric improvement values shown before, we can compare the shapes of the probability distribution in Fig. 7 . The probability distribution of the source MovieLens dataset (green-colour bars) is the target. The proposed WGANRS method (blue-colour bars) is much closer to the target than the baseline GANRS method (orange-colour bars). This is the reason for the relevant numerical improvements shown in the above paragraph. Additionally, the baseline method generates a Gaussian distribution excessively centred in the average rating (three stars), whereas the proposed method adequately fits its Gaussian distribution to the correct four-star mean. Regard- ing the Gaussian standard deviation, the baseline method does not adequately catch the source dataset shape. Its deviation is smaller, and consequently, it does not generate enough profiles in the distribution edges (one star and five stars). In contrast, the proposed method performs nearly perfectly on both edges of the source distribution. Thus, the samples generated using the proposed WGANRS method are more diverse and unbiased than those obtained running the SOTA baseline. Additionally, the obtained result better follows the Gaussian distribution that describes the source shape of ratings. This result reinforces and Fig.‚ÄØ5 Traditional CF validation of the methods and models versus the validation of the synthetic datasets generated by the GAN Wasserstein GAN-based architecture to generate collaborative filtering synthetic datasets 2483 complements that obtained in Sect. 3.1 . Overall, the proposed method a) reduces repeated samples, b) generates more sam- ples, c) increases diversity, d) decreases the bias, and e) better mimics the probability distributions of the ratings. 3.3‚ÄÇ Precision and¬†recall In this subsection, we show the recommendation quality results obtained on synthetic datasets obtained using Mov- ieLens as a source. The WGANRS method was used for this experiment to generate the synthetic datasets. The state-of- the-art NCF (neural collaborative filtering) deep learning model has been used to make predictions and recommenda- tions. The relevancy ÌúÉ threshold was set to five. The top graphs in Fig. 8 show the results when the number of users varies, whereas the bottom graphs show the results when the number of items varies. Both the values and the trends obtained from the synthetic datasets (coloured curves) are similar and com- patible with the source datasets (black curves), which indi- cates that the proposed method generates suitable synthetic datasets to be used in the RS field. Additionally, as expected, the higher the number of users, the higher the recall is, since each user profile will contain fewer relevant ratings (recall denominator). Conversely, the higher the number of users, the lower the precision is, since the denominator is the con- stant N (number of recommendations), whereas the numerator contains the true positives of relevant ratings, where a high number of users involves less relevant ratings per user. Additionally, from the set of synthetic datasets where the number of users varies, the dataset that holds 1000 users pro- vides more precision and recall results like the MovieLens source. Since MovieLens 1¬†M contains 6000 users, it tells us that the GAN-based method generates data patterns where recommendations are easier than using the source dataset. This result is consistent with the one reported in [ 30 ]. Most importantly, the evolution of all the recommendation curves in the generated datasets (coloured curves) follow the same trends as those exhibited by the source MovieLens (black curve), indicating that the internal patterns of the source data- set have been adequately captured by the proposed WGANRS method. Regarding the results when the number of items var- ies, similar conclusions can be drawn, underlying that rec- ommendation qualities worsen in absolute values compared to the source dataset. This probably occurs because the dis- tribution of the item ratings is highly variable compared to the distribution of the user ratings, leading to more difficult pattern extraction. There is a number of items holding a very low number of ratings. 3.4‚ÄÇ User and¬†item distributions Once the rating distributions have been tested, it is also convenient to compare the user and the item distributions obtained by using both the proposed and the baseline methods. The user and item distributions of the synthetic datasets are very dependent on the Gaussian parameter values with which the noise vectors that feed the generative model have been created. In the original paper [ 28 ] that serves as a baseline, the standard deviation has been customized for each tested dataset. In contrast, by using the proposed method, we fixed it to one and then removed this hyperparameter, making it easier to fine tune the proposed approach compared to the baseline method. The top graph in Figure 9 shows the results when the number of users varies, while its bottom graph shows the result by varying the number of items. Dashed lines repre- sent the baseline results, and solid lines show the proposed approaches. In all cases, as expected, the higher the number of users there are, the lower the number of ratings assigned to Fig.‚ÄØ6 Number of samples generated using the baseline GANRS method (gan) versus the proposed WGANRS method (wgan).  Source dataset: MovieLens 1¬† M. Number of samples needed: 40,000. Left graph: generated datasets with 1000 items and a range of 500, 1000, 2000, 4000 and 8000 users. Right graph: generated datasets with 4000 users and a range of 500, 1000, 2000 and 4000 items. The higher the number of generated samples, the better the model is J. Bobadilla, A. Guti√©rrez 2484 each user, since the number of ratings in each dataset is fixed. It can also be observed that the proposed method generates Gaussian distributions with higher standard deviations than the baseline approach, which has been heuristically tailored to the dataset. Both the proposed and baseline methods generate suitable user and item distributions for the CF area. 3.5‚ÄÇ Discussion The experimental results show the superiority of the proposed WGANRS method compared to the GANRS baseline. Par- ticularly relevant is the high improvement (approximately 200%) in the number of generated samples. This indicates that the proposed Wasserstein approach effectively reduces the amount of mode collapse of the GAN, The WGANRS method also effectively mimics the rating distribution of the source dataset, obtaining high improvements compared to the baseline and making it possible that their quality precision and recall values and trends are compatible with those from the source dataset. Furthermore, even no standard quality meas- ures exist to test RS generated data, the user and item distribu- tions obtained using the proposed approach are comparable to those of the baseline method. Additionally, the proposed method has the advantage that it is not necessary to assign heuristic values to the standard deviation of the Gaussian dis- tribution used to create the noisy random vectors that feed the generator model of the WGAN. Finally, the results using the Netflix* dataset reinforce the results obtained by testing MovieLens. Appendix A shows the Netflix* results. Overall, the proposed method improves both the sta- tistical baselines and state-of-the-art generative methods. Statistical baselines are reported to reach poor accuracy. In contrast, they support adequate parameterization. Generative baselines operate quite differently. They do not support full parameterization and exceed the accuracy of statistical meth- ods [ 24 ]. Our proposed method is proven to provide both full Fig.‚ÄØ7 Comparative rating distributions among the MovieLens 1¬† M (ML) source dataset, the baseline GANRS method (gan), and the pro- posed WGANRS method (wgan). The 8000-user and 1000-item syn- thetic dataset has been chosen as a representative case from the set of generated data in the paper. The closer the distribution is to the source ML distribution, the better the model is Fig.‚ÄØ8 Quality of the recom- mendation: precision and recall obtained by varying the number N of recommendations from 2 to 10. The relevancy threshold ÌúÉ was set to 5. The upper graphs show the results on the synthetic datasets containing 500 to 8000 users. The lower graphs show the results on the synthetic datasets containing 500 to 4000 items. Precision can be seen in the left graphs, whereas recall is shown in the right graphs. The MovieLens dataset was used. The higher the values are, the better the results Wasserstein GAN-based architecture to generate collaborative filtering synthetic datasets 2485 parameterization and high accuracy, in addition to a strong reduction of the mode collapse problem inherent to the GAN architectures. On the other hand, our method inherits the most positive and the most negative features of its baseline [ 30 ]. However, its accuracy and performance are very high due to the short, dense, and continuous vectors that its GAN model takes as input. Its main drawback comes from the clustering stage of the method (Fig. 4 ), which requires addi- tional execution time and involves a discretization process that increases the probability of generating duplicated sam- ples. For this reason, the Wasserstein concept has been pro- posed to alleviate the explained drawback. The results show that the proposed method adequately reduces the mode col- lapse problem, maintains the baseline advantages, reduces its disadvantages, and confirms the hypothesis of this paper. 4‚ÄÇ Conclusions The most relevant conclusion in this paper is that the Wasser- stein approach reduces the mode collapse in the GAN genera- tion of the CF fake samples compared to the state-of-the-art methods. This positive effect is reflected in a relevant reduction in duplicated samples and consequently in the generation of larger synthetic datasets. Furthermore, the proposed approach returns very improved distributions of ratings, which facilitates obtaining correct values and trends in recommendation qual- ity measures. Finally, the distributions of the users and items are comparable to those of the state-of-the-art methods; these distributions act as quality measures due to the lack of stand- ard quality measures for RS generated data. Moreover, exist- ing hyperparameters are avoided in the proposed method. The standard deviation of the Gaussian distribution is used to create the noisy vectors that feed the generator model in the GAN. Overall, the results of the experiment show that by applying the Wasserstein distance and weight clipping to CF data, the generative process is improved compared to the state-of-the-art methods that use Wasserstein-based GANs. Proposed future work includes a) testing the proposed method on different RS datasets, with several sparsity ratios and different numbers of users or items, b) comparing the existing biases in the source datasets with the generated biases in the synthetic datasets, and c) checking the ability of the generated samples to serve as data augmentation when they are added to the source datasets. Fig.‚ÄØ9 Top graph: distribu- tion of the ratings when the number of users varies from 500 to 8000; comparative of the proposed WGANRS (wgan) method and the baseline GANRS (gan) method. Bottom graph: distribution of ratings when the number of items var- ies from 500 to 4000; compari- son of the proposed WGANRS (wgan) method and the baseline GANRS (gan) method. The source MovieLens (ML) dataset is used in both graphs J. Bobadilla, A. Guti√©rrez 2486 Appendix In this section, the same figures used for MovieLens are shown. However, in this case, the Netflix* dataset has been used as a source. Fig.‚ÄØ10 Number of samples generated using the baseline GANRS method (gan) versus the proposed WGANRS method (wgan).  Source dataset: Netflix*. Number of needed samples: 40,000. Left graph: generated datasets with 1000 items and a range of 500, 1000, 2000, 4000 and 8000 users; right graph: generated datasets with 4000 users and a range of 500, 1000, 2000 and 4000 items. The higher the num- ber of generated samples, the better the model is Fig.‚ÄØ11 Comparative rating distributions among the Netflix* source dataset, the baseline GANRS method (gan) and the proposed WGANRS method (wgan). The 8000-users and 1000-items synthetic dataset has been chosen as a representative case from the set of generated data in the paper. The closer the distribution is to the source ML distribution, the better the model is Wasserstein GAN-based architecture to generate collaborative filtering synthetic datasets 2487 Fig.‚ÄØ12 Quality of recommen- dation: precision and recall obtained by varying the number N of recommendations from 2 to 10. The relevancy threshold ÌúÉ was set to 5. The upper graphs show the results on the synthetic datasets containing 500 to 8000 users. The lower graphs show the results on the synthetic datasets containing 500 to 4000 items. Precision can be seen in the left graphs, whereas recall is shown in the right graphs. The Netflix* dataset was used. The higher the values are, the better the results Fig.‚ÄØ13 Top graph: distribu- tion of the ratings when the number of users varies from 500 to 8000. Comparison of the proposed WGANRS (wgan) method and the baseline GANRS (gan) method. Bottom graph: distribution of ratings when the number of ratings var- ies from 500 to 4000. Compari- son of the proposed WGANRS (wgan) method and the baseline GANRS (gan) method. The source Netflix* dataset is used in both graph J. Bobadilla, A. Guti√©rrez 2488 Author contributions Abraham Guti√©rrez ran most of the executions and prepared the figures and the paper format. Jes√∫s Bobadilla provided the paper concept, the model design, the experimental design, and wrote the paper. Funding Open Access funding provided thanks to the CRUE-CSIC agreement with Springer Nature. This work was partially supported by the Ministerio de Ciencia e Innovaci√≥n of Spain under the pro- ject PID2019-106493RB-I00 (DL-CEMG) and the Comunidad de Madrid under Convenio Plurianual with the Universidad Polit√©cnica de Madrid in the actuation line of Programa de Excelencia para el Profesorado Universitario. Data availability The datasets generated during and/or analysed during the current study are available in the GitHub repository, https://‚Äãgithub.‚Äã com/‚Äãjesus‚Äãbobad‚Äãilla/‚Äãganrs.‚Äãgit Declarations Ethics for obtaining the data In this paper, all the conditions specified for the use of the open datasets taken as a source for the generative process are satisfied, including the reference to the paper stated in the README file. Conflicts of interest The authors have no competing interests to de- clare that are relevant to the content of this article and agree to the publishing of its content. Open Access This article is licensed under a Creative Commons Attri- bution 4.0 International License, which permits use, sharing, adapta- tion, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article‚Äôs Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article‚Äôs Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/ . References 1.	 Shokeen J, Rana C (2020) A study on features of social recom- mender systems. Artif Intell Rev 53(2):965‚Äì988. https://‚Äãdoi.‚Äãorg/‚Äã 10.‚Äã1007/‚Äãs10462-‚Äã019-‚Äã09684-w 2.	 Bobadilla J, Guti√©rrez A, Alonso S, Gonz√°lez-Prieto A (2022) Neural Collaborative Filtering Classification Model to Obtain Prediction Reliabilities. International Journal of Interactive Mul- timedia and Artificial Intelligence 7(4):18‚Äì26. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã 9781/‚Äãijimai.‚Äã2021.‚Äã08.‚Äã010 3.	 Deldjoo Y, Schedl M, Cremonesi P, Pasi G (2020) Recommender systems leveraging multimedia content. ACM Computing Surveys (CSUR) 53(5):1‚Äì38. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã34071‚Äã90 4.	 Bobadilla J, Gonz√°lez-Prieto A, Ortega F, Lara-Cabrera R (2021) Deep learning feature selection to unhide demographic recom- mender systems factors. Neural Comput Appl 33(12):7291‚Äì7308. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1007/‚Äãs00521-‚Äã020-‚Äã05494-2 5.	 Bobadilla J, Lara-Cabrera R, Gonz√°lez-Prieto √Å, Ortega F (2021) DeepFair: Deep Learning for Improving Fairness in Recom- mender Systems. International Journal of Interactive Multimedia and Artificial Intelligence 6(6):86‚Äì94. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã9781/‚Äã ijimai.‚Äã2020.‚Äã11.‚Äã001 6.	 Kulkarni S, Rodd SF (2020) Context aware recommendation systems: A review of the state of the art techniques. Computer Science Review 37:100255. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1016/j.‚Äãcosrev.‚Äã2020.‚Äã 100255 7.	 Wang Z (2023) Intelligent recommendation model of tourist places based on collaborative filtering and user preferences. Appl Artif Intell 37(1):2203574. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1080/‚Äã08839‚Äã514.‚Äã 2023.‚Äã22035‚Äã74 8.	 Ray B, Garain A, Sarkar R (2021) An ensemble-based hotel rec- ommender system using sentiment analysis and aspect categoriza- tion of hotel reviews. Applied Soft Computing 98:106935. https://‚Äã doi.‚Äãorg/‚Äã10.‚Äã1016/j.‚Äãasoc.‚Äã2020.‚Äã106935 9.	 Kabul MS, Setiawan EB (2022) Recommender System with User-Based and Item-Based Collaborative Filtering on Twitter using K-Nearest Neighbors Classification. Journal of Computer System and Informat- ics 3:478‚Äì484. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã47065/‚Äãjosyc.‚Äãv3i4.‚Äã2204 10.	 Eslami G, Ghaderi F (2023) Incremental trust-aware matrix factor- ization for recommender systems: towards Green AI. Appl Intell 53:12599‚Äì12612. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1007/‚Äãs10489-‚Äã022-‚Äã04150-7 11.	 Mehdi HA (2022) A novel constrained non-negative matrix fac- torization method based on users and items pairwise relationship for recommender systems. Expert Syst Appl 195:116593. https://‚Äã doi.‚Äãorg/‚Äã10.‚Äã1016/j.‚Äãeswa.‚Äã2022.‚Äã116593 12.	 Gheorghe P, P√©rez-Jim√©nez M, Grzegorz R (2023) Infinite Spike Trains in Spiking Neural P Systems. Romanian Journal of Infor- mation Science and Technology 2023:251‚Äì275. https://‚Äãdoi.‚Äãorg/‚Äã 10.‚Äã59277/‚ÄãROMJI‚ÄãST.‚Äã2023.3-‚Äã4.‚Äã01 13.	 Liu H, Zheng C, Li D, Shen X, Lin K, Wang J, Zhang Z, Zhang Z, Xiong N (2021) EDMF: Efficient Deep Matrix Factorization With Review Feature Learning for Industrial Recommender System. IEEE Trans Industr Inf 18(7):4361‚Äì4371. https://‚Äãdoi.‚Äã org/‚Äã10.‚Äã1109/‚ÄãTII.‚Äã2021.‚Äã31282‚Äã40 14.	 Bobadilla J, Ortega F, Guti√©rrez A, Gonz√°lez-Prieto √Å (2022) Deep variational models for collaborative filtering-based recom- mender systems. Neural Comput Appl 35:7817‚Äì7831. https://‚Äã doi.‚Äãorg/‚Äã10.‚Äã1007/‚Äãs00521-‚Äã022-‚Äã08088-2 15.	 Hai C, Fulan Q, Jie C, Shu Z, Yanping Z (2021) Attribute-based Neural Collaborative Filtering. Expert Syst Appl 185:115539. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1016/j.‚Äãeswa.‚Äã2021.‚Äã115539 16.	 Min G, Junwei Z, Junliang Y, Jundong L, Junhao W, Qingyu X (2021) Recommender systems based on generative adversarial networks: A problem-driven perspective. Inf Sci 546:1166‚Äì 1185. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1016/j.‚Äãins.‚Äã2020.‚Äã09.‚Äã013 17.	 Forouzandeh S, Berahmand K, Rostami M (2021) Presentation of a recommender system with ensemble learning and graph embed- ding: a case on MovieLens. Multimedia tools and applications 80(5):7805‚Äì7832. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1007/‚Äãs11042-‚Äã020-‚Äã09949-5 18.	 Kumar A, Aggarwal RK (2022) An exploration of semi- supervised and language-adversarial transfer learning using hybrid acoustic model for hindi speech recognition. J Reli- able Intell Environ 8:117‚Äì132. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1007/‚Äã s40860-‚Äã021-‚Äã00140-7 19.	 Deldjoo Y, Noia DT, Merra FA (2021) Survey on Adversarial Recommender Systems: From Attack/Defense Strategies to Gen- erative Adversarial Networks. ACM Comput Surv 54(2):1‚Äì38. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã34397‚Äã29 20.	 Chae DK, Kang JS, Kim SW, Lee JT (2018) CFGAN: a generic collaborative filtering framework based on generative adversarial networks. In: Proceedings of the 27th, ACM International Con- ference on Information and Knowledge Management, CIKM 2018. Association for Computing Machinery, New York, NY, pp 137‚Äì146. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã32692‚Äã06.‚Äã32717‚Äã43 21.	 Guo G, Zhou H, Chen B et¬†al (2022) IPGAN: Generating informa- tive item pairs by adversarial sampling. IEEE Transactions on Wasserstein GAN-based architecture to generate collaborative filtering synthetic datasets 2489 Neural Networks and Learning Systems 33(2):694‚Äì706. https://‚Äã doi.‚Äãorg/‚Äã10.‚Äã1109/‚ÄãTNNLS.‚Äã2020.‚Äã30285‚Äã72 22.	 Zhao J, Li H, Qu L, Zhang Q, Sun Q, Huo H, Gong M (2022) DCF- GAN: An adversarial deep reinforcement learning framework with improved negative sampling for session-based recommender systems. Inf Sci 596:222‚Äì235. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1016/j.‚Äãins.‚Äã2022.‚Äã02.‚Äã045 23.	 Sun J, Liu B, Ren H, Huang W (2022) WNCGAN: A neural adver- sarial collaborative filtering for recommender system. Journal of intelligent & fuzzy systems 42(4):2915‚Äì2923. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã 3233/‚Äãjifs-‚Äã210123 24.	 Bharadhwaj H, Park H, Lim BY (2018) RecGAN: recurrent gen- erative adversarial networks for recommendation systems. In: Pro- ceedings of the 12th ACM Conference on Recommender Systems, RecSys september 2019. Association for Computing Machinery, New York, NY, pp 372‚Äì376. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã32403‚Äã23.‚Äã 32403‚Äã83 25.	 Shafqat W, Byun YC (2022) A Hybrid GAN-Based Approach to Solve Imbalanced Data Problem in Recommendation Systems. IEEE access 10:11036‚Äì11047. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1109/‚ÄãACCESS.‚Äã 2022.‚Äã31417‚Äã76 26.	 Wen J, Zhu XR, Wang CD, Tian Z (2022) A framework for per- sonalized recommendation with conditional generative adversarial networks. Knowl Inf Syst 64(10):2637‚Äì2660. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã 1007/‚Äãs10115-‚Äã022-‚Äã01719-z 27.	 Wang Q, Huang Q, Ma K, Zhang X (2021) A Recommender System Based on Model Regularization Wasserstein Generative Adversarial Network. Inf Sci 546:1166‚Äì1185. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã 1016/j.‚Äãins.‚Äã2020.‚Äã09.‚Äã013 28.	 Zhang X, Zhong J, Liu K (2021) Wasserstein autoencoders for collaborative filtering. Neural Comput Appl 33(7):2793‚Äì2802. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1007/‚Äãs00521-‚Äã020-‚Äã05117-w 29.	 Schlett T, Rathgeb C, Henniger O, Galbally J, Fierrez J, Busch C (2022) Face Image Quality Assessment: A Literature Survey. ACM Comput Surv 54(10):1‚Äì49. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã35079‚Äã01 30.	 Bobadilla J, Guti√©rrez A, Yera R, Mart√≠nez L (2023) Creating Syn- thetic Datasets for Collaborative Filtering Recommender Systems using Generative Adversarial Networks. Knowledge Based Systems 280(1):111016. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1016/j.‚Äãknosys.‚Äã2023.‚Äã111016 31.	 Ioan-Daniel B, Radu-Emil P, Alexandra-Bianca B (2022) Improvement of K-means Cluster Quality by Post Processing Resulted Clusters. Procedia Computer Science 199:63‚Äì70. https://‚Äã doi.‚Äãorg/‚Äã10.‚Äã1016/j.‚Äãprocs.‚Äã2022.‚Äã01.‚Äã009 32.	 Ortega F, Mayor J, L√≥pez-Fern√°ndez D, Lara-Cabrera R (2021) CF4J 2.0: adapting collaborative filtering for java to new chal- lenges of collaborative filtering based recommender sys- tems.¬†Knowledge-Based Syst 215(4):106629. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã 1016/j.‚Äãknosys.‚Äã2020.‚Äã106629 33.	 Gong Y (2023) Distribution constraining for combating mode collapse in generative adversarial networks. J Electron Imaging 32(4):43029‚Äì43030. https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1117/1.‚ÄãJEI.‚Äã32.4.‚Äã043029 Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Jes√∫s Bobadilla received the B.S. and the Ph.D. degrees in computer science from the Uni- versidad Polit√©cnica de Madrid and the Universidad Carlos III. Currently, he is a full professor with the Department of Informa- tion Systems, Universidad Poli- t√©cnica de Madrid. He is a habit- ual author of programming languages books working with McGraw- Hill, Ra-Ma and Alfa Omega publishers. His research interests include information retrieval, recommender systems and speech processing. He over- sees the FilmAffinity.com research team working on the collaborative filtering kernel of the web site. He has been a researcher into the Inter- national Computer Science Institute at Berkeley University and into the Sheffield University. Abraham Guti√©rrez received the B.S. and the Ph.D. degrees in computer science from the Uni- versidad Polit√©cnica de Madrid. Currently, he is currently an associate professor with the Department of Information Sys- tems, Universidad Polit√©cnica de Madrid. He is the author of research papers in most prestig- ious international journals. He is a habitual author of program- ming languages books working with McGraw-Hill, Ra-Ma and Alfa Omega publishers. His research interests include P-Sys- tems, machine learning, data analysis and artificial intelligence. He is in charge of this group innovation issues, including the commercial projects. J. Bobadilla, A. Guti√©rrez 2490",httpsdoiorgs wasserstein ganbased architecture generate collaborative filtering synthetic datasets jes√∫s bobadilla abraham guti√©rrez accepted february author currently generative application reshaping different field art computer vision speech processing natural language computer science personalization area increasingly relevant since large company spotify netflix tripadvisor amazon google use recommender system rational expect generative learning increasingly used improve current recommender system proposed generate synthetic recommender datasets used test recommendation performance accuracy company dif ferent simulated scenario large increase dataset size number user number item specifically improvement stateoftheart proposed applying wasserstein concept generative adversarial network recommender system ganrs seminal generate synthetic datasets result show pro posed reduces mode collapse increase size synthetic datasets improves rating distribution maintains potential choose desired number user number item starting size dataset baseline ganrs proposed wassersteinbased wganrs deep learning architecture generate fake profile dense short continuous embeddings latent space instead sparse large discrete raw sample previ ous gan model used source enable reproducibility python kera code provided open repository along synthetic datasets generated test proposed architecture httpsgithubcomjesusbobadillaganrsgit keywords wganrs generative adversarial network recommender system wasserstein distance synthetic datasets collaborative filtering recommender system rss used provide personali zation facility user internet service large compa ny use rss spotify tripadvisor netflix google music etc rss becoming increasingly important due capacity provide accurate recommendation recommendation designed retain people service recommendation provided suggesting product service higher probability liked user consequently necessary filter available item product service r reason rss usually classified according filtering social contentbased demographic contextaware collaborative filtering cf ensemble commonly used strategy social filtering recommends active user item followed group friend contact etc like contentbased recommendation include item similar content active user liked usual compare description even item image demographic filtering selects user demographic feature active user similar age sex zip code near zip code etc extract item preference contextaware filtering usually relies geographic gps coordinate accurate relevant filtering strategy jes√∫s bobadilla jesusbobadillaupmes abraham guti√©rrez abrahamgutierrezupmes universidad polit√©cnica de etsisi ctra de valencia km spain technical university etsisi ctra de valencia km spain published online february applied intelligence collaborative strategy strategy recommendation preference similar user machine learning best fit cf concept knearest neighbour knn simple directly implement cf concept neigh bours similar user active user main drawback knn memorybased run slowly sufficiently accurate modelbased matrix factorization mf solves knn limitation moreover contains two vector hidden factor first vector used code compress relevant user whereas second vec tor used code relevant item vector belong latent space com bined dot product additionally hidden factor optimized minimizing prediction error non negative matrix factorization nmf ensures hidden factor nonnegative enable semantic interpretation prediction deep learning currently implemented obtain improved mf result simplest deep learn ing architecture similar mf hidden factor user replaced neural user embedding analogously hidden factor item replaced neural item embedding called deep matrix factorization deepmf better mf due ability neural network remove complex nonlinear pattern raw deepmf combine embeddings dot layer improved deepmf variational deep matrix factorization vdeepmf intermediate layer code parameter chosen distribution usually gaussian stochasticbased sampling process spread sample latent space deepmf vdeepmf dot layer improved replacing multilayer perceptron mlp combine hidden factor user item embeddings generates manifold called neural collaborative filtering ncf proposed architecture combine deepmf wasserstein generative adversarial network gan gan network generate fake sample fol lowing distribution source set real sample common use gan network generate realistic fake face dataset real human face similarly objective generate synthetic fake cf sample existing dataset cf sample movielens collecting many fake sample synthetic cf dataset created generating synthetic cf datasets make possible simulate stress situation r gener ated family datasets gradually parameter selected example gener ate family cf datasets number user grows several thousand million test advance performance different scenario number user gradually sud denly grows eg due marketing campaign influ encer action simulation avoid failure extreme situation similarly family datasets generated growing number item lead sparse scenario r accuracy could decrease type simulation give u conveni ence incorporating many product service short period time additionally generation synthetic datasets make possible researcher test machine learning model bounded scenario difficult find real datasets increasingly sparse matrix different cold start situation extreme pattern variation user profile stateoftheart method cf generation include statistical method able adequately determine pattern complex datasets therefore adversarial approach ganbased approach proposed preventing shilling attack relevant objective r field ganbased approach act defence augmentation obvi ous field gans applied purchase profile used collaborative filtering generative adversarial net work cfgan increase number training sample dataset commercial product identitypreservation generative adversarial network ipgan incorporates negative sampling improve accuracy result allows two separate generative model incorporated one managing posi tive processing negative sample session used deep collaborative filter ing generative adversarial network dcfgan instead matrix vote combining gan reinforce ment learning run recommendation training neural collaborative generative adversarial network ncgan incorporates regular gan process intermediate cf result provided neural network stage recurrent generative adversarial network recgan combine recurrent neural network rnn gan process temporal pattern unbalanced datasets managed wasserstein gan acting generator packing generative adversarial network pacgan discriminator finally conditional generative adversarial network cgan performs conditional generation rating r stateoftheart generates synthetic cf datasets divided statistical machine learning approach solution first group allow u param eterize result change number item user etc adequately capture complex non linear relation user item consequently accuracy poor second group make wasserstein ganbased architecture generate collaborative filtering synthetic datasets use deep learning generative adversarial network cre ate fake profile fake sample accuracy improved gan architecture group take discrete heavily sparse cf datasets source leading result obtained slowly subjecttomode collapse prob lem addition number item changed nevertheless existing generative adversarial network recommender system ganrs make gan generation start dense continuous latent space embeddings obtaining accurate result enabling u choose number user number item synthetic datasets proposed borrows ganrs architecture making necessary change introduce wasserstein concept wasserstein generative adversarial network wgans designed reduce inherent mode collapse gan architecture regularization wasserstein generative adver sarial network mrwgan r implemented moreover autoencoder used implement genus tive modelwasserstein regularized distance used function loss achieves better accuracy missing stateoftheart method analogously l regularized wasserstein loss function used autoencoderbased cf learn lowrank repre sentation variable latent space wasserstein distance also implemented tackle coldstart issue cf minimizing user embedding constraint gan approach also drawback particu larly long training time b long inference time gan deep c difficulty set relevant cf parameter number item number user dataset possibility suffering mode collapse behaviour e difficulty adequately learn sparse set cf e lack fine tuning variation result successive execution standard machine learning quality measure defined compare synthetic datasets created gener ated different statistical generative model model designed catch complex nonlinear pattern source simple comparations able discriminate quality gen erated result regression mae msd etc classification accuracy precision recall etc better understand drawback analyse face image quality assessment strategy character fidelity utility feature facial biometrics r field type make similar process since generating user item vector profile addition face image quality make distinction approach require reference reduced reference reference face two first case accurate quality measure pre cisely situation r manage equivalent reference face image quality field finally conceptual problem quality para dox inherent quality measure heavily present r scenario generated dataset similar source otherwise would useful different source otherwise would representative therefore research paper generate synthetic datasets test run ning several cf machine learning model comparing result obtained different instance generated datasets source strategy follows result section seminal ganrs relevant innovation incorporated previous r gan architecture compared generate synthetic datasets however signifi cant drawback occurs process convert latent space generated sample dense small continuous raw sample sparse large discrete form synthetic dataset generates duplicated sample must removed common drawback discretization task number duplicated sample high col lapse gan generation occur innovation proposed wasserstein gan wganrs wasserstein design function loss weight constraint etc existing ganrs hope mode collapse situation reduced proposed borrows stage defined replaces regular gan generation kernel wasserstein wgan wgan provides four relevant improvement incorporates new loss function interpretable clear stopping criterion empirically return better result gan mode collapse significantly reduced provides clear theoretical backing wgan loss function earth mover distance incorporates f w function act discrimina tor called critic critic estimate earth mover distance processing highest difference generated distribution real distribution sev eral parameterizations f w function critic make generator work harder looking different projec tions relevant predictor measure mode collapse mitigation reduce removed sample consequently increase number sample syn thetic file size also test quality measure precision recall distribution rating user item show innovation proposed com pared sota particularly currently published baseline ganrs shown top fig sota method generate cf datasets take raw profile generate synthetic r datasets analogous process fake face creation generated gans datasets real face known j bobadilla guti√©rrez recurrent problem process mode collapse lead lack balanced generation sample category overrepresented whereas category underrepresented example could obtain enor mous quantity fake sample number modi fied national institute standard technology mnist dataset however number rarely generated notably fig sota method gan module fed raw image pixel user pro file raw large discrete sparse leading mode collapse problem current research area ganrs baseline highlevel architecture shown fig b gan fed raw instead fed deep learning embedded embedded short continuous dense vector embedded contain compressed item user r performance accuracy ganrs improved compared previous sota model method ganrs baseline mode collapse problem reduced r datasets generated less biased created sota method regardless mode collapse remains produce certain degree redundant sample reduce mode collapse even proposed wganrs introduces wasserstein concept gan kernel fig c wasserstein shown yield better result reducing mode collapse applied gans requires new loss function benefit theoretical backing defined stopping criterion hypothesis claim incorporating wasserstein concept generative kernel ganrs lead decrease mode collapse problem inherent gan applied cf scenario consequently proposed wganrs expected gener ate accurate cf datasets structure follows section proposed wganrs existing ganrs infor mation explained formalized section design experimental execution code introduced result shown analysed movielens net flix datasets source moreover relevant result provided section remarkable conclusion presented future work proposed additionally reference section includes current representative paper main r area specific gan generation cf datasets section divided two subsection first subsection proposed concept architecture sequence process stage train generate synthetic datasets feedforward prediction explained second subsection contains necessary equation formalize grouped main stage architecture python kera code proposed available httpsgithub comjesusbobadillaganrsgit concept architecture proposed deep learning architecture five sequential stage neural cf wgan clustering process involved moreover cf dataset used source synthetic dataset format source dataset similar distribution generated key issue involving ganrs seminal baseline wganrs proposed architecture gan wgan stage fed dense short continuous embeddings latent space instead sparse large discrete raw make work generator discriminator model easier faster accurate obvious drawback proposed design theoretical loss quality involved com pression stage coder particularly subsequent decompression decoder however converting embedded raw sample significant benefit emerges choose target number user item mak ing ganrs wganrs model flexible useful stateoftheart method show overview proposed wganrs architecture existing source dataset mostleft side fig movielens synthetic dataset mostright side fig generated format useful researcher similar pattern distribution user item rating dataset generated choosing desired number user item starting number sam ples useful company researcher base simulation anticipating diverse future scenario ground new machine learning model proposed wganrs first convert compress input sparse dataset embeddingbased representation convert decompresses generated fake embed dingbased dataset raw sparse representation deepmf left side fig chosen perform compression stage due simplicity performance k mean clustering right side fig used run necessary decompression scenario k mean advantage setting k number user k number item want generated dataset hold finally architecture kernel wgan centre fig generate fake embedding sample real embedding sample deepmf used compression task previous learning stage topleft draw fig wasserstein ganbased architecture generate collaborative filtering synthetic datasets embedding weight set mean backpropagation optimization deepmf contains two separate embedding layer one layer user layer item embeddings must size usually range neuron expected similar user coded similar embedding map code applies item deepmf trained feedforward existing user id obtain embedding representation topright draw fig process performed existing item id thus obtain matrix x e containing embedding representation item number item source dataset e embed ding size analogously obtain matrix u x e containing embedding representation user u number user source dataset combining source dataset left side fig compressed item matrix compressed user matrix top right draw fig obtain embedding rep resentation source dataset shown embed dingbased cf dataset bottom left graph fig fig starting embeddingbased cf dataset source proposed wganrs architecture generates fake embeddingbased cf dataset centre fig performed mean wasserstein gan first stage generative task wgan training bottomleft fig generator creates synthetic sample gaussian stochastic vector containing random noise wasserstein critic discriminator performs necessary binary classification label sample real fake notably fake sample come generator whereas real sample randomly taken previously generated real embeddingbased cf set training process finished forget critic take generator create many fake embedding sample needed whole pro cess training feedforward generation expected fast due compressed embedding representation accurate due wasserstein restriction avoid mode collapse last stage proposed architecture neces sary decompress fake embeddingbased cf dataset right side fig bottom right draw fig stage generated large number fake sample consisting tuples user_embeddingitem_ embeddingrating user item embeddings produce vector real number convert set tuples discretized version user_ iditem_idrating user_ids integer range number user analogously item_ids integer range number item neural network trained user embedding assigns simi lar code similar user embedding layer inherent property embedding layer make possible incorporate clustering process proposed fig innovation proposed expected impact solving gan mode collapse show traditional gan cf context fig b show improvement introduced baseline adequately process sparse fig c detail proposed wasserstein ker nel reduce mode collapse problem j bobadilla guti√©rrez charge grouping similar user item desired number user item synthetic dataset discretization process wganrs designed set desired number user item generated dataset implement kmeans clustering performed since allows u set k number user k number item show follow ing concept kmeans used cluster k user whereas another kmeans process used cluster k item since similar user similar embeddings expected grouped cluster analogously item user number generated dataset corre sponds cluster number kmeans fake user embedding grouped example leftmost fake embeddingbased cf dataset left side fig grouped user green colour k group item blue colour group consequently generated fake synthetic dataset k rating example rating first source dataset left side fig finally due discretization process duplicated sam ples found happens two different generated sample share user id item id chosen number user item high diffi cult find duplicated sample since wider variety cluster expected user item assigned group balanced way duplicated sample managed simply removing spare sample expected balance clustering group could broken mode collapse happening gan indeed serstein concept used avoid mode collapse number removed sample used quality measure result section lower removed sample better since two hyperparameters proposed number user number item cluster ing better fit kmeans directly set k number user k number item fact one unusual situation k known clustering process thus relevant clustering method hierarchical distribution density fuzzybased one adequate scenario following subsection wganrs malized moreover equation provided formalization cf definition first define main set r set user u item range rating v existing sample let u set user make use cf r let set item available vote cf r let v range allowed vote v let set sample contained cf dataset n total number cast vote u v u v u v n u u v v fig overview proposed wganrs architecture wasserstein ganbased architecture generate collaborative filtering synthetic datasets formalization defined cf dataset consists set tuples userid itemid rating number star rating vote assigned userid itemid deepmf training deep mf training top left graph conducted create embed user id item id two embeddings feed wganrs generative stage embedding compressed representation user item embeddings unidimensional vector size e define f eu u function compress user u analogously f ei function compress item let e size two neural layer embeddings used vectorize user item belonging u respectively let f eu u e u e u e u e u e f eu embedding layer output user u u let f ei e e e e e f ei embedding layer output item fig deepmf wgan model involved wganrs architecture relevant equation back propaga tion defined set output error mean squared difference metric equation distinctive proposed deepmf feedforward deepmf learned collect embedding representation user item cf r therefore existing itemid userid r combining dense vector user item embeddings e u e u e u e u e e e e e e make rating prediction deepmf training stage dot product user embedding item embedding u v j provides rating prediction j f eu u f ei e iu e e u e u e u e e e e e j j output error used deepmf neural network start back propagation neural weight iteratively improved Ìõø j value Œ¥ w ji Ìõº j f net k w ik Ìõø k k hidden layer Œ¥ w ji Ìõº j f net k k k output layer j k successive sequential layer j bobadilla guti√©rrez dataset feed trained deepmf embed ded representation obtained done making feedforward prediction operation topright graph trained deepmf let e u e u e u e u e u e u u set embeddings r user let e u e u e u e u e u e let e e u e u e u e u e e e e e e set embeddings r item let e e e e e e setting dataset embeddings collect embedding representation itemid userid r translate set set r set r embeddingbased dataset version original raw dataset let r e u e v u v j embedding dataset real sample wgan training core concept gan methodology jointly train generator discriminator architecture trained generator creates new sample follow distribution training sample discriminator attempt differentiate real sample generated one minmax optimization problem form min g max Ìîº x p log x Ìîº z p latent log g z w h e r e g z x generator map latent space z input space x x ‚Ñù dis criminator map input space x clas sification realfake ‚Ñù ‚Ñù concave function formula optimization function expression network generator discriminator try optimize g aim minimize whereas want maximize bottomleft graph fig show generative learning gan architecture consists discriminator classifier generator generator creates fake sample r profile whereas discriminator try detect fake sample generative adversarial training discriminator progressively learns accurately differentiate fake profile real profile time generator learns make fake sam ples difficult distinguish real profile call f discriminator f g generator fig clustering stage wganrs architecture wasserstein ganbased architecture generate collaborative filtering synthetic datasets f f g iteratively learn improve minimizing loss function f gd f gd min g max f g e r f w r e z f w g z e r expected real sample z random noise feed generator g e z expected generated fake profile gz f w wasserstein function earth mover distance function satisfies lipschitz constraint f x f x x x x x r refers let f discriminator belonging gan let f g generator g belonging gan let f gd cost function gan notably wasserstein concept introduced eq mainly implemented loss function code generative wasserstein designed reduce mode collapse problem inherent gan implement reduce mode collapse wganrs proposed consequently reduce number excessively generated similar profile r wgan generation gan trained generate many sample needed introduce batch random gaussian noise vector z implement feedforward process modelpredict batch fake embedded prof le bottomright graph let f f g generated dataset fake sample different random noise vector z clustering item user show clustering process set k number user generated dataset k number item n gen erated fake profile contain fake user embed ding fake item embeddings n k n k let k number cluster used group embeddings user let k number cluster used group embeddings item generated fake user user n must select nearest user k existing user h u function make group process used item generated fake item one n must select nearest item k existing item h function make group let h u c c k clustering operation assigns centroid user let h c c k clustering operation assigns centroid item setting dataset item id user id create synthetic dataset generated set embed ding f converted discretized version h let h item id user id discrete dataset obtained embeddingbased dataset f fake sample sometimes different generated sample set f discretized user item h u h v h u h v h h u h v e u e v f particularly happens gan suffers mode collapse case sample identical create set h duplicated sam ples removed let h synthetic generated dataset version h duplicated sample removed last transformation remove sample fake user cast different vote v v item let g h u h v h h u h v h h u h u h h v v j bobadilla guti√©rrez result proposed tested two opensource representative cf datasets movielens httpsgrouplens orgdatasetsmovielensm subset netflix call netflix two datasets chosen representative cf field movielens probably tested dataset family year cf research result obtained movielens informative r researcher hand netflix widely used due enor mous size longer available utilized open version netflix randomly shortened net flix selected dataset research internal pattern different movielens movielens created relatively short time academic environment whereas netflix enormous com mercial dataset growing long period since research involves catching internal pattern source dataset parameterizing translating pattern generated dataset convenient use different source show main parameter value result datasets follow trend therefore ensure length appropriate explain mov ielens result group netflix result fig appendix test wganrs two set synthetic datasets created first set varied number user whereas second set varied number item row show value set first row indicates five synthetic datasets generated first dataset contains user item second dataset hold user item last dataset user item generated datasets created starting thousand sample set allows u test impact changing number user analogously second row show four synthetic datasets created four datasets user however number item varies first dataset last set allows u measure impact changing number item since use ganrs baseline datasets also created ganrs thirtysix datasets generated movielens source netflix ganrs wganrs test datasets four different exections conducted number generated sample number sample returned ganrs wganrs compared wganrs expected perform better focus particularly avoiding typical mode collapse gans better managed mode col lapse varied embedding sample wganrs generates better performance clustering process create raw sample finally lesser number collision increasing size synthetic datasets rating distribution important rating distri bution generated datasets similar possible source particularly relevant rating usually star indication pat tern fake profile correct contain adequate proportion relevant nonrelevant vote user item distribution interesting test user item distribution number user item var y comparing source dataset expected gaussian random noise used create stochastic vector feed wganrs generator force dif ferent gaussian distribution user item precision recall regarding ground distribution balanced vote high number sample gen erated datasets used adequately analyse cf task recommendation quality measure return suitable value trend execution cover potential comparative avail able generative creation synthetic datasets cf area show concept top graph show traditional cf different stateoftheart method model applied one several existing cf datasets recommendation result measured traditional quality prediction recommendation quality metric precision recall f mean absolute error mae however field synthetic cf dataset generation com pletely different source dataset fig b create one several synthetic datasets set different number user item sample etc generated dataset hold compare proposed generative selected stateoftheart baseline must create synthetic dataset group synthetic datasets proposed orange datasets fig b different dataset group datasets sota baseline blue datasets fig b need determine datasets group bet ter comparing generated datasets fig b different task comparing method model applied existing dataset fig b show three type code execution perform decide whether generated datasets proposed orange datasets better generated datasets baseline blue datasets main parameter value tested datasets dataset user item rating score sparsity movielens netflix wasserstein ganbased architecture generate collaborative filtering synthetic datasets mode collapse impact measured cf field removing similar user profile gan collapse reduced number source profile higher number deleted profile higher mode collapse impact higher deleted profile lower number sample generated dataset b show comparison axis represents number sample proposed orange colour improves sota baseline generated datasets probability distribu tions similar source dataset user item rating distribution synthetic set compared b show distribu tion rating source dataset green colour compared baseline dataset orange colour graph proposed dataset blue colour notably synthetic datasets expected distribution source dataset genus tive process create similar datasets identical datasets identical datasets rep licating real face valuable field computer vision therefore absolute metric measure type quality extreme distribution similarity large distribution difference must avoided quality generated datasets indirectly meas ured running stateoftheart cf method model expect similar behaviour obtained apply method source dataset different trend absolute value generated dataset graph compared source dataset tell u generated dataset contain main pattern source dataset b show precision recall result source dataset left graph generated dataset right graph measured several sota cf deep learning model trend value similar explained expect identical behaviour value since synthetic datasets mimic source pat tern copy reason standard quality measure compare graph fig b taking account consideration several experiment performed three explained approach shown b b b fig individual execution explained result structured subsects followed discussion subsection number generated sample explained previous section proposed us wgan generate synthetic embedding sample dense continuous sample converted sparse discrete version mean clustering process translation raw tuples synthetic dataset discretization stage cause proportion collision identical similar generated sample must removed smaller number sample removed accu rate generative richer synthetic dataset wasserstein gan expected improve result designed prevent mode collapse inherent gan model please note hypothesis reducing mode collapse variability generated embedded sample increase clustering process able spread user item id homogeneous way consequently number discretized sample repeated deleted decrease overall total size generated datasets increase gan mode collapse reduced wasserstein final number sample generated relevant qual ity measure since directly related impact mode collapse generative process baseline ganrs suffers mode collapse problem leading generation repeated fake profile han dle situation removing spare profile provide necessary diversity sample proposed wganrs expected improve result due wasserstein ability reduce mode collapse improve diversity increase synthetic dataset size show comparison ganrs gan versus wganrs wgan synthetic datasets number user varies left graph synthetic datasets number item varies right graph overall proposed wgan significantly improves base line gan specifically duplicate number gener ated sample improvement left graph improvement right graph achieved relevant predictor superiority proposed additionally expected higher number user item higher number generated sam ples clustering process better spread sample latent space number centroid increase number duplicated sample decrease result show relevant improvement pro posed applied compared baseline con firm hypothesis fulfilled moreover incor porating wasserstein concept generative kernel ganrs lead decrease mode collapse problem inherent gan applied cf scenario generated datasets less redundant profile accordingly diverse contain parameter value initial sample user item j bobadilla guti√©rrez sample overall proposed wganrs generates richer unbiased longer synthetic datasets rating distribution distribution rating one star two star five star important quality measure cf synthetic dataset generation process recommendation model sensitive relevant versus nonrelevant thresh old usually set four five star cf datasets containing five possible rating enough gaussian distribution rating generated dataset similar mean gaussian distribution source dataset also necessary standard deviation analogous show proposed wganrs generates gaussian distribution similar mov ielens distribution baseline ganrs specifically achieves improvement improvement aver age obtained synthetic datasets first row number user varies net flix whereas second row number item varies return improvement average netflix expected positive result contribute providing adequate recommendation quality result next subsection beyond numeric improvement value shown compare shape probability distribution fig probability distribution source movielens dataset greencolour bar target proposed wganrs bluecolour bar much closer target baseline ganrs orangecolour bar reason relevant numerical improvement shown paragraph additionally baseline generates gaussian distribution excessively centred average rating three star whereas proposed adequately fit gaussian distribution correct fourstar mean regard ing gaussian standard deviation baseline adequately catch source dataset shape deviation smaller consequently generate enough profile distribution edge one star five star contrast proposed performs nearly perfectly edge source distribution thus sample generated proposed wganrs diverse unbiased obtained running sota baseline additionally obtained better follows gaussian distribution describes source shape rating reinforces fig traditional cf validation method model versus validation synthetic datasets generated gan wasserstein ganbased architecture generate collaborative filtering synthetic datasets complement obtained sect overall proposed reduces repeated sample b generates sam ples c increase diversity decrease bias e better mimic probability distribution rating precision recall subsection show recommendation quality result obtained synthetic datasets obtained mov ielens source wganrs used experiment generate synthetic datasets stateof theart ncf neural collaborative filtering deep learning used make prediction recommenda tions relevancy ÌúÉ threshold set five top graph fig show result number user varies whereas bottom graph show result number item varies value trend obtained synthetic datasets coloured curve similar com patible source datasets black curve indi cates proposed generates suitable synthetic datasets used r field additionally expected higher number user higher recall since user profile contain fewer relevant rating recall denominator conversely higher number user lower precision since denominator con stant n number recommendation whereas numerator contains true positive relevant rating high number user involves less relevant rating per user additionally set synthetic datasets number user varies dataset hold user pro vides precision recall result like movielens source since movielens contains user tell u ganbased generates pattern recommendation easier source dataset consistent one reported importantly evolution recommendation curve generated datasets coloured curve follow trend exhibited source movielens black curve indicating internal pattern source set adequately captured proposed wganrs regarding result number item var y similar conclusion drawn underlying rec ommendation quality worsen absolute value compared source dataset probably occurs dis tribution item rating highly variable compared distribution user rating leading difficult pattern extraction number item holding low number rating user item distribution rating distribution tested also convenient compare user item distribution obtained proposed baseline method user item distribution synthetic datasets dependent gaussian parameter value noise vector feed generative created original serf baseline standard deviation customized tested dataset contrast proposed fixed one removed hyperparameter making easier fine tune proposed compared baseline top graph show result number user varies bottom graph show varying number item dashed line repre sent baseline result solid line show proposed approach case expected higher number user lower number rating assigned fig number sample generated baseline ganrs gan versus proposed wganrs wgan source dataset movielens number sample needed left graph generated datasets item range user right graph generated datasets user range item higher number generated sample better j bobadilla guti√©rrez user since number rating dataset fixed also observed proposed generates gaussian distribution higher standard deviation baseline heuristically tailored dataset proposed baseline method generate suitable user item distribution cf area discussion experimental result show superiority proposed wganrs compared ganrs baseline par ticularly relevant high improvement approximately number generated sample indicates proposed wasserstein effectively reduces amount mode collapse gan wganrs also effectively mimic rating distribution source dataset obtaining high improvement compared baseline making possible quality precision recall value trend compatible source dataset furthermore even standard quality meas ures exist test r generated user item distribu tions obtained proposed comparable baseline additionally proposed advantage necessary assign heuristic value standard deviation gaussian dis tribution used create noisy random vector feed generator wgan finally result netflix dataset reinforce result obtained testing movielens appendix show netflix result overall proposed improves sta tistical baseline stateoftheart generative method statistical baseline reported reach poor accuracy contrast support adequate parameterization generative baseline operate quite differently support full parameterization exceed accuracy statistical meth od proposed proven provide full fig comparative rating distribution among movielens ml source dataset baseline ganrs gan pro posed wganrs wgan user item syn thetic dataset chosen representative set generated closer distribution source ml distribution better fig quality recom mendation precision recall obtained varying number n recommendation relevancy threshold ÌúÉ set upper graph show result synthetic datasets containing user lower graph show result synthetic datasets containing item precision seen left graph whereas recall shown right graph movielens dataset used higher value better result wasserstein ganbased architecture generate collaborative filtering synthetic datasets parameterization high accuracy addition strong reduction mode collapse problem inherent gan architecture hand inherits positive negative feature baseline however accuracy performance high due short dense continuous vector gan take input main drawback come clustering stage fig requires addi tional execution time involves discretization process increase probability generating duplicated sam ples reason wasserstein concept pro posed alleviate explained drawback result show proposed adequately reduces mode col lapse problem maintains baseline advantage reduces disadvantage confirms hypothesis conclusion relevant wasser stein reduces mode collapse gan genus tion cf fake sample compared stateoftheart method positive effect reflected relevant reduction duplicated sample consequently generation larger synthetic datasets furthermore proposed return improved distribution rating facilitates obtaining correct value trend recommendation qual ity measure finally distribution user item comparable stateoftheart method distribution act quality measure due lack stand ard quality measure r generated moreover exist ing hyperparameters avoided proposed standard deviation gaussian distribution used create noisy vector feed generator gan overall result experiment show applying wasserstein distance weight clipping cf generative process improved compared stateoftheart method use wassersteinbased gans proposed future work includes testing proposed different r datasets several sparsity ratio different number user item b comparing existing bias source datasets generated bias synthetic datasets c checking ability generated sample serve augmentation added source datasets fig top graph distribu tion rating number user varies comparative proposed wganrs wgan baseline ganrs gan bottom graph distribution rating number item var y compari son proposed wganrs wgan baseline ganrs gan source movielens ml dataset used graph j bobadilla guti√©rrez appendix section figure used movielens shown however netflix dataset used source fig number sample generated baseline ganrs gan versus proposed wganrs wgan source dataset netflix number needed sample left graph generated datasets item range user right graph generated datasets user range item higher num ber generated sample better fig comparative rating distribution among netflix source dataset baseline ganrs gan proposed wganrs wgan user item synthetic dataset chosen representative set generated closer distribution source ml distribution better wasserstein ganbased architecture generate collaborative filtering synthetic datasets fig quality recommen dation precision recall obtained varying number n recommendation relevancy threshold ÌúÉ set upper graph show result synthetic datasets containing user lower graph show result synthetic datasets containing item precision seen left graph whereas recall shown right graph netflix dataset used higher value better result fig top graph distribu tion rating number user varies comparison proposed wganrs wgan baseline ganrs gan bottom graph distribution rating number rating var y compari son proposed wganrs wgan baseline ganrs gan source netflix dataset used graph j bobadilla guti√©rrez author contribution abraham guti√©rrez ran execution prepared figure format jes√∫s bobadilla provided concept design experimental design wrote funding open access funding provided thanks cruecsic agreement springer nature work partially supported ministerio de ciencia e innovaci√≥n spain pro ject pidrbi dlcemg comunidad de convenio plurianual universidad polit√©cnica de actuation line programa de excelencia para el profesorado universitario availability datasets generated andor analysed current available github repository httpsgithub comjesusbobadillaganrsgit declaration ethic obtaining condition specified use open datasets taken source generative process satisfied including reference stated readme file conflict interest author competing interest de clare relevant content article agree publishing content open access article licensed creative common attri bution international license permit use sharing adapta tion distribution reproduction medium format long give appropriate credit original author source provide link creative common licence indicate change made image third party material article included article creative common licence unless indicated otherwise credit line material material included article creative common licence intended use permitted statutory regulation exceeds permitted use need obtain permission directly copyright holder view copy licence visit httpcreativecommonsorglicensesby reference shokeen j rana c feature social recom mender system artif intell rev httpsdoiorg sw bobadilla j guti√©rrez alonso gonz√°lezprieto neural collaborative filtering classification obtain prediction reliability international journal interactive mul timedia artificial intelligence httpsdoiorg ijimai deldjoo schedl cremonesi p pasi g recommender system leveraging multimedia content acm computing survey csur httpsdoiorg bobadilla j gonz√°lezprieto ortega f laracabrera r deep learning feature selection unhide demographic recom mender system factor neural comput appl httpsdoiorgs bobadilla j laracabrera r gonz√°lezprieto √° ortega f deepfair deep learning improving fairness recom mender system international journal interactive multimedia artificial intelligence httpsdoiorg ijimai kulkarni rodd sf context aware recommendation system review state art technique computer science review httpsdoiorgjcosrev wang z intelligent recommendation tourist place collaborative filtering user preference appl artif intell httpsdoiorg ray b garain sarkar r ensemblebased hotel rec ommender sentiment aspect categoriza tion hotel review applied soft computing http doiorgjasoc kabul m setiawan eb recommender userbased itembased collaborative filtering twitter knearest neighbor classification journal computer informat ic httpsdoiorgjosycvi eslami g ghaderi f incremental trustaware matrix factor ization recommender system towards green ai appl intell httpsdoiorgs mehdi ha novel constrained nonnegative matrix fac torization user item pairwise relationship recommender system expert syst appl http doiorgjeswa gheorghe p p√©rezjim√©nez grzegorz r infinite spike train spiking neural p system romanian journal infor mation science technology httpsdoiorg romjist liu h zheng c li shen x lin k wang j zhang z zhang z xiong n edmf efficient deep matrix factorization review feature learning industrial recommender ieee trans industr inf httpsdoi orgtii bobadilla j ortega f guti√©rrez gonz√°lezprieto √° deep variational model collaborative filteringbased recom mender system neural comput appl http doiorgs hai c fulan q jie c shu z yanping z attributebased neural collaborative filtering expert syst appl httpsdoiorgjeswa min g junwei z junliang jundong l junhao w qingyu x recommender system generative adversarial network problemdriven perspective inf sci httpsdoiorgjins forouzandeh berahmand k rostami presentation recommender ensemble learning graph embed ding movielens multimedia tool application httpsdoiorgs kumar aggarwal rk exploration semi supervised languageadversarial transfer learning hybrid acoustic hindi speech recognition j reli able intell environ httpsdoiorg deldjoo noia dt merra fa survey adversarial recommender system attackdefense strategy gen erative adversarial network acm comput surv httpsdoiorg chae dk kang j kim sw lee jt cfgan generic collaborative filtering framework generative adversarial network proceeding th acm international con ference knowledge management cikm association computing machinery new york ny pp httpsdoiorg guo g zhou h chen b et al ipgan generating informa tive item pair adversarial sampling ieee transaction wasserstein ganbased architecture generate collaborative filtering synthetic datasets neural network learning system http doiorgtnnls zhao j li h qu l zhang q sun q huo h gong dcf gan adversarial deep reinforcement learning framework improved negative sampling sessionbased recommender system inf sci httpsdoiorgjins sun j liu b ren h huang w wncgan neural adver sarial collaborative filtering recommender journal intelligent fuzzy system httpsdoiorg jifs bharadhwaj h park h lim recgan recurrent gen erative adversarial network recommendation system pro ceedings th acm conference recommender system recsys september association computing machinery new york ny pp httpsdoiorg shafqat w byun yc hybrid ganbased solve imbalanced problem recommendation system ieee access httpsdoiorgaccess wen j zhu xr wang cd tian z framework per sonalized recommendation conditional generative adversarial network knowl inf syst httpsdoiorg sz wang q huang q k zhang x recommender regularization wasserstein generative adversarial network inf sci httpsdoiorg jins zhang x zhong j liu k wasserstein autoencoders collaborative filtering neural comput appl httpsdoiorgsw schlett rathgeb c henniger galbally j fierrez j busch c face image quality assessment literature survey acm comput surv httpsdoiorg bobadilla j guti√©rrez yera r mart√≠nez l creating syn thetic datasets collaborative filtering recommender system generative adversarial network knowledge system httpsdoiorgjknosys ioandaniel b raduemil p alexandrabianca b improvement kmeans cluster quality post processing resulted cluster procedia computer science http doiorgjprocs ortega f mayor j l√≥pezfern√°ndez laracabrera r cfj adapting collaborative filtering java new chal lenges collaborative filtering recommender sys tems knowledgebased syst httpsdoiorg jknosys gong distribution constraining combating mode collapse generative adversarial network j electron imaging httpsdoiorgjei publisher note springer nature remains neutral regard jurisdictional claim published map institutional affiliation jes√∫s bobadilla received b phd degree computer science uni versidad polit√©cnica de universidad carlos iii currently full professor department informa tion system universidad poli t√©cnica de habit ual author programming language book working mcgraw hill rama alfa omega publisher research interest include retrieval recommender system speech processing see filmaffinitycom research team working collaborative filtering kernel web site researcher inter national computer science institute berkeley university sheffield university abraham guti√©rrez received b phd degree computer science uni versidad polit√©cnica de currently currently associate professor department sys tems universidad polit√©cnica de author research paper prestig iou international journal habitual author program ming language book working mcgrawhill rama alfa omega publisher research interest include psys tems machine learning artificial intelligence charge group innovation issue including commercial project j bobadilla guti√©rrez,wasserstein ganbased architecture generate collaborative filtering synthetic datasets,wganrs generative adversarial network recommender system wasserstein distance synthetic,wasserstein ganbased architecture generate collaborative filtering synthetic datasets wasserstein ganbased architecture generate collaborative filtering synthetic datasets wasserstein ganbased architecture generate collaborative filtering synthetic datasets wganrs generative adversarial network recommender system wasserstein distance synthetic wganrs generative adversarial network recommender system wasserstein distance synthetic httpsdoiorgs wasserstein ganbased architecture generate collaborative filtering synthetic datasets jes√∫s bobadilla abraham guti√©rrez accepted february author currently generative application reshaping different field art computer vision speech processing natural language computer science personalization area increasingly relevant since large company spotify netflix tripadvisor amazon google use recommender system rational expect generative learning increasingly used improve current recommender system proposed generate synthetic recommender datasets used test recommendation performance accuracy company dif ferent simulated scenario large increase dataset size number user number item specifically improvement stateoftheart proposed applying wasserstein concept generative adversarial network recommender system ganrs seminal generate synthetic datasets result show pro posed reduces mode collapse increase size synthetic datasets improves rating distribution maintains potential choose desired number user number item starting size dataset baseline ganrs proposed wassersteinbased wganrs deep learning architecture generate fake profile dense short continuous embeddings latent space instead sparse large discrete raw sample previ ous gan model used source enable reproducibility python kera code provided open repository along synthetic datasets generated test proposed architecture httpsgithubcomjesusbobadillaganrsgit keywords wganrs generative adversarial network recommender system wasserstein distance synthetic datasets collaborative filtering recommender system rss used provide personali zation facility user internet service large compa ny use rss spotify tripadvisor netflix google music etc rss becoming increasingly important due capacity provide accurate recommendation recommendation designed retain people service recommendation provided suggesting product service higher probability liked user consequently necessary filter available item product service r reason rss usually classified according filtering social contentbased demographic contextaware collaborative filtering cf ensemble commonly used strategy social filtering recommends active user item followed group friend contact etc like contentbased recommendation include item similar content active user liked usual compare description even item image demographic filtering selects user demographic feature active user similar age sex zip code near zip code etc extract item preference contextaware filtering usually relies geographic gps coordinate accurate relevant filtering strategy jes√∫s bobadilla jesusbobadillaupmes abraham guti√©rrez abrahamgutierrezupmes universidad polit√©cnica de etsisi ctra de valencia km spain technical university etsisi ctra de valencia km spain published online february applied intelligence collaborative strategy strategy recommendation preference similar user machine learning best fit cf concept knearest neighbour knn simple directly implement cf concept neigh bours similar user active user main drawback knn memorybased run slowly sufficiently accurate modelbased matrix factorization mf solves knn limitation moreover contains two vector hidden factor first vector used code compress relevant user whereas second vec tor used code relevant item vector belong latent space com bined dot product additionally hidden factor optimized minimizing prediction error non negative matrix factorization nmf ensures hidden factor nonnegative enable semantic interpretation prediction deep learning currently implemented obtain improved mf result simplest deep learn ing architecture similar mf hidden factor user replaced neural user embedding analogously hidden factor item replaced neural item embedding called deep matrix factorization deepmf better mf due ability neural network remove complex nonlinear pattern raw deepmf combine embeddings dot layer improved deepmf variational deep matrix factorization vdeepmf intermediate layer code parameter chosen distribution usually gaussian stochasticbased sampling process spread sample latent space deepmf vdeepmf dot layer improved replacing multilayer perceptron mlp combine hidden factor user item embeddings generates manifold called neural collaborative filtering ncf proposed architecture combine deepmf wasserstein generative adversarial network gan gan network generate fake sample fol lowing distribution source set real sample common use gan network generate realistic fake face dataset real human face similarly objective generate synthetic fake cf sample existing dataset cf sample movielens collecting many fake sample synthetic cf dataset created generating synthetic cf datasets make possible simulate stress situation r gener ated family datasets gradually parameter selected example gener ate family cf datasets number user grows several thousand million test advance performance different scenario number user gradually sud denly grows eg due marketing campaign influ encer action simulation avoid failure extreme situation similarly family datasets generated growing number item lead sparse scenario r accuracy could decrease type simulation give u conveni ence incorporating many product service short period time additionally generation synthetic datasets make possible researcher test machine learning model bounded scenario difficult find real datasets increasingly sparse matrix different cold start situation extreme pattern variation user profile stateoftheart method cf generation include statistical method able adequately determine pattern complex datasets therefore adversarial approach ganbased approach proposed preventing shilling attack relevant objective r field ganbased approach act defence augmentation obvi ous field gans applied purchase profile used collaborative filtering generative adversarial net work cfgan increase number training sample dataset commercial product identitypreservation generative adversarial network ipgan incorporates negative sampling improve accuracy result allows two separate generative model incorporated one managing posi tive processing negative sample session used deep collaborative filter ing generative adversarial network dcfgan instead matrix vote combining gan reinforce ment learning run recommendation training neural collaborative generative adversarial network ncgan incorporates regular gan process intermediate cf result provided neural network stage recurrent generative adversarial network recgan combine recurrent neural network rnn gan process temporal pattern unbalanced datasets managed wasserstein gan acting generator packing generative adversarial network pacgan discriminator finally conditional generative adversarial network cgan performs conditional generation rating r stateoftheart generates synthetic cf datasets divided statistical machine learning approach solution first group allow u param eterize result change number item user etc adequately capture complex non linear relation user item consequently accuracy poor second group make wasserstein ganbased architecture generate collaborative filtering synthetic datasets use deep learning generative adversarial network cre ate fake profile fake sample accuracy improved gan architecture group take discrete heavily sparse cf datasets source leading result obtained slowly subjecttomode collapse prob lem addition number item changed nevertheless existing generative adversarial network recommender system ganrs make gan generation start dense continuous latent space embeddings obtaining accurate result enabling u choose number user number item synthetic datasets proposed borrows ganrs architecture making necessary change introduce wasserstein concept wasserstein generative adversarial network wgans designed reduce inherent mode collapse gan architecture regularization wasserstein generative adver sarial network mrwgan r implemented moreover autoencoder used implement genus tive modelwasserstein regularized distance used function loss achieves better accuracy missing stateoftheart method analogously l regularized wasserstein loss function used autoencoderbased cf learn lowrank repre sentation variable latent space wasserstein distance also implemented tackle coldstart issue cf minimizing user embedding constraint gan approach also drawback particu larly long training time b long inference time gan deep c difficulty set relevant cf parameter number item number user dataset possibility suffering mode collapse behaviour e difficulty adequately learn sparse set cf e lack fine tuning variation result successive execution standard machine learning quality measure defined compare synthetic datasets created gener ated different statistical generative model model designed catch complex nonlinear pattern source simple comparations able discriminate quality gen erated result regression mae msd etc classification accuracy precision recall etc better understand drawback analyse face image quality assessment strategy character fidelity utility feature facial biometrics r field type make similar process since generating user item vector profile addition face image quality make distinction approach require reference reduced reference reference face two first case accurate quality measure pre cisely situation r manage equivalent reference face image quality field finally conceptual problem quality para dox inherent quality measure heavily present r scenario generated dataset similar source otherwise would useful different source otherwise would representative therefore research paper generate synthetic datasets test run ning several cf machine learning model comparing result obtained different instance generated datasets source strategy follows result section seminal ganrs relevant innovation incorporated previous r gan architecture compared generate synthetic datasets however signifi cant drawback occurs process convert latent space generated sample dense small continuous raw sample sparse large discrete form synthetic dataset generates duplicated sample must removed common drawback discretization task number duplicated sample high col lapse gan generation occur innovation proposed wasserstein gan wganrs wasserstein design function loss weight constraint etc existing ganrs hope mode collapse situation reduced proposed borrows stage defined replaces regular gan generation kernel wasserstein wgan wgan provides four relevant improvement incorporates new loss function interpretable clear stopping criterion empirically return better result gan mode collapse significantly reduced provides clear theoretical backing wgan loss function earth mover distance incorporates f w function act discrimina tor called critic critic estimate earth mover distance processing highest difference generated distribution real distribution sev eral parameterizations f w function critic make generator work harder looking different projec tions relevant predictor measure mode collapse mitigation reduce removed sample consequently increase number sample syn thetic file size also test quality measure precision recall distribution rating user item show innovation proposed com pared sota particularly currently published baseline ganrs shown top fig sota method generate cf datasets take raw profile generate synthetic r datasets analogous process fake face creation generated gans datasets real face known j bobadilla guti√©rrez recurrent problem process mode collapse lead lack balanced generation sample category overrepresented whereas category underrepresented example could obtain enor mous quantity fake sample number modi fied national institute standard technology mnist dataset however number rarely generated notably fig sota method gan module fed raw image pixel user pro file raw large discrete sparse leading mode collapse problem current research area ganrs baseline highlevel architecture shown fig b gan fed raw instead fed deep learning embedded embedded short continuous dense vector embedded contain compressed item user r performance accuracy ganrs improved compared previous sota model method ganrs baseline mode collapse problem reduced r datasets generated less biased created sota method regardless mode collapse remains produce certain degree redundant sample reduce mode collapse even proposed wganrs introduces wasserstein concept gan kernel fig c wasserstein shown yield better result reducing mode collapse applied gans requires new loss function benefit theoretical backing defined stopping criterion hypothesis claim incorporating wasserstein concept generative kernel ganrs lead decrease mode collapse problem inherent gan applied cf scenario consequently proposed wganrs expected gener ate accurate cf datasets structure follows section proposed wganrs existing ganrs infor mation explained formalized section design experimental execution code introduced result shown analysed movielens net flix datasets source moreover relevant result provided section remarkable conclusion presented future work proposed additionally reference section includes current representative paper main r area specific gan generation cf datasets section divided two subsection first subsection proposed concept architecture sequence process stage train generate synthetic datasets feedforward prediction explained second subsection contains necessary equation formalize grouped main stage architecture python kera code proposed available httpsgithub comjesusbobadillaganrsgit concept architecture proposed deep learning architecture five sequential stage neural cf wgan clustering process involved moreover cf dataset used source synthetic dataset format source dataset similar distribution generated key issue involving ganrs seminal baseline wganrs proposed architecture gan wgan stage fed dense short continuous embeddings latent space instead sparse large discrete raw make work generator discriminator model easier faster accurate obvious drawback proposed design theoretical loss quality involved com pression stage coder particularly subsequent decompression decoder however converting embedded raw sample significant benefit emerges choose target number user item mak ing ganrs wganrs model flexible useful stateoftheart method show overview proposed wganrs architecture existing source dataset mostleft side fig movielens synthetic dataset mostright side fig generated format useful researcher similar pattern distribution user item rating dataset generated choosing desired number user item starting number sam ples useful company researcher base simulation anticipating diverse future scenario ground new machine learning model proposed wganrs first convert compress input sparse dataset embeddingbased representation convert decompresses generated fake embed dingbased dataset raw sparse representation deepmf left side fig chosen perform compression stage due simplicity performance k mean clustering right side fig used run necessary decompression scenario k mean advantage setting k number user k number item want generated dataset hold finally architecture kernel wgan centre fig generate fake embedding sample real embedding sample deepmf used compression task previous learning stage topleft draw fig wasserstein ganbased architecture generate collaborative filtering synthetic datasets embedding weight set mean backpropagation optimization deepmf contains two separate embedding layer one layer user layer item embeddings must size usually range neuron expected similar user coded similar embedding map code applies item deepmf trained feedforward existing user id obtain embedding representation topright draw fig process performed existing item id thus obtain matrix x e containing embedding representation item number item source dataset e embed ding size analogously obtain matrix u x e containing embedding representation user u number user source dataset combining source dataset left side fig compressed item matrix compressed user matrix top right draw fig obtain embedding rep resentation source dataset shown embed dingbased cf dataset bottom left graph fig fig starting embeddingbased cf dataset source proposed wganrs architecture generates fake embeddingbased cf dataset centre fig performed mean wasserstein gan first stage generative task wgan training bottomleft fig generator creates synthetic sample gaussian stochastic vector containing random noise wasserstein critic discriminator performs necessary binary classification label sample real fake notably fake sample come generator whereas real sample randomly taken previously generated real embeddingbased cf set training process finished forget critic take generator create many fake embedding sample needed whole pro cess training feedforward generation expected fast due compressed embedding representation accurate due wasserstein restriction avoid mode collapse last stage proposed architecture neces sary decompress fake embeddingbased cf dataset right side fig bottom right draw fig stage generated large number fake sample consisting tuples user_embeddingitem_ embeddingrating user item embeddings produce vector real number convert set tuples discretized version user_ iditem_idrating user_ids integer range number user analogously item_ids integer range number item neural network trained user embedding assigns simi lar code similar user embedding layer inherent property embedding layer make possible incorporate clustering process proposed fig innovation proposed expected impact solving gan mode collapse show traditional gan cf context fig b show improvement introduced baseline adequately process sparse fig c detail proposed wasserstein ker nel reduce mode collapse problem j bobadilla guti√©rrez charge grouping similar user item desired number user item synthetic dataset discretization process wganrs designed set desired number user item generated dataset implement kmeans clustering performed since allows u set k number user k number item show follow ing concept kmeans used cluster k user whereas another kmeans process used cluster k item since similar user similar embeddings expected grouped cluster analogously item user number generated dataset corre sponds cluster number kmeans fake user embedding grouped example leftmost fake embeddingbased cf dataset left side fig grouped user green colour k group item blue colour group consequently generated fake synthetic dataset k rating example rating first source dataset left side fig finally due discretization process duplicated sam ples found happens two different generated sample share user id item id chosen number user item high diffi cult find duplicated sample since wider variety cluster expected user item assigned group balanced way duplicated sample managed simply removing spare sample expected balance clustering group could broken mode collapse happening gan indeed serstein concept used avoid mode collapse number removed sample used quality measure result section lower removed sample better since two hyperparameters proposed number user number item cluster ing better fit kmeans directly set k number user k number item fact one unusual situation k known clustering process thus relevant clustering method hierarchical distribution density fuzzybased one adequate scenario following subsection wganrs malized moreover equation provided formalization cf definition first define main set r set user u item range rating v existing sample let u set user make use cf r let set item available vote cf r let v range allowed vote v let set sample contained cf dataset n total number cast vote u v u v u v n u u v v fig overview proposed wganrs architecture wasserstein ganbased architecture generate collaborative filtering synthetic datasets formalization defined cf dataset consists set tuples userid itemid rating number star rating vote assigned userid itemid deepmf training deep mf training top left graph conducted create embed user id item id two embeddings feed wganrs generative stage embedding compressed representation user item embeddings unidimensional vector size e define f eu u function compress user u analogously f ei function compress item let e size two neural layer embeddings used vectorize user item belonging u respectively let f eu u e u e u e u e u e f eu embedding layer output user u u let f ei e e e e e f ei embedding layer output item fig deepmf wgan model involved wganrs architecture relevant equation back propaga tion defined set output error mean squared difference metric equation distinctive proposed deepmf feedforward deepmf learned collect embedding representation user item cf r therefore existing itemid userid r combining dense vector user item embeddings e u e u e u e u e e e e e e make rating prediction deepmf training stage dot product user embedding item embedding u v j provides rating prediction j f eu u f ei e iu e e u e u e u e e e e e j j output error used deepmf neural network start back propagation neural weight iteratively improved Ìõø j value Œ¥ w ji Ìõº j f net k w ik Ìõø k k hidden layer Œ¥ w ji Ìõº j f net k k k output layer j k successive sequential layer j bobadilla guti√©rrez dataset feed trained deepmf embed ded representation obtained done making feedforward prediction operation topright graph trained deepmf let e u e u e u e u e u e u u set embeddings r user let e u e u e u e u e u e let e e u e u e u e u e e e e e e set embeddings r item let e e e e e e setting dataset embeddings collect embedding representation itemid userid r translate set set r set r embeddingbased dataset version original raw dataset let r e u e v u v j embedding dataset real sample wgan training core concept gan methodology jointly train generator discriminator architecture trained generator creates new sample follow distribution training sample discriminator attempt differentiate real sample generated one minmax optimization problem form min g max Ìîº x p log x Ìîº z p latent log g z w h e r e g z x generator map latent space z input space x x ‚Ñù dis criminator map input space x clas sification realfake ‚Ñù ‚Ñù concave function formula optimization function expression network generator discriminator try optimize g aim minimize whereas want maximize bottomleft graph fig show generative learning gan architecture consists discriminator classifier generator generator creates fake sample r profile whereas discriminator try detect fake sample generative adversarial training discriminator progressively learns accurately differentiate fake profile real profile time generator learns make fake sam ples difficult distinguish real profile call f discriminator f g generator fig clustering stage wganrs architecture wasserstein ganbased architecture generate collaborative filtering synthetic datasets f f g iteratively learn improve minimizing loss function f gd f gd min g max f g e r f w r e z f w g z e r expected real sample z random noise feed generator g e z expected generated fake profile gz f w wasserstein function earth mover distance function satisfies lipschitz constraint f x f x x x x x r refers let f discriminator belonging gan let f g generator g belonging gan let f gd cost function gan notably wasserstein concept introduced eq mainly implemented loss function code generative wasserstein designed reduce mode collapse problem inherent gan implement reduce mode collapse wganrs proposed consequently reduce number excessively generated similar profile r wgan generation gan trained generate many sample needed introduce batch random gaussian noise vector z implement feedforward process modelpredict batch fake embedded prof le bottomright graph let f f g generated dataset fake sample different random noise vector z clustering item user show clustering process set k number user generated dataset k number item n gen erated fake profile contain fake user embed ding fake item embeddings n k n k let k number cluster used group embeddings user let k number cluster used group embeddings item generated fake user user n must select nearest user k existing user h u function make group process used item generated fake item one n must select nearest item k existing item h function make group let h u c c k clustering operation assigns centroid user let h c c k clustering operation assigns centroid item setting dataset item id user id create synthetic dataset generated set embed ding f converted discretized version h let h item id user id discrete dataset obtained embeddingbased dataset f fake sample sometimes different generated sample set f discretized user item h u h v h u h v h h u h v e u e v f particularly happens gan suffers mode collapse case sample identical create set h duplicated sam ples removed let h synthetic generated dataset version h duplicated sample removed last transformation remove sample fake user cast different vote v v item let g h u h v h h u h v h h u h u h h v v j bobadilla guti√©rrez result proposed tested two opensource representative cf datasets movielens httpsgrouplens orgdatasetsmovielensm subset netflix call netflix two datasets chosen representative cf field movielens probably tested dataset family year cf research result obtained movielens informative r researcher hand netflix widely used due enor mous size longer available utilized open version netflix randomly shortened net flix selected dataset research internal pattern different movielens movielens created relatively short time academic environment whereas netflix enormous com mercial dataset growing long period since research involves catching internal pattern source dataset parameterizing translating pattern generated dataset convenient use different source show main parameter value result datasets follow trend therefore ensure length appropriate explain mov ielens result group netflix result fig appendix test wganrs two set synthetic datasets created first set varied number user whereas second set varied number item row show value set first row indicates five synthetic datasets generated first dataset contains user item second dataset hold user item last dataset user item generated datasets created starting thousand sample set allows u test impact changing number user analogously second row show four synthetic datasets created four datasets user however number item varies first dataset last set allows u measure impact changing number item since use ganrs baseline datasets also created ganrs thirtysix datasets generated movielens source netflix ganrs wganrs test datasets four different exections conducted number generated sample number sample returned ganrs wganrs compared wganrs expected perform better focus particularly avoiding typical mode collapse gans better managed mode col lapse varied embedding sample wganrs generates better performance clustering process create raw sample finally lesser number collision increasing size synthetic datasets rating distribution important rating distri bution generated datasets similar possible source particularly relevant rating usually star indication pat tern fake profile correct contain adequate proportion relevant nonrelevant vote user item distribution interesting test user item distribution number user item var y comparing source dataset expected gaussian random noise used create stochastic vector feed wganrs generator force dif ferent gaussian distribution user item precision recall regarding ground distribution balanced vote high number sample gen erated datasets used adequately analyse cf task recommendation quality measure return suitable value trend execution cover potential comparative avail able generative creation synthetic datasets cf area show concept top graph show traditional cf different stateoftheart method model applied one several existing cf datasets recommendation result measured traditional quality prediction recommendation quality metric precision recall f mean absolute error mae however field synthetic cf dataset generation com pletely different source dataset fig b create one several synthetic datasets set different number user item sample etc generated dataset hold compare proposed generative selected stateoftheart baseline must create synthetic dataset group synthetic datasets proposed orange datasets fig b different dataset group datasets sota baseline blue datasets fig b need determine datasets group bet ter comparing generated datasets fig b different task comparing method model applied existing dataset fig b show three type code execution perform decide whether generated datasets proposed orange datasets better generated datasets baseline blue datasets main parameter value tested datasets dataset user item rating score sparsity movielens netflix wasserstein ganbased architecture generate collaborative filtering synthetic datasets mode collapse impact measured cf field removing similar user profile gan collapse reduced number source profile higher number deleted profile higher mode collapse impact higher deleted profile lower number sample generated dataset b show comparison axis represents number sample proposed orange colour improves sota baseline generated datasets probability distribu tions similar source dataset user item rating distribution synthetic set compared b show distribu tion rating source dataset green colour compared baseline dataset orange colour graph proposed dataset blue colour notably synthetic datasets expected distribution source dataset genus tive process create similar datasets identical datasets identical datasets rep licating real face valuable field computer vision therefore absolute metric measure type quality extreme distribution similarity large distribution difference must avoided quality generated datasets indirectly meas ured running stateoftheart cf method model expect similar behaviour obtained apply method source dataset different trend absolute value generated dataset graph compared source dataset tell u generated dataset contain main pattern source dataset b show precision recall result source dataset left graph generated dataset right graph measured several sota cf deep learning model trend value similar explained expect identical behaviour value since synthetic datasets mimic source pat tern copy reason standard quality measure compare graph fig b taking account consideration several experiment performed three explained approach shown b b b fig individual execution explained result structured subsects followed discussion subsection number generated sample explained previous section proposed us wgan generate synthetic embedding sample dense continuous sample converted sparse discrete version mean clustering process translation raw tuples synthetic dataset discretization stage cause proportion collision identical similar generated sample must removed smaller number sample removed accu rate generative richer synthetic dataset wasserstein gan expected improve result designed prevent mode collapse inherent gan model please note hypothesis reducing mode collapse variability generated embedded sample increase clustering process able spread user item id homogeneous way consequently number discretized sample repeated deleted decrease overall total size generated datasets increase gan mode collapse reduced wasserstein final number sample generated relevant qual ity measure since directly related impact mode collapse generative process baseline ganrs suffers mode collapse problem leading generation repeated fake profile han dle situation removing spare profile provide necessary diversity sample proposed wganrs expected improve result due wasserstein ability reduce mode collapse improve diversity increase synthetic dataset size show comparison ganrs gan versus wganrs wgan synthetic datasets number user varies left graph synthetic datasets number item varies right graph overall proposed wgan significantly improves base line gan specifically duplicate number gener ated sample improvement left graph improvement right graph achieved relevant predictor superiority proposed additionally expected higher number user item higher number generated sam ples clustering process better spread sample latent space number centroid increase number duplicated sample decrease result show relevant improvement pro posed applied compared baseline con firm hypothesis fulfilled moreover incor porating wasserstein concept generative kernel ganrs lead decrease mode collapse problem inherent gan applied cf scenario generated datasets less redundant profile accordingly diverse contain parameter value initial sample user item j bobadilla guti√©rrez sample overall proposed wganrs generates richer unbiased longer synthetic datasets rating distribution distribution rating one star two star five star important quality measure cf synthetic dataset generation process recommendation model sensitive relevant versus nonrelevant thresh old usually set four five star cf datasets containing five possible rating enough gaussian distribution rating generated dataset similar mean gaussian distribution source dataset also necessary standard deviation analogous show proposed wganrs generates gaussian distribution similar mov ielens distribution baseline ganrs specifically achieves improvement improvement aver age obtained synthetic datasets first row number user varies net flix whereas second row number item varies return improvement average netflix expected positive result contribute providing adequate recommendation quality result next subsection beyond numeric improvement value shown compare shape probability distribution fig probability distribution source movielens dataset greencolour bar target proposed wganrs bluecolour bar much closer target baseline ganrs orangecolour bar reason relevant numerical improvement shown paragraph additionally baseline generates gaussian distribution excessively centred average rating three star whereas proposed adequately fit gaussian distribution correct fourstar mean regard ing gaussian standard deviation baseline adequately catch source dataset shape deviation smaller consequently generate enough profile distribution edge one star five star contrast proposed performs nearly perfectly edge source distribution thus sample generated proposed wganrs diverse unbiased obtained running sota baseline additionally obtained better follows gaussian distribution describes source shape rating reinforces fig traditional cf validation method model versus validation synthetic datasets generated gan wasserstein ganbased architecture generate collaborative filtering synthetic datasets complement obtained sect overall proposed reduces repeated sample b generates sam ples c increase diversity decrease bias e better mimic probability distribution rating precision recall subsection show recommendation quality result obtained synthetic datasets obtained mov ielens source wganrs used experiment generate synthetic datasets stateof theart ncf neural collaborative filtering deep learning used make prediction recommenda tions relevancy ÌúÉ threshold set five top graph fig show result number user varies whereas bottom graph show result number item varies value trend obtained synthetic datasets coloured curve similar com patible source datasets black curve indi cates proposed generates suitable synthetic datasets used r field additionally expected higher number user higher recall since user profile contain fewer relevant rating recall denominator conversely higher number user lower precision since denominator con stant n number recommendation whereas numerator contains true positive relevant rating high number user involves less relevant rating per user additionally set synthetic datasets number user varies dataset hold user pro vides precision recall result like movielens source since movielens contains user tell u ganbased generates pattern recommendation easier source dataset consistent one reported importantly evolution recommendation curve generated datasets coloured curve follow trend exhibited source movielens black curve indicating internal pattern source set adequately captured proposed wganrs regarding result number item var y similar conclusion drawn underlying rec ommendation quality worsen absolute value compared source dataset probably occurs dis tribution item rating highly variable compared distribution user rating leading difficult pattern extraction number item holding low number rating user item distribution rating distribution tested also convenient compare user item distribution obtained proposed baseline method user item distribution synthetic datasets dependent gaussian parameter value noise vector feed generative created original serf baseline standard deviation customized tested dataset contrast proposed fixed one removed hyperparameter making easier fine tune proposed compared baseline top graph show result number user varies bottom graph show varying number item dashed line repre sent baseline result solid line show proposed approach case expected higher number user lower number rating assigned fig number sample generated baseline ganrs gan versus proposed wganrs wgan source dataset movielens number sample needed left graph generated datasets item range user right graph generated datasets user range item higher number generated sample better j bobadilla guti√©rrez user since number rating dataset fixed also observed proposed generates gaussian distribution higher standard deviation baseline heuristically tailored dataset proposed baseline method generate suitable user item distribution cf area discussion experimental result show superiority proposed wganrs compared ganrs baseline par ticularly relevant high improvement approximately number generated sample indicates proposed wasserstein effectively reduces amount mode collapse gan wganrs also effectively mimic rating distribution source dataset obtaining high improvement compared baseline making possible quality precision recall value trend compatible source dataset furthermore even standard quality meas ures exist test r generated user item distribu tions obtained proposed comparable baseline additionally proposed advantage necessary assign heuristic value standard deviation gaussian dis tribution used create noisy random vector feed generator wgan finally result netflix dataset reinforce result obtained testing movielens appendix show netflix result overall proposed improves sta tistical baseline stateoftheart generative method statistical baseline reported reach poor accuracy contrast support adequate parameterization generative baseline operate quite differently support full parameterization exceed accuracy statistical meth od proposed proven provide full fig comparative rating distribution among movielens ml source dataset baseline ganrs gan pro posed wganrs wgan user item syn thetic dataset chosen representative set generated closer distribution source ml distribution better fig quality recom mendation precision recall obtained varying number n recommendation relevancy threshold ÌúÉ set upper graph show result synthetic datasets containing user lower graph show result synthetic datasets containing item precision seen left graph whereas recall shown right graph movielens dataset used higher value better result wasserstein ganbased architecture generate collaborative filtering synthetic datasets parameterization high accuracy addition strong reduction mode collapse problem inherent gan architecture hand inherits positive negative feature baseline however accuracy performance high due short dense continuous vector gan take input main drawback come clustering stage fig requires addi tional execution time involves discretization process increase probability generating duplicated sam ples reason wasserstein concept pro posed alleviate explained drawback result show proposed adequately reduces mode col lapse problem maintains baseline advantage reduces disadvantage confirms hypothesis conclusion relevant wasser stein reduces mode collapse gan genus tion cf fake sample compared stateoftheart method positive effect reflected relevant reduction duplicated sample consequently generation larger synthetic datasets furthermore proposed return improved distribution rating facilitates obtaining correct value trend recommendation qual ity measure finally distribution user item comparable stateoftheart method distribution act quality measure due lack stand ard quality measure r generated moreover exist ing hyperparameters avoided proposed standard deviation gaussian distribution used create noisy vector feed generator gan overall result experiment show applying wasserstein distance weight clipping cf generative process improved compared stateoftheart method use wassersteinbased gans proposed future work includes testing proposed different r datasets several sparsity ratio different number user item b comparing existing bias source datasets generated bias synthetic datasets c checking ability generated sample serve augmentation added source datasets fig top graph distribu tion rating number user varies comparative proposed wganrs wgan baseline ganrs gan bottom graph distribution rating number item var y compari son proposed wganrs wgan baseline ganrs gan source movielens ml dataset used graph j bobadilla guti√©rrez appendix section figure used movielens shown however netflix dataset used source fig number sample generated baseline ganrs gan versus proposed wganrs wgan source dataset netflix number needed sample left graph generated datasets item range user right graph generated datasets user range item higher num ber generated sample better fig comparative rating distribution among netflix source dataset baseline ganrs gan proposed wganrs wgan user item synthetic dataset chosen representative set generated closer distribution source ml distribution better wasserstein ganbased architecture generate collaborative filtering synthetic datasets fig quality recommen dation precision recall obtained varying number n recommendation relevancy threshold ÌúÉ set upper graph show result synthetic datasets containing user lower graph show result synthetic datasets containing item precision seen left graph whereas recall shown right graph netflix dataset used higher value better result fig top graph distribu tion rating number user varies comparison proposed wganrs wgan baseline ganrs gan bottom graph distribution rating number rating var y compari son proposed wganrs wgan baseline ganrs gan source netflix dataset used graph j bobadilla guti√©rrez author contribution abraham guti√©rrez ran execution prepared figure format jes√∫s bobadilla provided concept design experimental design wrote funding open access funding provided thanks cruecsic agreement springer nature work partially supported ministerio de ciencia e innovaci√≥n spain pro ject pidrbi dlcemg comunidad de convenio plurianual universidad polit√©cnica de actuation line programa de excelencia para el profesorado universitario availability datasets generated andor analysed current available github repository httpsgithub comjesusbobadillaganrsgit declaration ethic obtaining condition specified use open datasets taken source generative process satisfied including reference stated readme file conflict interest author competing interest de clare relevant content article agree publishing content open access article licensed creative common attri bution international license permit use sharing adapta tion distribution reproduction medium format long give appropriate credit original author source provide link creative common licence indicate change made image third party material article included article creative common licence unless indicated otherwise credit line material material included article creative common licence intended use permitted statutory regulation exceeds permitted use need obtain permission directly copyright holder view copy licence visit httpcreativecommonsorglicensesby reference shokeen j rana c feature social recom mender system artif intell rev httpsdoiorg sw bobadilla j guti√©rrez alonso gonz√°lezprieto neural collaborative filtering classification obtain prediction reliability international journal interactive mul timedia artificial intelligence httpsdoiorg ijimai deldjoo schedl cremonesi p pasi g recommender system leveraging multimedia content acm computing survey csur httpsdoiorg bobadilla j gonz√°lezprieto ortega f laracabrera r deep learning feature selection unhide demographic recom mender system factor neural comput appl httpsdoiorgs bobadilla j laracabrera r gonz√°lezprieto √° ortega f deepfair deep learning improving fairness recom mender system international journal interactive multimedia artificial intelligence httpsdoiorg ijimai kulkarni rodd sf context aware recommendation system review state art technique computer science review httpsdoiorgjcosrev wang z intelligent recommendation tourist place collaborative filtering user preference appl artif intell httpsdoiorg ray b garain sarkar r ensemblebased hotel rec ommender sentiment aspect categoriza tion hotel review applied soft computing http doiorgjasoc kabul m setiawan eb recommender userbased itembased collaborative filtering twitter knearest neighbor classification journal computer informat ic httpsdoiorgjosycvi eslami g ghaderi f incremental trustaware matrix factor ization recommender system towards green ai appl intell httpsdoiorgs mehdi ha novel constrained nonnegative matrix fac torization user item pairwise relationship recommender system expert syst appl http doiorgjeswa gheorghe p p√©rezjim√©nez grzegorz r infinite spike train spiking neural p system romanian journal infor mation science technology httpsdoiorg romjist liu h zheng c li shen x lin k wang j zhang z zhang z xiong n edmf efficient deep matrix factorization review feature learning industrial recommender ieee trans industr inf httpsdoi orgtii bobadilla j ortega f guti√©rrez gonz√°lezprieto √° deep variational model collaborative filteringbased recom mender system neural comput appl http doiorgs hai c fulan q jie c shu z yanping z attributebased neural collaborative filtering expert syst appl httpsdoiorgjeswa min g junwei z junliang jundong l junhao w qingyu x recommender system generative adversarial network problemdriven perspective inf sci httpsdoiorgjins forouzandeh berahmand k rostami presentation recommender ensemble learning graph embed ding movielens multimedia tool application httpsdoiorgs kumar aggarwal rk exploration semi supervised languageadversarial transfer learning hybrid acoustic hindi speech recognition j reli able intell environ httpsdoiorg deldjoo noia dt merra fa survey adversarial recommender system attackdefense strategy gen erative adversarial network acm comput surv httpsdoiorg chae dk kang j kim sw lee jt cfgan generic collaborative filtering framework generative adversarial network proceeding th acm international con ference knowledge management cikm association computing machinery new york ny pp httpsdoiorg guo g zhou h chen b et al ipgan generating informa tive item pair adversarial sampling ieee transaction wasserstein ganbased architecture generate collaborative filtering synthetic datasets neural network learning system http doiorgtnnls zhao j li h qu l zhang q sun q huo h gong dcf gan adversarial deep reinforcement learning framework improved negative sampling sessionbased recommender system inf sci httpsdoiorgjins sun j liu b ren h huang w wncgan neural adver sarial collaborative filtering recommender journal intelligent fuzzy system httpsdoiorg jifs bharadhwaj h park h lim recgan recurrent gen erative adversarial network recommendation system pro ceedings th acm conference recommender system recsys september association computing machinery new york ny pp httpsdoiorg shafqat w byun yc hybrid ganbased solve imbalanced problem recommendation system ieee access httpsdoiorgaccess wen j zhu xr wang cd tian z framework per sonalized recommendation conditional generative adversarial network knowl inf syst httpsdoiorg sz wang q huang q k zhang x recommender regularization wasserstein generative adversarial network inf sci httpsdoiorg jins zhang x zhong j liu k wasserstein autoencoders collaborative filtering neural comput appl httpsdoiorgsw schlett rathgeb c henniger galbally j fierrez j busch c face image quality assessment literature survey acm comput surv httpsdoiorg bobadilla j guti√©rrez yera r mart√≠nez l creating syn thetic datasets collaborative filtering recommender system generative adversarial network knowledge system httpsdoiorgjknosys ioandaniel b raduemil p alexandrabianca b improvement kmeans cluster quality post processing resulted cluster procedia computer science http doiorgjprocs ortega f mayor j l√≥pezfern√°ndez laracabrera r cfj adapting collaborative filtering java new chal lenges collaborative filtering recommender sys tems knowledgebased syst httpsdoiorg jknosys gong distribution constraining combating mode collapse generative adversarial network j electron imaging httpsdoiorgjei publisher note springer nature remains neutral regard jurisdictional claim published map institutional affiliation jes√∫s bobadilla received b phd degree computer science uni versidad polit√©cnica de universidad carlos iii currently full professor department informa tion system universidad poli t√©cnica de habit ual author programming language book working mcgraw hill rama alfa omega publisher research interest include retrieval recommender system speech processing see filmaffinitycom research team working collaborative filtering kernel web site researcher inter national computer science institute berkeley university sheffield university abraham guti√©rrez received b phd degree computer science uni versidad polit√©cnica de currently currently associate professor department sys tems universidad polit√©cnica de author research paper prestig iou international journal habitual author program ming language book working mcgrawhill rama alfa omega publisher research interest include psys tems machine learning artificial intelligence charge group innovation issue including commercial project j bobadilla guti√©rrez,1,latent space and group in synthetic datasets
Comprehensive Evaluation of Matrix Factorization Models for Collaborative Filtering Recommender Systems.pdf,Comprehensive Evaluation of Matrix Factorization Models for Collaborative | Filtering Recommender Systems | Keywords | Abstract | Comprehensive Evaluation of Matrix Factorization | Models for Collaborative Filtering Recommender | Systems | R,,"See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/370797388 Comprehensive Evaluation of Matrix Factorization Models for Collaborative Filtering Recommender Systems Article in International Journal of Interactive Multimedia and Artificial Intelligence ¬∑ January 2023 DOI: 10.9781/ijimai.2023.04.008 CITATIONS 3 READS 46 4 authors: Jesus Bobadilla Universidad Polit√©cnica de Madrid 97 PUBLICATIONS 6,377 CITATIONS SEE PROFILE Jorge Due√±as-Ler√≠n Comunidad de Madrid 7 PUBLICATIONS 14 CITATIONS SEE PROFILE Fernando Ortega Universidad Polit√©cnica de Madrid 69 PUBLICATIONS 5,648 CITATIONS SEE PROFILE Abraham Gutierrez Universidad La Salle M√©xico 39 PUBLICATIONS 588 CITATIONS SEE PROFILE All content following this page was uploaded by Jorge Due√±as-Ler√≠n on 20 July 2023. The user has requested enhancement of the downloaded file. - 1 - * Corresponding author. E-mail addresses: jesus.bobadilla@upm.es (J. Bobadilla), jorgedl@alumnos.upm.es (J. Due√±as-Ler√¨n), fernando.ortega@upm.es (F. Ortega), abraham.gutierrez@upm.es (A. Gutierrez). Please cite this article in press as: J. Bobadilla, J. Due√±as-Ler√≠n, F. Ortega, A. Gutierrez. Comprehensive Evaluation of Matrix Factorization Models for Collaborative Filtering Recommender Systems, International Journal of Interactive Multimedia and Artificial Intelligence, (2023), http://dx.doi.org/10.9781/ijimai.2023.04.008 Keywords Collaborative Filtering, Matrix Factorization, Recommender Systems. Abstract Matrix factorization models are the core of current commercial collaborative filtering Recommender Systems. This paper tested six representative matrix factorization models, using four collaborative filtering datasets. Experiments have tested a variety of accuracy and beyond accuracy quality measures, including prediction, recommendation of ordered and unordered lists, novelty, and diversity. Results show each convenient matrix factorization model attending to their simplicity, the required prediction quality, the necessary recommendation quality, the desired recommendation novelty and diversity, the need to explain recommendations, the adequacy of assigning semantic interpretations to hidden factors, the advisability of recommending to groups of users, and the need to obtain reliability values. To ensure the reproducibility of the experiments, an open framework has been used, and the implementation code is provided. DOI: 10.9781/ijimai.2023.04.008 Comprehensive Evaluation of Matrix Factorization Models for Collaborative Filtering Recommender Systems Jes√∫s Bobadilla, Jorge Due√±as-Ler√≠n, Fernando Ortega, Abraham Gutierrez * Dpt. Sistemas Inform√°ticos and KNODIS Research Group, Universidad Polit√©cnica de Madrid (Spain) Received 2 July 2022 | Accepted 4 March 2023 | Early Access 28 April 2023 I.	 Introduction R ecommender System (RS) [1] is the field of artificial intelligence specialized in user personalization. Mainly, RSs provide accurate item recommendations to users: movies, trips, books, music, etc. Recommendations are made following some filtering approach. The most accurate filtering approach is the Collaborative Filtering (CF) [2] , where recommending to an active user involves a first stage to make predictions about all his or her not consumed or voted items. Then, the top predicted items are recommended to the active user. The CF approach assumes the existence of a dataset that contains explicitly voted items or implicitly consumed items from a large number of users. Remarkable commercial RSs are Amazon, Spotify, Netflix, or TripAdvisor. Regardless of the machine learning model used to implement CF, the key concept is to extract user and item patterns and then to recommend to the active user those items that he or she has not voted or consumed, and that similar users have highly valued. It fits with the K Nearest Neighbors (KNN) memory-based algorithm [3] , and it is the reason why the initial RS research was based on KNN. There are also some other filtering approaches such as demographic, social, content- based, context-aware, and their ensembles. Demographic filtering [4] makes use of user information such as gender, age, or zip code, and item information such as movie genre, country to travel, etc. Social filtering [5] , [6] has a growing importance in current RS, due to the social networks boom. The existence of trust relations and graphs [7] can improve the quality of the CF recommendations. In this decentralized and dynamic environment, trust between users provides additional information to the centralized set of ratings. Trust relationships can be local, collective, or global [8] ; local information is based on shared users‚Äô opinions, collective information uses friends‚Äô opinions, whereas global information relates to users‚Äô reputation [9] . Content- based filtering [10] recommends items with the same type (content) to consumed items (e.g. to recommend Java books to a programmer that bought some other Java book). Context-aware filtering [11] uses GPS information, biometric sensor data, etc. Finally, ensemble architectures [12] get high accuracy by merging several types of filtering. Memory-based algorithms have two main drawbacks: their accuracy is not high, and each recommendation process requires to recompute the whole dataset. Model-based approaches solve both problems: their accuracy is higher than that of memory-based methods, and they first create a model from the dataset. From the created model we can make many different recommendations, and it can be efficiently updated when the dataset changes. Matrix Factorization (MF) [13] is the most popular approach to implement current RSs: it provides accurate predictions, it is conceptually simple, it has a straightforward implementation, the model learns fast, and also updates efficiently. The MF model makes a compression of information, coding very sparse and large vectors of discrete values (ratings) to low dimensional embeddings of real numbers, called hidden factors. The hidden factors, both from the user vector and from the item vector, are combined by means of a dot product to return predictions. This is an iterative process in which the distance between training predictions and their target ratings is minimized. The Probabilistic Matrix Factorization (PMF) model based on MF [13] scales linearly with the size of the data set. It also returns accurate - 2 - International Journal of Interactive Multimedia and Artificial Intelligence results when applied to sparse, large, and imbalanced CF datasets. PMF has also been extended to include an adaptive prior on the model parameters, and it can generalize adequately, providing accurate recommendation to cold-start users. CF RSs are usually biased. A typical CF bias source comes from the fact that some users tend to highly rate items (mainly 4 and 5 stars), whereas some other users tend to be more restrictive in their ratings (mainly 3 and 4 stars). This fact leads to the extension of the MF model to handle biased data. An user-based rating centrality and an item-based rating centrality [14] have been used to improve the accuracy of the regular PMF. These centrality measures are obtained by processing the degree of deviation of each rating in the overall rating distribution of the user and the item. non-Negative Matrix Factorization (NMF) [15] can extract significant features from sparse and non-negative CF datasets (please note that CF ratings are usually a non-negative number of stars, listened songs, watched movies, etc.). When nonnegativity is imposed, prediction errors are reduced and the semantic interpretability of hidden factors is easier. The Bernoulli Matrix Factorization (BeMF) [16] has been designed to provide both prediction and reliability values; this model uses the Bernoulli distribution to implement a set of binary classification approaches. The results of the binary classification are combined by means of an aggregation process. The Bayesian non-Negative Matrix Factorization (BNMF) [17] was designed to provide useful information about user groups, in addition to the PMF prediction results. The authors factorize the rating matrix into two nonnegative matrices whose components lie within the range [0, 1] . The resulting hidden factors provide an understandable probabilistic meaning. Finally, The User Ratings Profile Model (URP) is a generative latent variable model [18] ; it produces complete rating user profiles. In the URP model, first attitudes for each item are generated, then a user attitude for the item is selected from the set of existing attitudes. URP borrows several concepts from LDA [19] and the multinomial aspect model [20] . The set of MF models mentioned above: PMF, Biased Matrix Factorization (BiasedMF), NMF, BeMF, BNMF, and URP, can be considered representative in the CF area. These models will be used in this paper to compare their behavior when applied to representative datasets. Specifically, the following quality measures will be tested: Mean Absolute Error (MAE), novelty, diversity, precision, recall, and Normalized Discounted Cumulative Gain (NDCG). Prediction accuracy will be tested using MAE [21] , whereas NDCG, Precision and Recall [22] will be used to test recommendation accuracy. Modern CF models should be tested not only regarding accuracy, but also beyond accuracy properties [23] : novelty [24] , [25] and diversity [26] . Novelty can be defined as the quality of a system to avoid redundancy; diversity is a quality that helps to cope with ambiguity or under-specification. The models have been tested using four CF datasets: MovieLens (100K and 1M versions) [27] , Filmtrust [28] and MyAnimeList [29] . These are representative open datasets and are popular in RS research. Overall, this paper provides a complete evaluation of MF methods, where the PMF, BiasedMF, NMF, BeMF, BNMF, and URP models have been tested using representative CF quality measures, both for prediction and recommendation, and also beyond accuracy ones. As far as we know this is the experimental most complete work evaluating current MF models in the CF area. The rest of the paper is structured as follows: Section II introduces the tested models, the experiment design, the selected quality measures, and the chosen datasets. Section III shows the obtained results and provides their explanations in Section IV. Section V highlights the main conclusions of the paper and the suggested future works. Finally, a references section lists current research in the area. II.	 Methods and Experiments This section abstracts the fundamentals of each baseline model (PMF, BiasedMF, NMF, BeMF, BNMF, URP), introduces the tested quality measures (MAE, precision, recall, NDCG, novelty, diversity), and shows the main parameters of the tested datasets ( Movielens , FilmTrust , MyAnimeList ). Experiments are performed by combining the previous entities. The vanilla MF [13] , [30] is used to generate rating predictions from a matrix of ratings R . This matrix contains the set of casted ratings (explicit or implicit) from a set of users U to a set of items I . Since regular users only vote or consume a very limited subset of the available items, matrix R is very sparse. The MF key concept is to compress the very sparse item and user vectors of ratings to small size and dense item and user vectors of real numbers; these small size dense vectors can be considered as embeddings, and they usually are called ‚Äòhidden factors‚Äô, since each embedding factor codes some complex non-lineal (‚Äòhidden‚Äô) relation of user or item features. The parameter K is usually chosen to set the embedding (hidden factors) size. MF makes use of two matrices: P (| U |* K ) to contain the K hidden factors of each user, and Q (| I |* K ) to contain the K hidden factors of each item. To predict how much a user u likes an item i , we compare each hidden factor of u with each corresponding hidden factor of i . Then, the dot product u ‚ãÖ i can be used as suitable CF prediction measure. MF predicts ratings by minimizing errors between the original R matrix and the predicted matrix: (1) (2) Using gradient descent, we minimize learning errors (differences between real ratings r and predicted ratings ). (3) To minimize the error, we differentiate equation (3) with respect to p uk and q ki : (4) (5) Introducing the learning rate Œ± , we can iteratively update the required hidden factors p uk and q ki : (6) (7) CF datasets have biases, since different users vote or consume items in different ways. In particular, there are users who are more demanding than others when rating products or services. Analogously, there are items more valued than others on average. Biased MF [14] is designed to consider data biases; The following equations extend the previous ones, introducing the bias concept and making the necessary regularization to maintain hidden factor values in their suitable range: (8) where Œº , b u , b i are the average bias, the user bias and the item bias. - 3 - Article in Press We minimize the regularized squared error: (9) where Œª is the regularization term. Obtaining the following updating rules: (10) (11) (12) (13) NMF [15] can be considered as a regular MF subject to the following constraints: (14) In the NMF case, predictions are made by linearly combining positive coefficients (hidden factors). NMF hidden factors are easier to semantically interpret than regular MF ones: sometimes it is not straightforward to assign semantic meanings to negative coefficient values. In the CF context, another benefit of using NMF decomposition is the emergence of a natural clustering of users and items. Intuitively, users and items can be clustered according to the dominant factor (i.e. the factor having the highest value). In the same way, the original features (gender, age, item type, item year, etc.) can be grouped according to the factor (from the k hidden factors) on which they have the greatest influence. This is possible due to the condition of positivity of the coefficients. BeMF [16] is an aggregation-based architecture that combines a set of Bernoulli factorization results to provide pairs <prediction, reliability>. BeMF uses as many Bernoulli factorization processes as possible scores in the dataset. Reliability values can be used to detect shilling attacks, to explain the recommendations, and to improve prediction and recommendation accuracy [31] . BeMF is a classification model based on the Bernoulli distribution. It adequately adapts to the expected binary results of each of the possible scores in the dataset. Using BeMF, the prediction for user u to item i is a vector of probabilities , where is the probability that i is assigned the s-th score from user u . The BeMF model can be abstracted as follows: Let S = { s 1 , ‚Ä¶, s D } be the set of D possible scores in the dataset (e.g. 1 to 5 stars: D = 5 ). From R we generate D distinct matrices ; each matrix is a sparse matrix such that . BeMF will attempt to fit the matrices by performing D parallel MFs The BeMF assumes that, given the user P matrix and the item Q matrix containing k > 0 hidden factors, the rate R ui is a Bernoulli distribution with the success probability œà ( P u . Q i ) . The mass function of this random variable is: (15) The associated likelihood is: (16) The BeMF updating equations are: (17) (18) And the aggregation to obtain the final output Œ¶ : (19) where . Let ; the prediction is: , and the reliability is . BNMF [17] provides a Bayesian-based NMF model that not only allows accurate prediction of user ratings, but also to find groups of users with the same tastes, as well as to explain recommendations. The BNMF model approximates the real posterior distribution by the distribution: (20) where: ‚Ä¢ is a random variable from a categorical distribution. ‚Ä¢ is a random variable from a Binomial distribution (which takes values from 0 to D ‚àí 1 ) ‚Ä¢ (a and b are hidden matrices). ‚Ä¢ ‚Ä¢ follows a Dirichlet distribution. ‚Ä¢ follows a Beta distribution. ‚Ä¢ follows a categorical distribution ‚Ä¢ Œª uik are parameters to be learned: BNMF iteratively approximates parameters : (21) (22) (23) (24) (25) (26) (27) where œà is the digamma function as the logarithmic derivative of the gamma function. URP is a generative latent variable model [18] . The model assigns to each user a mixture of user attitudes. Mixing is performed by a Dirichlet random variable: (28) (29) (30) - 4 - International Journal of Interactive Multimedia and Artificial Intelligence (31) (32) (33) In this paper, baseline models will be tested using a) prediction measure, b) recommendation measures, and c) beyond accuracy measures. The chosen prediction measure is the MAE, where the absolute differences of the errors are averaged. Absolute precision and relative recall measures are tested to compare the quality of an unordered list of N recommendations. The ordered lists of recommendations will be compared using the NDCG quality measure. From the beyond accuracy metrics, we have selected novelty and diversity. Novelty returns the distance from the items the user ‚Äòknows‚Äô (has voted or consumed) to his recommended set of items. Diversity tells us about the distance between the set of recommended items. Recommendations with high novelty values are valuable, since they show to the user unknown types of items. Diverse recommendations are valuable because they provide different types of items (and each type of item can be novel, or not, to the user). The GroupLens research group [27] made available several CF datasets, collected over different intervals of time. MovieLens 100K and MovieLens 1M describe 5-star rating and free-text tagging activity. These data were created from 1996 to 2018. In the Movielens 100K dataset, users were selected at random from those who had rated at least 20 movies, whereas the MovieLens 1M dataset has not this constraint. Only movies with at least one rating or tag are included in the dataset. No demographic information is included. Each user is represented by an ‚Äòid‚Äô, and no other information is provided. The dataset files are written as comma-separated values files with a single header row. Columns that contain commas (,) areescapedusing double-quotes (""). These files are encoded as UTF-8. All ratings are contained in the file named ‚Äòratings.csv‚Äô. Each line of this file after the header row represents one rating of one movie by one user, and has the following format: ‚ÄòuserId, movieId, rating, timestamp‚Äô. The lines within this file are ordered first by ‚ÄòuserId‚Äô, then, within user, by ‚ÄòmovieId‚Äô. Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970. FilmTrust is a small dataset crawled from the entire FilmTrust website in June, 2011. As the Movielens datasets, it contains ratings voted from users to items; additionally, it provides social information structured as a graph network. Finally, MyAnimeList contains information about anime and ‚Äòotaku‚Äô consumers (anime, manga, video games and computers). Each user is able to add ‚Äòanimes‚Äô to their completed list and give them a rating; this data set is a compilation of those ratings. The MyAnimeList CF information is contained in the file ‚ÄòAnime.csv‚Äô, where their main columns are ‚Äòanime_id‚Äô: myanimelist.net‚Äôs unique ‚Äòid‚Äô identifying an anime; ‚Äòname‚Äô: full name of anime; ‚Äògenre‚Äô: comma separated list of genres for this anime; ‚Äòtype‚Äô: movie, TV, OVA, etc; ‚Äòepisodes‚Äô: how many episodes in this show; ‚Äòrating‚Äô: average rating out of 10 for this anime. These datasets are available in the Kaggle and GitHub repositories, as well as in the KNODIS research group CF4J [32] repository https://github.com/ferortega/cf4j. Table I contains the values of the main parameters of the selected CF data sets: Movielens 100K, Movielens 1M, FilmTrust and MyAnimeList. We have run the explained MF models on each of the four Table I datasets, testing the chosen quality measures. Please note that the MyAnimeList dataset ratings range from 1 to 10 , whereas MovieLens datasets range from 1 to 5 and FilmTrust ranges from 0 to 5 with 0.5 increments. It is also remarkable the sparsity difference between FilmTrust and the rest of the tested datasets. TABLE I. Main Parameter Values of the Tested Datasets Dataset #users #items #ratings Scores Sparsity MovieLens100k 943 1682 99,831 1 to 5 93.71 MovieLens1M 6,040 3,706 911,031 1 to 5 95.94 MyAnimeList 19,179 2,692 548,967 1 to 10 98.94 FilmTrust 1,508 2,071 35,497 0 to 5 87.98 Experiments have been performed using random search and applying four-fold cross-validation. To ensure reproducibility, we used a seed in the random process. Results shown in the paper are the average of the partial results obtained by setting the number k of latent factors to {4, 8, 12} , and the number of MF iterations to {20, 50, 75, 100} . Additionally, to run the PMF, BiasedMF, and BeMF models, both the learning rate and the regularization parameters have been set to {0.001, 0.01, 0.1, 1.0} . The BNMF model requires two specific parameters: Œ± and Œ≤ ; the chosen values por these parameters are: Œ± = {0.2, 0.4, 0.6, 0.8} , and Œ≤ = {5, 15, 25} . The tested number of recommendations N ranges from 1 to 10. We have used 4 stars as recommendation threshold Œ∏ for datasets whose ratings range from 1 to 5 , while the testing threshold has been 8 when MyAnimeList was chosen. The experiments have been implemented using the open framework [33] and the code has been made available at https://github.com/KNODIS-Research-Group/choice-of-mf-models. III.	Results The prediction quality obtained by testing each baseline model is shown in table II. The bold numbers correspond to the best results, and, of them, those highlighted gray are the top ones. As can be seen, BiasedMF and BNMF models provide the best CF prediction results. PMF, NMF, BeMF and URP seem to be more sensitive to the type of CF input data. TABLE II. Prediction Quality Results Using the Mean Absolute Error (MAE). The Lower the Error Value, the Better the Result PMF BiasedMF NMF BeMF BNMF URP MovieLens 100K 0.770 0.754 0.804 0.805 0.748 0.837 MovieLens 1M 0.729 0.712 0.744 0.748 0.693 0.795 FilmTrust 0.863 0.652 0.876 0.712 0.666 0.831 MyAnimeList 1.110 0.926 1.147 1.034 0.943 1.159 Fig. 1 shows the quality of recommendation obtained using the Precision measure. The most remarkable in Fig. 1 is the superiority of the models PMF and BiasedMF. For the remaining models, URP and BeMF provide the worst results, whereas the nonnegative NMF and BNMF return an intermediate quality. It is important to highlight the good performance of the BiasedMF model for both the prediction and the recommendation tasks. To test the quality of CF recommendations of unordered recommendations, precision and recall measures are usually processed, and they are provided separately, or joined in the F1 score. We have done these experiments and we have not found appreciable differences in Recall values for the tested models in the selected datasets. In order to maintain the paper as short as possible, Fig. 2 only shows the Recall results obtained by processing the Movielens 1M dataset. Results from the rest of datasets are very similar; consequently, the Recall quality measure does not help, in this context, to find out the best MF models in the CF area. - 5 - Article in Press Fig. 2. Recall Recommendation quality results obtained in the MovieLens 1M dataset. The results of the other three considered datasets are very similar to this one; to maintain the paper as short as possible, the results of other datasets are not shown. PMF 0,6 0,5 0,4 0,3 0,2 0,1 0 1 3 5 Number of recommendations Recall 7 9 BiasedMF BeMF NMF BNMF URP Fig. 2. Recall Recommendation quality results obtained in the MovieLens 1M dataset. The results of the other three considered datasets are very similar to this one; to maintain the paper as short as possible, the results of other datasets are not shown. In the RSs field, recommendations are usually provided in an ordered list. Users‚Äô trust in RSs quickly decays when the first recommendations in the list do not meet their expectations; for that reason, the NDCG quality measure particularly penalizes errors in the first recommendations of the list. Fig. 3 (NDCG results) shows a similar behavior to Fig. 1, where the BiasedMF and PMF models provide the best recommendation quality. So, these two models perform fine both in recommending ordered and unordered lists. Traditionally, RSs have been evaluated attending to their prediction and recommendation accuracy; nevertheless, there are some other valuable beyond accuracy aims and their corresponding quality measures. The Diversity measure tests the variety of recommendations, penalizing recommendations focused on the same ‚Äòarea‚Äô (Star Wars III, Star Wars I, Star Wars V, Han Solo). Fig. 4 shows the Diversity results obtained by testing the selected models; the most diverse recommendations are usually returned when the BiasedMF model is used, followed by both PMF and NMF. This fact is particularly interesting, since it is not intuitive that the same model (BiasedMF) can, simultaneously, provide accurate and diverse recommendations. Novelty is an important beyond accuracy objective in RSs. Users appreciate accurate recommendations, but they also want to discover unexpected (and accurate enough) recommendations. Please note that a set of recommendations can be diverse and not novel, as they can be novel and not diverse. It would be great to receive, simultaneously, accurate, novel, and diverse recommendations, but usually improving some of the objectives leads to worsening others. Fig. 5 shows the results of the novelty quality measure: NMF returns novel recommendations, compared to other models; NMF provides a balance between accuracy and novelty. BiasedMF and PMF also provide novel recommendations compared to BeMF and URP. PMF 0,85 0,8 0,75 0,7 0,65 0,9 0,95 0,85 0,8 0,75 0,7 1 3 5 Number of recommendations Precision 7 9 1 3 5 7 9 BiasedMF BeMF NMF BNMF URP PMF BiasedMF BeMF NMF BNMF URP PMF 0,85 0,81 0,83 0,79 0,75 0,77 0,70 1 3 5 Number of recommendations Precision 7 9 BiasedMF BeMF NMF BNMF URP PMF 0,85 0,87 0,89 0,81 0,83 0,79 0,75 0,77 0,73 1 3 5 Number of recommendations Number of recommendations Precision Precision 7 9 BiasedMF BeMF NMF BNMF URP (a) (b) (c) (d) Fig. 1. Precision recommendation quality results; a) MovieLens100K , b) MovieLens 1M , c) FilmTrust , d) MyAnimeList . The higher the values, the better the results. - 6 - International Journal of Interactive Multimedia and Artificial Intelligence PMF 0,85 0,8 0,75 0,7 0,65 0,6 0,65 0,67 0,69 0,71 0,73 0,75 0,77 0,79 0,81 0,83 1 3 5 Number of recommendations NDCG NDCG 7 9 1 3 5 7 9 BiasedMF BeMF NMF BNMF URP PMF BiasedMF BeMF NMF BNMF URP PMF 0,95 0,9 0,85 0,75 0,8 0,7 1 3 5 Number of recommendations NDCG 7 9 BiasedMF BeMF NMF BNMF URP PMF 0,79 0,82 0,73 0,76 0,7 0,64 0,67 0,61 1 3 5 Number of recommendations Number of recommendations NDCG 7 9 BiasedMF BeMF NMF BNMF URP (a) (b) (c) (d) Fig. 3. Normalized Discounted Cumulative Gain recommendation quality results; a) MovieLens100K , b) MovieLens 1M , c) FilmTrust , d) MyAnimeList . The higher the values, the better the results. PMF 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 Diversity Diversity 2 4 6 8 10 BiasedMF BeMF NMF BNMF URP PMF BiasedMF BeMF NMF BNMF URP PMF Diversity BiasedMF BeMF NMF BNMF URP PMF Number of recommendations 2 4 6 8 10 Number of recommendations 2 4 6 8 10 Number of recommendations 2 4 6 8 10 Number of recommendations Diversity BiasedMF BeMF NMF BNMF URP (a) (b) (c) (d) Fig. 4. Diversity beyond accuracy results; a) MovieLens100K , b) MovieLens 1M , c) FilmTrust , d) MyAnimeList . The higher the values, the better the results. - 7 - Article in Press IV.	Discussion In this section, we provide a comparative discussion of the most adequate MF models when applied to a set of different CF databases. To judge each MF model, we simultaneously measure a set of conflicting goals: prediction accuracy, recommendation accuracy (unordered and ordered lists) and beyond accuracy aims. We will promote some MF models as ‚Äòwinners‚Äô, attending to their high performance (overall quality results) when applied to the tested datasets. We also provide a summary table to better identify those MF models that perform particularly fine on any individual quality objective: novelty, diversity, precision, etc., as well as any combination of those quality measures. TABLE III. MF Models Comparative PMF BiasedMF NMF BeMF BNMF URP MAE ++ +++ + + +++ + Precision +++ +++ ++ + ++ + NDCG +++ +++ + + + + Diversity ++ +++ ++ + + + Novelty ++ ++ +++ + + + Total 12 14 9 5 8 5 Table III summarizes the results of this section. BiasedMF is the most appropriate model when novelty of recommendations is not a particularly relevant issue. PMF can be used instead BiasedMF when simplicity is required (e.g. educational environments). BeMF should only be used when reliability information is required or when reliability values are used to improve accuracy [31] . NMF and BNMF are adequate when semantic interpretation of hidden factors is needed. NMF is the best choice when we want to be recommended with novel items. BNMF provides good accuracy and it is designed to recommend to group of users. V.	 Conclusions This paper makes a comparative of relevant MF models applied to collaborative filtering recommender systems. Prediction, recommendation, and beyond accuracy quality measures have been tested on four representative datasets. The results show the superiority of the BiasedMF model, followed by the PMF one. BiasedMF arises as the most convenient model when novelty is not a particularly important feature. PMF combines simplicity with accuracy; it can be the best choice for educational or not commercial implementations. NMF and BNMF are adequate when we want to do a semantic interpretation of their non-negative hidden factors. NMF is preferable to BNMF when beyond accuracy (novelty and diversity) results are required, whereas it is better to make use of BNMF when prediction accuracy is required or when recommending to group of users, or when explaining recommendations is needed. NMF and BiasedMF are the best choices when beyond accuracy aims are selected, whereas PMF or BiasedMF performs particularly well in recommendation task, both for unordered and ordered options. BeMF can only be selected when reliability values are required or when they are used to improve accuracy. Finally, URP does not seem to be an adequate choice in any of the combinations tested. As future work, it is proposed to add new MF models, quality measures, and datasets to the experiments, as well as the possibility of including neural network models such as DeepMF or Neural Collaborative Filtering (NCF). PMF 9,4 9,6 9,8 10 10,2 10,4 10 10 10 10 10 11 11 8,6 8,8 9,2 9 9,4 9,6 9,8 06 06 07 07 07 07 07 Novelty Novelty BiasedMF BeMF NMF BNMF URP PMF BiasedMF BeMF NMF BNMF URP PMF Novelty BiasedMF BeMF NMF BNMF URP PMF Number of recommendations Number of recommendations 1 3 5 7 9 1 3 5 7 9 1 3 5 7 9 1 3 5 7 9 Number of recommendations Number of recommendations Novelty BiasedMF BeMF NMF BNMF URP (a) (b) (c) (d) Fig. 5. Novelty beyond accuracy quality results; a) MovieLens100K , b) MovieLens 1M , c) FilmTrust , d) MyAnimeList . The higher the values, the better the results. - 8 - International Journal of Interactive Multimedia and Artificial Intelligence Acknowledgments This work has been co-funded by the Ministerio de Ciencia e Innovaci√≥n of Spain and European Regional Development Fund (FEDER) under grants PID2019-106493RB-I00 (DL-CEMG) and the Comunidad de Madrid under Convenio Plurianual with the Universidad Polit√©cnica de Madrid in the actuation line of Programa de Excelencia para el Profesorado Universitario . References [1] Z. Batmaz, A. Yurekli, A. Bilge, C. Kaleli, ‚ÄúA review on deep learning for recommender systems: challenges and remedies,‚Äù Artificial Intelligence Review , vol. 52, no. 1, pp. 1‚Äì37, 2019. [2] J. Bobadilla, S. Alonso, A. Hernando, ‚ÄúDeep learning architecture for collaborative filtering recommender systems,‚Äù Applied Sciences, vol. 10, no. 7, p. 2441, 2020. [3] B. Zhu, R. Hurtado, J. Bobadilla, F. Ortega, ‚ÄúAn efficient recommender system method based on the numerical relevances and the non-numerical structures of the ratings,‚Äù IEEE Access , vol. 6, pp. 49935‚Äì49954, 2018. [4] J. Bobadilla, R. Lara-Cabrera, √Å. Gonz√°lez-Prieto, F. Ortega, ‚ÄúDeepfair: Deep learning for improving fairness in recommender systems,‚Äù International Journal of Interactive Multimedia and Artificial Intelligence , vol. 6, no. 6, pp. 86‚Äì94, 2021, doi: 10.9781/ijimai.2020.11.001. [5] J. Carb√≥, J. M. Molina, J. D√°vila, ‚ÄúFuzzy referral based cooperation in social networks of agents,‚Äù AI Communications , vol. 18, pp. 1‚Äì13, 2005. 1. [6] D. Medel, C. Gonz√°lez-Gonz√°lez, S. V. Aciar, ‚ÄúSocial relations and methods in recommender systems: A systematic review,‚Äù International Journal of Interactive Multimedia and Artificial Intelligence , vol. 7, no. 4, p. 7, 2022, doi: 10.9781/ijimai.2021.12.004. [7] M. Caro-Mart√≠nez, G. Jim√©nez-D√≠az, J. A. Recio- Garc√≠a, ‚ÄúLocal model- agnostic explanations for black-box recommender systems using interaction graphs and link prediction techniques,‚Äù International Journal of Interactive Multimedia and Artificial Intelligence , vol. InPress, no. InPress, p. 1, 2021, doi: 10.9781/ijimai.2021.12.001. [8] S. Afef, Z. Brahmi, M. Gammoudi, ‚ÄúTrust-based recommender systems: An overview,‚Äù in 27th IBIMA Conference , 05 2016. [9] I. Pinyol, J. Sabater-Mir, ‚ÄúComputational trust and reputation models for open multi-agent systems: a review,‚Äù Artificial Intelligence Review , vol. 40, pp. 1‚Äì25, Jun 2013, doi: 10.1007/s10462-011-9277-z. [10] Y. Deldjoo, M. Schedl, P. Cremonesi, G. Pasi, ‚ÄúRecommender systems leveraging multimedia content,‚Äù ACM Computing Surveys (CSUR) , vol. 53, no. 5, pp. 1‚Äì38, 2020. [11] S. Kulkarni, S. F. Rodd, ‚ÄúContext aware recommendation systems: A review of the state of the art techniques,‚Äù Computer Science Review , vol. 37, p. 100255, 2020. [12] S. Forouzandeh, K. Berahmand, M. Rostami, ‚ÄúPresentation of a recommender system with ensemble learning and graph embedding: a case on movielens,‚Äù Multimedia Tools and Applications , vol. 80, no. 5, pp. 7805‚Äì7832, 2021. [13] R. Salakhutdinov, A. Mnih, ‚ÄúProbabilistic matrix factorization,‚Äù in Proceedings of the 20th International Conference on Neural Information Processing Systems , NIPS‚Äô07, Red Hook, NY, USA, 2007, p. 1257‚Äì1264, Curran Associates Inc. [14] Z. Wu, H. Tian, X. Zhu, S. Wang, ‚ÄúOptimization matrix factorization recommendation algorithm based on rating centrality,‚Äù in International Conference on Data Mining and Big Data , 2018, pp. 114‚Äì125, Springer. [15] C. F√©votte, J. Idier, ‚ÄúAlgorithms for nonnegative matrix factorization with the Œ≤-divergence,‚Äù Neural computation , vol. 23, no. 9, pp. 2421‚Äì2456, 2011. [16] F. Ortega, R. Lara-Cabrera, √Å. Gonz√°lez-Prieto, J. Bobadilla, ‚ÄúProviding reliability in recommender systems through bernoulli matrix factorization,‚Äù Information Sciences , vol. 553, pp. 110‚Äì128, 2021. [17] A. Hernando, J. Bobadilla, F. Ortega, ‚ÄúA non negative matrix factorization for collaborative filtering recommender systems based on a bayesian probabilistic model,‚Äù Knowledge-Based Systems , vol. 97, pp. 188‚Äì202, 2016. [18] B. M. Marlin, ‚ÄúModeling user rating profiles for collaborative filtering,‚Äù Advances in neural information processing systems , vol. 16, 2003. [19] D. M. Blei, A. Y. Ng, M. I. Jordan, ‚ÄúLatent dirichlet allocation,‚Äù Journal of machine Learning research , vol. 3, no. Jan, pp. 993‚Äì1022, 2003. [20] T. Hofmann, ‚ÄúLearning what people (don‚Äôt) want,‚Äù in European Conference on Machine Learning , 2001, pp. 214‚Äì 225, Springer. [21] A. Gunawardana, G. Shani, ‚ÄúEvaluating recommender systems,‚Äù in Recommender systems handbook , Springer, 2015, pp. 265‚Äì308. [22] C. C. Aggarwal, ‚ÄúEvaluating recommender systems,‚Äù in Recommender systems , Springer, 2016, pp. 225‚Äì254. [23] J. Bobadilla, A. Guti√©rrez, S. Alonso, √Å. Gonz√°lez- Prieto, ‚ÄúNeural collaborative filtering classification model to obtain prediction reliabilities,‚Äù International Journal of Interactive Multimedia and Artificial Intelligence , vol. 7, no. 4, pp. 18‚Äì26, 2022, doi: 10.9781/ijimai.2021.08.010. [24] S. Vargas, P. Castells, ‚ÄúRank and relevance in novelty and diversity metrics for recommender systems,‚Äù in Proceedings of the fifth ACM conference on Recommender systems , 2011, pp. 109‚Äì116. [25] P. Castells, S. Vargas, J. Wang, ‚ÄúNovelty and diversity metrics for recommender systems: choice, discovery and relevance,‚Äù in Proceedings of the 33rd European Conference on Information Retrieval (ECIR‚Äô11) , 2011. [26] S. Vargas, P. Castells, D. Vallet, ‚ÄúIntent-oriented diversity in recommender systems,‚Äù in Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval , 2011, pp. 1211‚Äì 1212. [27] F. M. Harper, J. A. Konstan, ‚ÄúThe movielens datasets: History and context,‚Äù Acm transactions on interactive intelligent systems (tiis) , vol. 5, no. 4, pp. 1‚Äì19, 2015, doi: https://doi.org/10.1145/2827872. [28] J. Golbeck, J. A. Hendler, ‚ÄúFilmtrust: movie recommendations using trust in web-based social networks,‚Äù CCNC 2006. 2006 3rd IEEE Consumer Communications and Networking Conference, 2006. , vol. 1, pp. 282‚Äì286, 2006, doi: 10.1109/CCNC.2006.1593032. [29] J. Miller, G. Southern, ‚ÄúRecommender system for animated video,‚Äù Issues in Information Systems , vol. 15, no. 2, pp. 321‚Äì7, 2014. [30] Y. Koren, R. Bell, C. Volinsky, ‚ÄúMatrix factorization techniques for recommender systems,‚Äù Computer , vol. 42, no. 8, pp. 30‚Äì37, 2009. [31] J. Bobadilla, A. Guti√©rrez, S. Alonso, √Å. Gonz√°lez- Prieto, ‚ÄúNeural collaborative filtering classification model to obtain prediction reliabilities,‚Äù International Journal of Interactive Multimedia and Artificial Intelligence , vol. 7, no. 4, pp. 18‚Äì26, 2022, doi: 10.9781/ijimai.2021.08.010. [32] F. Ortega, B. Zhu, J. Bobadilla, A. Hernando, ‚ÄúCf4j: Collaborative filtering for java,‚Äù Knowledge- Based Systems , vol. 152, pp. 94‚Äì99, 2018, doi: https:// doi.org/10.1016/j.knosys.2018.04.008. [33] F. Ortega, J. Mayor, D. L√≥pez-Fern√°ndez, R. Lara- Cabrera, ‚ÄúCf4j 2.0: Adapting collaborative filtering for java to new challenges of collaborative filtering based recommender systems,‚Äù Knowledge-Based Systems , vol. 215, p. 106629, 2021. Jorge Due√±as-Ler√≠n Jorge Due√±as-Ler√≠n received the B.S. in computer science from the Universidad Polit√©cnica de Madrid. He received the M.S. degree in highschool, vocational training and languages teacher from the Universidad Nacional de Educaci√≥n a Distancia. He is currently a Ph.D. student as part of the KNOledge Discovery and Information Systems - KNODIS research group. Jes√∫s Bobadilla Jes√∫s Bobadilla received the B.S. and the Ph.D. degrees in computer science from the Universidad Polit√©cnica de Madrid and the Universidad Carlos III. Currently, he is a full professor with the Department of Applied Intelligent Systems, Universidad Polit√©cnica de Madrid. He is a habitual author of programming languages books working with McGraw-Hill, Ra-Ma and Alfa Omega publishers. His research interests include information retrieval, recommender systems and speech processing. He oversees the FilmAffinity.com research teamworking on the collaborative filtering kernel of the web site. He has been a researcher into the International Computer Science Institute at Berkeley University and into the Sheffield University. - 9 - Article in Press Fernando Ortega Fernando Ortega was born in Madrid, Spain, in 1988. He received the B.S. degree in software engineering, the M.S. degree in artificial intelligence, and the Ph.D. degree in computer sciences from theUniversidad Polit√©cnica de Madrid, in 2010, 2011, and 2015, respectively. He is currently Associate Professor in the Universidad Polit√©cnica de Madrid. He is author of more than 50 research papers in most prestigious international journals. He leads several national projects to include machine learning algorithms into the society. His research interests include machine learning, data analysis, and artificial intelligence. He is the head researcher of the KNOledge Discovery and Information Systems - KNODIS research group. Abraham Guti√©rrez Abraham Guti√©rrez received the B.S. and the Ph.D. degrees in computer science from the Universidad Polit√©cnica de Madrid. Currently, he is currently an associate professor with the Department of Information Systems, Universidad Polit√©cnica de Madrid. He is the author of search papers in most prestigious international journals. He is a habitual author of programming languages books working with McGraw-Hill, Ra-Ma and Alfa Omega publishers. His research interests include P-Systems, machine learning, data analysis and artificial intelligence. He is in charge of this group innovation issues, including the commercial projects. View publication stats",see discussion stats author profile publication httpswwwresearchgatenetpublication comprehensive evaluation matrix factorization model collaborative filtering recommender system article international journal interactive multimedia artificial intelligence january doi ijimai citation read author jesus bobadilla universidad polit√©cnica de publication citation see profile jorge due√±asler√≠n comunidad de publication citation see profile fernando ortega universidad polit√©cnica de publication citation see profile abraham gutierrez universidad la salle m√©xico publication citation see profile content following page uploaded jorge due√±asler√≠n july user requested enhancement downloaded file corresponding author email address jesusbobadillaupmes j bobadilla jorgedlalumnosupmes j due√±asler√¨n fernandoortegaupmes f ortega abrahamgutierrezupmes gutierrez please cite article press j bobadilla j due√±asler√≠n f ortega gutierrez comprehensive evaluation matrix factorization model collaborative filtering recommender system international journal interactive multimedia artificial intelligence httpdxdoiorgijimai keywords collaborative filtering matrix factorization recommender system matrix factorization model core current commercial collaborative filtering recommender system tested six representative matrix factorization model four collaborative filtering datasets experiment tested variety accuracy beyond accuracy quality measure including prediction recommendation ordered unordered list novelty diversity result show convenient matrix factorization attending simplicity required prediction quality necessary recommendation quality desired recommendation novelty diversity need explain recommendation adequacy assigning semantic interpretation hidden factor advisability recommending group user need obtain reliability value ensure reproducibility experiment open framework used implementation code provided doi ijimai comprehensive evaluation matrix factorization model collaborative filtering recommender system jes√∫s bobadilla jorge due√±asler√≠n fernando ortega abraham gutierrez dpt sistemas inform√°ticos knodis research group universidad polit√©cnica de spain received july accepted march early access april r ecommender r field artificial intelligence specialized user personalization mainly rss provide accurate item recommendation user movie trip book music etc recommendation made following filtering accurate filtering collaborative filtering cf recommending active user involves first stage make prediction consumed voted item top predicted item recommended active user cf assumes existence dataset contains explicitly voted item implicitly consumed item large number user remarkable commercial rss amazon spotify netflix tripadvisor regardless machine learning used implement cf key concept extract user item pattern recommend active user item voted consumed similar user highly valued fit k nearest neighbor knn memorybased reason initial r research knn also filtering approach demographic social content contextaware ensemble demographic filtering make use user gender age zip code item movie genre country travel etc social filtering growing importance current r due social network boom existence trust relation graph improve quality cf recommendation decentralized dynamic environment trust user provides additional centralized set rating trust relationship local collective global local shared user opinion collective us friend opinion whereas global relates user reputation content filtering recommends item type content consumed item eg recommend java book programmer bought java book contextaware filtering us gps biometric sensor etc finally ensemble architecture get high accuracy merging several type filtering memorybased algorithm two main drawback accuracy high recommendation process requires recompute whole dataset modelbased approach solve problem accuracy higher memorybased method first create dataset created make many different recommendation efficiently updated dataset change matrix factorization mf popular implement current rss provides accurate prediction conceptually simple straightforward implementation learns fast also update efficiently mf make compression coding sparse large vector discrete value rating low dimensional embeddings real number called hidden factor hidden factor user vector item vector combined mean dot product return prediction iterative process distance training prediction target rating minimized probabilistic matrix factorization pmf mf scale linearly size set also return accurate international journal interactive multimedia artificial intelligence result applied sparse large imbalanced cf datasets pmf also extended include adaptive prior parameter generalize adequately providing accurate recommendation coldstart user cf rss usually biased typical cf bias source come fact user tend highly rate item mainly star whereas user tend restrictive rating mainly star fact lead extension mf handle biased userbased rating centrality itembased rating centrality used improve accuracy regular pmf centrality measure obtained processing degree deviation rating overall rating distribution user item nonnegative matrix factorization nmf extract significant feature sparse nonnegative cf datasets please note cf rating usually nonnegative number star listened song watched movie etc nonnegativity imposed prediction error reduced semantic interpretability hidden factor easier bernoulli matrix factorization bemf designed provide prediction reliability value us bernoulli distribution implement set binary classification approach result binary classification combined mean aggregation process bayesian nonnegative matrix factorization bnmf designed provide useful user group addition pmf prediction result author factorize rating matrix two nonnegative matrix whose component lie within range resulting hidden factor provide understandable probabilistic meaning finally user rating profile urp generative latent variable produce complete rating user profile urp first attitude item generated user attitude item selected set existing attitude urp borrows several concept lda multinomial aspect set mf model mentioned pmf biased matrix factorization biasedmf nmf bemf bnmf urp considered representative cf area model used compare behavior applied representative datasets specifically following quality measure tested mean absolute error mae novelty diversity precision recall normalized discounted cumulative gain ndcg prediction accuracy tested mae whereas ndcg precision recall used test recommendation accuracy modern cf model tested regarding accuracy also beyond accuracy property novelty diversity novelty defined quality avoid redundancy diversity quality help cope ambiguity underspecification model tested four cf datasets movielens k version filmtrust myanimelist representative open datasets popular r research overall provides complete evaluation mf method pmf biasedmf nmf bemf bnmf urp model tested representative cf quality measure prediction recommendation also beyond accuracy one far know experimental complete work evaluating current mf model cf area rest structured follows section ii introduces tested model experiment design selected quality measure chosen datasets section iii show obtained result provides explanation section iv section v highlight main conclusion suggested future work finally reference section list current research area ii method experiment section abstract fundamental baseline pmf biasedmf nmf bemf bnmf urp introduces tested quality measure mae precision recall ndcg novelty diversity show main parameter tested datasets movielens filmtrust myanimelist experiment performed combining previous entity vanilla mf used generate rating prediction matrix rating r matrix contains set casted rating explicit implicit set user u set item since regular user vote consume limited subset available item matrix r sparse mf key concept compress sparse item user vector rating small size dense item user vector real number small size dense vector considered embeddings usually called hidden factor since embedding factor code complex nonlineal hidden relation user item feature parameter k usually chosen set embedding hidden factor size mf make use two matrix p u k contain k hidden factor user q k contain k hidden factor item predict much user u like item compare hidden factor u corresponding hidden factor dot product u used suitable cf prediction measure mf predicts rating minimizing error original r matrix predicted matrix gradient descent minimize learning error difference real rating r predicted rating minimize error differentiate equation respect p uk q ki introducing learning rate Œ± iteratively update required hidden factor p uk q ki cf datasets bias since different user vote consume item different way particular user demanding others rating product service analogously item valued others average biased mf designed consider bias following equation extend previous one introducing bias concept making necessary regularization maintain hidden factor value suitable range Œº b u b average bias user bias item bias article press minimize regularized squared error Œª regularization term obtaining following updating rule nmf considered regular mf subject following constraint nmf prediction made linearly combining positive coefficient hidden factor nmf hidden factor easier semantically interpret regular mf one sometimes straightforward assign semantic meaning negative coefficient value cf context another benefit nmf decomposition emergence natural clustering user item intuitively user item clustered according dominant factor ie factor highest way original feature gender age item type item year etc grouped according factor k hidden factor greatest influence possible due condition positivity coefficient bemf aggregationbased architecture combine set bernoulli factorization result provide pair prediction reliability bemf us many bernoulli factorization process possible score dataset reliability value used detect shilling attack explain recommendation improve prediction recommendation accuracy bemf classification bernoulli distribution adequately adapts expected binary result possible score dataset bemf prediction user u item vector probability probability assigned sth score user u bemf abstracted follows let set possible score dataset eg star r generate distinct matrix matrix sparse matrix bemf attempt fit matrix performing parallel mf bemf assumes given user p matrix item q matrix containing k hidden factor rate r ui bernoulli distribution success probability œà p u q mass function random variable associated likelihood bemf updating equation aggregation obtain final output œÜ let prediction reliability bnmf provides bayesianbased nmf allows accurate prediction user rating also find group user taste well explain recommendation bnmf approximates real posterior distribution distribution random variable categorical distribution random variable binomial distribution take value b hidden matrix follows dirichlet distribution follows beta distribution follows categorical distribution Œª uik parameter learned bnmf iteratively approximates parameter œà digamma function logarithmic derivative gamma function urp generative latent variable assigns user mixture user attitude mixing performed dirichlet random variable international journal interactive multimedia artificial intelligence baseline model tested prediction measure b recommendation measure c beyond accuracy measure chosen prediction measure mae absolute difference error averaged absolute precision relative recall measure tested compare quality unordered list n recommendation ordered list recommendation compared ndcg quality measure beyond accuracy metric selected novelty diversity novelty return distance item user know voted consumed recommended set item diversity tell u distance set recommended item recommendation high novelty value valuable since show user unknown type item diverse recommendation valuable provide different type item type item novel user grouplens research group made available several cf datasets collected different interval time movielens k movielens describe star rating freetext tagging activity created movielens k dataset user selected random rated least movie whereas movielens dataset constraint movie least one rating tag included dataset demographic included user represented id provided dataset file written commaseparated value file single header row column contain comma areescapedusing doublequotes file encoded utf rating contained file named ratingscsv line file header row represents one rating one movie one user following format userid movieid rating timestamp line within file ordered first userid within user movieid timestamps represent second since midnight coordinated universal time utc january filmtrust small dataset crawled entire filmtrust website june movielens datasets contains rating voted user item additionally provides social structured graph network finally myanimelist contains anime otaku consumer anime manga video game computer user able add anime completed list give rating set compilation rating myanimelist cf contained file animecsv main column anime_id myanimelistnets unique id identifying anime name full name anime genre comma separated list genre anime type movie tv ovum etc episode many episode show rating average rating anime datasets available kaggle github repository well knodis research group cfj repository httpsgithubcomferortegacfj contains value main parameter selected cf set movielens k movielens filmtrust myanimelist run explained mf model four datasets testing chosen quality measure please note myanimelist dataset rating range whereas movielens datasets range filmtrust range increment also remarkable sparsity difference filmtrust rest tested datasets main parameter value tested datasets dataset user item rating score sparsity movielensk movielensm myanimelist filmtrust experiment performed random search applying fourfold crossvalidation ensure reproducibility used seed random process result shown average partial result obtained setting number k latent factor number mf iteration additionally run pmf biasedmf bemf model learning rate regularization parameter set bnmf requires two specific parameter Œ± Œ≤ chosen value por parameter Œ± Œ≤ tested number recommendation n range used star recommendation threshold Œ∏ datasets whose rating range testing threshold myanimelist chosen experiment implemented open framework code made available httpsgithubcomknodisresearchgroupchoiceofmfmodels iii result prediction quality obtained testing baseline shown ii bold number correspond best result highlighted gray top one seen biasedmf bnmf model provide best cf prediction result pmf nmf bemf urp seem sensitive type cf input ii prediction quality result mean absolute error mae lower error better pmf biasedmf nmf bemf bnmf urp movielens k movielens filmtrust myanimelist fig show quality recommendation obtained precision measure remarkable fig superiority model pmf biasedmf remaining model urp bemf provide worst result whereas nonnegative nmf bnmf return intermediate quality important highlight good performance biasedmf prediction recommendation task test quality cf recommendation unordered recommendation precision recall measure usually processed provided separately joined f score done experiment found appreciable difference recall value tested model selected datasets order maintain short possible fig show recall result obtained processing movielens dataset result rest datasets similar consequently recall quality measure help context find best mf model cf area article press fig recall recommendation quality result obtained movielens dataset result three considered datasets similar one maintain short possible result datasets shown pmf number recommendation recall biasedmf bemf nmf bnmf urp fig recall recommendation quality result obtained movielens dataset result three considered datasets similar one maintain short possible result datasets shown rss field recommendation usually provided ordered list user trust rss quickly decay first recommendation list meet expectation reason ndcg quality measure particularly penalizes error first recommendation list fig ndcg result show similar behavior fig biasedmf pmf model provide best recommendation quality two model perform fine recommending ordered unordered list traditionally rss evaluated attending prediction recommendation accuracy nevertheless valuable beyond accuracy aim corresponding quality measure diversity measure test variety recommendation penalizing recommendation focused area star war iii star war star war v han solo fig show diversity result obtained testing selected model diverse recommendation usually returned biasedmf used followed pmf nmf fact particularly interesting since intuitive biasedmf simultaneously provide accurate diverse recommendation novelty important beyond accuracy objective rss user appreciate accurate recommendation also want discover unexpected accurate enough recommendation please note set recommendation diverse novel novel diverse would great receive simultaneously accurate novel diverse recommendation usually improving objective lead worsening others fig show result novelty quality measure nmf return novel recommendation compared model nmf provides balance accuracy novelty biasedmf pmf also provide novel recommendation compared bemf urp pmf number recommendation precision biasedmf bemf nmf bnmf urp pmf biasedmf bemf nmf bnmf urp pmf number recommendation precision biasedmf bemf nmf bnmf urp pmf number recommendation number recommendation precision precision biasedmf bemf nmf bnmf urp b c fig precision recommendation quality result movielensk b movielens c filmtrust myanimelist higher value better result international journal interactive multimedia artificial intelligence pmf number recommendation ndcg ndcg biasedmf bemf nmf bnmf urp pmf biasedmf bemf nmf bnmf urp pmf number recommendation ndcg biasedmf bemf nmf bnmf urp pmf number recommendation number recommendation ndcg biasedmf bemf nmf bnmf urp b c fig normalized discounted cumulative gain recommendation quality result movielensk b movielens c filmtrust myanimelist higher value better result pmf diversity diversity biasedmf bemf nmf bnmf urp pmf biasedmf bemf nmf bnmf urp pmf diversity biasedmf bemf nmf bnmf urp pmf number recommendation number recommendation number recommendation number recommendation diversity biasedmf bemf nmf bnmf urp b c fig diversity beyond accuracy result movielensk b movielens c filmtrust myanimelist higher value better result article press iv discussion section provide comparative discussion adequate mf model applied set different cf database judge mf simultaneously measure set conflicting goal prediction accuracy recommendation accuracy unordered ordered list beyond accuracy aim promote mf model winner attending high performance overall quality result applied tested datasets also provide summary better identify mf model perform particularly fine individual quality objective novelty diversity precision etc well combination quality measure iii mf model comparative pmf biasedmf nmf bemf bnmf urp mae precision ndcg diversity novelty total iii summarizes result section biasedmf appropriate novelty recommendation particularly relevant issue pmf used instead biasedmf simplicity required eg educational environment bemf used reliability required reliability value used improve accuracy nmf bnmf adequate semantic interpretation hidden factor needed nmf best choice want recommended novel item bnmf provides good accuracy designed recommend group user v conclusion make comparative relevant mf model applied collaborative filtering recommender system prediction recommendation beyond accuracy quality measure tested four representative datasets result show superiority biasedmf followed pmf one biasedmf arises convenient novelty particularly important feature pmf combine simplicity accuracy best choice educational commercial implementation nmf bnmf adequate want semantic interpretation nonnegative hidden factor nmf preferable bnmf beyond accuracy novelty diversity result required whereas better make use bnmf prediction accuracy required recommending group user explaining recommendation needed nmf biasedmf best choice beyond accuracy aim selected whereas pmf biasedmf performs particularly well recommendation task unordered ordered option bemf selected reliability value required used improve accuracy finally urp seem adequate choice combination tested future work proposed add new mf model quality measure datasets experiment well possibility including neural network model deepmf neural collaborative filtering ncf pmf novelty novelty biasedmf bemf nmf bnmf urp pmf biasedmf bemf nmf bnmf urp pmf novelty biasedmf bemf nmf bnmf urp pmf number recommendation number recommendation number recommendation number recommendation novelty biasedmf bemf nmf bnmf urp b c fig novelty beyond accuracy quality result movielensk b movielens c filmtrust myanimelist higher value better result international journal interactive multimedia artificial intelligence acknowledgment work cofunded ministerio de ciencia e innovaci√≥n spain european regional development fund feder grant pidrbi dlcemg comunidad de convenio plurianual universidad polit√©cnica de actuation line programa de excelencia para el profesorado universitario reference z batmaz yurekli bilge c kaleli review deep learning recommender system challenge remedy artificial intelligence review vol pp j bobadilla alonso hernando deep learning architecture collaborative filtering recommender system applied science vol p b zhu r hurtado j bobadilla f ortega efficient recommender numerical relevance nonnumerical structure rating ieee access vol pp j bobadilla r laracabrera √° gonz√°lezprieto f ortega deepfair deep learning improving fairness recommender system international journal interactive multimedia artificial intelligence vol pp doi ijimai j carb√≥ j molina j d√°vila fuzzy referral cooperation social network agent ai communication vol pp medel c gonz√°lezgonz√°lez v aciar social relation method recommender system systematic review international journal interactive multimedia artificial intelligence vol p doi ijimai caromart√≠nez g jim√©nezd√≠az j recio garc√≠a local agnostic explanation blackbox recommender system interaction graph link prediction technique international journal interactive multimedia artificial intelligence vol inpress inpress p doi ijimai afef z brahmi gammoudi trustbased recommender system overview th ibima conference pinyol j sabatermir computational trust reputation model open multiagent system review artificial intelligence review vol pp jun doi sz deldjoo schedl p cremonesi g pasi recommender system leveraging multimedia content acm computing survey csur vol pp kulkarni f rodd context aware recommendation system review state art technique computer science review vol p forouzandeh k berahmand rostami presentation recommender ensemble learning graph embedding movielens multimedia tool application vol pp r salakhutdinov mnih probabilistic matrix factorization proceeding th international conference neural processing system nip red hook ny usa p curran associate inc z wu h tian x zhu wang optimization matrix factorization recommendation rating centrality international conference mining big pp springer c f√©votte j idier algorithm nonnegative matrix factorization Œ≤divergence neural computation vol pp f ortega r laracabrera √° gonz√°lezprieto j bobadilla providing reliability recommender system bernoulli matrix factorization science vol pp hernando j bobadilla f ortega non negative matrix factorization collaborative filtering recommender system bayesian probabilistic knowledgebased system vol pp b marlin modeling user rating profile collaborative filtering advance neural processing system vol blei ng jordan latent dirichlet allocation journal machine learning research vol jan pp hofmann learning people dont want european conference machine learning pp springer gunawardana g shani evaluating recommender system recommender system handbook springer pp c c aggarwal evaluating recommender system recommender system springer pp j bobadilla guti√©rrez alonso √° gonz√°lez prieto neural collaborative filtering classification obtain prediction reliability international journal interactive multimedia artificial intelligence vol pp doi ijimai vargas p castells rank relevance novelty diversity metric recommender system proceeding fifth acm conference recommender system pp p castells vargas j wang novelty diversity metric recommender system choice discovery relevance proceeding rd european conference retrieval ecir vargas p castells vallet intentoriented diversity recommender system proceeding th international acm sigir conference research development retrieval pp f harper j konstan movielens datasets history context acm transaction interactive intelligent system tiis vol pp doi httpsdoiorg j golbeck j hendler filmtrust movie recommendation trust webbased social network ccnc rd ieee consumer communication networking conference vol pp doi ccnc j miller g southern recommender animated video issue system vol pp koren r bell c volinsky matrix factorization technique recommender system computer vol pp j bobadilla guti√©rrez alonso √° gonz√°lez prieto neural collaborative filtering classification obtain prediction reliability international journal interactive multimedia artificial intelligence vol pp doi ijimai f ortega b zhu j bobadilla hernando cfj collaborative filtering java knowledge system vol pp doi http doiorgjknosys f ortega j mayor l√≥pezfern√°ndez r lara cabrera cfj adapting collaborative filtering java new challenge collaborative filtering recommender system knowledgebased system vol p jorge due√±asler√≠n jorge due√±asler√≠n received b computer science universidad polit√©cnica de received m degree highschool vocational training language teacher universidad nacional de educaci√≥n distancia currently phd student part knoledge discovery system knodis research group jes√∫s bobadilla jes√∫s bobadilla received b phd degree computer science universidad polit√©cnica de universidad carlos iii currently full professor department applied intelligent system universidad polit√©cnica de habitual author programming language book working mcgrawhill rama alfa omega publisher research interest include retrieval recommender system speech processing oversees filmaffinitycom research teamworking collaborative filtering kernel web site researcher international computer science institute berkeley university sheffield university article press fernando ortega fernando ortega born spain received b degree software engineering m degree artificial intelligence phd degree computer science theuniversidad polit√©cnica de respectively currently associate professor universidad polit√©cnica de author research paper prestigious international journal lead several national project include machine learning algorithm society research interest include machine learning artificial intelligence head researcher knoledge discovery system knodis research group abraham guti√©rrez abraham guti√©rrez received b phd degree computer science universidad polit√©cnica de currently currently associate professor department system universidad polit√©cnica de author search paper prestigious international journal habitual author programming language book working mcgrawhill rama alfa omega publisher research interest include psystems machine learning artificial intelligence charge group innovation issue including commercial project view publication stats,comprehensive evaluation matrix factorization model collaborative filtering recommender system keywords comprehensive evaluation matrix factorization model collaborative filtering recommender system r,,comprehensive evaluation matrix factorization model collaborative filtering recommender system keywords comprehensive evaluation matrix factorization model collaborative filtering recommender system r comprehensive evaluation matrix factorization model collaborative filtering recommender system keywords comprehensive evaluation matrix factorization model collaborative filtering recommender system r comprehensive evaluation matrix factorization model collaborative filtering recommender system keywords comprehensive evaluation matrix factorization model collaborative filtering recommender system r nan nan see discussion stats author profile publication httpswwwresearchgatenetpublication comprehensive evaluation matrix factorization model collaborative filtering recommender system article international journal interactive multimedia artificial intelligence january doi ijimai citation read author jesus bobadilla universidad polit√©cnica de publication citation see profile jorge due√±asler√≠n comunidad de publication citation see profile fernando ortega universidad polit√©cnica de publication citation see profile abraham gutierrez universidad la salle m√©xico publication citation see profile content following page uploaded jorge due√±asler√≠n july user requested enhancement downloaded file corresponding author email address jesusbobadillaupmes j bobadilla jorgedlalumnosupmes j due√±asler√¨n fernandoortegaupmes f ortega abrahamgutierrezupmes gutierrez please cite article press j bobadilla j due√±asler√≠n f ortega gutierrez comprehensive evaluation matrix factorization model collaborative filtering recommender system international journal interactive multimedia artificial intelligence httpdxdoiorgijimai keywords collaborative filtering matrix factorization recommender system matrix factorization model core current commercial collaborative filtering recommender system tested six representative matrix factorization model four collaborative filtering datasets experiment tested variety accuracy beyond accuracy quality measure including prediction recommendation ordered unordered list novelty diversity result show convenient matrix factorization attending simplicity required prediction quality necessary recommendation quality desired recommendation novelty diversity need explain recommendation adequacy assigning semantic interpretation hidden factor advisability recommending group user need obtain reliability value ensure reproducibility experiment open framework used implementation code provided doi ijimai comprehensive evaluation matrix factorization model collaborative filtering recommender system jes√∫s bobadilla jorge due√±asler√≠n fernando ortega abraham gutierrez dpt sistemas inform√°ticos knodis research group universidad polit√©cnica de spain received july accepted march early access april r ecommender r field artificial intelligence specialized user personalization mainly rss provide accurate item recommendation user movie trip book music etc recommendation made following filtering accurate filtering collaborative filtering cf recommending active user involves first stage make prediction consumed voted item top predicted item recommended active user cf assumes existence dataset contains explicitly voted item implicitly consumed item large number user remarkable commercial rss amazon spotify netflix tripadvisor regardless machine learning used implement cf key concept extract user item pattern recommend active user item voted consumed similar user highly valued fit k nearest neighbor knn memorybased reason initial r research knn also filtering approach demographic social content contextaware ensemble demographic filtering make use user gender age zip code item movie genre country travel etc social filtering growing importance current r due social network boom existence trust relation graph improve quality cf recommendation decentralized dynamic environment trust user provides additional centralized set rating trust relationship local collective global local shared user opinion collective us friend opinion whereas global relates user reputation content filtering recommends item type content consumed item eg recommend java book programmer bought java book contextaware filtering us gps biometric sensor etc finally ensemble architecture get high accuracy merging several type filtering memorybased algorithm two main drawback accuracy high recommendation process requires recompute whole dataset modelbased approach solve problem accuracy higher memorybased method first create dataset created make many different recommendation efficiently updated dataset change matrix factorization mf popular implement current rss provides accurate prediction conceptually simple straightforward implementation learns fast also update efficiently mf make compression coding sparse large vector discrete value rating low dimensional embeddings real number called hidden factor hidden factor user vector item vector combined mean dot product return prediction iterative process distance training prediction target rating minimized probabilistic matrix factorization pmf mf scale linearly size set also return accurate international journal interactive multimedia artificial intelligence result applied sparse large imbalanced cf datasets pmf also extended include adaptive prior parameter generalize adequately providing accurate recommendation coldstart user cf rss usually biased typical cf bias source come fact user tend highly rate item mainly star whereas user tend restrictive rating mainly star fact lead extension mf handle biased userbased rating centrality itembased rating centrality used improve accuracy regular pmf centrality measure obtained processing degree deviation rating overall rating distribution user item nonnegative matrix factorization nmf extract significant feature sparse nonnegative cf datasets please note cf rating usually nonnegative number star listened song watched movie etc nonnegativity imposed prediction error reduced semantic interpretability hidden factor easier bernoulli matrix factorization bemf designed provide prediction reliability value us bernoulli distribution implement set binary classification approach result binary classification combined mean aggregation process bayesian nonnegative matrix factorization bnmf designed provide useful user group addition pmf prediction result author factorize rating matrix two nonnegative matrix whose component lie within range resulting hidden factor provide understandable probabilistic meaning finally user rating profile urp generative latent variable produce complete rating user profile urp first attitude item generated user attitude item selected set existing attitude urp borrows several concept lda multinomial aspect set mf model mentioned pmf biased matrix factorization biasedmf nmf bemf bnmf urp considered representative cf area model used compare behavior applied representative datasets specifically following quality measure tested mean absolute error mae novelty diversity precision recall normalized discounted cumulative gain ndcg prediction accuracy tested mae whereas ndcg precision recall used test recommendation accuracy modern cf model tested regarding accuracy also beyond accuracy property novelty diversity novelty defined quality avoid redundancy diversity quality help cope ambiguity underspecification model tested four cf datasets movielens k version filmtrust myanimelist representative open datasets popular r research overall provides complete evaluation mf method pmf biasedmf nmf bemf bnmf urp model tested representative cf quality measure prediction recommendation also beyond accuracy one far know experimental complete work evaluating current mf model cf area rest structured follows section ii introduces tested model experiment design selected quality measure chosen datasets section iii show obtained result provides explanation section iv section v highlight main conclusion suggested future work finally reference section list current research area ii method experiment section abstract fundamental baseline pmf biasedmf nmf bemf bnmf urp introduces tested quality measure mae precision recall ndcg novelty diversity show main parameter tested datasets movielens filmtrust myanimelist experiment performed combining previous entity vanilla mf used generate rating prediction matrix rating r matrix contains set casted rating explicit implicit set user u set item since regular user vote consume limited subset available item matrix r sparse mf key concept compress sparse item user vector rating small size dense item user vector real number small size dense vector considered embeddings usually called hidden factor since embedding factor code complex nonlineal hidden relation user item feature parameter k usually chosen set embedding hidden factor size mf make use two matrix p u k contain k hidden factor user q k contain k hidden factor item predict much user u like item compare hidden factor u corresponding hidden factor dot product u used suitable cf prediction measure mf predicts rating minimizing error original r matrix predicted matrix gradient descent minimize learning error difference real rating r predicted rating minimize error differentiate equation respect p uk q ki introducing learning rate Œ± iteratively update required hidden factor p uk q ki cf datasets bias since different user vote consume item different way particular user demanding others rating product service analogously item valued others average biased mf designed consider bias following equation extend previous one introducing bias concept making necessary regularization maintain hidden factor value suitable range Œº b u b average bias user bias item bias article press minimize regularized squared error Œª regularization term obtaining following updating rule nmf considered regular mf subject following constraint nmf prediction made linearly combining positive coefficient hidden factor nmf hidden factor easier semantically interpret regular mf one sometimes straightforward assign semantic meaning negative coefficient value cf context another benefit nmf decomposition emergence natural clustering user item intuitively user item clustered according dominant factor ie factor highest way original feature gender age item type item year etc grouped according factor k hidden factor greatest influence possible due condition positivity coefficient bemf aggregationbased architecture combine set bernoulli factorization result provide pair prediction reliability bemf us many bernoulli factorization process possible score dataset reliability value used detect shilling attack explain recommendation improve prediction recommendation accuracy bemf classification bernoulli distribution adequately adapts expected binary result possible score dataset bemf prediction user u item vector probability probability assigned sth score user u bemf abstracted follows let set possible score dataset eg star r generate distinct matrix matrix sparse matrix bemf attempt fit matrix performing parallel mf bemf assumes given user p matrix item q matrix containing k hidden factor rate r ui bernoulli distribution success probability œà p u q mass function random variable associated likelihood bemf updating equation aggregation obtain final output œÜ let prediction reliability bnmf provides bayesianbased nmf allows accurate prediction user rating also find group user taste well explain recommendation bnmf approximates real posterior distribution distribution random variable categorical distribution random variable binomial distribution take value b hidden matrix follows dirichlet distribution follows beta distribution follows categorical distribution Œª uik parameter learned bnmf iteratively approximates parameter œà digamma function logarithmic derivative gamma function urp generative latent variable assigns user mixture user attitude mixing performed dirichlet random variable international journal interactive multimedia artificial intelligence baseline model tested prediction measure b recommendation measure c beyond accuracy measure chosen prediction measure mae absolute difference error averaged absolute precision relative recall measure tested compare quality unordered list n recommendation ordered list recommendation compared ndcg quality measure beyond accuracy metric selected novelty diversity novelty return distance item user know voted consumed recommended set item diversity tell u distance set recommended item recommendation high novelty value valuable since show user unknown type item diverse recommendation valuable provide different type item type item novel user grouplens research group made available several cf datasets collected different interval time movielens k movielens describe star rating freetext tagging activity created movielens k dataset user selected random rated least movie whereas movielens dataset constraint movie least one rating tag included dataset demographic included user represented id provided dataset file written commaseparated value file single header row column contain comma areescapedusing doublequotes file encoded utf rating contained file named ratingscsv line file header row represents one rating one movie one user following format userid movieid rating timestamp line within file ordered first userid within user movieid timestamps represent second since midnight coordinated universal time utc january filmtrust small dataset crawled entire filmtrust website june movielens datasets contains rating voted user item additionally provides social structured graph network finally myanimelist contains anime otaku consumer anime manga video game computer user able add anime completed list give rating set compilation rating myanimelist cf contained file animecsv main column anime_id myanimelistnets unique id identifying anime name full name anime genre comma separated list genre anime type movie tv ovum etc episode many episode show rating average rating anime datasets available kaggle github repository well knodis research group cfj repository httpsgithubcomferortegacfj contains value main parameter selected cf set movielens k movielens filmtrust myanimelist run explained mf model four datasets testing chosen quality measure please note myanimelist dataset rating range whereas movielens datasets range filmtrust range increment also remarkable sparsity difference filmtrust rest tested datasets main parameter value tested datasets dataset user item rating score sparsity movielensk movielensm myanimelist filmtrust experiment performed random search applying fourfold crossvalidation ensure reproducibility used seed random process result shown average partial result obtained setting number k latent factor number mf iteration additionally run pmf biasedmf bemf model learning rate regularization parameter set bnmf requires two specific parameter Œ± Œ≤ chosen value por parameter Œ± Œ≤ tested number recommendation n range used star recommendation threshold Œ∏ datasets whose rating range testing threshold myanimelist chosen experiment implemented open framework code made available httpsgithubcomknodisresearchgroupchoiceofmfmodels iii result prediction quality obtained testing baseline shown ii bold number correspond best result highlighted gray top one seen biasedmf bnmf model provide best cf prediction result pmf nmf bemf urp seem sensitive type cf input ii prediction quality result mean absolute error mae lower error better pmf biasedmf nmf bemf bnmf urp movielens k movielens filmtrust myanimelist fig show quality recommendation obtained precision measure remarkable fig superiority model pmf biasedmf remaining model urp bemf provide worst result whereas nonnegative nmf bnmf return intermediate quality important highlight good performance biasedmf prediction recommendation task test quality cf recommendation unordered recommendation precision recall measure usually processed provided separately joined f score done experiment found appreciable difference recall value tested model selected datasets order maintain short possible fig show recall result obtained processing movielens dataset result rest datasets similar consequently recall quality measure help context find best mf model cf area article press fig recall recommendation quality result obtained movielens dataset result three considered datasets similar one maintain short possible result datasets shown pmf number recommendation recall biasedmf bemf nmf bnmf urp fig recall recommendation quality result obtained movielens dataset result three considered datasets similar one maintain short possible result datasets shown rss field recommendation usually provided ordered list user trust rss quickly decay first recommendation list meet expectation reason ndcg quality measure particularly penalizes error first recommendation list fig ndcg result show similar behavior fig biasedmf pmf model provide best recommendation quality two model perform fine recommending ordered unordered list traditionally rss evaluated attending prediction recommendation accuracy nevertheless valuable beyond accuracy aim corresponding quality measure diversity measure test variety recommendation penalizing recommendation focused area star war iii star war star war v han solo fig show diversity result obtained testing selected model diverse recommendation usually returned biasedmf used followed pmf nmf fact particularly interesting since intuitive biasedmf simultaneously provide accurate diverse recommendation novelty important beyond accuracy objective rss user appreciate accurate recommendation also want discover unexpected accurate enough recommendation please note set recommendation diverse novel novel diverse would great receive simultaneously accurate novel diverse recommendation usually improving objective lead worsening others fig show result novelty quality measure nmf return novel recommendation compared model nmf provides balance accuracy novelty biasedmf pmf also provide novel recommendation compared bemf urp pmf number recommendation precision biasedmf bemf nmf bnmf urp pmf biasedmf bemf nmf bnmf urp pmf number recommendation precision biasedmf bemf nmf bnmf urp pmf number recommendation number recommendation precision precision biasedmf bemf nmf bnmf urp b c fig precision recommendation quality result movielensk b movielens c filmtrust myanimelist higher value better result international journal interactive multimedia artificial intelligence pmf number recommendation ndcg ndcg biasedmf bemf nmf bnmf urp pmf biasedmf bemf nmf bnmf urp pmf number recommendation ndcg biasedmf bemf nmf bnmf urp pmf number recommendation number recommendation ndcg biasedmf bemf nmf bnmf urp b c fig normalized discounted cumulative gain recommendation quality result movielensk b movielens c filmtrust myanimelist higher value better result pmf diversity diversity biasedmf bemf nmf bnmf urp pmf biasedmf bemf nmf bnmf urp pmf diversity biasedmf bemf nmf bnmf urp pmf number recommendation number recommendation number recommendation number recommendation diversity biasedmf bemf nmf bnmf urp b c fig diversity beyond accuracy result movielensk b movielens c filmtrust myanimelist higher value better result article press iv discussion section provide comparative discussion adequate mf model applied set different cf database judge mf simultaneously measure set conflicting goal prediction accuracy recommendation accuracy unordered ordered list beyond accuracy aim promote mf model winner attending high performance overall quality result applied tested datasets also provide summary better identify mf model perform particularly fine individual quality objective novelty diversity precision etc well combination quality measure iii mf model comparative pmf biasedmf nmf bemf bnmf urp mae precision ndcg diversity novelty total iii summarizes result section biasedmf appropriate novelty recommendation particularly relevant issue pmf used instead biasedmf simplicity required eg educational environment bemf used reliability required reliability value used improve accuracy nmf bnmf adequate semantic interpretation hidden factor needed nmf best choice want recommended novel item bnmf provides good accuracy designed recommend group user v conclusion make comparative relevant mf model applied collaborative filtering recommender system prediction recommendation beyond accuracy quality measure tested four representative datasets result show superiority biasedmf followed pmf one biasedmf arises convenient novelty particularly important feature pmf combine simplicity accuracy best choice educational commercial implementation nmf bnmf adequate want semantic interpretation nonnegative hidden factor nmf preferable bnmf beyond accuracy novelty diversity result required whereas better make use bnmf prediction accuracy required recommending group user explaining recommendation needed nmf biasedmf best choice beyond accuracy aim selected whereas pmf biasedmf performs particularly well recommendation task unordered ordered option bemf selected reliability value required used improve accuracy finally urp seem adequate choice combination tested future work proposed add new mf model quality measure datasets experiment well possibility including neural network model deepmf neural collaborative filtering ncf pmf novelty novelty biasedmf bemf nmf bnmf urp pmf biasedmf bemf nmf bnmf urp pmf novelty biasedmf bemf nmf bnmf urp pmf number recommendation number recommendation number recommendation number recommendation novelty biasedmf bemf nmf bnmf urp b c fig novelty beyond accuracy quality result movielensk b movielens c filmtrust myanimelist higher value better result international journal interactive multimedia artificial intelligence acknowledgment work cofunded ministerio de ciencia e innovaci√≥n spain european regional development fund feder grant pidrbi dlcemg comunidad de convenio plurianual universidad polit√©cnica de actuation line programa de excelencia para el profesorado universitario reference z batmaz yurekli bilge c kaleli review deep learning recommender system challenge remedy artificial intelligence review vol pp j bobadilla alonso hernando deep learning architecture collaborative filtering recommender system applied science vol p b zhu r hurtado j bobadilla f ortega efficient recommender numerical relevance nonnumerical structure rating ieee access vol pp j bobadilla r laracabrera √° gonz√°lezprieto f ortega deepfair deep learning improving fairness recommender system international journal interactive multimedia artificial intelligence vol pp doi ijimai j carb√≥ j molina j d√°vila fuzzy referral cooperation social network agent ai communication vol pp medel c gonz√°lezgonz√°lez v aciar social relation method recommender system systematic review international journal interactive multimedia artificial intelligence vol p doi ijimai caromart√≠nez g jim√©nezd√≠az j recio garc√≠a local agnostic explanation blackbox recommender system interaction graph link prediction technique international journal interactive multimedia artificial intelligence vol inpress inpress p doi ijimai afef z brahmi gammoudi trustbased recommender system overview th ibima conference pinyol j sabatermir computational trust reputation model open multiagent system review artificial intelligence review vol pp jun doi sz deldjoo schedl p cremonesi g pasi recommender system leveraging multimedia content acm computing survey csur vol pp kulkarni f rodd context aware recommendation system review state art technique computer science review vol p forouzandeh k berahmand rostami presentation recommender ensemble learning graph embedding movielens multimedia tool application vol pp r salakhutdinov mnih probabilistic matrix factorization proceeding th international conference neural processing system nip red hook ny usa p curran associate inc z wu h tian x zhu wang optimization matrix factorization recommendation rating centrality international conference mining big pp springer c f√©votte j idier algorithm nonnegative matrix factorization Œ≤divergence neural computation vol pp f ortega r laracabrera √° gonz√°lezprieto j bobadilla providing reliability recommender system bernoulli matrix factorization science vol pp hernando j bobadilla f ortega non negative matrix factorization collaborative filtering recommender system bayesian probabilistic knowledgebased system vol pp b marlin modeling user rating profile collaborative filtering advance neural processing system vol blei ng jordan latent dirichlet allocation journal machine learning research vol jan pp hofmann learning people dont want european conference machine learning pp springer gunawardana g shani evaluating recommender system recommender system handbook springer pp c c aggarwal evaluating recommender system recommender system springer pp j bobadilla guti√©rrez alonso √° gonz√°lez prieto neural collaborative filtering classification obtain prediction reliability international journal interactive multimedia artificial intelligence vol pp doi ijimai vargas p castells rank relevance novelty diversity metric recommender system proceeding fifth acm conference recommender system pp p castells vargas j wang novelty diversity metric recommender system choice discovery relevance proceeding rd european conference retrieval ecir vargas p castells vallet intentoriented diversity recommender system proceeding th international acm sigir conference research development retrieval pp f harper j konstan movielens datasets history context acm transaction interactive intelligent system tiis vol pp doi httpsdoiorg j golbeck j hendler filmtrust movie recommendation trust webbased social network ccnc rd ieee consumer communication networking conference vol pp doi ccnc j miller g southern recommender animated video issue system vol pp koren r bell c volinsky matrix factorization technique recommender system computer vol pp j bobadilla guti√©rrez alonso √° gonz√°lez prieto neural collaborative filtering classification obtain prediction reliability international journal interactive multimedia artificial intelligence vol pp doi ijimai f ortega b zhu j bobadilla hernando cfj collaborative filtering java knowledge system vol pp doi http doiorgjknosys f ortega j mayor l√≥pezfern√°ndez r lara cabrera cfj adapting collaborative filtering java new challenge collaborative filtering recommender system knowledgebased system vol p jorge due√±asler√≠n jorge due√±asler√≠n received b computer science universidad polit√©cnica de received m degree highschool vocational training language teacher universidad nacional de educaci√≥n distancia currently phd student part knoledge discovery system knodis research group jes√∫s bobadilla jes√∫s bobadilla received b phd degree computer science universidad polit√©cnica de universidad carlos iii currently full professor department applied intelligent system universidad polit√©cnica de habitual author programming language book working mcgrawhill rama alfa omega publisher research interest include retrieval recommender system speech processing oversees filmaffinitycom research teamworking collaborative filtering kernel web site researcher international computer science institute berkeley university sheffield university article press fernando ortega fernando ortega born spain received b degree software engineering m degree artificial intelligence phd degree computer science theuniversidad polit√©cnica de respectively currently associate professor universidad polit√©cnica de author research paper prestigious international journal lead several national project include machine learning algorithm society research interest include machine learning artificial intelligence head researcher knoledge discovery system knodis research group abraham guti√©rrez abraham guti√©rrez received b phd degree computer science universidad polit√©cnica de currently currently associate professor department system universidad polit√©cnica de author search paper prestigious international journal habitual author programming language book working mcgrawhill rama alfa omega publisher research interest include psystems machine learning artificial intelligence charge group innovation issue including commercial project view publication stats,2,nmf bnmf and hidden factor in number
Recommender systems survey.pdf,Recommender systems survey | Knowledge-Based Systems,Recommender systems,"Recommender systems survey J. Bobadilla ‚áë , F. Ortega, A. Hernando, A. Guti√©rrez Universidad Polit√©cnica de Madrid, Ctra. De Valencia, Km. 7, 28031 Madrid, Spain a r t i c l e i n f o Article history: Received 7 October 2012 Received in revised form 4 March 2013 Accepted 19 March 2013 Available online 6 April 2013 Keywords: Recommender systems Collaborative Ô¨Åltering Similarity measures Evaluation metrics Prediction Recommendation Hybrid Social Internet of things Cold-start a b s t r a c t Recommender systems have developed in parallel with the web. They were initially based on demo- graphic, content-based and collaborative Ô¨Åltering. Currently, these systems are incorporating social infor- mation. In the future, they will use implicit, local and personal information from the Internet of things. This article provides an overview of recommender systems as well as collaborative Ô¨Åltering methods and algorithms; it also explains their evolution, provides an original classiÔ¨Åcation for these systems, iden- tiÔ¨Åes areas of future implementation and develops certain areas selected for past, present or future importance.  2013 Elsevier B.V. All rights reserved. 1. Introduction Recommender Systems (RSs) collect information on the prefer- ences of its users for a set of items (e.g., movies, songs, books, jokes, gadgets, applications, websites, travel destinations and e-learning material). The information can be acquired explicitly (typically by collecting users‚Äô ratings) or implicitly [134,60,164] (typically by monitoring users‚Äô behavior, such as songs heard, applications downloaded, web sites visited and books read). RS may use demo- graphic features of users (like age, nationality, gender). Social information, like followers, followed, twits, and posts, is commonly used in Web 2.0. There is a growing tend towards the use of infor- mation from Internet of things (e.g., GPS locations, RFID, real-time health signals). RS make use of different sources of information for providing users with predictions and recommendations of items. They try to balance factors like accuracy, novelty, dispersity and stability in the recommendations. Collaborative Filtering (CF) methods play an important role in the recommendation, although they are often used along with other Ô¨Ålterning techniques like content-based, knowledge-based or social ones. CF is based on the way in which humans have made decisions throughout history: besides on our own experiences, we also base our decisions on the experiences and knowledge that reach each of us from a relatively large group of acquaintances. Recently, RS implementation in the Internet has increased, which has facilitated its use in diverse areas [171] . The most com- mon research papers are focused on movie recommendation stud- ies [53,230] ; however, a great volume of literature for RS is centered on different topics, such as music [134,162,216] , televi- sion [238,18] , books [164,88] , documents [206,184,183,185] , e- learning [241,30] , e-commerce [104,54] , applications in markets [67] and web search [154] , among others. The kinds of Ô¨Åltering most used at the beginning of the RS (col- laborative, content-based and demographic) were described in [177] . Breese et al. [43] evaluated the predictive accuracy of differ- ent algorithms for CF; later, the classical paper [94] describes the base for evaluating the Collaborative Filtering RS. The evolution of RS has shown the importance of hybrid tech- niques of RS, which merge different techniques in order to get the advantages of each of them. A survey focused on the hybrid RS has been presented in [47] . However, it does not deal with the role of social-Ô¨Åltering, a technique which has become more popular in the recent years through social networks. The neighborhood-based CF has been the recommendation method most popular at the beginning of the RS; Herlocker et al. [93] provides a set of guidelines for designing neighborhood-based prediction systems. Adomavicius and Tuzhilin [3] present an over- view on the RS Ô¨Åeld standing out the most complex areas on which 0950-7051/$ - see front matter  2013 Elsevier B.V. All rights reserved. http://dx.doi.org/10.1016/j.knosys.2013.03.012 ‚áë Corresponding author. Tel.: +34 913365133; fax: +34 913367527. E-mail address: jesus.bobadilla@upm.es (J. Bobadilla). Knowledge-Based Systems 46 (2013) 109‚Äì132 Contents lists available at SciVerse ScienceDirect Knowledge-Based Systems journal homepage: www.elsevier.com/locate/knosys researchers in RS should focus in the ‚Äò‚Äònext generation of RS‚Äô‚Äô: lim- ited content analysis and overspecialization in content-based methods, cold-start and sparsity in CF methods, model-based tech- niques, nonintrusiveness, Ô¨Çexibility (real-time customization), etc. While researchers have been developing RS, different survey papers have been published summarizing the most important is- sues in this Ô¨Åeld. In view of the impossibility of showing every de- tail of all these techniques in just a paper, this publication selects those issues the authors have felt most suitable to understand the evolution of RS. While the existing surveys focus on the most relevant methods and algorithms of the RS Ô¨Åeld, our survey instead tries to enhance the evolution of the RS: from a Ô¨Årst phase based on the tradi- tional Web to the present second phase based on social Web, which is presently progressing to a third phase (Internet of things). With the purpose of being useful to the new readers of RS Ô¨Åeld, we have included in this survey some traditional topics: RS foundations, k -Nearest Neighbors algorithm, cold-start issues, similarity measures, and evaluation of RS. The rest of the paper deals with novel topics that existing surveys do not consider. Through this survey, advanced readers in RS will study in depth concepts, classiÔ¨Åcations and approaches related to social informa- tion (social Ô¨Åltering: followers, followed, trust, reputation, credi- bility, content-based Ô¨Åltering of social data; social tagging and taxonomies), recommending to groups of users and explaining recommendations. Readers interested in brand new and future applications will Ô¨Ånd this survey useful since it informs about the most recent works in location-aware RS trends and bio-in- spired approaches. They will also discover some important issues, such as privacy, security, P2P information and Internet of things use (RFID data, health parameters, surveillance data, teleopera- tion, telepresence, etc.). According to the idea that RS tend to make use of different sources of information (collaborative, social, demographic, content, knowledge-based, geographic, sensors, tags, implicit and explicit data acquisition, etc.), this survey emphasizes hybrid architectures, based on making recommendations through different known tech- nologies (each one designed on behalf of a speciÔ¨Åc source of information). Much of the quality of a survey can be measured by an appro- priate choice of its references. This survey contains 249 references systematically obtained, which have been selected taking into ac- count factors like the number of recent citations and the impor- tance of the journal in which the paper has been published. The remainder of this article is structured as follows: In Sec- tion 2 , we explain concisely the methodology used to select the most signiÔ¨Åcative papers on the RS Ô¨Åeld. Section 3 describes the RS foundations: methods, algorithms and models used for provid- ing recommendations based from the information of the tradi- tional web: ratings, demographic data and item data (CF, demographic Ô¨Åltering, content-based Ô¨Åltering and hybrid Ô¨Åltering). Section 4 describes measures for evaluating the quality of the RS predictions and recommendations. Section 5 shows the use of so- cial information from Web 2.0 for making recomendations through concepts like trust, reputation and credibility. We will also de- scribe techniques based on content-based for social information (e.g. tags and posts). Section 6 focusses on two important areas (although not very well studied yet): recommendation to group of users and explanation of recommendations. Section 7 focusses on recommender system trends, covering bio-inspired approaches and Web 3.0 information Ô¨Åltering such as location-aware RS. Sec- tion 8 explains related works and the original contributions of this survey. The concluding section summarizes the RS history and focuses on the type of data used as well as the development of algorithms and evaluation measures. The conclusions section also indicates seven new areas that we consider likely to be the focus of RS re- search in the scientiÔ¨Åc community in the near future. 2. Methodology An initial study was performed to determine the most represen- tative topics and terms in the RS Ô¨Åeld. First, 300 RS papers were se- lected from journals, with a higher priority for current and for often-cited articles. Next, we extracted from these 300 papers the most signiÔ¨Åcant terms. We gave the most emphasis to keywords, less emphasis to titles and, Ô¨Ånally, the least emphasis to abstracts. We have overlooked common words, like articles, prepositions and general-use words from the remaining pool, we selected 300 terms represented in the RS Ô¨Åeld. From a matrix of arti- cles  words, wherein we stored the importance of each word from each article, we generated a tree of relationships between the words. Fig. 1 depicts the most signiÔ¨Åcant section of the graph (due to space constraints, the entire tree is not shown, but it is pro- vided as additional material in Fig. 1 AdditionalData.png ). The short distances between words indicate the highest similarities; warm colors indicate a greater reliability for the relationships. The size of the nodes indicates the importance of the words as a function of the parameters N k , N t , N a (number of signiÔ¨Åcative words in the keywords, title and abstract) and N k w ; N t w ; N a w (number of times that the word w appears in the keywords, title and abstract). The equa- tion used to determine the importance of each word w is as follows: f w ¬º 1 3 N k w N k √æ N t w N t log N a N t √æ N a w N a N a N t ! Example : we will consider a paper where N k = 5 keywords, N t = 11 words in the title, and N a = 52 words of abstract length. We will get the values of f factorization and f matrix , where the word ‚Äòfactorization‚Äô appears once as a keyword, once in the title and three times in the abstract; the word ‚Äòmatrix‚Äô does not appear as a keyword, but it is contained once in the title and twice in the abstract. The importance of these words will be: f factorization ¬º 1 3 1 5 √æ 1 11 log 52 11 √æ 3 52 52 11 ! ¬º 0 : 09 f matrix ¬º 1 3 0 5 √æ 1 11 log 52 11 √æ 2 52 52 11 ! ¬º 0 : 02 The information depicted in Fig. 1 is used to identify the most relevant aspects of RS. They are represented by the most signiÔ¨Åcant words in the graph and the related terms. The articles referenced herein were chosen based on the following criteria: (a) the tran- scendence of the subject according to the importance of the words in Fig. 1 ; (b) its historical contribution (a signiÔ¨Åcant fraction of the classic reference articles are included); (c) the number of times the article is cited; (d) articles published in journals with an impact factor were preferred over conferences and workshops; and (e) re- cent articles were preferred over articles published many years ago. Fig. 2 shows a temporal distribution for the referenced papers. We use the clusters of words in Fig. 1 to structure the explica- tions of the survey. For each concept explained: (1) we have ob- tained their keywords and all the words related to them according to Fig. 1 ; (2) we have identiÔ¨Åed, among the set of 300 pa- pers, those which are more related to the set of words associated to the concept; (3) we have selected the subset of papers which deal with the concept, giving priority to those with high values in crite- ria like importance of the paper and the number of cites; and (4) we have tried to balance the number of times a paper is referenced in our survey, aiming to reference most of the 300 papers selected. 110 J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 3. Recommender systems foundations This section presents the most relevant concepts on which the traditional RS are based. Here, we provide general descriptions on the classical taxonomies, algorithms, methods, Ô¨Åltering ap- proaches, databases, etc. Besides, we show a graphic depicting the traditional models of recommendations and their relations. Next, we will describe the cold-start problem, which will illustrate the difÔ¨Åculty of making collaborative recommendation when the RS contains a small amount of data. Next, we will describe the k NN algorithm; the most used algorithm for implementing RS based on CF. Finally, we will describe different proposed similarity measures for comparing users or items. We will show graphics for measuring the quality of these similarity measures. 3.1. Fundamentals The process for generating an RS recommendation is based on a combination of the following considerations:  The type of data available in its database (e.g., ratings, user reg- istration information, features and content for items that can be ranked, social relationships among users and location-aware information).  The Ô¨Åltering algorithm used (e.g., demographic, content-based, collaborative, social-based, context-aware and hybrid).  The model chosen (e.g., based on direct use of data: ‚Äò‚Äòmemory- based,‚Äô‚Äô or a model generated using such data: ‚Äò‚Äòmodel-based‚Äô‚Äô).  The employed techniques are also considered: probabilistic approaches, Bayesian networks, nearest neighbors algorithm; bio-inspired algorithms such as neural networks and genetic algorithms; fuzzy models, singular value decomposition tech- niques to reduce sparsity levels, etc.  Sparsity level of the database and the desired scalability.  Performance of the system (time and memory consuming).  The objective sought is considered (e.g., predictions and top N recommendations) as well as  The desired quality of the results (e.g., novelty, coverage and precision). Research in RS requires using a representative set of public dat- abases to facilitate investigations on the techniques, methods and algorithms developed by researchers in the Ô¨Åeld. Through these databases, the scientiÔ¨Åc community can replicate experiments to validate and improve their techniques. Table 1 lists the current public databases referenced most often in the literature. Last.Fm and Delicious incorporate implicit ratings and social information; their data were generated from the versions released in the HetRec, 2011 data sets, hosted by the GroupLens research Group. The internal functions for RS are characterized by the Ô¨Åltering algorithm . The most widely used classiÔ¨Åcation divides the Ô¨Åltering algorithms into [3,51,203] : (a) collaborative Ô¨Åltering, (b) demo- graphic Ô¨Åltering, (c) content-based Ô¨Åltering and (d) hybrid Ô¨Åltering. Fig. 1. Words represented in the recommender systems research Ô¨Åeld. Short distances indicate higher similarities, and a warm color indicates greater reliability. The size of the nodes is proportional to the importance of the words. Fig. 2. Temporal distribution for the referenced papers. J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 111 Content-based Ô¨Åltering [131,11,158] makes recommendations based on user choices made in the past (e.g. in a web-based e-com- merce RS, if the user purchased some Ô¨Åction Ô¨Ålms in the past, the RS will probably recommend a recent Ô¨Åction Ô¨Ålm that he has not yet purchased on this website). Content-based Ô¨Åltering also gener- ates recommendations using the content from objects intended for recommendation; therefore, certain content can be analyzed, like text, images and sound. From this analysis, a similarity can be established between objects as the basis for recommending items similar to items that a user has bought, visited, heard, viewed and ranked positively. Demographic Ô¨Åltering [177,126,185] is justiÔ¨Åed on the principle that individuals with certain common personal attributes (sex, age, country, etc.) will also have common preferences. Collaborative Filtering [3,94,92,51,212] allows users to give rat- ings about a set of elements (e.g. videos, songs, Ô¨Ålms, etc. in a CF based website) in such a way that when enough information is stored on the system, we can make recommendations to each user based on information provided by those users we consider to have the most in common with them. CF is an interesting open research Ô¨Åeld [232,34,32] . As noted earlier, user ratings can also be Table 1 Most often used memory-based recommender systems public databases. Without social information With social information (hosted by the GroupLens) MovieLens 1M MovieLens 10M NetÔ¨Çix Jester EachMovie Book-crossing ML Last.Fm Delicious Ratings 1 million 10 million 100 million 4.1 million 2.8 million 1.1 million 855,598 92,834 104,833 Users 6040 71,567 480,189 73,421 72,916 278,858 2113 1892 1867 Items 3592 10,681 17,770 100 1628 271,379 10,153 17,632 69,226 Range {1, . . . ,5} {1, . . . ,5} {1, . . . ,5}  10, 10 [0,1] {1, . . . ,10} {1, . . . ,5} Implicit Implicit Tags N/A N/A N/A N/A N/A N/A 13222 11946 53388 Tags assignment N/A N/A N/A N/A N/A N/A 47957 186479 437593 Friends relations N/A N/A N/A N/A N/A N/A N/A 25434 15328 Items Movies Movies Movies Jokes Movies Books Movies Music URL‚Äôs Fig. 3. Traditional models of recommendations and their relationships. 112 J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 implicitly acquired (e.g., number of times a song is heard, informa- tion consulted and access to a resource). The most widely used algorithm for collaborative Ô¨Åltering is the k Nearest Neighbors (kNN) [3,203,32] . In the user to user version, k NN executes the following three tasks to generate recommenda- tions for an active user: (1) determine k users neighbors (neighbor- hood) for the active user a ; (2) implement an aggregation approach with the ratings for the neighborhood in items not rated by a ; and (3) extract the predictions from in step 2 then select the top N recommendations . Hybrid Ô¨Åltering [47,185] . Commonly uses a combination of CF with demographic Ô¨Åltering [224] or CF with content-based Ô¨Åltering [18,60] to exploit merits of each one of these techniques. Hybrid Ô¨Åltering is usually based on bioinspired or probabilistic methods such as genetic algorithms [76,99] , fuzzy genetic [7] , neural net- works [133,62,192] , Bayesian networks [50] , clustering [209] and latent features [199] . A widely accepted taxonomy divides recommendation methods into memory-based and model-based method categories: Memory-based methods [3,51,123,214] . Memory-based methods can be deÔ¨Åned as methods that (a) act only on the matrix of user ratings for items and (b) use any rating generated before the refer- ral process (i.e., its results are always updated). Memory-based methods usually use similarity metrics to obtain the distance be- tween two users, or two items, based on each of their ratios. Model-based methods [3,212] . Use RS information to create a model that generates the recommendations. Herein, we consider a method model-based if new information from any user outdates the model. Among the most widely used models we have Bayesian classiÔ¨Åers [59] , neural networks [107] , fuzzy systems [234] , genetic algorithms [76,99] , latent features [251] and matrix factorization [142] , among others. To reduce the problems from high levels of sparsity in RS dat- abases, certain studies have used dimensionality reduction tech- niques [202] . The reduction methods are based on Matrix Factorization [124,142,143] . Matrix factorization is especially ade- quate for processing large RS databases and providing scalable ap- proaches [215] . The model-based technique Latent Semantic Index (LSI) and the reduction method Singular Value Decomposition (SVD) are typically combined [224,244,48] . SVD methods provide good prediction results but are computationally very expensive; they can only be deployed in static off-line settings where the known preference information does not change with time. RS can use clustering techniques to improve the prediction qual- ity and reduce the cold-start problem when applied to hybrid Ô¨Ål- tering. It is typical to form clusters of items in hybrid RS [209,237] . A different common approach uses clustering both for items and users ( bi-clustering ) [252,85] . RS comprising social infor- mation have been clustered to improve the following areas: tagging [208] , explicit social links [179] and explicit trust information [181,70] . The graph in Fig. 3 shows the most signiÔ¨Åcant traditional meth- ods, techniques and algorithms for the recommendation process as well as their relationships and groupings. Different sections of this paper provide more detail on the most important aspects involved in the recommendation process. As may be seen in Fig. 3 , we can use some of the traditional Ô¨Ål- tering methods (content-based, demographic and collaborative) applied to databases. Model-based technologies (genetic algo- rithms, neural networks, etc.) make use of this kind of information. Typical memory-based approaches are: item to item; user to user; and hybrids of the two previous. The main purpose of both mem- ory-based and model-based approaches is to get the most accurate predictions in the tastes of users. The accuracy of these predictions may be evaluated through the classical information retrieval mea- sures, like MAE, precision, and recall. Researchers make use of these measures in order to improve the RS methods and technologies. 3.2. Cold-start The cold-start problem [203,3] occurs when it is not possible to make reliable recommendations due to an initial lack of ratings. We can distinguish three kinds of cold-start problems: new com- munity , new item and new user . The last kind is the most important in RS that are already in operation. The new community problem [204,129] refers to the difÔ¨Åculty, when starting up a RS, in obtaining, a sufÔ¨Åcient amount of data (ratings) for making reliable recommendations. Two common ways are used for tackling this problem: to encourage users to make ratings through different means; to take CF-based recom- mendations when there are enough users and ratings. The new item problem [174,172] arises because the new items entered in RS do not usually have initial ratings, and therefore, they are not likely to be recommended. In turn, an item that is not rec- ommended goes unnoticed by a large part of the community of users, and as they are unaware of it they do not rate it; this way, we can enter a vicious circle in which a set of items of the RS are left out of the ratings/recommendations process. The new item problem has less of an impact on RS in which the items can be dis- covered via other means (e.g. movies) than in RS where this is not the case (i.e. e-commerce, blogs, photos, videos, etc.). A common solution to this problem is to have a set of motivated users who are responsible for rating each new item in the system. The new user problem [190,197] represents one of the great dif- Ô¨Åculties faced by the RS in operation. Since new users in the RS have not yet provided any rating in the RS, they cannot receive any personalized recommendations based on memory-based CF; when the users enter their Ô¨Årsts ratings they expect the RS to offer them personalized recommendations, but the number of ratings introduced in the RS is usually not yet sufÔ¨Åcient to be able to make reliable CF-based recommendations, and, therefore, new users may feel that the RS does not offer the service they expected and they may stop using it. The common strategy to tackle the new user problem consists of turning to additional information to the set of ratings in order to be able to make recommendations based on the data available for each user. The cold-start problem is often faced using hybrid approaches (usually CF-content based RS, CF-demographic based RS, CF-social based RS) [118,140] . Leung et al. [135] propose a no- vel content-based hybrid approach that makes use of cross-level association rules to integrate content information about domains items. Kim et al. [118] use collaborative tagging employed as an approach in order to grasp and Ô¨Ålter users‚Äô preferences for items and they explore the advantages of the collaborative tagging for data sparseness and cold-start users (they collected the dataset by crawling the collaborative tagging delicious site). Weng et al. [228] combine the implicit relations between users‚Äô items prefer- ences and the additional taxonomic preferences to make better quality recommendations as well as alleviate the cold-start prob- lem. Loh et al. [140] represent user‚Äôs proÔ¨Åles with information ex- tracted from their scientiÔ¨Åc publications. Martinez et al. [148] present a hybrid RS which combines a CF algorithm with a knowl- edge-based one. Chen and He [56] propose a number of common terms/ term frequency (NCT/TF) CF algorithm based on demo- graphic vector. Saranya and Atsuhiro [199] propose a hybrid RS that utilizes latent features extracted from items represented by a multi-attributed record using a probabilistic model. Park et al. [173] propose a new approach: they use Ô¨Ålterbots, and surrogate users that rate items based only on user or item attributes. J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 113 3.3. The k nearest neighbors recommendation algorithm The k Nearest Neighbors ( k NN) recommendation algorithm is the reference algorithm for the collaborative Ô¨Åltering recommendation process. Its primary virtues are simplicity and reasonably accurate results; its major pitfalls are low scalability and vulnerability to sparsity in the RS databases. This section provides a general expla- nation of this algorithm function. CF based on the k NN algorithm is conceptually simple, with a straightforward implementation; it also generally produces good- quality predictions and recommendations. However, due to the high level of sparsity [142,29] in RS databases, similarity measures often encounter processing problems (typically from insufÔ¨Åcient mutual ratings for a comparison of users and items) and cold start situations (users and items with low number of rankings) [204,98,36,135] . Another major problem for the k NN algorithm is its low scalabil- ity [142] . As the databases (such as NetÔ¨Çix) increase in size (hun- dreds of thousands of users, tens of thousands of items, and hundreds of millions of rankings), the process for generating a neighborhood for an active user becomes too slow; The similarity measure must be processed as often as new users are registered in the database. The item to item version of the k NN algorithm sig- niÔ¨Åcantly reduces the scalability problem [200] . To this end, neigh- bors are calculated for each item; their top n similarity values are stored, and for a period of time, predictions and recommendations are generated using the stored information. Although the stored information does not include the ratings from previous process- ing/storage, outdated information for items is less sensitive than for the users. A recurrent theme in CF research is generating metrics to calcu- late with accuracy and precision the existing similarity for the users (or items). Traditionally, a series of statistical metrics have been used [3,51] , such as the Pearson correlation , cosine , constraint Pearson correlation and mean squared differences . Recently, metrics have been designed to Ô¨Åt the constraints and peculiarities of RS [31,35] . The relevance ( signiÔ¨Åcance ) concept was introduced to af- ford more importance to more relevant users and items [34,227] . Additionally, a group of metrics was speciÔ¨Åcally designed to ade- quately function in cold-start situations [6,36] . The k NN algorithm is based on similarity measures. Next sub- section provides further details on the current RS similarity mea- sures. The similarity approaches typically compute the similarity between two users x and y (user to user) based on both users‚Äô item ratings. The item to item k NN version computes the similarity be- tween two items i and j . A formal approach of the k NN algorithm may be found in [32] . In this section, we will provide an illustrative example of this algo- rithm. The method for making recommendations is based on the following three steps: (a) Using the selected similarity measure, we produce the set of k neighbors for the active user a . The k neighbors for a are the nearest k (similar) users to u . (b) Once the set of k users (neighbors) similar to active a has been calculated, in order to obtain the prediction of item i on user a , one of the following aggregation approaches is often used: the average, the weighted sum and the adjusted weighted aggregation (deviation-from-mean). (c) To obtain the top- n recommendations, we choose the n items, which provide most satisfaction to the active user according to our predictions. Fig. 4 shows a case study using the user to user k NN algorithm mechanism. In the item to item version [200,77] of the k NN algorithm, the following three tasks are executed: (1) determine q items neigh- bors for each item in the database; (2) for each item i not ranked by the active user a , calculate its prediction based on the ratings of a from the q neighbors of i ; and (3) select the top n recommen- dations for the active user (typically the n major predictions from a ). Step (1) can be executed periodically, which facilitates an accel- erated recommendation with regard to the user to user version. The item to item and user to user versions of the k NN algorithm can be combined [188] to take advantage of the positive aspects from each approach. These approaches are typically fused by pro- cessing the similarity between objects. 3.4. Similarity measures A metric or a Similarity Measure (SM) determines the similarity between pairs of users (user to user CF) or the similarity between pairs of items (item to item CF). For this purpose, we compare the ratings of all the items rated by two users (user to user) or the rat- ings of all users who have rated two items (item to item). The k NN algorithm is based essentially on the use of traditional similarity metrics of statistical origin. These metrics require, as the only source of information, the set of votes made by the users on the items (memory-based CF). Among the most commonly used traditional metrics we have: Pearson correlation (CORR), cosine (COS), adjusted cosine (ACOS), constrained correlation (CCORR), Mean Squared Differences (MSD) and Euclidean (EUC) [51,3] . We will describe and compare a representative group of SM used in the k NN algorithm. The SM discussed include the following variations: (a) cold-start and general cases, (b) based or not based on models, and (c) using trust information or only ratings. Table 2 shows a classiÔ¨Åcation of the memory-based CF SM which will be tested in this section. A new metric (JMSD) has recently been published, which be- sides using the numerical information from the ratings (via mean squared differences) also uses the non-numerical information pro- vided by the arrangement of these (via Jaccard) [31] . Ortega et al. [169] use Pareto dominance to perform a pre-Ô¨Åltering process eliminating less representative users from the k -neighbur selection process while retaining the most promising ones. A specialization of the memory-based CF SM, which appeared recently [35] , uses the information contained in the votes of all users, instead of restricting it to the ratings of the two users com- pared (user to user) or the two items compared (item to item). We will call this SM SING (singularities). The possibility exists to create a model (model-based CF) from the full set of users‚Äô ratings in order to later determine the similar- ity between pairs of users or pairs of items based on the model cre- ated. The potential advantages of this focus are an increase in the accuracy obtained, in the performance (time consuming) achieved or in both. The drawback is that the model must be regularly up- dated in order to consider the most recently entered set of ratings. Fig. 4. User to user k NN algorithm example, k = 3. Similarity measure: 1 ‚Äì (mean squared differences). Aggregation approach: average. 114 J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 Bobadilla et al. [33] provides a metric based on a model generated using genetic algorithms. We will call this SM GEN (genetic-based). As a result of the increase in web 2.0 websites on the Internet, a set of metrics has appeared which use the new social information available (friends, followers, followeds, etc.). Most of these SM are grouped in papers related to trust, reputation and credibility [71,239,138] , although this situation is also produced in other Ô¨Åelds [30] . These metrics could not be considered strictly mem- ory-based CF, as they use additional information which not all RS have. In this sense, each SM proposed is tailored to a speciÔ¨Åc RS or at most to a very small set of RS which share the same structure in their social information. There are SM [112,127] which aim to extract information re- lated to trust and reputation by only using the users‚Äô set of ratings (memory-based CF). The advantage is that their use can be general- ized to all CF RS; the drawback is that the social information ex- tracted is really poor. We will call TRUST the SM proponed in Jeong et al. [112] . Currently, two new interesting SM get more cov- erage [38] and accuracy [61] . Fig. 5 shows the results from several evaluation measures gen- erated by applying the SM discussed in this section. The results show that the RS-tailored SM are superior compared with the tra- ditional SM from statistics. Processing for the memory-based infor- mation and results from Fig. 5 follow the framework schematic published previously [32] . There are so far research papers dealing with the cold-start prob- lem through the users‚Äô ratings information. Ahn [6] presents a heu- ristic SM named PIP, that outperforms the traditional statistical SM Table 2 Tested collaborative Ô¨Åltering similarity measures. Not based on models Model-based No trust extraction Trust extraction Traditional (only the ratings of both users or both items) Not tailored to cold-start users JMSD, CORR, CCORR, COS, ACOS, MSD, EUC GEN Tailored to cold-start users PIP UERROR NCS Extended to all the ratings SING TRUST Fig. 5. Evaluation measures results obtained from current similarities measures; MovieLens database. (A) Prediction results, (B) recommendation results, (C) novelty results, and (D) trust results. J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 115 (Pearson correlation, cosine, etc.). Heung-Nam et al. [98] proposes a method (UERROR) that predicts Ô¨Årst actual ratings and subsequently identiÔ¨Åes prediction errors for each user. Taking into account this er- ror information, some speciÔ¨Åc ‚Äò‚Äòerror-reÔ¨Çected‚Äô‚Äô models, are de- signed. Bobadilla et al. [36] presents a metric based on neural learning (model-based CF) and adapted for new user cold-start situ- ations, called NCS. Fig. 6 shows results from several evaluation measures gener- ated by applying the cold-start SM presented in this section; These results show that the RS-tailored SM are superior compared with the traditional SM from statistics. Since the database Movielens does not take into account cold-start users, we have removed rat- ings of this database in order to achieve cold-start users. Indeed, we have removed randomly between 5 and 20 ratings of those users who have rated between 20 and 30 items. In this way, we will regard those users who now result to rate between 2 and 20 items as cold-start users. 4. Evaluation of recommender systems results Since RS research began, evaluation of predictions and recom- mendations has become important [94,201] . Research in the RS Ô¨Åeld requires quality measures and evaluation metrics [90] to know the quality of the techniques, methods, and algorithms for predic- tions and recommendations. Evaluation metrics [94,95] and evalua- tion frameworks [92,32] facilitate comparisons of several solutions for the same problem and selection from different promising lines of research that generate better results. Because of evaluation measures, RS recommendations have gradually been tested and improved [48] . A representative set of existing evaluation measures has standard formulations, and a group of open RS public databases has been generated. These two advances have facilitated quality comparisons for new proposed recommendation methods and previously published methods; thus, RS methods and algorithms research has progressed continuously. The most commonly used quality measures are the following [90,95] : (1) prediction evaluations, (2) evaluations for recommen- dation as sets, and (3) evaluations for recommendations as ranked lists. Fig. 5 shows results from applying several evaluation mea- sures to a set of representative similarity measures. Evaluation metrics [12] can be classiÔ¨Åed as [94,95] (a) predic- tion metrics: such as the accuracy ones: Mean Absolute Error ( MAE ), Root of Mean Square Error ( RMSE ), Normalized Mean Average Error ( NMAE ); and the coverage (b) set recommendation metrics: such as Precision , Recall and Receiver Operating Characteristic ( ROC ) [204] (c) rank recommendation metrics: such as the half-life [43] and the discounted cumulative gain [17] and (d) diversity met- rics: such as the diversity and the novelty of the recommended items [105] . The validation process is performed by employing the most common cross validation techniques ( random sub-sam- pling and k-fold cross validation ) [21] ; for cold-start situations, due to the limited number of users (or items) votes involved, the usual method chosen to carry out the experiments is leave-one- out cross validation [36] . Hern√°ndez and Gaudioso [95] propose an evaluation process based on the distinction between interactive and non-interactive Fig. 6. Evaluation results obtained from current cold-start similarities measures. (A) Prediction results, (B) recommendation results, (C) novelty results, and (D) trust results. 116 J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 subsystems. General publications and reviews also exist which in- clude the most commonly accepted evaluation measures: mean absolute error , coverage , precision , recall and derivatives of these: mean squared error , normalized mean absolute error , ROC and fallout ; Goldberg et al. [87] focuses on the aspects not related to the eval- uation, Breese et al. [43] compare the predictive accuracy of vari- ous methods in a set of representative problem domains. The majority of articles discuss attempted improvements to the accuracy of RS results ( RMSE , MAE , etc.). It is also common to at- tempt an improvement in recommendations (precision, recall, ROC, etc.). However, additional objectives should be considered for generating greater user satisfaction [253] , such as topic diversi- Ô¨Åcation and coverage serendipity . Currently, the Ô¨Åeld has a growing interest in generating algo- rithms with diverse and innovative recommendations, even at the expense of accuracy and precision. To evaluate these aspects, various metrics have been proposed to measure recommendation novelty and diversity [105,220] . The frameworks aid in deÔ¨Åning and standardizing the methods and algorithms employed by RS as well as the mechanisms to eval- uate the quality of the results. Among the most signiÔ¨Åcant papers that propose CF frameworks are Herlocker et al. [92] which evaluates the following: similarity weight, signiÔ¨Åcance weighting, variance weighting, selecting neighborhood and rating normaliza- tion; Hern√°ndez and Gaudioso [95] proposes a framework in which any RS is formed by two different subsystems, one of them to guide the user and the other to provide useful/interesting items. Koutrika et al. [125] is a framework which introduces levels of abstraction in CF process, making the modiÔ¨Åcations in the RS more Ô¨Çexible. Antunes et al. [12] presents an evaluation framework assuming that evaluation is an evolving process during the system lifecicle. The majority of RS evaluation frameworks proposed until now present two deÔ¨Åciencies: the Ô¨Årst of these is the lack of formal- ization. Although the evaluation metrics are well deÔ¨Åned, there are a variety of details in the implementation of the methods which, in the event they are not speciÔ¨Åed, can lead to the generation of different results in similar experiments. The second deÔ¨Åciency is the absence of standardization of the evalu- ation measures in aspects such as novelty and trust of the recommendations. Bobadilla et al. [32] provides a complete series of mathematical formalizations based on sets theory. Authors provide a set of eval- uation measures, which include the quality analysis of the follow- ing aspects: predictions, recommendations, novelty and trust. Presented next is a representative selection of the RS evaluation quality measures most often used in the bibliography. 4.1. Quality of the predictions: mean absolute error, accuracy and coverage In order to measure the accuracy of the results of an RS, it is usual to use the calculation of some of the most common predic- tion error metrics, amongst which the Mean Absolute Error (MAE) and its related metrics: mean squared error, root mean squared error, and normalized mean absolute error stand out. We deÔ¨Åne U as the set of the RS users, I as the set of the RS items, r u , i the rating of user u on item i ,  the lack of rating ( r u , i =  means user u has not rated item i ), p u , i the prediction of item i on user u . Let O u = { i 2 I j p u , i ‚Äì  ^ r u , i ‚Äì  }, set of items rated by user u hav- ing prediction values. We deÔ¨Åne the MAE and RMSE of the system as the average of the user‚Äôs MAE. We remark that the absolute dif- ference between prediction and real value, j p u , i  r u , i j , informs about the error in the prediction. MAE ¬º 1 # U X u 2 U 1 # O u X i 2 O u j p u ; i  r u ; i j ! √∞ 1 √û RMSE ¬º 1 # U X u 2 U Ô¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨É 1 # O u X i 2 O u √∞ p u ; i  r u ; i √û 2 s √∞ 2 √û The coverage could be deÔ¨Åned as the capacity of predicting from a metric applied to a speciÔ¨Åc RS. In short, it calculates the percent- age of situations in which at least one k -neighbor of each active user can rate an item that has not been rated yet by that active user. We deÔ¨Åned K u , i as the set of neighbors of u which have rated the item i . We deÔ¨Åne the coverage of the system as the average of the user‚Äôs coverage: Let C u ¬º f i 2 I j r u ; i ¬º  ^ K u ; i ‚Äì ¬£ g ; D u ¬º f i 2 I j r u ; i ¬º g co v erage ¬º 1 # U X u 2 U 100  # C u # D u   √∞ 3 √û 4.2. Quality of the set of recommendations: precision, recall and F1 The conÔ¨Ådence of users for a certain RS does not depend directly on the accuracy for the set of possible predictions. A user gains conÔ¨Ådence on the RS when this user agrees with a reduced set of recommendations made by the RS. In this section, we deÔ¨Åne the following three most widely used recommendation quality measures: (1) precision, which indicates the proportion of relevant recommended items from the total number of recommended items, (2) recall, which indicates the pro- portion of relevant recommended items from the number of rele- vant items, and (3) F1, which is a combination of precision and recall. Let X u as the set of recommendations to user u , and Z u as the set of n recommendations to user u . We will represent the evaluation precision, recall and F 1 measures for recommendations obtained by making n test recommendations to the user u , taking a h rele- vancy threshold. Assuming that all users accept n test recommendations: precision ¬º 1 # U X u 2 U # f i 2 Z u j r u ; i P h g n √∞ 4 √û recall ¬º 1 # U X u 2 U # f i 2 Z u j r u ; i P h g # f i 2 Z u j r u ; i P h g √æ # i 2 Z c u  r u ; i P h   √∞ 5 √û F 1 ¬º 2  precision  recall precision √æ recall √∞ 6 √û 4.3. Quality of the list of recommendations: rank measures When the number n of recommended items is not small, users give greater importance to the Ô¨Årst items on the list of recommen- dations. The mistakes incurred in these items are more serious er- rors than those in the last items on the list. The ranking measures consider this situation. Among the ranking measures most often used are the following standard information retrieval measures: (a) half-life (7) [43] , which assumes an exponential decrease in the interest of users as they move away from the recommenda- tions at the top and (b) discounted cumulative gain (8) [17] , wherein decay is logarithmic. HL ¬º 1 # U X u 2 U X N i ¬º 1 max √∞ r u ; p i  d ; 0 √û 2 √∞ i  1 √û = √∞ a  1 √û √∞ 7 √û DCG k ¬º 1 # U X u 2 U r u ; p 1 √æ X k i ¬º 2 r u ; p i log 2 √∞ i √û ! √∞ 8 √û J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 117 p 1 , . . . , p n represents the recommendation list, r u , pi represents the true rating of the user u for the item p i , k is the rank of the eval- uated item, d is the default rating, a is the number of the item on the list such that there is a 50% chance the user will review that item. 4.4. Novelty and diversity The novelty evaluation measure indicates the degree of differ- ence between the items recommended to and known by the user. The diversity quality measure indicates the degree of differentia- tion among recommended items. Currently, novelty and diversity measures do not have a stan- dard; therefore, different authors propose different metrics [163,220] . Certain authors have [105] used the following: di v ersity Z u ¬º 1 # Z u √∞ # Z u  1 √û X i 2 Z u X j 2 Z u ; j ‚Äì i ¬Ω 1  sim √∞ i ; j √û √∞ 9 √û no v elty i ¬º 1 # Z u  1 X j 2 Z u ¬Ω 1  sim √∞ i ; j √û ; i 2 Z u √∞ 10 √û Here, sim ( i , j ) indicates item to item memory-based CF similar- ity measures. Z u indicates the set of n recommendations to user u . 4.5. Stability The stability in the predictions and recommendations inÔ¨Çu- ences on the users‚Äô trust towards the RS. A RS is stable if the pre- dicitions it provides do not change strongly over a short period of time. Adomavicius and Zhang [4] propose a quality measure of stability, MAS (Mean Absolute Shift). This measure is deÔ¨Åned through a set of known ratings R 1 and a set of predictions of all un- known ratings, P 1 . For an interval of time, users of the RS will have rated a subset S of these unknown ratings and the RS can now make new predictions, P 2 . MAS is deÔ¨Åned as follows: stability ¬º MAS ¬º 1 j P 2 j X √∞ u ; i √û2 P 2 j P 2 √∞ u ; i √û  P 1 √∞ u ; i √ûj √∞ 11 √û 4.6. Reliability The reliability of a prediction or a recommendation informs about how seriously we may consider this prediction. When RS recommends an item to a user with prediction 4.5 in a scale {1, . . . ,5}, this user hopes to be satisÔ¨Åed by this item. However, this value of prediction (4.5 over 5) does not reÔ¨Çect with which certain degree the RS has concluded that the user will like this item (with value 4.5 over 5). Indeed, this prediction of 4.5 is much more reli- able if it has obtained by means of 200 similar users than if it has obtained by only two similar users. In Hernando et al. [96] , a realibility measure is proposed accord- ing the usual notion that the more reliable a prediction, the less lia- ble to be wrong. Although this reliability measure is not a quality measure used for comparing different techniques of RS through cross validation, this can be regarded as a quality measure associ- ated to a prediction and a recommendation. In this way, the RS pro- vides a pair of values (prediction value, reliability value), through which users may balance its preference: for example users would probably prefer the option (4,0.9) to the option (4.5,0.1). Conse- quently, the reliability measure proposed in Hernando et al. [96] provides a new understandable factor, which users may consider for taking its decisions. Nevertheless, the use of this reliability measure is just constrained to those RS based on the k NN algorithm. The deÔ¨Ånition of reliability on the prediction, p u , i , is based on two numeric factors: s u , i and v u , i . s u , i measures the similar- ity of the neighbors used for making the prediction p u , i ; v u , i measures the degree of disagreement between these neighbors rating the item i . Finally, the reliablity measure is deÔ¨Åned as follows: f S √∞ s u ; i √û ¬º 1   s  s √æ s u ; i ; s u ; i ¬º X v 2 K u ; i sim √∞ u ; v √û √∞ 12 √û where f S √∞ s u ; i √û ¬º 1   s  s √æ s u ; i ; s u ; i ¬º X v 2 K u ; i sim √∞ u ; v √û √∞ 13 √û Fig. 7. Recommender systems evaluation process. 118 J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 f v √∞ v u ; i √û ¬º max  min  v u ; i max  min   ln 0 : 5 ln max  min   v max  min ; v u ; i ¬º P v 2 K u ; i sim √∞ u ; v √û√∞ r v ; i   r v  p u ; i √æ  r u √û 2 P v 2 K u ; i sim √∞ u ; v √û √∞ 14 √û where  s and  v are respectively the median of the values of s u , i and v u , i in the speciÔ¨Åc RS. K u , i is the set of neighbors of u which have rated the item i . {min, . . . ,max} is the discrete range of rating values. Fig. 7 shows the general mechanism for cross validation used to generate quality results form the evaluation measures. The data- base is divided in training and test areas for both users and items. In the Ô¨Årst phase (top on the left side), k -neighbors are calculated for the active user (while the active user is selected from the set of test users, the k -neighbors are selected from the set of training users). In the aggregation phase (top on the right side), predictions are calculated for the active user (from the set of test items). Final- ly, evaluation metrics are used to compare the predictions and rec- ommendations obtained with the real ratings of the user; the more accurate the predictions and recommendations, better quality of the proposed recommendation algorithm. 5. Social information As the web 2.0 has developed, RS have increasingly incorpo- rated social information (e.g., trusted and untrusted users, fol- lowed and followers, friends lists, posts, blogs, and tags). This new contextual information [145,216] improves the RS. Social information improves the sparsity problem inherent in memory- based RS because social information reinforces traditional mem- ory-based information (users ratings): users connected by a net- work of trust exhibit signiÔ¨Åcantly higher similarity on items and meta-data that non-connected users [132] . Social information is used by researchers with three primary objectives: (a) to improve the quality of predictions and recom- mendations [53,13] , (b) propose or generate new RS [139,210] , and (c) elucidate the most signiÔ¨Åcant relationships between social information and collaborative processes [100,178] . Trust and reputation is an important area of research in RS [166] ; this area is closely related to the social information currently in- cluded in RS [114] . The most common approachs to generating trust and reputation measurements are the following: (a) user trust: to calculate the credibility of users through explicit informa- tion of the rest of users [239,138] or to calculate the credibility of users through implicit information obtained in a social network [59,150] and (b) item trust: to calculate the reputation of items through a feedback of users [114] or to calculate the reputation of items studying how users work with these items [58,122] . In the social RS Ô¨Åeld, users can introduce labels associated with items. The set of triples h user, item, tag i form information spaces referred to as folksonomies . Fundamentally, folksonomies are used in the following two ways: (1) to create tag recommendation sys- tems (RS based only on tags) [147] and (2) to enrich the recom- mendation processes using tags [81] . Content-based Ô¨Åltering has recently become more important due to the surge in social networks. RS show a clear trend to allow users to introduce content [13,178] , such as comments, critiques, ratings, opinions and labels as well as to establish social relation- ship links (e.g., followed, followers, like user and dislike user). This additional information increases the accuracy of predictions and recommendations, which has generated a variety of research arti- cles: Kim et al. [117] , Zheng and Li [248] and Carrer-Neto et al. [53] . The rest of this section deal is dealt with the concepts and re- search in the two lines considered previously: Filtering of social information and content Ô¨Åltering. 5.1. Social Filtering Social information can be gathered explicitly or implicitly through identiÔ¨Åcation of a community network or afÔ¨Ånity network [196] using the individual information that users generate (e.g., communications and web logs) [178] . Even using only the ratings from the users, it is possible to improve the RS results creating an implicit social networking [180] . Both implicit and explicit information sources can be combined to generate recommenda- tions [144] . The explicit social information can be used via a trust-based CF in order to improve the quality of recommendations. Trust infor- mation can be generated or used through different approaches, such as trust propagation mechanisms [42] , a ‚Äòfollow the leader‚Äô approach [8,186] , personality-based similarity measures [101] , trust networks [239,221] , distrust analysis [223,20] , and dynamic trust based on the ant colonies metaphor [20] . Most of the research work that uses social information applied to RS aims to obtain improvements in the recommendations made by referring to the extra information provided by the social infor- mation used. Among the most relevant current work which uses this approach we have: Woerndl and Groh [231] use social net- works to enhance collaborative Ô¨Åltering; Their evaluation shows that the social recommender outperforms traditional collaborative Ô¨Åltering algorithms in the used scenario. Arazy et al. [13] improve accuracy by using data from online social networks and electronic communication tools. Xin et al. [233] propose an approach for improving RS through exploiting the learners note taking activity. They maintain that notes‚Äô features can be exploited by collabora- tive learning systems in order to enrich and extend the user proÔ¨Åle and improve personalized learning. The Bonhard and Sasse [41] re- search has shown that the relationship between advice-seeker and recommender is extremely important, so ways of indicating social closeness and taste overlap are required. They thus suggest that drawing on similarity and familiarity between the user and the persons who have rated the items can aid judgment and decision making. Fengkun and Hong [75] developed a way to increase rec- ommendation effectiveness by incorporating social network infor- mation into CF. They collected data about users‚Äô preference ratings and their social network relationships from a social networking web site; then, they evaluated CF performance with diverse neigh- bor groups combining groups of friends and nearest neighbors. Carmagnola et al. [52] state that joining in a network with other people exposes individuals to social dynamics which can inÔ¨Çuence their attitudes, behaviors and preferences: They present SoNARS , an algorithm for recommending content in social RS. SoNARS tar- gets users as members of social networks, suggesting items that re- Ô¨Çect the trend of the network itself, based on its structure and on the inÔ¨Çuence relationships among users. In Ramaswamy et al. [189] the design of the social network based RS incorporates three features that complement each other to derive highly targeted ads. First, they analyze information such as customer‚Äôs address books to estimate the level of social afÔ¨Ånity among various users. This social afÔ¨Ånity information is used to identify the recommendations to be sent to an individual user. Another group of research work uses social information to cre- ate or enable RS. That is, the aim is not to improve the results of a particular RS in operation, the aim is to propose or make possible RS which still do not exist, or if they do exist they are not based on social information: The Siersdorfer and Sergei [210] objective is to construct social recommender systems that predict the utility of items, users, or groups based on the multi-dimensional social environment of a given user; they do a mining of the rich set of structures and social relationships that provides the folksonomies. In the Li and Chen [137] study they propose a blog recommenda- tion mechanism that combines trust model, social relation and J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 119 semantic analysis and illustrates how it can be applied to a presti- gious online blogging system. In the Jason [111] research project, they have applied a system to discover the social networks be- tween mobile users by collecting a dataset from about two millions of users. They argue that social network is applicable to generate context-based recommendation services. Jyun and Chui [115] pa- per uses trading relationships to calculate level of recommendation for trusted online auction sellers. They demonstrate that network structures formed by transactional histories can be used to expose such underlying opportunistic collusive seller behaviors. In Dell‚Äôamico and Capra [69] users‚Äô trustworthiness has been mea- sured according to one of the following two criteria: taste similar- ity (i.e., ‚Äò‚ÄòI trust those who agree with me‚Äô‚Äô), or social ties (i.e., ‚Äò‚ÄòI trust my friends, and the people that my friends trust‚Äô‚Äô). They argue that, in order to be trusted, users must be both well intentioned and competent. Based on this observation, they propose a novel approach that they call social Ô¨Åltering. A third group of work provides the foundation of the research to discover the most signiÔ¨Åcant relationships between social informa- tion and collaborative processes, without creating, proposing or improving any particular RS. This research moves at a higher level of abstraction, with the aim of establishing bases and general prin- ciples. Bonhard [40] paper explains that qualitative research con- ducted to date has shown that the relationship between recommender and recommendee has a signiÔ¨Åcant impact on deci- sion-making. Hossain and Fazio [100] present a study exploring the connection between social networks and collaborative process. They focus on exploring academics‚Äô network position and its effect on their collaborative networks. By deÔ¨Åning network position in this way, they develop a social network that uses the academics as nodes within the network instead of each published paper. The Esslimani et al. [72] paper presents a new CF approach based on a behavioral network that uses navigational patterns to model relationships between users and exploits social networks tech- niques. Golbeck and Kuter [86] present an experimental study of several types of trust inference algorithms to answer the following questions on trust and change: How far does a single change prop- agate through the network? How large is the impact of that change? How does this relate to the type of inference algorithm? The experimental results provide insights into which algorithms are most suitable for certain applications. Research in the Ô¨Åeld of trust and reputation could provide a suitable starting point to create social interaction among users of the RS, however, the most relevant work on the subject is limited to the use of trust relationships to improve the quality of the rec- ommendation services. O‚Äôdonovan [165] book chapter examines the diversity of sources from which trust information can be har- nessed within social web applications and discusses a high level classiÔ¨Åcation of those sources. It is shown that harnessing an in- creased amount of information upon which to make trust decisions greatly enhances the user experience with the social web applica- tion. Massa and Avesani [151] explain that RS making use of trust information are the most effective in term of accuracy while pre- serving a good coverage. This is especially evident on users who provided few ratings. Yuan et al. [239] choose the trust aware RS as an example to demonstrate the advantages by making use of the veriÔ¨Åed small-world nature of the trust network. Li and Kao [138] present a RS based on the trust of social networks; Through the trust computing, the quality and the veracity of peer produc- tion services can be appropriately assessed. The experimental re- sults show that the proposed RS can signiÔ¨Åcantly enhance the quality of peer production services. Table 3 classiÔ¨Åes the current approaches to address user credi- bility and item reputation in social-based RS. In the CF Ô¨Åeld, the trust of users is used to make predictions, weighting trust values. That is to say, the more trust a user has, the more important its ratings are for making predictions [58,112,239] . In Ma et al. [145] , they propose a probabilistic factor analysis framework, combining ratings and trusted friends; this framework can be applied to pure user-item rating matrix. 5.2. Content-based Ô¨Åltering Content-based Ô¨Åltering (CBF) tries to recommend items to the active user similar to those rated positively in the past. It is based on the concept that items with similar attributes will be rated sim- ilarly [16,177,203] . For example, if a user likes a web page with the words ‚Äò‚Äòcar‚Äô‚Äô, ‚Äò‚Äòengine‚Äô‚Äô and ‚Äò‚Äògasoline‚Äô‚Äô, the CBF will recommend pages related to the automotive world. CBF is becoming especially important as RS incorporate infor- mation on items from users working in web 2.0 environments, such as tags, posts, opinions and multimedia material. Two challenging problems for content-based Ô¨Åltering are lim- ited content analysis and overspecialization [3] . The Ô¨Årst problem arises from the difÔ¨Åculty in extracting reliable automated informa- tion from various content (e.g., images, video, audio and text), which can greatly reduce the quality of recommendations. The sec- ond problem (overspecialization) refers to the phenomenon in which users only receive recommendations for items that are very similar to items they liked or preferred; therefore, the users are not receiving recommendations for items that they might like but are unknown (e.g., when a user only receives recommendations about Ô¨Åction Ô¨Ålms). Recommendations can be evaluated for novelty [32,105] . For CBF to operate, attributes of the items you wish to recom- mend must be extracted [176] . Typically, a set of attributes is man- ually deÔ¨Åned for each item depending on its domain. In certain instances, such as when it is desired to recommend textual infor- mation, classic information retrieval techniques must be used to automatically deÔ¨Åne such attributes (e.g., term frequency, inverse document frequency and normalization to page length). Fig. 8 shows the CBF mechanism, which includes the following steps: (1) extract the attributes of items for recommendation, (2) compare the attributes of items with the preferences of the active Table 3 State of the art on trust and reputation. User trust Item trust Explicit trust systems The ‚Äòcredibility‚Äô of users is calculated through explicit information of the rest of users. [71,239,240] . Services P2P usually implement this technique [138] The ‚Äòreputation‚Äô of items is calculated by means of a feedback of users who are asked about their opinions [114] . E-commerce services often use this technique Implicit trust systems The ‚Äòcredibility‚Äô of users is calculated through implicit information obtained in a social network [59,150,200] The ‚Äòreputation‚Äô of items is calculated studying how users work with these items (for example, the number of times a song is played) [58,122] Memory based trust The ‚Äòcredibility‚Äô measure is calculated taking into account the users‚Äô ratings [112,127,145] 120 J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 user, and (3) recommend items with characteristics that Ô¨Åt the user‚Äôs interests. When the attributes of the items and the user proÔ¨Åles are known, the key purpose for CBF [158] is to determine whether a user will like a speciÔ¨Åc item. This task is resolved traditionally by using heuristic methods [198,15,79] or classiÔ¨Åcation algorithms , such us: rule induction [65,119] , nearest neighbors methods [236,27] , Rocchio‚Äôs algorithm [131,16] , linear classiÔ¨Åers [113] , and probabilistic methods [175,160,84] . The pure CBF has several shortcomings [16,176,212] : (a) In certain domains (e.g., music, blogs, and videos), it is a complicated task to generate the attributes for items. (b) CBF suffers from an overspecialization problem because by nature it tends to recommend the same types of items. (c) It is more difÔ¨Åcult to acquire feedback from users because with CBF, users do not typically rate the items (as in CF), and, therefore, it is not possible to determine whether the recommendation is correct. Because of these shortcomings, it is rare to Ô¨Ånd a pure CBF implementation. It is more common to use the hybrid CBF/CF Burke 2002. CF solves CBF‚Äôs problems because it can function in any domain; it is less affected by overspecialization; and it ac- quires feedback from users. CBF adds the following qualities to CF: improvement to the quality of the predictions, because they are calculated with more information, and reduced impact from the cold-start and sparsity problems. CBF and CF can be combined in different ways [3] . Fig. 9 shows the different alternatives. Fig. 9 a shows the methods that calculate CBF and CF recom- mendations separately and subsequently combine them. Claypool et al. [64] propose to use a weighted average for combining CBF and CF predictions depending on the type of prediction. In another study, Pazzani [177] proposes combining the CBF and CF recom- mendation lists by assigning the items scores according to their position on the lists. Additionally, Billsus and Pazzani [26] and Tran and Cohen [218] propose to select the CBF or CF prediction in accordance with the quality. Fig. 9 b depicts the methods that incorporate CBF characteristics into the CF approach. Balabanovic and Shoham [16] maintain user proÔ¨Åles based on content analysis and directly compare the pro- Ô¨Åles to determine similar users for CF recommendations. Good et al. [89] construct specialized Ô¨Ålterbots using CBF techniques, which later act as neighbors in the CF stage. Melville et al. [157] propose to add predictions from the CBF into the ratting matrix employed by the CF. Li [136] modiÔ¨Åes the ratting matrix, which is input for the CF, by combining it with another matrix generated from clustering the items according to their attributes. In Hu and Pu [101] , authors incorporate personality characteristics in the CF similarity measure to minimize the new-user problem. Fig. 9 c illustrates the methods to construct a uniÔ¨Åed model with both CBF and CF characteristics. Basu et al. [19] propose using CBF and CF characteristics in a single rule-based classiÔ¨Åer. Popescul et al. [182] and Schein et al. [204] propose using prob- ability models to combine CBF and CF recommendations. In an- other studies [66,10,50] , the authors employ Bayesian networks to combine CBF and CF characteristics and generate more accu- rate recommendations. Burke [45] and Middleton et al. [159] propose using knowledge-based techniques to solve the cold- start problem. Fig. 9 d shows the methods that incorporate CF characteristics into a CBF approach. In Soboroff and Nicholas [211] , the authors use LSI to create the user proÔ¨Åles used in CBF recommendations beginning with the CF ratting matrix. Mooney and Roy [160] use CF system predictions as input for CBF. The current trend in CBF is to add social information to the items attributes, such as tags, comments, opinion, and social net- work sharing. Social tagging systems are the most popular because they allow users to annotate online resources with arbitrary labels, which produces rich information spaces ( folksonomies ). These new components have opened novel lines of RS research that can be di- vided into two categories: (1) tag recommendation systems and (2) use of tags in the recommendation process: (1) RS tags attempt to provide personalized item recommenda- tions to users through the most representative tags. In J√§chke et al. [110] , the authors compare different mecha- nisms for tags recommendations. Marinho and Schmidt-Thi- eme [147] improve tags recommendations by applying classic recommendation methods. Additionally, Landia and Anand [130] propose a method that combines clustering- based CBF with CF to suggest new tags to users. (2) The methods using tags in the recommendation process increase the capacity of traditional RS. Tso-Sutter et al. [219] propose a generic method that allows tags to be incor- porated to standard CF algorithms. Bogers and Van Den Bosh [39] examine how to incorporate the tags and other metada- ta into a hybrid CBF/CF algorithm by replacing the tradi- tional user-based and item-based similarity measures by tag overlap. Gemmell et al. [83] propose a weighted hybrid recommender, wherein they combine the graph-based tag recommendations with user-based CF and item-based CF. Gedikli and Jannach [81] propose to use tags as a means to express which features of an item users particularly like or dislike. In Gemmell et al. [82] , the authors offer a hybrid RS, wherein they predict the user preferences for items by only consulting the user‚Äôs tagging history. 6. Additional recommender systems objectives Commercial RS compete in the market by offering the best con- tent and quality in recommendations as well as greatest variety of services. Recommendations to user groups [108] facilitate joint recommendations to user groups (e.g., a group of four friends who wish to choose a movie). For CF, four design approaches offer an opportunity for action: (1) acting into the similarity measures stage [168] , (2) acquiring neighbors [37] , (3) acquiring predictions [63] , and (4) generating recommendations [17] . Research results [168] indicate that the quality of the recommendations does not vary greatly between the different approaches, but the execution time is dramatically reduced as we advance when it is used (when the design of a similarity measure for groups is the most efÔ¨Åcient solution). For the RS generated recommendations to be valuable for users, they must be explained well in a simple, compelling and accurate manner. The recommendation explanation Ô¨Åeld has been investi- gated with new developments in RS [91] until now [170] . Tradi- tionally, the explanation type is divided into the following categories: (a) human style (user to user approach), (b) item style (item to item approach), (c) feature style (items features), and (d) hybrid . It also employs the use of conversational techniques [155] and incorporates geo-social information [235] . 6.1. Recommending to groups of users RS that consider groups of users [108] are starting to expand and to be used in different areas: tourism [14] , music [55] , TV [238] , web [176] . Given the speciÔ¨Åc characteristics of the recommendation to groups, it is appropriate to establish a consensus for different J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 121 group semantics that formalize the agreements and disagreements among users [195] . With the aim of presenting the work carried out to date in a structured way, we provide a classiÔ¨Åcation of the recommendation to groups in CF RS. Fig. 10 graphically illustrates the four basic lev- els on which we can act in order to unify the group‚Äôs users‚Äô data with the objective of obtaining the data of the group of users: sim- ilarity metric, establishing the neighborhood, prediction phase, determination of recommended items. In Fig. 10 , the individual members of a group are represented on the left, in grey; each graticule represents the matrix of ratings by the users (horizontal) on the items (vertical). The graph shows the four representative cases of tackling the solution to recommenda- tion by groups (one case for each matrix on the left of the Ô¨Ågure). The circles show key information: they indicate the CF process phase where the uniÔ¨Åcation is performed: ‚Äò‚Äò n users ? 1 group‚Äô‚Äô. In the Ô¨Årst case, at the top of the graph, the data uniÔ¨Åcation is performed in the prediction phase of the CF process: n individual predictions of n users of the group are combined in one prediction of the group (predictions aggregation). This approach has been used by Berkovsky and Freyne [22] , Garc√≠a et al. [78] and Christen- sen and SchiafÔ¨Åno [63] . The second case acts on the sets of neighbors of the group‚Äôs users, by unifying them in one neighborhood for the whole group. This approach has been studied by Bobadilla et al. [37] , proposing the intersection of a large number ( k ) of neighbors of each user of the group. In the third case, the recommendations obtained for each indi- vidual user of the group are merged into one recommendation for the group. Baltrunas et al. [17] use rank aggregation of individual lists of recommendations. The fourth case [168] uses a similarity metric that acts directly on the set of ratings of the group of users. This solution is the only one that directly provides a set of neighbors for the group of users. A study exists [9] which, prior to any of the previous cases, pro- poses, as a front-end, the incorporation of a process of estimation of missing information when dealing with incomplete fuzzy lin- guistic preference relations. 6.2. Explaining recommendations An important research subject in the RS Ô¨Åeld focuses on provid- ing explanations that justify the recommendations the user has re- ceived. This is an important aspect of an RS because it aids in maintaining a higher degree of user conÔ¨Ådence in the results gen- erated by the system. The type of explanations used thus far can be classiÔ¨Åed as fol- lows [170] . Human style explanations (user to user approach). For example, we recommend movie i because it was liked by the users who rated movies j , k , m , . . . very positively ( j , k , m , . . . are movies rated well by the active user). Item style explanations (item to item approach). For example, we recommend the vacation destination i because you liked the vacation destinations g , c , r , . . . ( g , c , r , . . . are vacation destina- tions similar to i and rated well by the active user). Feature style explanations (it is recommended based on items‚Äô features). For example, we recommend movie i because it was directed by director d , it features actors a , b , and it belongs to genre g ( d , a , b , g are features the active user is interested in). Hybrid methods . This category primarily includes the following: human/item, human/feature, feature/item, and human/feature/ item. Additionally, in geo-social RS (Foursquare, Google latitude, etc.), location information exists that must be used in the recommenda- tion explanation mechanism [235] . Geo-social RS typically adopt a hybrid human/item explanation method based on social, location and memory-based information. A reference publication that is a helpful introduction to the RS explanations research Ô¨Åeld has been published previously [91] . They explore the utility of explanations in CF RS, and they stated three key research questions: (1) What models and techniques are effective in supporting explanations? (2) Can explanation facil- ities increase the acceptance of CF RS? (3) Can explanation facilities increase the Ô¨Åltering performance of the CF RS users? To answer to the Ô¨Årst question, they propose using rating histograms, indica- tions of past performance, comparisons to similar rated items, and use of domain speciÔ¨Åc content features. The results from the experiments conducted with RS users support an afÔ¨Årmative re- sponse to the second question. The third question is unanswered Fig. 8. Content-based Ô¨Åltering mechanism. Fig. 9. Different alternatives for combining CF and CBF. 122 J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 because users perform Ô¨Åltering based on many different channels of input. A dynamic approach that favors the mechanisms for RS expla- nations includes using conversational techniques, such as the CCBR (conversational case-base reasoning), explained into McSherry [155] . As CCBR they use an incremental nearest neighbor process based on the Pareto case dominance approach. In a different study [153] , a dynamic approach is also adopted, but it employs a differ- ent perspective. Instead of attempting to justify a particular recom- mendation they focus on how explanations can help users to understand the recommendation opportunities that remain if the current recommendation should not meet their requirements. They generate compound critiques as explanations: Users have the opportunity to accept or critique recommendations. If they cri- tique a recommendation, the critique acts as a Ô¨Ålter over the remaining recommendations. In a separate study [24] , authors differentiate between the con- cepts promotion (increasing of the acceptance of the recommended item) and satisfaction (user satisfaction with the recommended item). They also produced better results by using the keyword style explanation (based on content data) compared with the neighbor style explanation (human style explanation). Authors propose a new classiÔ¨Åcation of the recommendation justiÔ¨Åcations: Keyword Style Explanation (for content-based RS), Neighbor Style Explana- tion (for collaborative Ô¨Åltering RS) and InÔ¨Çuence Style Explanation (tells the user how their interactions with the RS inÔ¨Çuences the recommendation). Tintarev and Masthoff [217] describe the advantages of making justiÔ¨Åcations in recommendations: trans- parency, scutability, trustworthiness, effectiveness, persuasive- ness, efÔ¨Åciency and satisfaction. Billus and Pazzani [25] propose a recommendation system on news, which provides keyword style justiÔ¨Åcations of the recom- mendations through the weights used for obtaining these recom- mendations. Wang et al. [226] describe a system of justiÔ¨Åcations based on the features of users‚Äô preference. Tintarnev and Masthoff [217] design a recommedation system on Ô¨Ålms whose recommen- dations are justiÔ¨Åed through the features. Vig et al. [222] propose a mechanism for justifying recommendations called tagsplanations, which is based on community tags. Trangsplanations have two key components: tag relevance, the degree to which a tag describes an item; and tag preference, the user‚Äôs sentiment toward a tag. Fahri [73] provides a framework for organizing justiÔ¨Åcations, used to categorize explanations; they propose the categorization of the discourse: explicative, theoretical, pragmatic, ethical, moral, legal, aesthetic, and personal. Although this theoretical framework has not been used into the research literature, it can be used to de- sign new types of explanations. Hernando et al. [97] present a no- vel explanation technique based on the visualization of trees of items; these trees provide valuable information about the reliabil- ity of recommendations and the importance of the ratings the user has made. The most relevant investigations that produce justiÔ¨Åcations in recommender systems include a study [187] wherein the authors design a new organization interface where results are grouped according to their tradeoff properties. They have developed a trust model for recommender agents based on the Pareto algorithm (excluding dominated categories). Symeonidis et al. [213] Ô¨Årst con- struct a feature proÔ¨Åle for the users to reveal their favorite features, later they group users into biclusters to exploit partial matching between de preferences of groups of users over groups of items. Additionally they propose a metric to measure the quality of justi- Ô¨Åcations: the explain coverage ratio. In Symeonidis et al. [214] they use a prototype ‚Äò‚ÄòMoviExplain‚Äô‚Äô to put into the test the research showed into Symeonidis et al. [213] . In Hu et al. [102] they use im- plicit feedback to derive an estimate of the user preference (like or dislike an item) and user conÔ¨Ådence for each user-item pair. 7. Recommender systems trends From the evolution of existing RS and research papers in the Ô¨Åeld, there is a clear tendency to collect and integrate more and different types of data. This trend is parallel to the evolution of the web, which we can deÔ¨Åne through the following three primary stages: (1) at the genesis of the web, RS used only the explicit rat- ings from users as well as their demographic information and con- tent-based information included by the RS owners. (2) For the web 2.0, in addition to the above information, RS collect and use social Fig. 10. ClassiÔ¨Åcation of the recommendations to groups in CF RS. The Ô¨Ågure represents the four representative cases for approaching the solution to group recommendations. J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 123 information, such as friends, followers, followed, both trusted and untrusted. Simultaneously, users aid in the collaborative inclusion of such information: blogs, tags, comments, photos and videos. (3) For the web 3.0 and the Internet of things, context-aware informa- tion from a variety of devices and sensors will be incorporated with the above information. Currently, geographic information is included, and the expected trend is gradual incorporation of information, such as radio frequency identiÔ¨Åcation (RFID) data, sur- veillance data, on-line health parameters and food and shopping habits, as well as teleoperation and telepresence. Context-aware recommender systems [5,1] , focus on additional contextual information, such as time, location, and wireless sensor networks [80] . The contextual information can be obtained explic- itly, implicitly, using data mining or with a mixture of these meth- ods (hybrid). Currently, mobile applications increasingly use geographic information; this information enables geographic RS that can be considered as location-aware RS. For geographic RS [167,152] , recommendations are typically generated by consider- ing the geographical position of the user that receives the recommendation. This section provides an introduction of concepts, which are gaining popularity in the RS research Ô¨Åeld: Internet of things, pri- vacy preservation, shilling attacks, new frameworks, etc. In this introduction, we provide a novel classiÔ¨Åcation for analyzing these RS concepts. Next, we will deal with the research on the loca- tion-aware RS, which may be regarded as the Ô¨Årst steps for future RS based on Web 3.0. Finally, we will describe the most signiÔ¨Åca- tive results on a promising research Ô¨Åeld: the RS based on bio-in- spired models. 7.1. Introduction There is a clear trend towards collection of implicit information instead of a traditional explicit evaluation of items by ratings. Last.Fm is a good example of this situation; the user ratings are in- ferred by the number of times they have heard each song. The same can be applied in a number of everyday situations, such as for access to web addresses, use of various public transport sys- tems, food purchased, access to sports facilities and access to learn- ing resources. Incorporation of implicit information on the daily habits of users allows RS to use a variety of data; these data will be used in future CF processes, which are increasingly useful and accurate. Privacy and security considerations will be increasingly important with the widespread trend in using, with consent, devices and sen- sors for the Internet of things. Privacy is an important issue for RS [23] because the systems contain information on large numbers of registered users. For pri- vacy preservation in RS, a certain level of uncertainty must be intro- duced into the predictions [156] , primarily through tradeoffs between accuracy and privacy [146] . Furthermore, privacy can be preserved when different RS companies share information (com- bining their data) [116,242] . Privacy becomes more important as RS increasingly incorporate social information. Because RS are often used in electronic commerce , unscrupulous producers may Ô¨Ånd proÔ¨Åtable to shill RS by lying to the systems in order to have their products recommended more often than those of their competitors. RS can experience shilling attacks [128,57] , which generate many positive ratings for a product, while products from competitors receive negative ratings. RS are still highly vul- nerable to such attacks [191] . Knowledge-based Ô¨Åltering is emerging as an important Ô¨Åeld of RS. Knowledge RS [46] ‚Äò‚Äòuse knowledge about users and products to pursue a knowledge-based approach to generating recommenda- tions, reasoning about what products meet the user‚Äôs requeri- ments‚Äô‚Äô. Recommendations are based on inferences about users needs and preferences. User models are based on knowledge struc- tures such as querys (preferred features por products) [109] , cases (case-based reasoning) [44] , constraints (constraint-based reason- ing) [74] , ontologies [159] , matching metrics and knowledge vec- tors [194] , and social knowledge [53] . WorkÔ¨Çow is a current knowledge Ô¨Åeld where the user model is based on ‚Äò‚Äòusers-roles-tasks reference information that describes which member plays which roles or fulÔ¨Ålls which tasks‚Äô‚Äô [245,246] . Peer-to-peer (P2P) networks are other current knowl- edge Ô¨Åeld, where user information is based on the distributed information existing from each peer and the set of peers who may need her [247] . Gradual incorporation of different types of information (e.g., ex- plicit ratings, social relations, user contents, locations, use trends, knowledge-based information) has forced RS to use hybrid ap- proaches. Once the memory-based, social and location-aware methods and algorithms are consolidated, the evolution of RS dem- onstrates a clear trend toward combining existing collaborative methods. The latest research in the CF Ô¨Åeld has generated only modest improvements for predictions and recommendations from a single type of information (e.g., when the only information used is user ratings, information from social relations, or item content). The re- sults improve further when several algorithms are combined with their respective data types. A growing number of publications ad- dress hybrid approaches that use current databases to simulta- neously incorporate memory-based, social and content-based information. To unify the above concepts, Fig. 11 provides an original taxon- omy for RS. The taxonomy is classiÔ¨Åed depending on the nature of the data rather than according to the methods and algorithms used. The core of the taxonomy focuses on data classiÔ¨Åcation by three factors: (1) the target of the data: user or item; (2) mode of acquisition: explicit (i.e., ratings to items made by users) or impli- cit (e.g., number of times a user has heard a song); and (3) informa- tion level: memory, content or social context. Fig. 11 shows the recommender methods and algorithms (la- beled as ‚Äò‚Äòcollaborative Ô¨Åltering algorithms‚Äô‚Äô). Depending on the information type in each RS database, it adopts a hybrid Ô¨Åltering approach. Each hybrid approach will use an appropriate subset of algorithms to consider processing of existing information in a coor- dinated manner. Future developments will include different rec- ommendation frameworks that address the most common situations. These frameworks allow RS to incorporate the CF kernel with the most appropriate recommendations methods based on the available information in a simple and straightforward manner. At higher levels (prediction and recommendation), Fig. 11 incorporates current evaluation quality measures, such as those for diversity and novelty. The importance of such measures, and measures developed in the future will grow as users demand novel, stable and less predictable recommendations. 7.2. Location-aware recommender systems Due to the increasing use of mobile devices, location-aware sys- tems are becoming more widespread. These systems show a ten- dency towards their consolidation as web 3.0 services and this naturally leads to location-aware CF and location-aware RS, which can be called geographic CF and geographic RS. We introduce a classiÔ¨Åcation for geographic CF RS and focus on the most relevant section of the classiÔ¨Åcation obtained. Table 4 establishes the different possibilities of tackling a geographic RS according to the nature of the ratings made (‚Äò‚Äòrating stage‚Äô‚Äô) and the recommendation process followed (‚Äò‚Äòrecommendation stage‚Äô‚Äô). ‚Äò‚ÄòUser‚Äô‚Äô indicates that the rating and/or recommendation are made without having or using the user‚Äôs Geographic Information (GI). 124 J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 Similarly, ‚Äò‚ÄòItem‚Äô‚Äô indicates that the rating and/or recommendation are made without having or using the item‚Äôs GI. In the cases la- beled as ‚Äò‚ÄòUser g ‚Äô‚Äô and ‚Äò‚ÄòItem g ‚Äô‚Äô the GI is used. The cases identiÔ¨Åed are:  RS: Traditional RS, in which ratings and recommendations are made without using geographical information.  RS + G: Traditional RS, which also contributes the item‚Äôs geo- graphical position. These RS cannot be regarded as geographic RS, as the GI does not play a part in the recommendation process.  GRS: This group of Geographic RS is most likely to become pop- ular in the near future. In these, ratings are made in a traditional way, whilst recommendations are made by considering the geo- graphical position of the user to whom the recommendation is to be made. A representative example is that of a RS for restau- rants; the users rate a restaurant using very diverse concepts, which do not include the distance at the time of voting between the user and the restaurant. However, users of a Geographic RS expects a restaurant to be recommended to them not only because of good ratings from similar users ( k -neighbors), but also according to the distance between their current position and that of the restaurant. Other possible examples are RS for cinemas, pubs, supermarkets, cultural activities in a city, lan- guage learning centers, gyms and sports clubs, etc.  GRS + : In this case, users establish ratings on items by weighting the distance between them and the items rated. In this type of geographic RS two possibilities can be established: 1. Hybrid CF/Demographic Ô¨Åltering: Each item accepts a max- imum of one vote per user, to which the geographical posi- tion from which it has been issued is associated. 2. Geographic RS where each item accepts more than one rat- ing for each user, depending on the geographical position from which each rating is made. 3. The hybrid RS in case 1 respond to regional or national geo- graphical approaches, in which recommendations can be established according to weighting between the similarity of the votes (CF) and their origin. This type of GRS may be regarded as an extended case of hybrid CF/demographic Ô¨Åltering, in which the GI is given for each vote instead of for each user. From a theoretical point of view, Type 2 GRS + are the most com- plete; however, from a practical point of view, they involve a semantic difÔ¨Åculty in the item rating process, which makes their use very difÔ¨Åcult. Rating items in this GRS + involves that each user can rate items according to the relative distances between the user and the items. In this way, a user can rate a restaurant from their home differently to how they would rate it from their workplace; and when the distances are very different, the ratings are also likely to be so. The mental process would be something like this: I am 1 km from the restaurant and I rate very positively travelling 1 km to go to that restaurant which I think is good; but after some time, the same user, who is at work, 24 km away from the restau- rant, could cast a vote indicating they do not consider it to be po- sitive to travel 24 km to go to the restaurant even if they think it is good. In summary, GRS + have the advantage that they accept a wider variety of ratings and that these also contain the relative impor- tance that each user gives to the items according to the distance re- quired to access them. The disadvantage is that it is difÔ¨Åcult to involve users in a particularly complex and demanding ratings process. This subsection focuses on the GRS-type geographic CF RS. At present, there are few publications regarding GI-based RS; This is due, to a great extent, to the lack of public databases that include ratings and geographic positions capable of being combined in an RS. Some of the publications that focus more closely on the Ô¨Åeld are as follows: Martinez et al. [149] and Biuk-Aghai et al. [28] are examples of the RS + G group. In Schlieder [205] , they propose a novel approach for modeling the collaborative semantics of geographic folksono- mies. This approach is based on multi-object tagging, that is, the analysis of tags that users assign to composite objects. This paper is based on the concept of groups of people who share a common geospatial feature data dictionary (including deÔ¨Ånitions of feature relationships) and a common metadata schema. Wan-Shiou et al. [225] can be considered as a hybrid content based/geographic RS. The core of the system is a hybrid content based/geographic recommendation mechanism that analyzes a customer‚Äôs history and position so that vendor information can be ranked according to the match with the preferences of a customer. Matyas and Schlieder [152] show a collaborative system that we could situate between a RS and a GRS. In this case, the users‚Äô ratings are taken based on the photos they have downloaded from a Web 2.0 and the photos they have uploaded to the same Web (the photos have a GPS address associated to them). After this, a search of k -neighborhoods based on this data is carried out. The recommendation process does not take into account the user‚Äôs position. It is possible to collect travel GPS traces from users and use the database to generate recommendations [249] . The travel GPS traces can be reinforced with social information based on friends [250] . Both papers can be classiÔ¨Åed as GRS + . 7.3. Bio-inspired approaches Much of the proposed model-based RS are based on bio-in- spired approaches, which primarily use Genetic Algorithms (GAs) and Neural Networks (NNs). Models have also been proposed based on ArtiÔ¨Åcial Immune Networks (AINs). GA are heuristic approaches based on evolutionary principles such as natural selection and survival of the Ô¨Åtest. GA have mainly been used in two aspects of RS: clustering [120,243] and hybrid user models [76,99,7] . A common technique to improve the fea- tures of RS consists of initially carrying out a clustering on all of the users, in such a way that a group of classes of similar users is obtained, after this, the desired CF techniques can be applied to each of the clusters, obtaining similar results but in much shorter calculation times; It is usual to use common genetic clustering algorithms such as GA-based K -means [121] . The RS hybrid user models commonly use a combination of CF with demographic Ô¨Åltering or CF with content based Ô¨Åltering, to exploit merits of each one of these techniques. In these cases, the chromosome structure can easily contain the demographic charac- teristics and/or those related to content-based Ô¨Åltering. In order to tackle location-based advertisement, Dao et al. [68] propose a model-based CF using GA. They combine both user‚Äôs preferences and interaction context. Bobadilla et al. [33] use GA to create a similarity metric, weighting a set of very simple similar- ity measures. Hwang et al. [106] employ a GA to learn personal preferences of customers. NN is a model based on the observed behavior of biological neu- rons. This model, intended to simulate the way the brain processes information, enables the computer to ‚Äò‚Äòlearn‚Äô‚Äô to a certain degree. A NN typically consists of a number of interconnected nodes. Each handles a designated sphere of knowledge, and has several inputs from the network. Based on the inputs it gets, a node can ‚Äò‚Äòlearn‚Äô‚Äô about the relationships between sets of data, pattern, and, based upon operational feedback, are molded into the pattern required to generate the required results. J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 125 The RS most relevant research available in which NN usually fo- cuses is hybrid RS, in which NN are used for learn users proÔ¨Åles; NN have also been used in the clustering processes of some RS. The hybrid approaches enable NN to act on the additional infor- mation to the ratings. In Ren et al. [192] they propose a hybrid rec- ommender approach that employs Widrow-Hoff [229] algorithm to learn each user‚Äôs proÔ¨Åle from the contents of rated items. This improves the granularity of the user proÔ¨Åling. In Christakou and Stafylopatis [62] they use a combination of content-based and CF in order to construct a system that provides more precise recom- mendations concerning movies. In Lee and Woo [133] Ô¨Årst, all users are segmented by demographic characteristics and users in Fig. 11. Recommender systems taxonomy. 126 J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 each segment are clustered according to the preference of items using the Self-Organizing Map (SOM) NN. Kohonon‚Äôs SOMs are a type of unsupervised learning; their goal is to discover some underlying structure of the data. Two alternative NN uses are presented in Huang et al. [103] and Roh et al. [193] . In the Ô¨Årst case paper, authors use a training back- propagation NN for generating association rules that are mined from a transactional database; in the second paper, authors pro- pose a model that combines a CF algorithm with two machine learning processes: SOM and Case Based Reasoning (CBR) by changing an unsupervised clustering problem into a supervised user preference reasoning problem. Neuro-fuzzy inference has been used in Sevarac et al. [207] to create pedagogical rules in e-learning. A new cold-start similarity measure has been perfected in Bobadilla et al. [36] using optimiza- tion based on neural learning. ArtiÔ¨Åcial immune systems are distributed and adaptive systems using the models and principles derived form the human immune system. They model the defence system which can protect our body against infections. In order to tackle the RS sparsity problem and to make algorithms more scalable, Acilar and Arslan [2] pres- ent a new CF model based on the AIN Algorithm (aiNet). AIN were previously proposed to general recommendations [49] and to rec- ommend web sites [161] . 8. Related works and original contributions of the paper As CF has become more complex, different survey papers have been published in this area. Schafer et al. [203] introduces the core concepts of CF: the theory and practice, the rating systems and their acquisition, evaluation, interaction interfaces and privacy is- sues. Candillier et al. [51] review the main CF Ô¨Åltering methods and compare their results. Su and Khoshgoftaar [212] presents a survey of CF techniques. Authors introduce the theory on CF and concisely deal with the main challenges: sparsity, scalability, synonymy, gray sheep, shil- ling attacks, privacy, etc. They also expose an overview table of CF techniques. Park et al. [171] review 210 papers on RS and classiÔ¨Åes them by the year and journal of the publication, their application Ô¨Åelds, and their data mining techniques. Additionaly, they categorized the pa- pers into eight application Ô¨Åelds (Ô¨Ålms, music, etc.). A review in RS algorithms is presented in [141] . This paper fo- cuses on explaining carefully how the most used algorithms in RS work. The paper presents also the basic concepts of CF and their evaluation metrics, dimensionality reduction techniques, diffu- sion-based methods, social Ô¨Åltering and meta approaches. Our survey tries to include the most novel issues that have not been dealt carefully in the previous papers. Next, we will stand out the most outstanding features of this survey:  Uses a methodology for selecting the most suitable papers in the RS, standing out the latest and most cited papers in the area of RS.  Provides an updated overview table of the most used RS public databases, including tags and friend relations information.  Studies the cold-start problem inherent to all the RS.  Presents a novel overview table informing both the classical similarity measure and those which have recently been pro- posed. It includes both the tailored metrics for cold-start users and the general-purpose metrics. Besides, we show the quality measures obtained when evaluating such metrics.  Includes the recent quality measurements, beyond accuracy, to evaluate RS: novelty, diversity and stability. Additionaly, we include a reliability measure associated to predictions and recommendations.  Provides a comprehensive survey on social Ô¨Åltering, presenting a novel overview table on trust, reputation and credibility.  Introduces the content-based Ô¨Åltering from a modern perspec- tive standing out its application for dealing with social informa- tion, such as social tagging.  Presents a summary of the most relevant contributions in the RS for group of users. We will show a novel classiÔ¨Åcation for the existing methods.  Deals with a fast growing RS Ô¨Åeld: the location-aware RS, based on geographic information. This section is estructured with the help of a novel geographic RS classiÔ¨Åcation table.  Summarizes the most relevant contributions on the use of bio- inspired approaches.  Describes the RS trends to implicitally collect data (specially those derived from the use of Internet of things).  Provides an RS taxonomy for classifying the RS through three factors: source of data (traditional web, social web 2.0, Internet of things/web 3.0); target of data (users, items); method for extracting data (explicit, implicit). 9. Conclusions Recommender systems are proving to be a useful tool for addressing a portion of the information overload phenomenon from the Internet. Its evolution has accompanied the evolution of the web. The Ô¨Årst generation of recommender systems used tradi- tional websites to collect information from the following three sources: (a) content-based data from purchased or used products, (b) demographic data collected in users‚Äô records, and (c) mem- ory-based data collected from users‚Äô item preferences. The second generation of recommender systems, extensively use the web 2.0 by gathering social information (e.g., friends, followers, followed, trusted users, untrusted users). The third generation of recom- mender systems will use the web 3.0 through information pro- vided by the integrated devices on the Internet. The use of location information already incorporated in many recommender systems will be followed by data from devices and sensors, which will be widely used (e.g., real-time health signals, RFID, food habits, online local weather parameters such as temperature and pressure). The Ô¨Årsts recommender systems were focused on improving recommendation accuracy through Ô¨Åltering. Most memory-based methods and algorithms were developed and optimized in this context (e.g., k NN metrics, aggregation approaches, singular value decomposition, diffusion-based methods, etc.). At this stage, hybrid approaches (primarily collaborative‚Äìdemographic and collabora- tive‚Äìcontent Ô¨Åltering) improved the quality of the recommenda- tions. In the second stage, algorithms that included social information with previous hybrid approaches were adapted and developed (e.g., trust-aware algorithms, social adaptive ap- proaches, social networks analysis, etc.). Currently, the hybrid ensemble algorithms incorporate location information into exist- ing recommendation algorithms. Evaluation of the predictions and recommendations has evolved since the origins of recommender systems, which weighted prediction errors (accuracy) heavily. They also recognized the Table 4 Geographic collaborative Ô¨Åltering recommender systems classiÔ¨Åcation. Rating stage Recommendation stage User GI Item Item g Item Item g User RS/GRS ‚Äì RS RS + G Not User g ‚Äì GRS + ‚Äì GRS/GRS + Yes Item GI Not Yes Not Yes J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 127 convenience of evaluating the quality of the top n recommenda- tions as a set; evaluation of the top n recommendations as a ranked list was then incorporated. Currently, there is a tendency to assess new evaluation measures, such as diversity and novelty. Future research will concentrate on advancing the existing methods and algorithms to improve the quality of recommender systems predictions and recommendations. Simultaneously, new lines of research will be developed for Ô¨Åelds and aims, such as on: (1) proper combination of existing recommendation methods that use different types of available information, (2) to get the maximum use of the individual potential of various sensors and devices on the Internet of things, (3) acquisition and integration of trends related to the habits, consumption and tastes of individ- ual users in the recommendation process, (4) data mining from RS databases for non-recommendation uses (e.g., market research, general trends, visualization of differential characteristics of demo- graphic groups), (5) enabling security and privacy for recom- mender systems processes, (6) new evaluation measures and developing a standard for non-standardized evaluation measures, and (7) designing Ô¨Çexible frameworks for automated analysis of heterogeneous data. References [1] S. Abbar, M. Bouzeghoub, S. Lopez, Context-aware recommender systems: a service oriented approach, in: Proceedings of the 3rd International Workshop on Personalized Access, ProÔ¨Åle Management and Context Awareness in Databases, 2009. [2] A.M. Acilar, A. Arslan, A collaborative Ô¨Åltering method based on artiÔ¨Åcial immune network, Expert Systems with Applications 36 (4) (2008) 8324‚Äì 8332 . [3] G. Adomavicius, A. Tuzhilin, Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions, IEEE Transactions on Knowledge and Data Engineering 17 (6) (2005) 734‚Äì749 . [4] G. Adomavicius, J. Zhang, On the stability of recommendations algorithms, in: ACM Conference on Recommender Systems, 2010, pp. 47‚Äì54. [5] G. Adomavicius, A. Tuzhilin, Context-Aware recommender Systems, in: F. Ricci, et al. (Ed.), Recommender Systems Handbook, 2011, pp. 217‚Äì253. [6] H.J. Ahn, A new similarity measure for collaborative Ô¨Åltering to alleviate the new user cold-starting problem, Information Sciences 178 (2008) 37‚Äì51 . [7] M.Y.H. Al-Shamri, K.K. Bharadwaj, Fuzzy-genetic approach to recommender systems based on a novel hybrid user model, Expert Systems with Applications 35 (3) (2008) 1386‚Äì1399 . [8] J. Al-Sharawneh, M.A. Williams, Credibility-aware Web-based social network recommender: follow the leader, in: Proceedings of the 2010 ACM Conference on Recommender Systems, 2010, pp. 1‚Äì8. [9] S. Alonso, F.J. Cabrerizo, F. Chiclana, F. Herrera, E. Herrera-Viedma, Group decision making with incomplete fuzzy linguistic preference relations, International Journal of Intelligent Systems 24 (2009) 201‚Äì222 . [10] A. Ansari, S. Essegaier, R. Kohli, Internet recommendation systems, Journal of Marketing Research 37 (3) (2000) 363‚Äì375 . [11] N. Antonopoulus, J. Salter, Cinema screen recommender agent: combining collaborative and content-based Ô¨Åltering, IEEE Intelligent Systems (2006) 35‚Äì 41 . [12] P. Antunes, V. Herskovic, S.F. Ochoa, J.A. Pino, Structuring dimensions for collaborative systems evaluation, ACM Computing Surveys 44 (2) (2012). Article 8 . [13] O. Arazy, N. Kumar, B. Shapira, Improving Social Recommender Systems, Journal IT Professional 11 (4) (2009) 31‚Äì37 . [14] L. Ardissono, A. Goy, G. Petrone, M. Segnan, P. Torasso, INTRIGUE: Personalized recommendation of tourist attractions for desktop and handset devices, Applied ArtiÔ¨Åcial Intelligence 17 (8-9) (2003) 687‚Äì714 . [15] R. Baeza-Yates, B. Ribeiro-Neto, Modern Information Retrieval, Addison- Wesley, 1999 . [16] M. Balabanovic, Y. Shoham, Content-based, collaborative recommendation, Communications of the ACM 40 (3) (1997) 66‚Äì72 . [17] L. Baltrunas, T. Makcinskas, F. Ricci, Group recommendation with rank aggregation and collaborative Ô¨Åltering, in: Proceedings of the 2010 ACM Conference on Recommender Systems, 2010, pp. 119‚Äì126. [18] A.B. Barrag√°ns-Martƒ±¬¥nez, E. Costa-Montenegro, J.C. Burguillo, M. Rey-L√≥pez, F.A. Mikic-Fonte, A. Peleteiro, A hybrid content-based and item-based collaborative Ô¨Åltering approach to recommend TV programs enhanced with singular value decomposition, Information Sciences 180 (22) (2010) 4290‚Äì 4311 . [19] C. Basu, H. Hirsh, W. Cohen, Recommendation as classiÔ¨Åcation: using social and content-based information in recommendation, in: Proceedings of the Fifteenth National Conference on ArtiÔ¨Åcial Intelligence, 1998, pp. 714‚Äì720. [20] P. Bedi, R. Sharma, Trust based recommender system using ant colony for trust computation, Expert Systems with Applications 39 (1) (2012) 1183‚Äì 1190 . [21] Y. Bengio, Y. Grandvalet, No umbiased estimator of the variance of k-fold cross-validation, Journal of Machine Learning Research 5 (2004) 1089‚Äì1105 . [22] S. Berkovsky, J. Freyne, Group-based recipe recommendations: analysis of data aggregation strategies, in: Proceedings of the 2010 ACM Conference on Recommender Systems, 2010, pp. 111‚Äì118. [23] A. Bilge, H. Polat, An improved privacy-preserving DWT-based collaborative Ô¨Åltering scheme, Experts Systems with Applications 39 (3) (2012) 3654‚Äì 3841 . [24] M. Bilgic, R. Mooney, Explanation for recommender systems: satisfaction vs. promotion, in: Next Stage of Recommender Systems Research Workshop (IUI conference), 2005, pp. 13‚Äì18. [25] D. Billsus, M. Pazzani, A personal news agent that talks, learns and explains, in: Proc. Auton. Agents Conf., 1999, pp. 268‚Äì275. [26] D. Billsus, M. Pazzani, User modeling for adaptive news access, User Modeling and User-Adapted Interaction 10 (2‚Äì3) (2000) 147‚Äì180 . [27] D. Billsus, M. Pazzani, J. Chen, A learning agent for wireless news access, in: Proceedings of the International Conference on Intelligent User Interfaces, 2002, pp. 33‚Äì36. [28] R.P. Biuk-Aghai, S. Fong, S. Yain-Whar, Design of a recommender system for mobile tourism multimedia selection, in: 2nd International Conference on Internet Multimedia Services Architecture and Applications (IMSAA), 2008, pp. 1‚Äì6. [29] J. Bobadilla, F. Serradilla, The effect of sparsity on collaborative Ô¨Åltering metrics, in: Australian Database Conference, 2009, pp. 9‚Äì17. [30] J. Bobadilla, F. Serradilla, A. Hernando, Collaborative Ô¨Åltering adapted to recommender systems of e-learning, Knowledge Based Systems 22 (2009) 261‚Äì265 . [31] J. Bobadilla, F. Serradilla, J. Bernal, A new collaborative Ô¨Åltering metric that improves the behavior of recommender systems, Knowledge Based Systems 23 (2010) 520‚Äì528 . [32] J. Bobadilla, A. Hernando, F. Ortega, J. Bernal, A framework for collaborative Ô¨Åltering recommender systems, Expert Systems with Applications 38 (12) (2011) 14609‚Äì14623 . [33] J. Bobadilla, F. Ortega, A. Hernando, J. Alcal√°, Improving collaborative Ô¨Åltering recommender systems results and performance using genetic algorithms, Knowledge Based Systems 24 (8) (2011) 1310‚Äì1316 . [34] J. Bobadilla, A. Hernando, F. Ortega, A. Guti√©rrez, Collaborative Ô¨Åltering based on signiÔ¨Åcances, Information Sciences 185 (1) (2012) 1‚Äì17 . [35] J. Bobadilla, F. Ortega, A. Hernando, A collaborative Ô¨Åltering similarity measure based on singularities, Information Processing and Management 48 (2) (2012) 204‚Äì217 . [36] J. Bobadilla, F. Ortega, A. Hernando, J. Bernal, A collaborative Ô¨Åltering approach to mitigate the new user cold start problem, Knowledge Based Systems 26 (2012) 225‚Äì238 . [37] J. Bobadilla, F. Ortega, A. Hernando, J. Bernal, Generalization of recommender systems: collaborative Ô¨Åltering extended to groups of users and restricted to groups of items, Expert Systems with Applications 39 (2012) 172‚Äì186 . [38] J. Bobadilla, F. Ortega, A. Hernando, A. Arroyo, A balanced memory-based collaborative Ô¨Åltering similarity measure, International Journal of Intelligent Systems 27 (10) (2013) 939‚Äì946 . [39] T. Bogers, A. Van Den Bosch, Collaborative and content-based Ô¨Åltering for item recommendation on social bookmarking websites, in: Proceedings of the 2009 ACM Conference on Recommender Systems, 2009, pp. 9‚Äì16. [40] P. Bonhard, Who do trust? Combining recommender systems and social networking for better advice, in: International Conference on Intelligent User Interfaces, 2005. [41] P. Bonhard, M.A. Sasse, ‚ÄòKnowing me, knowing you‚Äô‚ÄîUsing proÔ¨Åles and social networking to improve recommender Systems, BT Technology Journal 24 (3) (2006) 84‚Äì98 . [42] P. Borzymek, M. Sydow, A. Wierbicki, Enriching trust prediction model in social network with user rating similarity, in: Proceedings of the 2009 International Conference on Computational Aspects of Social Network, 2009, pp. 40‚Äì47. [43] J.S. Breese, D. Heckerman, C. Kadie, Empirical analysis of predictive algorithms for collaborative Ô¨Åltering, in: 14th Conference on Uncertainty in ArtiÔ¨Åcial Intelligence, 1998, pp. 43‚Äì52. [44] D. Bridge, M.H. Goker, L. McGinty, B. Smyth, Case-based recommender systems, The Knowledge Engineering Review 20 (3) (2005) 315‚Äì320 . [45] R. Burke, Encyclopedia of library and information systems, in: A. Kent (Ed.), vol. 69(Suppl. 32), Marcel Dekker, 2000 (Chapter: Knowledge-Based Recommender Systems). [46] R. Burke, A case-based reasoning approach to collaborative Ô¨Åltering, in: EWCBR 2000, 2000, pp. 370‚Äì379. [47] R. Burke, Hybrid recommender systems: survey and experiments, User Modeling and User-Adapted Interaction 12 (4) (2002) 331‚Äì370 . [48] F. Cacheda, V. Carneiro, D. Fern√°ndez, V. Formoso, Comparison of collaborative Ô¨Åltering algorithms: limitations of current techniques and proposals for scalable, high-performance recommender Systems, ACM Transactions on the Web 5 (1) (2011). Article 2 . [49] S. Caizer, U. Aickelin, A recommender system based on idiotypic artiÔ¨Åcial immune networks, Journal of Mathematics, Models and Algorithms 4 (2) (2005) 181‚Äì198 . 128 J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 [50] L.M. Campos, J.M. Fern√°ndez-Luna, J.F. Huete, M.A. Rueda-Morales, Combining content-based and collaborative recommendations: a hybrid approach based on Bayesian Networks, International Journal of Approximate Reasoning 51 (7) (2010) 785‚Äì799 . [51] L. Candillier, F. Meyer, M. Boull√©, Comparing state-of-the-art collaborative Ô¨Åltering systems, Lecture Notes in Computer Sciece 4571 (2007) 548‚Äì562 . [52] F. Carmagnola, F. Vernero, P. Grillo, SoNARS: a social networks-based algorithm for social recommender systems, in: Proceedings of the 17th International Conference on User Modeling, Adaptation, and Personalization: Formerly UM and AH, 2009, pp. 223‚Äì234. [53] W. Carrer-Neto, M.L. Hern√°ndez-Alcaraz, R. Valencia-Garcƒ±¬¥a, F. Garcƒ±¬¥a- S√°nchez, Social knowledge-based recommender system, Application to the movies domain. Expert Systems with Applications 39 (12) (2012) 10990‚Äì 11000 . [54] J.J. Castro-Sanchez, R. Miguel, D. Vallejo, L.M. L√≥pez-L√≥pez, A highly adaptive recommender system based on fuzzy logic for B2C e-commerce portals, Expert Systems with Applications 38 (3) (2011) 2441‚Äì2454 . [55] D. Chao, J. Balthrop, S. Forrest, Adaptive radio: achieving consensus using negative preferences, in: International ACM SIGGROUP Conference on Supporting Group Work, 2005, pp. 120‚Äì123. [56] T. Chen, L. He, Collaborative Ô¨Åltering based on demographic attribute vector, in: Proceedings of the International Conference on Future Computer and Communication, 2009, pp. 225‚Äì229. [57] P.A. Chirita, W. Nejdl, C. ZamÔ¨År, Preventing shilling attacks in online recommender systems, in: Workshop on Web Information and Data Management, 2005, pp. 67‚Äì74. [58] J. Cho, K. Kwon, Y. Park, Q-rater: a collaborative reputation system based on source credibility theory, Expert Systems with Applications 36 (2009) 3751‚Äì 3760 . [59] S.B. Cho, J.H. Hong, M.H. Park, Location-based recommendation system using Bayesian user‚Äôs preference model in mobile devices, Lecture Notes in Computer Science 4611 (2007) 1130‚Äì1139 . [60] K. Choi, D. Yoo, G. Kim, Y. Suh, A hybrid online-product recommendation system: combining implicit rating-based collaborative Ô¨Åltering and sequential pattern analysis. Electronic Commerce Research and Applications, in press, doi: 10.1016/j.elerap.2012.02.004. [61] K. Choi, Y. Suh, A new similarity fuction for selecting neighbors for each target item in collaborative Ô¨Åltering, Knowledge Based Systems 37 (2013) 146‚Äì153 . [62] C. Christakou, A. Stafylopatis, A hybrid movie recommender system based on neural networks, in: International Conference on Intelligent Systems Design and Applications, 2005, pp. 500‚Äì505. [63] I.A. Christensen, S. SchiafÔ¨Åno, Entertainment recommender systems for group of users, Expert Systems with Applications 38 (2011) 14127‚Äì14135 . [64] M. Claypool, A. Gokhale, T. Miranda, P. Murnikov, D. Netes, M. Sartin, Combining content-based and collaborative Ô¨Ålters in an online newspaper, in: Proceedings of ACM SIGIR Workshop on Recommender Systems, 1999, pp. 40‚Äì48. [65] W. Cohen, Fast effective rule induction, in: Proceedings of the Twelfth International Conference on Machine Learning, 1995, pp. 115‚Äì123. [66] M. Condliff, D. Lewis, D. Madigan, C. Posse, Bayesian mixed-effects models for recommender systems, in: ACM SIGIR ‚Äô99 Workshop on Recommender Systems: Algorithms and Evaluation, 1999, pp. 23‚Äì30. [67] E. Costa-Montenegro, A.B. Barrag√°ns-Martƒ± ¬¥ nez, M. Rey-L√≥pez, Which App? A recommender system of applications in markets: implementation of the service for monitoring users‚Äô interaction, Expert Systems with Applications 39 (10) (2012) 9367‚Äì9375 . [68] T.H. Dao, S.R. Jeong, H. Ahn, A novel recommendation model of location-based advertising: context-aware collaborative Ô¨Åltering using GA approach, Expert Systems with Applications 39 (3) (2012) 3731‚Äì3739 . [69] M. Dell‚Äôamico, L. Capra, SOFIA: social Ô¨Åltering for robust recommendation, IFIP Advances in Information and Communication Technology 263 (2008) 135‚Äì150 . [70] T. Dubois, J. Golbeck, J. Kleint, A. Srinivasan, Improving recommendation accuracy by clustering social networks with trust, in: Proceedings of the 2009 ACM Conference on Recommender Systems, 2009, pp. 1‚Äì8. [71] M. Ekstr√∂m, H. Bj√∂rnsson, C. Nass, A reputation mechanism for business-to- business electronic commerce that accounts for rater credibility, Journal of Organizational Computing and Electronic Commerce 15 (1) (2005) 1‚Äì18 . [72] I. Esslimani, A. Brun, A. Boyer, From social networks to behavioral networks in recommender systems, in: Proceedings of the 2009 International Conference on Advances in Social Network Analysis and Mining, 2009, pp. 143‚Äì148. [73] Y. Fahri, A Framework for Organizing JustiÔ¨Åcations for Strategic use in Adaptive Iteraction Contexts, ECIS, 2008. Article 250 . [74] A. Felfernig, R. Burke, Constraint-based recommender systems: technologies and research issues, in: 10th International Conference on Electronic Commerce, 2008 (Article No. 3). [75] L. Fengkun, J.L. Hong, Use of social network information to enhance collaborative Ô¨Åltering performance, Expert Systems with Applications 37 (7) (2010) 4772‚Äì4778 . [76] L.Q. Gao, C. Li, Hybrid personalizad recommended model based on genetic algorithm, in: International Conference on Wireless Communication, Networks and Mobile Computing, 2008, pp. 9215‚Äì9218. [77] M. Gao, Z. Wu, F. Jiang, Userrank for item-based collaborative Ô¨Åltering recommendation, Information Processing Letters 111 (9) (2011) 440‚Äì446 . [78] I. Garcƒ±¬¥ a, L. Sebastia, E. Onaindia, On the design of individual and group recommender systems for tourism, Expert Systems with Applications 38 (2011) 7683‚Äì7692 . [79] R. Garcƒ±¬¥a, X. Amatriain, Weighted content based methods for recommending connections in online social networks, in: Proceedings of the 2010 ACM conference on Recommender Systems, 2010, pp. 68‚Äì71. [80] D. Gavalas, M. Kenteris, A web-based pervasive recommendation system for mobile tourist guides, Personal and Ubiquitous Computing 15 (7) (2011) 759‚Äì770 . [81] F. Gedikli, D. Jannach, Rating items by rating tags, in: Proceedings of the 2010 ACM Conference on Recommender Systems, 2010, pp. 25‚Äì32. [82] J. Gemmell, T. Schimoler, B. Mobasher, R. Burke, Resource recommendation for social tagging: a multi-channel hybrid approach, in: Proceedings of the 2010 ACM Conference on Recommender Systems, 2010, pp. 60‚Äì67. [83] J. Gemmell, T. Schimoler, M. Ramezani, L. Christiansen, B. Mobasher, Improving FolkRank with item-based collaborative Ô¨Åltering, in: Proceedings of the 2009 ACM conference on Recommender Systems, 2009, pp. 17‚Äì24. [84] M. Gemmis, P. Lops, G. Semeraro, P. Basile, Integrating tags in a semantic content-based recommender, in: Proceedings of the 2008 ACM conference on Recommender Systems, 2008, pp. 163‚Äì170. [85] T. George, S. Meregu, A scalable collaborative Ô¨Åltering Framework base don co-clustering, in: IEEE International Conference on Data Mining (ICDM), 2005, pp. 625‚Äì628. [86] J. Golbeck, U. Kuter, The ripple effect: change in trust and its impact over a social network, in: Computing with Social Trust, Human‚ÄìComputer Interaction Series, Part II, 2009, pp. 169‚Äì181 (Chapter 7). [87] K. Goldberg, T. Roeder, D. Gupta, C. Perkins, Eigentaste: a constant time collaborative Ô¨Åltering algorithm, Information Retrieval 4 (2) (2001) 133‚Äì151 . [88] R. Gonz√°lez-Crespo, O. Sanju√°n-Martƒ±¬¥nez, J. Manuel-Cueva, B. Cristina-Pelayo, J.E. Labra-Gayo, P. Ordo√±ez, Recommendation system based on user interaction data applied to intelligent electronic books, Computers in Human Behavior 27 (4) (2011) 1445‚Äì1449 . [89] N. Good, J.B. Schafer, J.A. Konstan, A. Borchers, B. Sarwar, J.L. Herlocker, J. Riedl, in: Proceedings of the Sixteenth National Conference on ArtiÔ¨Åcial Intelligence and the Eleventh Innovative Applications of ArtiÔ¨Åcial Intelligence Conference Innovative Applications of ArtiÔ¨Åcial Intelligence, 1999, pp. 439‚Äì 446. [90] A. Gunawardana, G. Shani, A survey of accuracy evaluation metrics of recommender tasks, Journal of Machine Learning Reearch 10 (2009) 2935‚Äì 2962 . [91] J.L. Herlocker, J.A. Konstan, J. Riedl, Explaining collaborative Ô¨Åltering recommendations, in: ACM Conference on Computer Supported Cooperative Work (CSCW), 2000, pp. 241‚Äì250. [92] J.L. Herlocker, J.A. Konstan, A.L. Borchers, J.T. Riedl, An algorithmic framework for performing collaborative Ô¨Åltering, in: Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1999, pp. 230‚Äì237. [93] J.L. Herlocker, J.A. Konstan, J.T. Riedl, An empirical analysis of design choices in neighborhood-based collaborative Ô¨Åltering algorithms, Information Retrieval 5 (2002) 287‚Äì310 . [94] J.L. Herlocker, J.A. Konstan, J.T. Riedl, L.G. Terveen, Evaluating collaborative Ô¨Åltering recommender systems, ACM Transactions on Information Systems 22 (1) (2004) 5‚Äì53 . [95] F. Hern√°ndez, E. Gaudioso, Evaluation of recommender systems: a new approach, Expert Systems with Applications 35 (2008) 790‚Äì804 . [96] A. Hernando, J. Bobadilla, F. Ortega, J. Tejedor, Incorporating reliability measurements into the predictions of a recommender systems. Information Sciences, in press, doi: 10.1016/j.ins.2013.03.018. [97] A. Hernando, J. Bobadilla, F. Ortega, A. Guti√©rrez, Trees for explaining recommendations made through collaborative Ô¨Åltering, Information Sciences 218 (2013) 1‚Äì16 . [98] K. Heung-Nam, E.S. Abdulmotaleb, J. Geun-Sik, Collaborative error-reÔ¨Çected models for cold-start recommender systems, Decision Support Systems 51 (3) (2011) 519‚Äì531 . [99] Y. Ho, S. Fong, Z. Yan, A hybrid ga-based collaborative Ô¨Åltering model for online recommenders, in: International Conference on e-Business, 2007, pp. 200‚Äì203. [100] L. Hossain, D. Fazio, The social networks of collaborative process, The Journal of High Technology Management Research 20 (2) (2009) 119‚Äì130 . [101] H.R. Hu, P. Pu, Using personality information in collaborative Ô¨Åltering for new users, in: Proceedings of the 2010 ACM Conference on Recommender Systems, 2010, pp. 17‚Äì24. [102] Y. Hu, Y. Koren, C.H. Volinsky, Collaborative Ô¨Åltering for implicit feedback datasets, in: IEEE International Conference on Data Mining (ICDM), 2008, pp. 263‚Äì272. [103] Y.P. Huang, W.P. Chuang, Y.H. KE, F.E. Sandnes, Using back-propagation to learn association rules for service personalization, Expert Systems with Applications 35 (2008) 245‚Äì253 . [104] Z. Huang, D. Zeng, H. Chen, A comparison of collaborative Ô¨Åltering recommendation algorithms for e-commerce, IEEE Intelligent Systems 22 (5) (2007) 68‚Äì78 . [105] N. Hurley, M. Zhang, Novelty and diversity in top-N recommendations- analysis and evaluation, ACM Transactions on Internet Technology 10 (4) (2011) 1‚Äì29 . J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 129 [106] CH.S. Hwang, Y.CH. Su, K.CH. Tseng, Using genetic algorithms for personalized recommendation, Lecture Notes in Computer Science 6422 (2010) 104‚Äì112 . [107] H. Ingoo, J.O. Kyong, H.R. Tae, The collaborative Ô¨Åltering recommendation based on SOM cluster-indexing CBR, Expert Systems with Applications 25 (2003) 413‚Äì423 . [108] A. Jameson, B. Smyth, Recommendation to groups, in: P. Brusilovsky, A. Kobsa, W. Nejdl (Eds.), The Adaptive Web, 2007, pp. 596‚Äì627 (Chapter 20). [109] D. Jannach, Fast computation of query relaxations for knowledge-based recommenders, AI Communications 22 (4) (2009) 235‚Äì248 . [110] R. J√§schke, L. Marinho, A. Hotho, L. Schmidt-Thieme, G. Stumme, Tag Recommendations in Folksonomies, in: Proceedings of the 11th European Conference on Principles and Practice of Knowledge Discovery in Databases, 2007, pp. 506‚Äì514. [111] J.J. Jason, Contextualized mobile recommendation service based on interactive social network discovered from mobile users, Expert Systems with Applications 36 (9) (2009) 11950‚Äì11956 . [112] B. Jeong, J. Lee, H. Cho, User credit based collaborative Ô¨Åltering, Expert Systems with Applications 36 (2009) 7309‚Äì7312 . [113] T. Joachims, Text categorization with support vector machines: learning with many relevant features, in: European Conference on Machine Learning, 1998, pp. 137‚Äì142. [114] A. J√∏sang, R. Ismail, C. Boyd, A survey of trust and reputation systems for online service provision, Decision Support Systems 43 (2) (2007) 618‚Äì644 . [115] CH.W. Jyun, CH.CH. Chui, Recommending trusted online auction sellers using social network analysis, Expert Systems with Applications 34 (3) (2008) 1666‚Äì1679 . [116] C. Kaleli, H. Polat, Privacy-preserving SOM-based recommendations on horizontally distributed data, Knowledge Based Systems 33 (2012) 124‚Äì135 . [117] H.N. Kim, A. Alkhaldi, A.E. Saddik, G.S. Jo, Collaborative user modeling with user-generated tags for social recommender Systems, Expert Systems with Applications 38 (7) (2011) 8488‚Äì8496 . [118] H.N. Kim, A.T. Ji, I. Ha, G.S. Jo, Collaborative Ô¨Åltering based on collaborative tagging for enhancing the quality of recommendations, Electronic Commerce Research and Applications 9 (1) (2010) 73‚Äì83 . [119] J. Kim, B. Lee, M. Shaw, H. Chang, W. Nelson, Application of decision-tree induction techniques to personalized advertisements on internet storefronts, International Journal of Electronic Commerce 5 (3) (2001) 45‚Äì62 . [120] K. Kim, H. Ahn, Using a clustering genetic algorithm to support customer segmentation for personalizad recommender systems, in: Proceedings of the 13th International Conference on AI, Simulation, and Planning in High Autonomy Systems, 2004, pp. 409-415. [121] K. Kim, H. Ahn, A recommender system using GA K-means clustering in an online Shopping market, Expert Systems with Applications 34 (2) (2008) 1200‚Äì1209 . [122] S. Kitisin, C. Neuman, Reputation-based trust-aware recommender system, in: Securecomm and Workshops, 2009, pp. 1‚Äì7. [123] F. Kong, X. Sun, S. Ye, A comparison of several algorithms for collaborative Ô¨Åltering in startup stage, IEEE Transactions on Networks, Sensing and Control (2005) 25‚Äì28 . [124] Y. Koren, R. Bell, CH. Volinsky, Matrix factorization techniques dor recommender systems, IEEE Computer 42 (8) (2009) 42‚Äì49 . [125] G. Koutrika, B. Bercovitz, H. Garcia, FlexRecs: expressing and combining Ô¨Çexible recommendations, in: Proceedings of the 35th SIGMOD International Conference on Management of Data, 2009, pp. 745‚Äì757. [126] B. Krulwich, Lifestyle Ô¨Ånder: intelligent user proÔ¨Åling using large-scale demographic data, ArtiÔ¨Åcial Intelligence Magazine 18 (2) (1997) 37‚Äì45 . [127] K. Kwon, J. Cho, Y. Park, Multidimensional credibility model for neighbor selection in collaborative recommendation, Expert Systems with Applications 36 (2009) 7114‚Äì7122 . [128] S.K. Lam, J. Riedl, Shilling recommender systems for fun and proÔ¨Åt, in: International Conference on World Wide Web, 2004, pp. 393‚Äì402. [129] X.N. Lam, T. Vu, T.D. Le, A.D. Duong, Addressing cold-start problem in recommendation systems, in: Conference On Ubiquitous Information Management And Communication, 2008, pp. 208‚Äì211. [130] N. Landia, S.S. Anand, Personalised tag recommendation, in: Proceedings of the 2009 ACM Conference on Recommender Systems, 2009, pp. 83‚Äì36. [131] K. Lang, NewsWeeder: learning to Ô¨Ålter netnews, in: Proceedings 12th International Conference on Machine Learning, 1995, pp. 331‚Äì339. [132] D.H. Lee, P. Brusilovsky, Does trust inÔ¨Çuence information similarity? in: Proceedings of the 2009 ACM Conference on Recommender Systems, 2009, pp. 71‚Äì74. [133] M. Lee, Y. Woo, A hybrid recommender system combining collaborative Ô¨Åltering with neural network, Lecture Notes on Computer Sciences 2347 (2002) 531‚Äì534 . [134] S.K. Lee, Y.H. Cho, S.H. Kim, Collaborative Ô¨Åltering with ordinal scale-based implicit ratings for mobile music recommendations, Information Sciences 180 (11) (2010) 2142‚Äì2155 . [135] C.W. Leung, S.C. Chan, F.L. Chung, An empirical study of a cross-level association rule mining approach to cold-start recommendations, Knowledge Based Systems 21 (7) (2008) 515‚Äì529 . [136] Q. Li, Clustering approach for hybrid recommender system, in: Proceedings of the 2003 IEEE/WIC International Conference on Web Intelligence, 2003, pp. 33‚Äì38. [137] Y.M. Li, CH.W. Chen, A synthetical approach for blog recommendation: combining trust, social relation, and semantic an√°lisis, Expert Systems with Applications 36 (3) (2009) 6536‚Äì6547 . [138] Y.M. Li, CH.P. Kao, TREPPS: a trust-based recommender system for peer production services, Expert Systems with Applications 36 (2) (2009) 3263‚Äì 3277 . [139] Y.M. Li, T.F. Liao, CH.Y. Lai, A social recommender mechanism for improving knowledge sharing in online forums, Information Processing and Management, in press, doi: 10.106/j.ipm.2011.10.004. [140] S. Loh, F. Lorenzi, R. Granada, D. Lichtnow, L.K. Wives, J.P. Oliveira, Identifying similar users by their scientiÔ¨Åc publications to reduce cold start in recommender systems, in: Proceedings of the 5th International Conference on Web Information Systems and Technologies (WEBIST2009), 2009, pp. 593‚Äì600. [141] L. L√º, M. Medo, Ch.H. Yeung, Y.Ch. Zhang, Z.K. Zhang, T. Zhou, Recommender systems, Physics Reports 519 (2012) 1‚Äì49 . [142] X. Luo, Y. Xia, Q. Zhu, Incremental collaborative Ô¨Åltering recommender based on regularizad matrix factorization, Knowledge-Based Systems 27 (2012) 271‚Äì280 . [143] X. Luo, Y. Xia, Q. Zhu, Applying the learning rate adaptation to the matrix factorization based collaborative Ô¨Åltering, Knowledge Based Systems 37 (2013) 154‚Äì164 . [144] H. Ma, I. King, M.R. Lyu, Learning to recommend with explicit and implicit social relations, ACM Transactions on Intelligent Systems and Technology 2 (3) (2011). Article 29 . [145] H. Ma, T. CH. Zhou, M.R. Lyu, I. King, Improving recommender systems by incorporating social contextual information, ACM Transactions on Information Systems 29 (2) (2011). Article 9 . [146] A. Machanavajjhala, A. Korolova, A.D. Sharma, Personalized social recommendations: accurate or private, in: Proceedings of the VLDB Endowment, vol. 4, issue 7, 2011, pp. 440‚Äì450. [147] L.B. Marinho, L. Schmidt-Thieme, Collaborative tag recommendations, in: Proceedings of the 31st Annual Conference of the German ClassiÔ¨Åcation Society, 2008, pp. 533‚Äì540. [148] L. Martinez, L.G. Perez, M.J. Barranco, Incomplete preference relations to smooth out the cold-start in collaborative recommender systems, in: Proceedings of the 28th North American Fuzzy Information Processing Society Annual Conference (NAFIPS2009), 2009a, pp. 1‚Äì6. [149] L. Martinez, R.M. Rodriguez, M. Espinilla, REJA: a georeferenced hybrid recommender system for restaurants, in: IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technonolgy (WI-IAT 3), 2009b, pp. 187‚Äì190. [150] P. Massa, P. Avesani, Trust-aware collaborative Ô¨Åltering for recommender systems, Lecture Notes in Computer Science 3290 (2004) 492‚Äì508 . [151] P. Massa, P. Avesani, Trust-aware recommender Systems, in: Proceedings of the 2007 ACM conference on Recommender Systems, 2007, pp. 17‚Äì24. [152] C. Matyas, C. Schlieder, A spatial user similarity measure for geographic recommender systems, in: Proceedings of the 3rd International Conference on GeoSpatial Semantics, 2009, pp. 122‚Äì139. [153] K. Mccarthy, J. Reilly, L. Mcginty, B. Smyth, Thinking positively-explanatory feedback for conversational recommender systems, in: European Conference on Case-based reasoning (ECCBR), 2004, pp. 115‚Äì124. [154] K. Mcnally, M.P. O‚Äômahony, M. Coyle, P. Briggs, B. Smyth, A case study of collaboration and reputation in social web search, ACM Transactions on Intelligent Systems and Technology 3 (1) (2011). Article 4 . [155] D. Mcsherry, Explanation in recommender systems, ArtiÔ¨Åcial Intelligence Review 24 (2) (2005) 179‚Äì197 . [156] F. Mcsherry, I. Mironov, Differentially Private recommender systems: building privacy into the netÔ¨Çix prize contenders, in: Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 2009, pp. 627‚Äì636. [157] P. Melville, R.J. Mooney, R. Nagarajan, Content-boosted collaborative Ô¨Åltering for improved recommendations, in: Proceeding Eighteenth National Conference on ArtiÔ¨Åcial Intelligence, 2002, pp. 187‚Äì192. [158] R. Meteren, M. Someren, Using content-based Ô¨Åltering for recommendation, in: Proceedings of ECML 2000 Workshop: Maching Learning in Information Age, 2000, pp. 47‚Äì56. [159] S.E. Middleton, N.R. Shadbolt, D.C. De Roure, Ontological user proÔ¨Åling in recommender systems, ACM Transactions on Information Systems (TOIS) 22 (1) (2004) 54‚Äì88 . [160] R.J. Mooney, L. Roy, Content-based book recommending using learning for text categorization, in: Proceedings of the Fifth ACM Conference on Digital Libraries, 2000, pp. 195‚Äì204. [161] T. Morrison, U. Aickelin, An artiÔ¨Åcial immune system as a recommender for Web sites, in: International Conference on ArtiÔ¨Åcial Immune Systems, 2002, pp. 161‚Äì169. [162] A. Nanolopoulus, D. Rafailidis, P. Symeonidis, Y. Manolopoulus, Music Box: personalizad music recommendation based on cubic analysis of social tags, IEEE Transactions on Audio, Speech and Language Processing 18 (2) (2010) 407‚Äì412 . [163] K. Nehring, C. Puppe, A theory of diversity, Econometrica 70 (3) (2002) 1155‚Äì 1198 . [164] E.R. N√∫√±ez-Vald√©z, J.M. Cueva-Lovelle, O. Sanju√°n-Martƒ±¬¥nez, V. Garcƒ± ¬¥ a-Dƒ±¬¥az, P. Ordo√±ez, C.E. Montenegro-Marƒ±¬¥ n, Implicit feedback techniques on recommender systems applied to electronic books, Computers in Human Behavior 28 (4) (2012) 1186‚Äì1193 . 130 J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 [165] J. O‚Äôdonovan, Capturing trust in social web applications, in: J. Golbeck (Ed.), Computing with Social Trust, 2009, pp. 213‚Äì257. [166] J. O‚Äôdonovan, B. Smyth, Trust in recommender systems, in: International Conference on Intelligent user Interfaces, 2005, pp. 167‚Äì174. [167] K. Oku, R. Kotera, K. Sumiya, Geographical recommender system based on interaction between map operation and category selection, in: Workshop on Information Heterogeneity and Fusion in Recommender Systems, 2010, pp. 71‚Äì74. [168] J. Ortega, J. Bobadilla, A. Hernando, A. Guti√©rrez, Incorporating group recommendations to recommender systems: alternatives and performance, Information Processing and Management (2013), http://dx.doi.org/10.1016/ j.ipm.2013.02.003 . [169] J. Ortega, J.L. S√°nchez, J. Bobadilla, A. Guti√©rrez, Improving collaborative Ô¨Åltering-based recommender systems results using Pareto dominance, Information Sciences (2013), http://dx.doi.org/10.1016/j.ins.2013.03.011 . [170] A. Papadimitriou, P. Symeonidid, Y. Manolopoulus, A generalized taxonomy of explanations styles for traditional and social recommender systems, Data Minning Knowledge Discovery 24 (3) (2012) 555‚Äì583 . [171] D.H. Park, H.K. Kim, I.Y. Choi, J.K. Kim, A literature review and classiÔ¨Åcation of recommender Systems research, Expert Systems with Applications 39 (2012) 10059‚Äì10072 . [172] S.T. Park, W. Chu, Pairwise preference regression for cold-start recommendation, in: Proceedings of the 2009 ACM Conference on Recommender Systems, 2009, pp. 21‚Äì28. [173] S.T. Park, D.M. Pennock, O. Madani, N. Good, D. Coste, Naƒ±¬®ve Ô¨Ålterbots for robust cold-start recommendations, in: Proceedings of Knowledge Discovery and Data Mining (KDD2006), 2006, pp. 699‚Äì705. [174] Y.J. Park, A. Tuzhilin, The long tail of recommender systems and how to leverage it, in: Proceedings of the 2008 ACM Conference on Recommender Systems, 2008, pp. 11‚Äì18. [175] M. Pazzani, D. Billsus, Learning and revising user proÔ¨Åles: the identiÔ¨Åcation of interesting web sites, Machine Learning 27 (3) (1997) 313‚Äì331 . [176] M.J. Pazzani, D. Billsus, Content-based recommender systems, in: P. Brusilovsky, A. Kobsa, W. Nejdl (Eds.), The Adaptive Web, 2007, pp. 291‚Äì 324 (Chapter 10). [177] M. Pazzani, A framework for collaborative, content-based, and demographic Ô¨Åltering, ArtiÔ¨Åcial Intelligence Review-Special Issue on Data Mining on the Internet 13 (5-6) (1999) 393‚Äì408 . [178] S. Perugini, M.A. Gon√ßalves, E.A. Fox, Recomender systems research: a connection-centric Surrey, Journal of Intelligen Information Systems 23 (2) (2004) 107‚Äì143 . [179] M.C. Pham, Y. Cao, R. Klamma, M. Jarke, A clustering approach for collaborative Ô¨Åltering recommendation using social network analysis, Journal of Universal Computer Science 17 (4) (2011) 583‚Äì604 . [180] G. Pitsilis, S.J. Knapskog, Socila trust as a solution to address sparsity-inherent problems of recommender Systems, in: Proceedings of the 2009 ACM Conference on Recommender Systems, 2009, pp. 33‚Äì40. [181] G. Pitsilis, X. Zhang, W. Wang, Clustering recommenders in collaborative Ô¨Åltering using explicit trust information, Advances in Information and Communication Technology 358 (2011) 82‚Äì97 . [182] A. Popescul, L.H. Ungar, D.M. Pennock, S. Lawrence, Probabilistic models for uniÔ¨Åed collaborative and content-based recommendation in sparse-data environments, in: Proceeding UAI ‚Äô01 Proceedings of the 17th Conference in Uncertainty in ArtiÔ¨Åcial Intelligence, 2001, pp. 437‚Äì444. [183] C. Porcel, E. Herrera-Viedma, Dealing with incomplete information in a fuzzy linguistic recommender system to disseminate information in university digital libraries, Knowledge-Based Systems 23 (1) (2010) 32‚Äì39 . [184] C. Porcel, J.M. Moreno, E. Herrera-Viedma, A multi-disciplinar recommender system to advice research resources in university digital libraries, Expert Systems with Applications 36 (10) (2009) 12520‚Äì12528 . [185] C. Porcel, A. Tejeda-Lorente, M.A. Martƒ± ¬¥ nez, E. Herrera-Viedma, A hybrid recommender system for the selective dissemination of research resources in a technology transfer ofÔ¨Åce, Information Sciences 184 (1) (2012) 1‚Äì19 . [186] J. Preece, B. Shneiderman, The reader to leader framework: motivating technology-mediated social participation, AIS Transactions on Human‚Äì Computer Interaction 1 (1) (2009) 13‚Äì32 . [187] P. Pu, L. Chen, Trust-inspiring explanation interfaces for recommender systems, Knowledge Based Systems 20 (2007) 542‚Äì556 . [188] W. Qin, L. Xin, H. Liang, Unifying user-based and item-based algorithm to improve collaborative Ô¨Åltering accuracy, Energy Procedia 13 (2011) 8231‚Äì 8239 . [189] L. Ramaswamy, P. Deepak, R. Polavarapu, K. Gunasekera, D. Garg, K. Visweswariah, S. Kalyanaraman, CAESAR: a context-aware, social recommender system for low-end mobile devices, in: International Conference on Mobile Data Management: Systems, Services and Middleware, 2009, pp. 338‚Äì347. [190] A.M. Rashid, G. Karypis, J. Riedl, Learning preferences of new users in recommender systems: an information theoretic approach, in: ACM SIGKDD Explorations Newsletter, vol. 10, issue 2, 2008, pp. 90‚Äì100. [191] S. Ray, A. Mahanti, Strategies for effective shilling attacks against recommender systems, Lecture Notes in Computer Science 5456 (2009) 111‚Äì125 . [192] L. Ren, L. HE, J. Gu, W. Xia, F. Wu, A hybrid recommender approach based on Widrow‚ÄìHoff learning, in: International Conference on Future Generation Communication and Networking, 2008, pp. 40‚Äì45. [193] T.H. Roh, K.J. Oh, I. Han, The collaborative Ô¨Åltering recommendation based on SOM cluster-indexing CBR, Expert Systems with Applications 25 (2003) 413‚Äì 423 . [194] J.A. Rodrigues, L.F. Cardoso, J. Moreira, G. Xexeo, Bringing knowledge into recommender systems, The Journal of Systems and Software, in press, http:// dx.doi.org/10.1016/j.jss.2012.10.002 . [195] S.B. Roy, S. Amer-Yahia, A. Chala, G. Das, C. Yu, Space efÔ¨Åciency in group recommendation, The International Journal on Very Large Data Bases 19 (6) (2010) 877‚Äì900 . [196] G. Ruffo, R. Schifanella, A peer-to-peer recommender system base don spontaneous afÔ¨Ånities, ACM Transactions on Internet Technology 9 (1) (2009) 1‚Äì34 . [197] P.B. Ryan, D. Bridge, Collaborative recommending using formal concept analysis, Knowledge Based Systems 19 (5) (2006) 309‚Äì315 . [198] G. Salton, Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer, Addison-Wesley, Reading, MA, 1989 . [199] M. Saranya, T. Atsuhiro, Hybrid recommender systems using latent features, in: Proceedings of the International Conference on Advanced Information Networking and Applications Workshops, 2009, pp. 661‚Äì666. [200] B. Sarwar, G. Karypis, J.A. Konstan, J. Riedl, Item-based collaborative Ô¨Åltering recommendation algorithms, in: 10th International Conference on World Wide Web, 2001, pp. 285‚Äì295. [201] B. Sarwar, G. Karypis, J. Konstan, J. Riedl, Analysis of recommendation algorithms for e-commerce, in: ACM Conference on Electronic Commerce, 2000a, pp. 158‚Äì167. [202] B. Sarwar, G. Karypis, J. Konstan, J. Riedl, Application of dimensionality reduction in recommender system ‚Äì a case study, in: ACM WebKDD Workshop, 2000b, pp. 264‚Äì272. [203] J.B. Schafer, D. Frankowski, J. Herlocker, S. Sen, Collaborative Ô¨Ålltering recommender systems, in: P. Brusilovsky, A. Kobsa, W. Nejdl (Eds.), The Adaptive Web, 2007, pp. 291‚Äì324 (Chapter 9). [204] A.I. Schein, A. Popescul, L.H. Ungar, D.M. Pennock, Methods and metrics for cold-start recommendations, in: Proceeding SIGIR ‚Äô02 Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2002, pp. 253‚Äì260. [205] C. Schlieder, Modeling collaborative semantics with a geographic recommender, in: Workshop on Semantic and Conceptual Issues in Geographic Information Systems, 2007, pp. 336‚Äì347. [206] J. Serrano-Guerrero, E. Herrera-Viedma, J.A. Olivas, A. Cerezo, F.P. Romero, A google wave-based fuzzy recommender system to disseminate information in University Digital Libraries 2.0., Information Sciences 181 (9) (2011) 1503‚Äì 1516 . [207] Z. Severac, V. Devedzic, J. Jovanovic, Adaptive neuro-fuzzy pedagogical recommender, Expert Systems with Applications 39 (10) (2012) 9797‚Äì9806 . [208] A. Shepitsen, J. Gemmell, B. Mobasher, R. Burke, Personalized recommendation in social tagging systems using hierarchical clustering, in: Proceedings of the 2008 ACM Conference on Recommender Systems, 2008, pp. 259‚Äì266. [209] S.K. Shinde, U. Kulkami, Hybrid personalizad recommender system using centering‚Äìbunching based clustering algorithm, Expert Systems with Applications 39 (1) (2012) 1381‚Äì1387 . [210] S. Siersdorfer, S. Sergei, Social recommender systems for web 2.0 folksonomies, in: 20th ACM conference on Hypertext and hipermedia, 2009, pp. 261‚Äì269. [211] I. Soboroff, C. Nicholas, Combining content and collaboration in text Ô¨Åltering, in: Proceedings of the IJCAI‚Äô99 Workshop on Machine Learning for Information Filtering, 1999, pp. 86‚Äì91. [212] X. Su, T.M. Khoshgoftaar, A survey of collaborative Ô¨Åltering techniques, Advance in ArtiÔ¨Åcial Intelligence 2009 (2009) 1‚Äì19 . [213] P. Symeonidis, A. Nanopoulus, Y. Manolopoulus, Providing justiÔ¨Åcations in recommender systems, IEEE Transactions on Systems, Man and Cybernet 38 (6) (2008) 1262‚Äì1272 . [214] P. Symeonidis, A. Nanopoulus, Y. Manolopoulus, MovieExplain: a recommender system with explanations, in: Proceedings of the 2009 ACM Conference on Recommender Systems, 2009, pp. 317‚Äì320. [215] G. Tak√°cs, I. Pil√°szy, B. N√©meth, D. Tikk, Scalable collaborative Ô¨Åltering approaches for large recommender systems, Journal of Machine Learning Research 10 (2009) 623‚Äì656 . [216] S. Tan, J. Bu, CH. Chen, X. He, Using rich social media information for music recommendation via hypergraph model, ACM Transactions on Multimedia Computing, Communications, and Applications 7 (1) (2011). Article 7 . [217] N. Tintarev, J. Masthoff, A survey of explanations in recommender systems, in: IEEE 23rd International Conference on Data Engineering Workshop, 2007, 801‚Äì810. [218] T. Tran, R. Cohen, Hybrid recommender systems for electronic commerce, in: Proceedings of the 17th National Conference on ArtiÔ¨Åcial Intelligence, AAAI, 2000, pp. 78‚Äì84. [219] K.H.L. Tso-Sutter, L.B. Marinho, L. Schmidt-Thieme, Tag-aware recommender systems by fusion of collaborative Ô¨Åltering algorithms, in: Proceedings of the 2008 ACM Symposium on Applied Computing, 2008, pp. 1995‚Äì1999. [220] S. Vargas, P. Castells, Rank and relevance in novelty and diversity metrics for recommender systems, in: Proceedings of the 2011 ACM Conference on Recommender Systems, 2011, pp. 109‚Äì116. [221] P. Victor, CH. Cornelis, M. De-Cock, Trust Networks for Recommender Systems, Antalis Press, 2011 . J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132 131 [222] J. Vig, S. Sen, J. Riedle, Tagsplanations: Explaining recommendations using tags, Proceedings of the 13th international conference on Intelligent user interfaces, 2009, pp. 47-56. [223] P. Victor, CH. Cornelis, M. De-Cock, P.P. DA-SILVA, Gradual tust and distrust in recommender systems, Fuzzy Sets and Systems 160 (10) (2009) 1367‚Äì1382 . [224] M.G. Vozalis, K.G. Margaritis, Using SVD and demographic data for the enhancement of generalized collaborative Ô¨Åltering, Information Sciences 177 (2007) 3017‚Äì3037 . [225] Y. Wan-Shiou, CH. Hung-Chi, D. Jia-Ben, A location-aware recommender system for mobile shopping environments, Expert Systems with Applications 34 (1) (2008) 437‚Äì445 . [226] J. Wang, A. Vries, M. Reinders, Unifying user-based and item-based collaborative Ô¨Åltering approaches by similarity fusion, in: Proc. SIGIR Conf., 2006, pp. 501‚Äì508. [227] J. Wang, A.P. Vries, M.J. Reinders, UniÔ¨Åed relevance models for rating prediction in collaborative Ô¨Åltering, ACM Transactions in Information Systems 26 (3) (2008) 1‚Äì42 . [228] L.T. Weng, Y. Xu, Y. Li, R. Nayak, Exploiting item taxonomy for solving cold- start problem in recommendation making, in: Proceedings of the 20th IEEE International Conference on Tools with ArtiÔ¨Åcial Intelligence (ICTAI2008), 2008, pp. 113‚Äì120. [229] B. Widrow, M.E. Hoff, Adaptive switching circuits, in: Convention Record, IRE WESCON, 1960, pp. 96‚Äì104. [230] P. Winoto, T.Y. Tang, The role of user mood in movie recommendations, Expert Systems with Applications 37 (8) (2010) 6086‚Äì6092 . [231] W. Woerndl, G. Groh, Utilizing physical and social context to improve recommender systems, in: IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology, 2007, pp. 123‚Äì128. [232] B. Xie, P. Han, F. Yang, R.M. Shen, H.J. Zeng, Z. Chen, DCFLA: a distributed collaborative-Ô¨Åltering neighbor-locating algorithm, Information Sciences 177 (6) (2007) 1349‚Äì1363 . [233] W. Xin, Q. Jamaliding, T. Okamoto, Discovering social network to improve recommender system for group learning support, in: International Conference on Computational Intelligence and Software Engineering, 2009, pp. 1‚Äì4. [234] R.R. Yager, Fuzzy logic methods in recommender systems, Fuzzy Sets and Systems 136 (2) (2003) 133‚Äì149 . [235] W.S. Yang, H.CH. Cheng, J.B. Dia, A location-aware recommender system for mobile shopping environments, Expert Systems With Applications 34 (1) (2008) 437‚Äì445 . [236] Y. Yang, An evaluation of statistical approaches to text categorization, Information Retrieval 1 (1) (1999) 67‚Äì88 . [237] Z. Yao, Q. Zhang, Item-based clustering collaborative Ô¨Åltering algorithm under high dimensional sparse data, in: International Joint Confeence on Computational Sciences and Optimization, 2009, pp. 787‚Äì790. [238] Z. Yu, X. Zhou, Y. Hao, J. Gu, TV program recommendation for multiple viewers based on user proÔ¨Åle merging, User Modeling and User-Adapted Interaction 16 (1) (2006) 63‚Äì82 . [239] W. Yuan, D. Guan, Y.K. Lee, S. Lee, S.J. Hur, Improved trust-aware recommender system using small-worldness of trust networks, Knowledge Based Systems 23 (3) (2010) 232‚Äì238 . [240] G. Zacharia, A. Moukas, P. Maes, Collaborative reputation mechanisms for electronic marketplaces, Decision Support Systems 29 (2000) 371‚Äì388 . [241] O. Zaiane, Building a recommender agent for e-learning systems, in: Proceedings of the International Conference on Computers Education (ICCE‚Äô02), vol. 1, 2002, pp. 55‚Äì59. [242] J. Zhan, Privacy-preserving collaborative recommender systems, IEEE Transactions on Systems, Man and Cybernetics 40 (4) (2010) 472‚Äì476 . [243] F. Zhang, H.Y. Chang, A collaborative Ô¨Åltering algorithm employing genetic clustering to ameliorate the scalability issue, in: IEEE International Conference on e-Business Engineering, 2006, pp. 331‚Äì338. [244] S. Zhang, W. Wang, J. Ford, F. Makedon, Using singular value decomposition approximation for collaborative Ô¨Åltering, in: IEEE International Conference on E-Commerce Technology, 2005, pp. 1‚Äì8. [245] L. Zhen, G.Q. Huang, Z. Jiang, Recommender systems based on workÔ¨Çow, Decision Support Systems 48 (2009) 237‚Äì245 . [246] L. Zhen, G.Q. Huang, Z. Jiang, Collaborative Ô¨Åltering based on workÔ¨Çow space, Expert Systems with Applications 36 (2009) 7873‚Äì7881 . [247] L. Zhen, Z. Jiang, H. Song, Distributed recommender for peer-to-peer knowledge sharing, Information Sciences 210 (2010) 3546‚Äì3561 . [248] N. Zheng, Q. Li, A recommender system based on tag and time information for social tagging systems, Expert Systems with Applications 38 (4) (2011) 4575‚Äì4587 . [249] Y. Zheng, X. Xie, Learning travel recommendations from user-generated GPS traces, ACM Transactions on Intelligent Systems and Technology 2 (2011) 1. Article 2 . [250] Y. Zheng, L. Zhang, Z. Ma, X. Xie, W.Y. Ma, Recommending friends and locations based on individual location history, ACM Transactions on the Web 5 (2011) 1. Article 5 . [251] J. Zhong, X. Li, UniÔ¨Åed collaborative Ô¨Åltering model based on combination of latent features, Expert Systems with Applications 37 (2010) 5666‚Äì5672 . [252] R.L. Zhu, S.J. Gong, Analyzing of collaborative Ô¨Åltering using clustering technology, international colloquium on computing, in: ISECS International Colloquium on Computing, Communication, Control, and Management, 2009, pp. 57‚Äì59. [253] C.N. Ziegler, S.M. Mcnee, J.A. Konstan, G. Lausen, Improving recommendation lists through topic diversiÔ¨Åcation, in: Proceedings of the 14th International Conference on World Wide Web, 2005, pp. 22‚Äì32. 132 J. Bobadilla et al. / Knowledge-Based Systems 46 (2013) 109‚Äì132",recommender system survey j bobadilla f ortega hernando guti√©rrez universidad polit√©cnica de ctra de valencia km spain r c l e n f article history received october received revised form march accepted march available online april keywords recommender system collaborative Ô¨Åltering similarity measure evaluation metric prediction recommendation hybrid social internet thing coldstart b r c recommender system developed parallel web initially demo graphic contentbased collaborative Ô¨Åltering currently system incorporating social infor mation future use implicit local personal internet thing article provides overview recommender system well collaborative Ô¨Åltering method algorithm also explains evolution provides original classiÔ¨Åcation system iden tiÔ¨Åes area future implementation develops certain area selected past present future importance elsevier bv right reserved recommender system rss collect prefer ences user set item eg movie song book joke gadget application website travel destination elearning material acquired explicitly typically collecting user rating implicitly typically monitoring user behavior song heard application downloaded web site visited book read r may use demo graphic feature user like age nationality gender social like follower followed twit post commonly used web growing tend towards use infor mation internet thing eg gps location rfid realtime health signal r make use different source providing user prediction recommendation item try balance factor like accuracy novelty dispersity stability recommendation collaborative filtering cf method play important role recommendation although often used along Ô¨Ålterning technique like contentbased knowledgebased social one cf way human made decision throughout history besides experience also base decision experience knowledge reach u relatively large group acquaintance recently r implementation internet increased facilitated use diverse area com mon research paper focused movie recommendation stud y however great volume literature r centered different topic music televi sion book document e learning ecommerce application market web search among others kind Ô¨Åltering used beginning r col laborative contentbased demographic described breese et al evaluated predictive accuracy differ ent algorithm cf later classical describes base evaluating collaborative filtering r evolution r shown importance hybrid tech niques r merge different technique order get advantage survey focused hybrid r presented however deal role socialÔ¨Åltering technique become popular recent year social network neighborhoodbased cf recommendation popular beginning r herlocker et al provides set guideline designing neighborhoodbased prediction system adomavicius tuzhilin present view r Ô¨Åeld standing complex area see front matter elsevier bv right reserved httpdxdoiorgjknosys corresponding author tel fax email address jesusbobadillaupmes j bobadilla knowledgebased system content list available sciverse sciencedirect knowledgebased system journal homepage wwwelseviercomlocateknosys researcher r focus next generation r lim ited content overspecialization contentbased method coldstart sparsity cf method modelbased tech niques nonintrusiveness Ô¨Çexibility realtime customization etc researcher developing r different survey paper published summarizing important sue Ô¨Åeld view impossibility showing every de tail technique publication selects issue author felt suitable understand evolution r existing survey focus relevant method algorithm r Ô¨Åeld survey instead try enhance evolution r Ô¨Årst phase tradi tional web present second phase social web presently progressing third phase internet thing purpose useful new reader r Ô¨Åeld included survey traditional topic r foundation k nearest neighbor coldstart issue similarity measure evaluation r rest deal novel topic existing survey consider survey advanced reader r depth concept classiÔ¨Åcations approach related social informa tion social Ô¨Åltering follower followed trust reputation credi bility contentbased Ô¨Åltering social social tagging taxonomy recommending group user explaining recommendation reader interested brand new future application Ô¨Ånd survey useful since informs recent work locationaware r trend bioin spired approach also discover important issue privacy security pp internet thing use rfid health parameter surveillance teleopera tion telepresence etc according idea r tend make use different source collaborative social demographic content knowledgebased geographic sensor tag implicit explicit acquisition etc survey emphasizes hybrid architecture making recommendation different known tech nologies one designed behalf speciÔ¨Åc source much quality survey measured appro priate choice reference survey contains reference systematically obtained selected taking ac count factor like number recent citation impor tance journal published remainder article structured follows sec tion explain concisely methodology used select signiÔ¨Åcative paper r Ô¨Åeld section describes r foundation method algorithm model used provid ing recommendation tradi tional web rating demographic item cf demographic Ô¨Åltering contentbased Ô¨Åltering hybrid Ô¨Åltering section describes measure evaluating quality r prediction recommendation section show use cial web making recomendations concept like trust reputation credibility also de scribe technique contentbased social eg tag post section focusses two important area although well studied yet recommendation group user explanation recommendation section focusses recommender trend covering bioinspired approach web Ô¨Åltering locationaware r sec tion explains related work original contribution survey concluding section summarizes r history focus type used well development algorithm evaluation measure conclusion section also indicates seven new area consider likely focus r search scientiÔ¨Åc community near future methodology initial performed determine represen tative topic term r Ô¨Åeld first r paper se lected journal higher priority current oftencited article next extracted paper signiÔ¨Åcant term gave emphasis keywords less emphasis title Ô¨Ånally least emphasis abstract overlooked common word like article preposition generaluse word remaining pool selected term represented r Ô¨Åeld matrix arti cles word wherein stored importance word article generated tree relationship word fig depicts signiÔ¨Åcant section graph due space constraint entire tree shown pro vided additional material fig additionaldatapng short distance word indicate highest similarity warm color indicate greater reliability relationship size node indicates importance word function parameter n k n n number signiÔ¨Åcative word keywords title n k w n w n w number time word w appears keywords title equa tion used determine importance word w follows f w ¬º n k w n k √æ n w n log n n √æ n w n n n example consider n k keywords n word title n word length get value f factorization f matrix word factorization appears keyword title three time word matrix appear keyword contained title twice importance word f factorization ¬º √æ log √æ ¬º f matrix ¬º √æ log √æ ¬º depicted fig used identify relevant aspect r represented signiÔ¨Åcant word graph related term article referenced herein chosen following criterion tran scendence subject according importance word fig b historical contribution signiÔ¨Åcant fraction classic reference article included c number time article cited article published journal impact factor preferred conference workshop e cent article preferred article published many year ago fig show temporal distribution referenced paper use cluster word fig structure explica tions survey concept explained ob tained keywords word related according fig identiÔ¨Åed among set pa pers related set word associated concept selected subset paper deal concept giving priority high value crite ria like importance number cite tried balance number time referenced survey aiming reference paper selected j bobadilla et al knowledgebased system recommender system foundation section present relevant concept traditional r provide general description classical taxonomy algorithm method Ô¨Åltering ap proaches database etc besides show graphic depicting traditional model recommendation relation next describe coldstart problem illustrate difÔ¨Åculty making collaborative recommendation r contains small amount next describe k nn used implementing r cf finally describe different proposed similarity measure comparing user item show graphic measuring quality similarity measure fundamental process generating r recommendation combination following consideration type available database eg rating user reg istration feature content item ranked social relationship among user locationaware Ô¨Åltering used eg demographic contentbased collaborative socialbased contextaware hybrid chosen eg direct use memory generated modelbased employed technique also considered probabilistic approach bayesian network nearest neighbor bioinspired algorithm neural network genetic algorithm fuzzy model singular decomposition tech niques reduce sparsity level etc sparsity level database desired scalability performance time memory consuming objective sought considered eg prediction top n recommendation well desired quality result eg novelty coverage precision research r requires representative set public dat abases facilitate investigation technique method algorithm developed researcher Ô¨Åeld database scientiÔ¨Åc community replicate experiment validate improve technique list current public database referenced often literature lastfm delicious incorporate implicit rating social generated version released hetrec set hosted grouplens research group internal function r characterized Ô¨Åltering widely used classiÔ¨Åcation divide Ô¨Åltering algorithm collaborative Ô¨Åltering b demo graphic Ô¨Åltering c contentbased Ô¨Åltering hybrid Ô¨Åltering fig word represented recommender system research Ô¨Åeld short distance indicate higher similarity warm color indicates greater reliability size node proportional importance word fig temporal distribution referenced paper j bobadilla et al knowledgebased system contentbased Ô¨Åltering make recommendation user choice made past eg webbased ecom merce r user purchased Ô¨Åction Ô¨Ålms past r probably recommend recent Ô¨Åction Ô¨Ålm yet purchased website contentbased Ô¨Åltering also gener ate recommendation content object intended recommendation therefore certain content analyzed like text image sound similarity established object basis recommending item similar item user bought visited heard viewed ranked positively demographic Ô¨Åltering justiÔ¨Åed principle individual certain common personal attribute sex age country etc also common preference collaborative filtering allows user give rat ings set element eg video song Ô¨Ålms etc cf website way enough stored make recommendation user provided user consider common cf interesting open research Ô¨Åeld noted earlier user rating also often used memorybased recommender system public database without social social hosted grouplens movielens movielens netÔ¨Çix jester eachmovie bookcrossing ml lastfm delicious rating million million million million million million user item range implicit implicit tag na na na na na na tag assignment na na na na na na friend relation na na na na na na na item movie movie movie joke movie book movie music url fig traditional model recommendation relationship j bobadilla et al knowledgebased system implicitly acquired eg number time song heard informa tion consulted access resource widely used collaborative Ô¨Åltering k nearest neighbor knn user user version k nn executes following three task generate recommenda tions active user determine k user neighbor neighbor hood active user implement aggregation rating neighborhood item rated extract prediction step select top n recommendation hybrid Ô¨Åltering commonly us combination cf demographic Ô¨Åltering cf contentbased Ô¨Åltering exploit merit one technique hybrid Ô¨Åltering usually bioinspired probabilistic method genetic algorithm fuzzy genetic neural net work bayesian network clustering latent feature widely accepted taxonomy divide recommendation method memorybased modelbased category memorybased method memorybased method deÔ¨Åned method act matrix user rating item b use rating generated refer ral process ie result always updated memorybased method usually use similarity metric obtain distance tween two user two item ratio modelbased method use r create generates recommendation herein consider modelbased new user outdates among widely used model bayesian classiÔ¨Åers neural network fuzzy system genetic algorithm latent feature matrix factorization among others reduce problem high level sparsity r dat abases certain study used dimensionality reduction tech niques reduction method matrix factorization matrix factorization especially ade quate processing large r database providing scalable ap proaches modelbased technique latent semantic index lsi reduction singular decomposition svd typically combined svd method provide good prediction result computationally expensive deployed static offline setting known preference change time r use clustering technique improve prediction qual ity reduce coldstart problem applied hybrid Ô¨Ål tering typical form cluster item hybrid r different common us clustering item user biclustering r comprising social infor mation clustered improve following area tagging explicit social link explicit trust graph fig show signiÔ¨Åcant traditional meth od technique algorithm recommendation process well relationship grouping different section provide detail important aspect involved recommendation process may seen fig use traditional Ô¨Ål tering method contentbased demographic collaborative applied database modelbased technology genetic algo rithms neural network etc make use kind typical memorybased approach item item user user hybrid two previous main purpose mem orybased modelbased approach get accurate prediction taste user accuracy prediction may evaluated classical retrieval mea sures like mae precision recall researcher make use measure order improve r method technology coldstart coldstart problem occurs possible make reliable recommendation due initial lack rating distinguish three kind coldstart problem new com munity new item new user last kind important r already operation new community problem refers difÔ¨Åculty starting r obtaining sufÔ¨Åcient amount rating making reliable recommendation two common way used tackling problem encourage user make rating different mean take cfbased recom mendations enough user rating new item problem arises new item entered r usually initial rating therefore likely recommended turn item rec ommended go unnoticed large part community user unaware rate way enter vicious circle set item r left ratingsrecommendations process new item problem less impact r item dis covered via mean eg movie r ie ecommerce blog photo video etc common solution problem set motivated user responsible rating new item new user problem represents one great dif Ô¨Åculties faced r operation since new user r yet provided rating r receive personalized recommendation memorybased cf user enter Ô¨Årsts rating expect r offer personalized recommendation number rating introduced r usually yet sufÔ¨Åcient able make reliable cfbased recommendation therefore new user may feel r offer service expected may stop common strategy tackle new user problem consists turning additional set rating order able make recommendation available user coldstart problem often faced hybrid approach usually cfcontent r cfdemographic r cfsocial r leung et al vel contentbased hybrid make use crosslevel association rule integrate content domain item kim et al use collaborative tagging employed order grasp Ô¨Ålter user preference item explore advantage collaborative tagging sparseness coldstart user collected dataset crawling collaborative tagging delicious site weng et al combine implicit relation user item prefer ences additional taxonomic preference make better quality recommendation well alleviate coldstart prob lem loh et al represent user proÔ¨Åles ex tracted scientiÔ¨Åc publication martinez et al present hybrid r combine cf knowl edgebased one chen number common term term frequency ncttf cf demo graphic vector saranya atsuhiro hybrid r utilizes latent feature extracted item represented multiattributed record probabilistic park et al new use Ô¨Ålterbots surrogate user rate item user item attribute j bobadilla et al knowledgebased system k nearest neighbor recommendation k nearest neighbor k nn recommendation reference collaborative Ô¨Åltering recommendation process primary virtue simplicity reasonably accurate result major pitfall low scalability vulnerability sparsity r database section provides general expla nation function cf k nn conceptually simple straightforward implementation also generally produce good quality prediction recommendation however due high level sparsity r database similarity measure often encounter processing problem typically insufÔ¨Åcient mutual rating comparison user item cold start situation user item low number ranking another major problem k nn low scalabil ity database netÔ¨Çix increase size hun dreds thousand user ten thousand item hundred million ranking process generating neighborhood active user becomes slow similarity measure must processed often new user registered database item item version k nn sig niÔ¨Åcantly reduces scalability problem end neigh bors calculated item top n similarity value stored period time prediction recommendation generated stored although stored include rating previous process ingstorage outdated item less sensitive user recurrent theme cf research generating metric calcu late accuracy precision existing similarity user item traditionally series statistical metric used pearson correlation cosine constraint pearson correlation mean squared difference recently metric designed Ô¨Åt constraint peculiarity r relevance signiÔ¨Åcance concept introduced af ford importance relevant user item additionally group metric speciÔ¨Åcally designed ade quately function coldstart situation k nn similarity measure next sub section provides detail current r similarity mea sures similarity approach typically compute similarity two user x user user user item rating item item k nn version computes similarity tween two item j formal k nn may found section provide illustrative example algo rithm making recommendation following three step selected similarity measure produce set k neighbor active user k neighbor nearest k similar user u b set k user neighbor similar active calculated order obtain prediction item user one following aggregation approach often used average weighted sum adjusted weighted aggregation deviationfrommean c obtain top n recommendation choose n item provide satisfaction active user according prediction fig show user user k nn mechanism item item version k nn following three task executed determine q item neigh bors item database item ranked active user calculate prediction rating q neighbor select top n recommen dations active user typically n major prediction step executed periodically facilitates accel erated recommendation regard user user version item item user user version k nn combined take advantage positive aspect approach typically fused pro cessing similarity object similarity measure metric similarity measure sm determines similarity pair user user user cf similarity pair item item item cf purpose compare rating item rated two user user user rat ings user rated two item item item k nn essentially use traditional similarity metric statistical origin metric require source set vote made user item memorybased cf among commonly used traditional metric pearson correlation corr cosine co adjusted cosine acos constrained correlation ccorr mean squared difference msd euclidean euc describe compare representative group sm used k nn sm discussed include following variation coldstart general case b model c trust rating show classiÔ¨Åcation memorybased cf sm tested section new metric jmsd recently published side numerical rating via mean squared difference also us nonnumerical pro vided arrangement via jaccard ortega et al use pareto dominance perform preÔ¨Åltering process eliminating less representative user k neighbur selection process retaining promising one specialization memorybased cf sm appeared recently us contained vote user instead restricting rating two user com pared user user two item compared item item call sm sing singularity possibility exists create modelbased cf full set user rating order later determine similar ity pair user pair item cre ated potential advantage focus increase accuracy obtained performance time consuming achieved drawback must regularly dated order consider recently entered set rating fig user user k nn example k similarity measure mean squared difference aggregation average j bobadilla et al knowledgebased system bobadilla et al provides metric generated genetic algorithm call sm gen geneticbased increase web website internet set metric appeared use new social available friend follower followeds etc sm grouped paper related trust reputation credibility although situation also produced Ô¨Åelds metric could considered strictly mem orybased cf use additional r sense sm proposed tailored speciÔ¨Åc r small set r share structure social sm aim extract lated trust reputation user set rating memorybased cf advantage use general ized cf r drawback social ex tracted really poor call trust sm proponed jeong et al currently two new interesting sm get cov erage accuracy fig show result several evaluation measure gen erated applying sm discussed section result show rstailored sm superior compared tra ditional sm statistic processing memorybased infor mation result fig follow framework schematic published previously far research paper dealing coldstart prob lem user rating ahn present heu ristic sm named pip outperforms traditional statistical sm tested collaborative Ô¨Åltering similarity measure model modelbased trust extraction trust extraction traditional rating user item tailored coldstart user jmsd corr ccorr co acos msd euc gen tailored coldstart user pip uerror nc extended rating sing trust fig evaluation measure result obtained current similarity measure movielens database prediction result b recommendation result c novelty result trust result j bobadilla et al knowledgebased system pearson correlation cosine etc heungnam et al proposes uerror predicts Ô¨Årst actual rating subsequently identiÔ¨Åes prediction error user taking account er ror speciÔ¨Åc errorreÔ¨Çected model de signed bobadilla et al present metric neural learning modelbased cf adapted new user coldstart situ ations called nc fig show result several evaluation measure gener ated applying coldstart sm presented section result show rstailored sm superior compared traditional sm statistic since database movielens take account coldstart user removed rat ings database order achieve coldstart user indeed removed randomly rating user rated item way regard user rate item coldstart user evaluation recommender system result since r research began evaluation prediction recom mendations become important research r Ô¨Åeld requires quality measure evaluation metric know quality technique method algorithm predic tions recommendation evaluation metric evalua tion framework facilitate comparison several solution problem selection different promising line research generate better result evaluation measure r recommendation gradually tested improved representative set existing evaluation measure standard formulation group open r public database generated two advance facilitated quality comparison new proposed recommendation method previously published method thus r method algorithm research progressed continuously commonly used quality measure following prediction evaluation evaluation recommen dation set evaluation recommendation ranked list fig show result applying several evaluation mea sures set representative similarity measure evaluation metric classiÔ¨Åed predic tion metric accuracy one mean absolute error mae root mean square error rmse normalized mean average error nmae coverage b set recommendation metric precision recall receiver operating characteristic roc c rank recommendation metric halflife discounted cumulative gain diversity met rics diversity novelty recommended item validation process performed employing common cross validation technique random subsam pling kfold cross validation coldstart situation due limited number user item vote involved usual chosen carry experiment leaveone cross validation hern√°ndez gaudioso evaluation process distinction interactive noninteractive fig evaluation result obtained current coldstart similarity measure prediction result b recommendation result c novelty result trust result j bobadilla et al knowledgebased system subsystem general publication review also exist clude commonly accepted evaluation measure mean absolute error coverage precision recall derivative mean squared error normalized mean absolute error roc fallout goldberg et al focus aspect related eval uation breese et al compare predictive accuracy vari ous method set representative problem domain majority article discus attempted improvement accuracy r result rmse mae etc also common tempt improvement recommendation precision recall roc etc however additional objective considered generating greater user satisfaction topic diversi Ô¨Åcation coverage serendipity currently Ô¨Åeld growing interest generating algo rithms diverse innovative recommendation even expense accuracy precision evaluate aspect various metric proposed measure recommendation novelty diversity framework aid deÔ¨Åning standardizing method algorithm employed r well mechanism eval uate quality result among signiÔ¨Åcant paper cf framework herlocker et al evaluates following similarity weight signiÔ¨Åcance weighting variance weighting selecting neighborhood rating normaliza tion hern√°ndez gaudioso proposes framework r formed two different subsystem one guide user provide usefulinteresting item koutrika et al framework introduces level abstraction cf process making modiÔ¨Åcations r Ô¨Çexible antunes et al present evaluation framework assuming evaluation evolving process lifecicle majority r evaluation framework proposed present two deÔ¨Åciencies Ô¨Årst lack formal ization although evaluation metric well deÔ¨Åned variety detail implementation method event speciÔ¨Åed lead generation different result similar experiment second deÔ¨Åciency absence standardization evalu ation measure aspect novelty trust recommendation bobadilla et al provides complete series mathematical formalization set theory author provide set eval uation measure include quality follow ing aspect prediction recommendation novelty trust presented next representative selection r evaluation quality measure often used bibliography quality prediction mean absolute error accuracy coverage order measure accuracy result r usual use calculation common predic tion error metric amongst mean absolute error mae related metric mean squared error root mean squared error normalized mean absolute error stand deÔ¨Åne u set r user set r item r u rating user u item lack rating r u mean user u rated item p u prediction item user u let u j p u r u set item rated user u hav ing prediction value deÔ¨Åne mae rmse average user mae remark absolute dif ference prediction real j p u r u j informs error prediction mae ¬º u x u u u x u j p u r u j √∞ √æ rmse ¬º u x u u Ô¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨É u x u √∞ p u r u √æ √∞ √æ coverage could deÔ¨Åned capacity predicting metric applied speciÔ¨Åc r short calculates percent age situation least one k neighbor active user rate item rated yet active user deÔ¨Åned k u set neighbor u rated item deÔ¨Åne coverage average user coverage let c u ¬º f j r u ¬º k u g u ¬º f j r u ¬º g co v erage ¬º u x u u c u u √∞ √æ quality set recommendation precision recall f conÔ¨Ådence user certain r depend directly accuracy set possible prediction user gain conÔ¨Ådence r user agrees reduced set recommendation made r section deÔ¨Åne following three widely used recommendation quality measure precision indicates proportion relevant recommended item total number recommended item recall indicates pro portion relevant recommended item number rele vant item f combination precision recall let x u set recommendation user u z u set n recommendation user u represent evaluation precision recall f measure recommendation obtained making n test recommendation user u taking h rele vancy threshold assuming user accept n test recommendation precision ¬º u x u u f z u j r u p h g n √∞ √æ recall ¬º u x u u f z u j r u p h g f z u j r u p h g √æ z c u r u p h √∞ √æ f ¬º precision recall precision √æ recall √∞ √æ quality list recommendation rank measure number n recommended item small user give greater importance Ô¨Årst item list recommen dations mistake incurred item serious er rors last item list ranking measure consider situation among ranking measure often used following standard retrieval measure halflife assumes exponential decrease interest user move away recommenda tions top b discounted cumulative gain wherein decay logarithmic hl ¬º u x u u x n ¬º max √∞ r u p √æ √∞ √æ √∞ √æ √∞ √æ dcg k ¬º u x u u r u p √æ x k ¬º r u p log √∞ √æ √∞ √æ j bobadilla et al knowledgebased system p p n represents recommendation list r u pi represents true rating user u item p k rank eval uated item default rating number item list chance user review item novelty diversity novelty evaluation measure indicates degree differ ence item recommended known user diversity quality measure indicates degree differentia tion among recommended item currently novelty diversity measure stan dard therefore different author different metric certain author used following di v ersity z u ¬º z u √∞ z u √æ x z u x j z u j ¬Ω sim √∞ j √æ √∞ √æ v elty ¬º z u x j z u ¬Ω sim √∞ j √æ z u √∞ √æ sim j indicates item item memorybased cf similar ity measure z u indicates set n recommendation user u stability stability prediction recommendation inÔ¨Çu ences user trust towards r r stable pre dicitions provides change strongly short period time adomavicius zhang quality measure stability ma mean absolute shift measure deÔ¨Åned set known rating r set prediction un known rating p interval time user r rated subset unknown rating r make new prediction p ma deÔ¨Åned follows stability ¬º ma ¬º j p j x √∞ u √æ p j p √∞ u √æ p √∞ u √æj √∞ √æ reliability reliability prediction recommendation informs seriously may consider prediction r recommends item user prediction scale user hope satisÔ¨Åed item however prediction reÔ¨Çect certain degree r concluded user like item indeed prediction much reli able obtained mean similar user obtained two similar user hernando et al realibility measure proposed accord ing usual notion reliable prediction less lia ble wrong although reliability measure quality measure used comparing different technique r cross validation regarded quality measure associ ated prediction recommendation way r pro vides pair value prediction reliability user may balance preference example user would probably prefer option option conse quently reliability measure proposed hernando et al provides new understandable factor user may consider taking decision nevertheless use reliability measure constrained r k nn deÔ¨Ånition reliability prediction p u two numeric factor u v u u measure similar ity neighbor used making prediction p u v u measure degree disagreement neighbor rating item finally reliablity measure deÔ¨Åned follows f √∞ u √æ ¬º √æ u u ¬º x v k u sim √∞ u v √æ √∞ √æ f √∞ u √æ ¬º √æ u u ¬º x v k u sim √∞ u v √æ √∞ √æ fig recommender system evaluation process j bobadilla et al knowledgebased system f v √∞ v u √æ ¬º max min v u max min ln ln max min v max min v u ¬º p v k u sim √∞ u v √æ√∞ r v r v p u √æ r u √æ p v k u sim √∞ u v √æ √∞ √æ v respectively median value u v u speciÔ¨Åc r k u set neighbor u rated item min max discrete range rating value fig show general mechanism cross validation used generate quality result form evaluation measure base divided training test area user item Ô¨Årst phase top left side k neighbor calculated active user active user selected set test user k neighbor selected set training user aggregation phase top right side prediction calculated active user set test item final ly evaluation metric used compare prediction rec ommendations obtained real rating user accurate prediction recommendation better quality proposed recommendation social web developed r increasingly incorpo rated social eg trusted untrusted user fol lowed follower friend list post blog tag new contextual improves r social improves sparsity problem inherent memory r social reinforces traditional mem orybased user rating user connected net work trust exhibit signiÔ¨Åcantly higher similarity item metadata nonconnected user social used researcher three primary objective improve quality prediction recom mendations b generate new r c elucidate signiÔ¨Åcant relationship social collaborative process trust reputation important area research r area closely related social currently cluded r common approach generating trust reputation measurement following user trust calculate credibility user explicit informa tion rest user calculate credibility user implicit obtained social network b item trust calculate reputation item feedback user calculate reputation item studying user work item social r Ô¨Åeld user introduce label associated item set triple h user item tag form space referred folksonomies fundamentally folksonomies used following two way create tag recommendation sys tems r tag enrich recom mendation process tag contentbased Ô¨Åltering recently become important due surge social network r show clear trend allow user introduce content comment critique rating opinion label well establish social relation ship link eg followed follower like user dislike user additional increase accuracy prediction recommendation generated variety research arti cles kim et al zheng li carrerneto et al rest section deal dealt concept search two line considered previously filtering social content Ô¨Åltering social filtering social gathered explicitly implicitly identiÔ¨Åcation community network afÔ¨Ånity network individual user generate eg communication web log even rating user possible improve r result creating implicit social networking implicit explicit source combined generate recommenda tions explicit social used via trustbased cf order improve quality recommendation trust infor mation generated used different approach trust propagation mechanism follow leader personalitybased similarity measure trust network distrust dynamic trust ant colony metaphor research work us social applied r aim obtain improvement recommendation made referring extra provided social infor mation used among relevant current work us woerndl groh use social net work enhance collaborative Ô¨Åltering evaluation show social recommender outperforms traditional collaborative Ô¨Åltering algorithm used scenario arazy et al improve accuracy online social network electronic communication tool xin et al improving r exploiting learner note taking activity maintain note feature exploited collabora tive learning system order enrich extend user proÔ¨Åle improve personalized learning bonhard sasse search shown relationship adviceseeker recommender extremely important way indicating social closeness taste overlap required thus suggest drawing similarity familiarity user person rated item aid judgment decision making fengkun hong developed way increase rec ommendation effectiveness incorporating social network infor mation cf collected user preference rating social network relationship social networking web site evaluated cf performance diverse neigh bor group combining group friend nearest neighbor carmagnola et al state joining network people expose individual social dynamic inÔ¨Çuence attitude behavior preference present sonar recommending content social r sonar tar get user member social network suggesting item Ô¨Çect trend network structure inÔ¨Çuence relationship among user ramaswamy et al design social network r incorporates three feature complement derive highly targeted ad first analyze customer address book estimate level social afÔ¨Ånity among various user social afÔ¨Ånity used identify recommendation sent individual user another group research work us social cre ate enable r aim improve result particular r operation aim make possible r still exist exist social siersdorfer sergei objective construct social recommender system predict utility item user group multidimensional social environment given user mining rich set structure social relationship provides folksonomies li chen blog recommenda tion mechanism combine trust social relation j bobadilla et al knowledgebased system semantic illustrates applied presti gious online blogging jason research project applied discover social network tween mobile user collecting dataset two million user argue social network applicable generate contextbased recommendation service jyun chui pa per us trading relationship calculate level recommendation trusted online auction seller demonstrate network structure formed transactional history used expose underlying opportunistic collusive seller behavior dellamico capra user trustworthiness mea sured according one following two criterion taste similar ity ie trust agree social tie ie trust friend people friend trust argue order trusted user must well intentioned competent observation novel call social Ô¨Åltering third group work provides foundation research discover signiÔ¨Åcant relationship social informa tion collaborative process without creating proposing improving particular r research move higher level abstraction aim establishing base general prin ciples bonhard explains qualitative research con ducted date shown relationship recommender recommendee signiÔ¨Åcant impact deci sionmaking hossain fazio present exploring connection social network collaborative process focus exploring academic network position effect collaborative network deÔ¨Åning network position way develop social network us academic node within network instead published esslimani et al present new cf behavioral network us navigational pattern relationship user exploit social network tech niques golbeck kuter present experimental several type trust inference algorithm answer following question trust change far single change prop agate network large impact change relate type inference experimental result provide insight algorithm suitable certain application research Ô¨Åeld trust reputation could provide suitable starting point create social interaction among user r however relevant work subject limited use trust relationship improve quality rec ommendation service odonovan book chapter examines diversity source trust har nessed within social web application discusses high level classiÔ¨Åcation source shown harnessing creased amount upon make trust decision greatly enhances user experience social web applica tion massa avesani explain r making use trust effective term accuracy pre serving good coverage especially evident user provided rating yuan et al choose trust aware r example demonstrate advantage making use veriÔ¨Åed smallworld nature trust network li kao present r trust social network trust computing quality veracity peer produc tion service appropriately assessed experimental sults show proposed r signiÔ¨Åcantly enhance quality peer production service classiÔ¨Åes current approach address user credi bility item reputation socialbased r cf Ô¨Åeld trust user used make prediction weighting trust value say trust user important rating making prediction et al probabilistic factor framework combining rating trusted friend framework applied pure useritem rating matrix contentbased Ô¨Åltering contentbased Ô¨Åltering cbf try recommend item active user similar rated positively past concept item similar attribute rated sim ilarly example user like web page word car engine gasoline cbf recommend page related automotive world cbf becoming especially important r incorporate infor mation item user working web environment tag post opinion multimedia material two challenging problem contentbased Ô¨Åltering lim ited content overspecialization Ô¨Årst problem arises difÔ¨Åculty extracting reliable automated informa tion various content eg image video audio text greatly reduce quality recommendation sec ond problem overspecialization refers phenomenon user receive recommendation item similar item liked preferred therefore user receiving recommendation item might like unknown eg user receives recommendation Ô¨Åction Ô¨Ålms recommendation evaluated novelty cbf operate attribute item wish recom mend must extracted typically set attribute man ually deÔ¨Åned item depending domain certain instance desired recommend textual infor mation classic retrieval technique must used automatically deÔ¨Åne attribute eg term frequency inverse document frequency normalization page length fig show cbf mechanism includes following step extract attribute item recommendation compare attribute item preference active state art trust reputation user trust item trust explicit trust system credibility user calculated explicit rest user service pp usually implement technique reputation item calculated mean feedback user asked opinion ecommerce service often use technique implicit trust system credibility user calculated implicit obtained social network reputation item calculated studying user work item example number time song played memory trust credibility measure calculated taking account user rating j bobadilla et al knowledgebased system user recommend item characteristic Ô¨Åt user interest attribute item user proÔ¨Åles known key purpose cbf determine whether user like speciÔ¨Åc item task resolved traditionally heuristic method classiÔ¨Åcation algorithm u rule induction nearest neighbor method rocchios linear classiÔ¨Åers probabilistic method pure cbf several shortcoming certain domain eg music blog video complicated task generate attribute item b cbf suffers overspecialization problem nature tends recommend type item c difÔ¨Åcult acquire feedback user cbf user typically rate item cf therefore possible determine whether recommendation correct shortcoming rare Ô¨Ånd pure cbf implementation common use hybrid cbfcf burke cf solves cbfs problem function domain less affected overspecialization ac quire feedback user cbf add following quality cf improvement quality prediction calculated reduced impact coldstart sparsity problem cbf cf combined different way fig show different alternative fig show method calculate cbf cf recom mendations separately subsequently combine claypool et al use weighted average combining cbf cf prediction depending type prediction another pazzani proposes combining cbf cf recom mendation list assigning item score according position list additionally billsus pazzani tran cohen select cbf cf prediction accordance quality fig b depicts method incorporate cbf characteristic cf balabanovic shoham maintain user proÔ¨Åles content directly compare pro Ô¨Åles determine similar user cf recommendation good et al construct specialized Ô¨Ålterbots cbf technique later act neighbor cf stage melville et al add prediction cbf ratting matrix employed cf li modiÔ¨Åes ratting matrix input cf combining another matrix generated clustering item according attribute hu pu author incorporate personality characteristic cf similarity measure minimize newuser problem fig c illustrates method construct uniÔ¨Åed cbf cf characteristic basu et al cbf cf characteristic single rulebased classiÔ¨Åer popescul et al schein et al prob ability model combine cbf cf recommendation study author employ bayesian network combine cbf cf characteristic generate accu rate recommendation burke middleton et al knowledgebased technique solve cold start problem fig show method incorporate cf characteristic cbf soboroff nicholas author use lsi create user proÔ¨Åles used cbf recommendation beginning cf ratting matrix mooney roy use cf prediction input cbf current trend cbf add social item attribute tag comment opinion social net work sharing social tagging system popular allow user annotate online resource arbitrary label produce rich space folksonomies new component opened novel line r research di vided two category tag recommendation system use tag recommendation process r tag attempt provide personalized item recommenda tions user representative tag j√§chke et al author compare different mecha nisms tag recommendation marinho schmidtthi eme improve tag recommendation applying classic recommendation method additionally landia anand combine clustering cbf cf suggest new tag user method tag recommendation process increase capacity traditional r tsosutter et al generic allows tag incor porated standard cf algorithm bogers van den bosh examine incorporate tag metada ta hybrid cbfcf replacing tradi tional userbased itembased similarity measure tag overlap gemmell et al weighted hybrid recommender wherein combine graphbased tag recommendation userbased cf itembased cf gedikli jannach use tag mean express feature item user particularly like dislike gemmell et al author offer hybrid r wherein predict user preference item consulting user tagging history additional recommender system objective commercial r compete market offering best con tent quality recommendation well greatest variety service recommendation user group facilitate joint recommendation user group eg group four friend wish choose movie cf four design approach offer opportunity action acting similarity measure stage acquiring neighbor acquiring prediction generating recommendation research result indicate quality recommendation vary greatly different approach execution time dramatically reduced advance used design similarity measure group efÔ¨Åcient solution r generated recommendation valuable user must explained well simple compelling accurate manner recommendation explanation Ô¨Åeld investi gated new development r tradi tionally explanation type divided following category human style user user b item style item item c feature style item feature hybrid also employ use conversational technique incorporates geosocial recommending group user r consider group user starting expand used different area tourism music tv web given speciÔ¨Åc characteristic recommendation group appropriate establish consensus different j bobadilla et al knowledgebased system group semantics formalize agreement disagreement among user aim presenting work carried date structured way provide classiÔ¨Åcation recommendation group cf r fig graphically illustrates four basic lev el act order unify group user objective obtaining group user sim ilarity metric establishing neighborhood prediction phase determination recommended item fig individual member group represented left grey graticule represents matrix rating user horizontal item vertical graph show four representative case tackling solution recommenda tion group one matrix left Ô¨Ågure circle show key indicate cf process phase uniÔ¨Åcation performed n user group Ô¨Årst top graph uniÔ¨Åcation performed prediction phase cf process n individual prediction n user group combined one prediction group prediction aggregation used berkovsky freyne garc√≠a et al christen sen schiafÔ¨Åno second act set neighbor group user unifying one neighborhood whole group studied bobadilla et al proposing intersection large number k neighbor user group third recommendation obtained indi vidual user group merged one recommendation group baltrunas et al use rank aggregation individual list recommendation fourth us similarity metric act directly set rating group user solution one directly provides set neighbor group user exists prior previous case pro pose frontend incorporation process estimation missing dealing incomplete fuzzy lin guistic preference relation explaining recommendation important research subject r Ô¨Åeld focus provid ing explanation justify recommendation user ceived important aspect r aid maintaining higher degree user conÔ¨Ådence result gen erated type explanation used thus far classiÔ¨Åed fol low human style explanation user user example recommend movie liked user rated movie j k positively j k movie rated well active user item style explanation item item example recommend vacation destination liked vacation destination g c r g c r vacation destina tions similar rated well active user feature style explanation recommended item feature example recommend movie directed director feature actor b belongs genre g b g feature active user interested hybrid method category primarily includes following humanitem humanfeature featureitem humanfeature item additionally geosocial r foursquare google latitude etc location exists must used recommenda tion explanation mechanism geosocial r typically adopt hybrid humanitem explanation social location memorybased reference publication helpful r explanation research Ô¨Åeld published previously explore utility explanation cf r stated three key research question model technique effective supporting explanation explanation facil ities increase acceptance cf r explanation facility increase Ô¨Åltering performance cf r user answer Ô¨Årst question rating histogram indica tions past performance comparison similar rated item use domain speciÔ¨Åc content feature result experiment conducted r user support afÔ¨Årmative sponse second question third question unanswered fig contentbased Ô¨Åltering mechanism fig different alternative combining cf cbf j bobadilla et al knowledgebased system user perform Ô¨Åltering many different channel input dynamic favor mechanism r expla nation includes conversational technique ccbr conversational casebase reasoning explained mcsherry ccbr use incremental nearest neighbor process pareto dominance different dynamic also adopted employ differ ent perspective instead attempting justify particular recom mendation focus explanation help user understand recommendation opportunity remain current recommendation meet requirement generate compound critique explanation user opportunity accept critique recommendation cri tique recommendation critique act Ô¨Ålter remaining recommendation separate author differentiate con cepts promotion increasing acceptance recommended item satisfaction user satisfaction recommended item also produced better result keyword style explanation content compared neighbor style explanation human style explanation author new classiÔ¨Åcation recommendation justiÔ¨Åcations keyword style explanation contentbased r neighbor style explana tion collaborative Ô¨Åltering r inÔ¨Çuence style explanation tell user interaction r inÔ¨Çuences recommendation tintarev masthoff describe advantage making justiÔ¨Åcations recommendation trans parency scutability trustworthiness effectiveness persuasive ness efÔ¨Åciency satisfaction billus pazzani recommendation news provides keyword style justiÔ¨Åcations recom mendations weight used obtaining recom mendations wang et al describe justiÔ¨Åcations feature user preference tintarnev masthoff design recommedation Ô¨Ålms whose recommen dations justiÔ¨Åed feature vig et al mechanism justifying recommendation called tagsplanations community tag trangsplanations two key component tag relevance degree tag describes item tag preference user sentiment toward tag fahri provides framework organizing justiÔ¨Åcations used categorize explanation categorization discourse explicative theoretical pragmatic ethical moral legal aesthetic personal although theoretical framework used research literature used de sign new type explanation hernando et al present vel explanation technique visualization tree item tree provide valuable reliabil ity recommendation importance rating user made relevant investigation produce justiÔ¨Åcations recommender system include wherein author design new organization interface result grouped according tradeoff property developed trust recommender agent pareto excluding dominated category symeonidis et al Ô¨Årst con struct feature proÔ¨Åle user reveal favorite feature later group user biclusters exploit partial matching de preference group user group item additionally metric measure quality justi Ô¨Åcations explain coverage ratio symeonidis et al use prototype moviexplain put test research showed symeonidis et al hu et al use im plicit feedback derive estimate user preference like dislike item user conÔ¨Ådence useritem pair recommender system trend evolution existing r research paper Ô¨Åeld clear tendency collect integrate different type trend parallel evolution web deÔ¨Åne following three primary stage genesis web r used explicit rat ings user well demographic con tentbased included r owner web addition r collect use social fig classiÔ¨Åcation recommendation group cf r Ô¨Ågure represents four representative case approaching solution group recommendation j bobadilla et al knowledgebased system friend follower followed trusted untrusted simultaneously user aid collaborative inclusion blog tag comment photo video web internet thing contextaware informa tion variety device sensor incorporated currently geographic included expected trend gradual incorporation radio frequency identiÔ¨Åcation rfid sur veillance online health parameter food shopping habit well teleoperation telepresence contextaware recommender system focus additional contextual time location wireless sensor network contextual obtained explic itly implicitly mining mixture meth od hybrid currently mobile application increasingly use geographic enables geographic r considered locationaware r geographic r recommendation typically generated consider ing geographical position user receives recommendation section provides concept gaining popularity r research Ô¨Åeld internet thing pri vacy preservation shilling attack new framework etc provide novel classiÔ¨Åcation analyzing r concept next deal research loca tionaware r may regarded Ô¨Årst step future r web finally describe signiÔ¨Åca tive result promising research Ô¨Åeld r bioin spired model clear trend towards collection implicit instead traditional explicit evaluation item rating lastfm good example situation user rating ferred number time heard song applied number everyday situation access web address use various public transport sys tems food purchased access sport facility access learn ing resource incorporation implicit daily habit user allows r use variety used future cf process increasingly useful accurate privacy security consideration increasingly important widespread trend consent device sen sors internet thing privacy important issue r system contain large number registered user pri vacy preservation r certain level uncertainty must intro duced prediction primarily tradeoff accuracy privacy furthermore privacy preserved different r company share com bining privacy becomes important r increasingly incorporate social r often used electronic commerce unscrupulous producer may Ô¨Ånd proÔ¨Åtable shill r lying system order product recommended often competitor r experience shilling attack generate many positive rating product product competitor receive negative rating r still highly vul nerable attack knowledgebased Ô¨Åltering emerging important Ô¨Åeld r knowledge r use knowledge user product pursue knowledgebased generating recommenda tions reasoning product meet user requeri ments recommendation inference user need preference user model knowledge struc tures query preferred feature por product case casebased reasoning constraint constraintbased reason ing ontology matching metric knowledge vec tor social knowledge workÔ¨Çow current knowledge Ô¨Åeld user usersrolestasks reference describes member play role fulÔ¨Ålls task peertopeer pp network current knowl edge Ô¨Åeld user distributed existing peer set peer may need gradual incorporation different type eg ex plicit rating social relation user content location use trend knowledgebased forced r use hybrid ap proaches memorybased social locationaware method algorithm consolidated evolution r dem onstrates clear trend toward combining existing collaborative method latest research cf Ô¨Åeld generated modest improvement prediction recommendation single type eg used user rating social relation item content sults improve several algorithm combined respective type growing number publication ad dress hybrid approach use current database simulta neously incorporate memorybased social contentbased unify concept fig provides original taxon omy r taxonomy classiÔ¨Åed depending nature rather according method algorithm used core taxonomy focus classiÔ¨Åcation three factor target user item mode acquisition explicit ie rating item made user impli cit eg number time user heard song informa tion level memory content social context fig show recommender method algorithm la beled collaborative Ô¨Åltering algorithm depending type r database adopts hybrid Ô¨Åltering hybrid use appropriate subset algorithm consider processing existing coor dinated manner future development include different rec ommendation framework address common situation framework allow r incorporate cf kernel appropriate recommendation method available simple straightforward manner higher level prediction recommendation fig incorporates current evaluation quality measure diversity novelty importance measure measure developed future grow user demand novel stable less predictable recommendation locationaware recommender system due increasing use mobile device locationaware sys tems becoming widespread system show ten dency towards consolidation web service naturally lead locationaware cf locationaware r called geographic cf geographic r introduce classiÔ¨Åcation geographic cf r focus relevant section classiÔ¨Åcation obtained establishes different possibility tackling geographic r according nature rating made rating stage recommendation process followed recommendation stage user indicates rating andor recommendation made without user geographic gi j bobadilla et al knowledgebased system similarly item indicates rating andor recommendation made without item gi case la beled user g item g gi used case identiÔ¨Åed r traditional r rating recommendation made without geographical r g traditional r also contributes item geo graphical position r regarded geographic r gi play part recommendation process grs group geographic r likely become pop ular near future rating made traditional way whilst recommendation made considering geo graphical position user recommendation made representative example r restau rant user rate restaurant diverse concept include distance time voting user restaurant however user geographic r expects restaurant recommended good rating similar user k neighbor also according distance current position restaurant possible example r cinema pub supermarket cultural activity city lan guage learning center gym sport club etc grs user establish rating item weighting distance item rated type geographic r two possibility established hybrid cfdemographic Ô¨Åltering item accepts max imum one vote per user geographical posi tion issued associated geographic r item accepts one rat ing user depending geographical position rating made hybrid r respond regional national geo graphical approach recommendation established according weighting similarity vote cf origin type grs may regarded extended hybrid cfdemographic Ô¨Åltering gi given vote instead user theoretical point view type grs com plete however practical point view involve semantic difÔ¨Åculty item rating process make use difÔ¨Åcult rating item grs involves user rate item according relative distance user item way user rate restaurant home differently would rate workplace distance different rating also likely mental process would something like km restaurant rate positively travelling km go restaurant think good time user work km away restau rant could cast vote indicating consider po sitive travel km go restaurant even think good summary grs advantage accept wider variety rating also contain relative impor tance user give item according distance quired access disadvantage difÔ¨Åcult involve user particularly complex demanding rating process subsection focus grstype geographic cf r present publication regarding gibased r due great extent lack public database include rating geographic position capable combined r publication focus closely Ô¨Åeld follows martinez et al biukaghai et al example r g group schlieder novel modeling collaborative semantics geographic folksono mies multiobject tagging tag user assign composite object concept group people share common geospatial feature dictionary including deÔ¨Ånitions feature relationship common metadata schema wanshiou et al considered hybrid content basedgeographic r core hybrid content basedgeographic recommendation mechanism analyzes customer history position vendor ranked according match preference customer matyas schlieder show collaborative could situate r grs user rating taken photo downloaded web photo uploaded web photo gps address associated search k neighborhood carried recommendation process take account user position possible collect travel gps trace user use database generate recommendation travel gps trace reinforced social friend paper classiÔ¨Åed grs bioinspired approach much proposed modelbased r bioin spired approach primarily use genetic algorithm gas neural network nns model also proposed artiÔ¨Åcial immune network ains ga heuristic approach evolutionary principle natural selection survival Ô¨Åtest ga mainly used two aspect r clustering hybrid user model common technique improve fea tures r consists initially carrying clustering user way group class similar user obtained desired cf technique applied cluster obtaining similar result much shorter calculation time usual use common genetic clustering algorithm gabased k mean r hybrid user model commonly use combination cf demographic Ô¨Åltering cf content Ô¨Åltering exploit merit one technique case chromosome structure easily contain demographic charac teristics andor related contentbased Ô¨Åltering order tackle locationbased advertisement dao et al modelbased cf ga combine user preference interaction context bobadilla et al use ga create similarity metric weighting set simple similar ity measure hwang et al employ ga learn personal preference customer nn observed behavior biological neu ron intended simulate way brain process enables computer learn certain degree nn typically consists number interconnected node handle designated sphere knowledge several input network input get node learn relationship set pattern upon operational feedback molded pattern required generate required result j bobadilla et al knowledgebased system r relevant research available nn usually fo cuses hybrid r nn used learn user proÔ¨Åles nn also used clustering process r hybrid approach enable nn act additional infor mation rating ren et al hybrid rec ommender employ widrowhoff learn user proÔ¨Åle content rated item improves granularity user proÔ¨Åling christakou stafylopatis use combination contentbased cf order construct provides precise recom mendations concerning movie lee woo Ô¨Årst user segmented demographic characteristic user fig recommender system taxonomy j bobadilla et al knowledgebased system segment clustered according preference item selforganizing map som nn kohonons som type unsupervised learning goal discover underlying structure two alternative nn us presented huang et al roh et al Ô¨Årst author use training back propagation nn generating association rule mined transactional database second author pro pose combine cf two machine learning process som reasoning cbr changing unsupervised clustering problem supervised user preference reasoning problem neurofuzzy inference used sevarac et al create pedagogical rule elearning new coldstart similarity measure perfected bobadilla et al optimiza tion neural learning artiÔ¨Åcial immune system distributed adaptive system model principle derived form human immune defence protect body infection order tackle r sparsity problem make algorithm scalable acilar arslan pres ent new cf ainet previously proposed general recommendation rec ommend web site related work original contribution cf become complex different survey paper published area schafer et al introduces core concept cf theory practice rating system acquisition evaluation interaction interface privacy sue candillier et al review main cf Ô¨Åltering method compare result su khoshgoftaar present survey cf technique author introduce theory cf concisely deal main challenge sparsity scalability synonymy gray sheep shil ling attack privacy etc also expose overview cf technique park et al review paper r classiÔ¨Åes year journal publication application Ô¨Åelds mining technique additionaly categorized pa pers eight application Ô¨Åelds Ô¨Ålms music etc review r algorithm presented fo cuses explaining carefully used algorithm r work present also basic concept cf evaluation metric dimensionality reduction technique diffu sionbased method social Ô¨Åltering meta approach survey try include novel issue dealt carefully previous paper next stand outstanding feature survey us methodology selecting suitable paper r standing latest cited paper area r provides updated overview used r public database including tag friend relation study coldstart problem inherent r present novel overview informing classical similarity measure recently pro posed includes tailored metric coldstart user generalpurpose metric besides show quality measure obtained evaluating metric includes recent quality measurement beyond accuracy evaluate r novelty diversity stability additionaly include reliability measure associated prediction recommendation provides comprehensive survey social Ô¨Åltering presenting novel overview trust reputation credibility introduces contentbased Ô¨Åltering modern perspec tive standing application dealing social informa tion social tagging present summary relevant contribution r group user show novel classiÔ¨Åcation existing method deal fast growing r Ô¨Åeld locationaware r geographic section estructured help novel geographic r classiÔ¨Åcation summarizes relevant contribution use bio inspired approach describes r trend implicitally collect specially derived use internet thing provides r taxonomy classifying r three factor source traditional web social web internet thingsweb target user item extracting explicit implicit conclusion recommender system proving useful tool addressing portion overload phenomenon internet evolution accompanied evolution web Ô¨Årst generation recommender system used tradi tional website collect following three source contentbased purchased used product b demographic collected user record c mem orybased collected user item preference second generation recommender system extensively use web gathering social eg friend follower followed trusted user untrusted user third generation recom mender system use web pro vided integrated device internet use location already incorporated many recommender system followed device sensor widely used eg realtime health signal rfid food habit online local weather parameter temperature pressure Ô¨Årsts recommender system focused improving recommendation accuracy Ô¨Åltering memorybased method algorithm developed optimized context eg k nn metric aggregation approach singular decomposition diffusionbased method etc stage hybrid approach primarily collaborativedemographic collabora tivecontent Ô¨Åltering improved quality recommenda tions second stage algorithm included social previous hybrid approach adapted developed eg trustaware algorithm social adaptive ap proaches social network etc currently hybrid ensemble algorithm incorporate location exist ing recommendation algorithm evaluation prediction recommendation evolved since origin recommender system weighted prediction error accuracy heavily also recognized geographic collaborative Ô¨Åltering recommender system classiÔ¨Åcation rating stage recommendation stage user gi item item g item item g user rsgrs r r g user g grs grsgrs yes item gi yes yes j bobadilla et al knowledgebased system convenience evaluating quality top n recommenda tions set evaluation top n recommendation ranked list incorporated currently tendency assess new evaluation measure diversity novelty future research concentrate advancing existing method algorithm improve quality recommender system prediction recommendation simultaneously new line research developed Ô¨Åelds aim proper combination existing recommendation method use different type available get maximum use individual potential various sensor device internet thing acquisition integration trend related habit consumption taste individ ual user recommendation process mining r database nonrecommendation us eg market research general trend visualization differential characteristic demo graphic group enabling security privacy recom mender system process new evaluation measure developing standard nonstandardized evaluation measure designing Ô¨Çexible framework automated heterogeneous reference abbar bouzeghoub lopez contextaware recommender system service oriented proceeding rd international workshop personalized access proÔ¨Åle management context awareness database acilar arslan collaborative Ô¨Åltering artiÔ¨Åcial immune network expert system application g adomavicius tuzhilin toward next generation recommender system survey stateoftheart possible extension ieee transaction knowledge engineering g adomavicius j zhang stability recommendation algorithm acm conference recommender system pp g adomavicius tuzhilin contextaware recommender system f ricci et al ed recommender system handbook pp hj ahn new similarity measure collaborative Ô¨Åltering alleviate new user coldstarting problem science myh alshamri kk bharadwaj fuzzygenetic recommender system novel hybrid user expert system application j alsharawneh williams credibilityaware webbased social network recommender follow leader proceeding acm conference recommender system pp alonso fj cabrerizo f chiclana f herrera e herreraviedma group decision making incomplete fuzzy linguistic preference relation international journal intelligent system ansari essegaier r kohli internet recommendation system journal marketing research n antonopoulus j salter cinema screen recommender agent combining collaborative contentbased Ô¨Åltering ieee intelligent system p antunes v herskovic sf ochoa ja pino structuring dimension collaborative system evaluation acm computing survey article arazy n kumar b shapira improving social recommender system journal professional l ardissono goy g petrone segnan p torasso intrigue personalized recommendation tourist attraction desktop handset device applied artiÔ¨Åcial intelligence r baezayates b ribeironeto modern retrieval addison wesley balabanovic shoham contentbased collaborative recommendation communication acm l baltrunas makcinskas f ricci group recommendation rank aggregation collaborative Ô¨Åltering proceeding acm conference recommender system pp ab barrag√°nsmartƒ±nez e costamontenegro jc burguillo reyl√≥pez fa mikicfonte peleteiro hybrid contentbased itembased collaborative Ô¨Åltering recommend tv program enhanced singular decomposition science c basu h hirsh w cohen recommendation classiÔ¨Åcation social contentbased recommendation proceeding fifteenth national conference artiÔ¨Åcial intelligence pp p bedi r sharma trust recommender ant colony trust computation expert system application bengio grandvalet umbiased estimator variance kfold crossvalidation journal machine learning research berkovsky j freyne groupbased recipe recommendation aggregation strategy proceeding acm conference recommender system pp bilge h polat improved privacypreserving dwtbased collaborative Ô¨Åltering scheme expert system application bilgic r mooney explanation recommender system satisfaction v promotion next stage recommender system research workshop iui conference pp billsus pazzani personal news agent talk learns explains proc auton agent conf pp billsus pazzani user modeling adaptive news access user modeling useradapted interaction billsus pazzani j chen learning agent wireless news access proceeding international conference intelligent user interface pp rp biukaghai fong yainwhar design recommender mobile tourism multimedia selection nd international conference internet multimedia service architecture application imsaa pp j bobadilla f serradilla effect sparsity collaborative Ô¨Åltering metric australian database conference pp j bobadilla f serradilla hernando collaborative Ô¨Åltering adapted recommender system elearning knowledge system j bobadilla f serradilla j bernal new collaborative Ô¨Åltering metric improves behavior recommender system knowledge system j bobadilla hernando f ortega j bernal framework collaborative Ô¨Åltering recommender system expert system application j bobadilla f ortega hernando j alcal√° improving collaborative Ô¨Åltering recommender system result performance genetic algorithm knowledge system j bobadilla hernando f ortega guti√©rrez collaborative Ô¨Åltering signiÔ¨Åcances science j bobadilla f ortega hernando collaborative Ô¨Åltering similarity measure singularity processing management j bobadilla f ortega hernando j bernal collaborative Ô¨Åltering mitigate new user cold start problem knowledge system j bobadilla f ortega hernando j bernal generalization recommender system collaborative Ô¨Åltering extended group user restricted group item expert system application j bobadilla f ortega hernando arroyo balanced memorybased collaborative Ô¨Åltering similarity measure international journal intelligent system bogers van den bosch collaborative contentbased Ô¨Åltering item recommendation social bookmarking website proceeding acm conference recommender system pp p bonhard trust combining recommender system social networking better advice international conference intelligent user interface p bonhard sasse knowing knowing youusing proÔ¨Åles social networking improve recommender system bt technology journal p borzymek sydow wierbicki enriching trust prediction social network user rating similarity proceeding international conference computational aspect social network pp j breese heckerman c kadie empirical predictive algorithm collaborative Ô¨Åltering th conference uncertainty artiÔ¨Åcial intelligence pp bridge mh goker l mcginty b smyth casebased recommender system knowledge engineering review r burke encyclopedia library system kent ed vol suppl marcel dekker chapter knowledgebased recommender system r burke casebased reasoning collaborative Ô¨Åltering ewcbr pp r burke hybrid recommender system survey experiment user modeling useradapted interaction f cacheda v carneiro fern√°ndez v formoso comparison collaborative Ô¨Åltering algorithm limitation current technique proposal scalable highperformance recommender system acm transaction web article caizer u aickelin recommender idiotypic artiÔ¨Åcial immune network journal mathematics model algorithm j bobadilla et al knowledgebased system lm campos jm fern√°ndezluna jf huete ruedamorales combining contentbased collaborative recommendation hybrid bayesian network international journal approximate reasoning l candillier f meyer boull√© comparing stateoftheart collaborative Ô¨Åltering system lecture note computer sciece f carmagnola f vernero p grillo sonar social networksbased social recommender system proceeding th international conference user modeling adaptation personalization formerly um ah pp w carrerneto ml hern√°ndezalcaraz r valenciagarcƒ±a f garcƒ±a s√°nchez social knowledgebased recommender application movie domain expert system application jj castrosanchez r miguel vallejo lm l√≥pezl√≥pez highly adaptive recommender fuzzy logic bc ecommerce portal expert system application chao j balthrop forrest adaptive radio achieving consensus negative preference international acm siggroup conference supporting group work pp chen l collaborative Ô¨Åltering demographic attribute vector proceeding international conference future computer communication pp pa chirita w nejdl c zamÔ¨År preventing shilling attack online recommender system workshop web management pp j cho k kwon park qrater collaborative reputation source credibility theory expert system application sb cho jh hong mh park locationbased recommendation bayesian user preference mobile device lecture note computer science k choi yoo g kim suh hybrid onlineproduct recommendation combining implicit ratingbased collaborative Ô¨Åltering sequential pattern electronic commerce research application press doi jelerap k choi suh new similarity fuction selecting neighbor target item collaborative Ô¨Åltering knowledge system c christakou stafylopatis hybrid movie recommender neural network international conference intelligent system design application pp ia christensen schiafÔ¨Åno entertainment recommender system group user expert system application claypool gokhale miranda p murnikov netes sartin combining contentbased collaborative Ô¨Ålters online newspaper proceeding acm sigir workshop recommender system pp w cohen fast effective rule induction proceeding twelfth international conference machine learning pp condliff lewis madigan c posse bayesian mixedeffects model recommender system acm sigir workshop recommender system algorithm evaluation pp e costamontenegro ab barrag√°nsmartƒ± nez reyl√≥pez app recommender application market implementation service monitoring user interaction expert system application th dao sr jeong h ahn novel recommendation locationbased advertising contextaware collaborative Ô¨Åltering ga expert system application dellamico l capra sofia social Ô¨Åltering robust recommendation ifip advance communication technology dubois j golbeck j kleint srinivasan improving recommendation accuracy clustering social network trust proceeding acm conference recommender system pp ekstr√∂m h bj√∂rnsson c nass reputation mechanism businessto business electronic commerce account rater credibility journal organizational computing electronic commerce esslimani brun boyer social network behavioral network recommender system proceeding international conference advance social network mining pp fahri framework organizing justiÔ¨Åcations strategic use adaptive iteraction context ecis article felfernig r burke constraintbased recommender system technology research issue th international conference electronic commerce article l fengkun jl hong use social network enhance collaborative Ô¨Åltering performance expert system application lq gao c li hybrid personalizad recommended genetic international conference wireless communication network mobile computing pp gao z wu f jiang userrank itembased collaborative Ô¨Åltering recommendation processing letter garcƒ± l sebastia e onaindia design individual group recommender system tourism expert system application r garcƒ±a x amatriain weighted content method recommending connection online social network proceeding acm conference recommender system pp gavalas kenteris webbased pervasive recommendation mobile tourist guide personal ubiquitous computing f gedikli jannach rating item rating tag proceeding acm conference recommender system pp j gemmell schimoler b mobasher r burke resource recommendation social tagging multichannel hybrid proceeding acm conference recommender system pp j gemmell schimoler ramezani l christiansen b mobasher improving folkrank itembased collaborative Ô¨Åltering proceeding acm conference recommender system pp gemmis p lops g semeraro p basile integrating tag semantic contentbased recommender proceeding acm conference recommender system pp george meregu scalable collaborative Ô¨Åltering framework base coclustering ieee international conference mining icdm pp j golbeck u kuter ripple effect change trust impact social network computing social trust humancomputer interaction series part ii pp chapter k goldberg roeder gupta c perkins eigentaste constant time collaborative Ô¨Åltering retrieval r gonz√°lezcrespo sanju√°nmartƒ±nez j manuelcueva b cristinapelayo je labragayo p ordo√±ez recommendation user interaction applied intelligent electronic book computer human behavior n good jb schafer ja konstan borchers b sarwar jl herlocker j riedl proceeding sixteenth national conference artiÔ¨Åcial intelligence eleventh innovative application artiÔ¨Åcial intelligence conference innovative application artiÔ¨Åcial intelligence pp gunawardana g shani survey accuracy evaluation metric recommender task journal machine learning reearch jl herlocker ja konstan j riedl explaining collaborative Ô¨Åltering recommendation acm conference computer supported cooperative work cscw pp jl herlocker ja konstan al borchers jt riedl algorithmic framework performing collaborative Ô¨Åltering proceeding nd annual international acm sigir conference research development retrieval pp jl herlocker ja konstan jt riedl empirical design choice neighborhoodbased collaborative Ô¨Åltering algorithm retrieval jl herlocker ja konstan jt riedl lg terveen evaluating collaborative Ô¨Åltering recommender system acm transaction system f hern√°ndez e gaudioso evaluation recommender system new expert system application hernando j bobadilla f ortega j tejedor incorporating reliability measurement prediction recommender system science press doi jins hernando j bobadilla f ortega guti√©rrez tree explaining recommendation made collaborative Ô¨Åltering science k heungnam e abdulmotaleb j geunsik collaborative errorreÔ¨Çected model coldstart recommender system decision support system ho fong z yan hybrid gabased collaborative Ô¨Åltering online recommenders international conference ebusiness pp l hossain fazio social network collaborative process journal high technology management research hr hu p pu personality collaborative Ô¨Åltering new user proceeding acm conference recommender system pp hu koren ch volinsky collaborative Ô¨Åltering implicit feedback datasets ieee international conference mining icdm pp yp huang wp chuang yh ke fe sandnes backpropagation learn association rule service personalization expert system application z huang zeng h chen comparison collaborative Ô¨Åltering recommendation algorithm ecommerce ieee intelligent system n hurley zhang novelty diversity topn recommendation evaluation acm transaction internet technology j bobadilla et al knowledgebased system chs hwang ych su kch tseng genetic algorithm personalized recommendation lecture note computer science h ingoo jo kyong hr tae collaborative Ô¨Åltering recommendation som clusterindexing cbr expert system application jameson b smyth recommendation group p brusilovsky kobsa w nejdl ed adaptive web pp chapter jannach fast computation query relaxation knowledgebased recommenders ai communication r j√§schke l marinho hotho l schmidtthieme g stumme tag recommendation folksonomies proceeding th european conference principle practice knowledge discovery database pp jj jason contextualized mobile recommendation service interactive social network discovered mobile user expert system application b jeong j lee h cho user credit collaborative Ô¨Åltering expert system application joachim text categorization support vector machine learning many relevant feature european conference machine learning pp j√∏sang r ismail c boyd survey trust reputation system online service provision decision support system chw jyun chch chui recommending trusted online auction seller social network expert system application c kaleli h polat privacypreserving sombased recommendation horizontally distributed knowledge system hn kim alkhaldi ae saddik g jo collaborative user modeling usergenerated tag social recommender system expert system application hn kim ji ha g jo collaborative Ô¨Åltering collaborative tagging enhancing quality recommendation electronic commerce research application j kim b lee shaw h chang w nelson application decisiontree induction technique personalized advertisement internet storefront international journal electronic commerce k kim h ahn clustering genetic support customer segmentation personalizad recommender system proceeding th international conference ai simulation planning high autonomy system pp k kim h ahn recommender ga kmeans clustering online shopping market expert system application kitisin c neuman reputationbased trustaware recommender securecomm workshop pp f kong x sun ye comparison several algorithm collaborative Ô¨Åltering startup stage ieee transaction network sensing control koren r bell ch volinsky matrix factorization technique dor recommender system ieee computer g koutrika b bercovitz h garcia flexrecs expressing combining Ô¨Çexible recommendation proceeding th sigmod international conference management pp b krulwich lifestyle Ô¨Ånder intelligent user proÔ¨Åling largescale demographic artiÔ¨Åcial intelligence magazine k kwon j cho park multidimensional credibility neighbor selection collaborative recommendation expert system application sk lam j riedl shilling recommender system fun proÔ¨Åt international conference world wide web pp xn lam vu td le ad duong addressing coldstart problem recommendation system conference ubiquitous management communication pp n landia s anand personalised tag recommendation proceeding acm conference recommender system pp k lang newsweeder learning Ô¨Ålter netnews proceeding th international conference machine learning pp dh lee p brusilovsky trust inÔ¨Çuence similarity proceeding acm conference recommender system pp lee woo hybrid recommender combining collaborative Ô¨Åltering neural network lecture note computer science sk lee yh cho sh kim collaborative Ô¨Åltering ordinal scalebased implicit rating mobile music recommendation science cw leung sc chan fl chung empirical crosslevel association rule mining coldstart recommendation knowledge system q li clustering hybrid recommender proceeding ieeewic international conference web intelligence pp ym li chw chen synthetical blog recommendation combining trust social relation semantic an√°lisis expert system application ym li chp kao trepps trustbased recommender peer production service expert system application ym li tf liao chy lai social recommender mechanism improving knowledge sharing online forum processing management press doi jipm loh f lorenzi r granada lichtnow lk wife jp oliveira identifying similar user scientiÔ¨Åc publication reduce cold start recommender system proceeding th international conference web system technology webist pp l l√º medo chh yeung ych zhang zk zhang zhou recommender system physic report x luo xia q zhu incremental collaborative Ô¨Åltering recommender regularizad matrix factorization knowledgebased system x luo xia q zhu applying learning rate adaptation matrix factorization collaborative Ô¨Åltering knowledge system h king mr lyu learning recommend explicit implicit social relation acm transaction intelligent system technology article h ch zhou mr lyu king improving recommender system incorporating social contextual acm transaction system article machanavajjhala korolova ad sharma personalized social recommendation accurate private proceeding vldb endowment vol issue pp lb marinho l schmidtthieme collaborative tag recommendation proceeding st annual conference german classiÔ¨Åcation society pp l martinez lg perez mj barranco incomplete preference relation smooth coldstart collaborative recommender system proceeding th north american fuzzy processing society annual conference nafips pp l martinez rm rodriguez espinilla reja georeferenced hybrid recommender restaurant ieeewicacm international joint conference web intelligence intelligent agent technonolgy wiiat b pp p massa p avesani trustaware collaborative Ô¨Åltering recommender system lecture note computer science p massa p avesani trustaware recommender system proceeding acm conference recommender system pp c matyas c schlieder spatial user similarity measure geographic recommender system proceeding rd international conference geospatial semantics pp k mccarthy j reilly l mcginty b smyth thinking positivelyexplanatory feedback conversational recommender system european conference casebased reasoning eccbr pp k mcnally mp omahony coyle p briggs b smyth collaboration reputation social web search acm transaction intelligent system technology article mcsherry explanation recommender system artiÔ¨Åcial intelligence review f mcsherry mironov differentially private recommender system building privacy netÔ¨Çix prize contender proceeding th acm sigkdd international conference knowledge discovery mining kdd pp p melville rj mooney r nagarajan contentboosted collaborative Ô¨Åltering improved recommendation proceeding eighteenth national conference artiÔ¨Åcial intelligence pp r meteren someren contentbased Ô¨Åltering recommendation proceeding ecml workshop maching learning age pp se middleton nr shadbolt dc de roure ontological user proÔ¨Åling recommender system acm transaction system tois rj mooney l roy contentbased book recommending learning text categorization proceeding fifth acm conference digital library pp morrison u aickelin artiÔ¨Åcial immune recommender web site international conference artiÔ¨Åcial immune system pp nanolopoulus rafailidis p symeonidis manolopoulus music box personalizad music recommendation cubic social tag ieee transaction audio speech language processing k nehring c puppe theory diversity econometrica er n√∫√±ezvald√©z jm cuevalovelle sanju√°nmartƒ±nez v garcƒ± adƒ±az p ordo√±ez ce montenegromarƒ± n implicit feedback technique recommender system applied electronic book computer human behavior j bobadilla et al knowledgebased system j odonovan capturing trust social web application j golbeck ed computing social trust pp j odonovan b smyth trust recommender system international conference intelligent user interface pp k oku r kotera k sumiya geographical recommender interaction map operation category selection workshop heterogeneity fusion recommender system pp j ortega j bobadilla hernando guti√©rrez incorporating group recommendation recommender system alternative performance processing management httpdxdoiorg jipm j ortega jl s√°nchez j bobadilla guti√©rrez improving collaborative Ô¨Ålteringbased recommender system result pareto dominance science httpdxdoiorgjins papadimitriou p symeonidid manolopoulus generalized taxonomy explanation style traditional social recommender system minning knowledge discovery dh park hk kim iy choi jk kim literature review classiÔ¨Åcation recommender system research expert system application st park w chu pairwise preference regression coldstart recommendation proceeding acm conference recommender system pp st park dm pennock madani n good coste naƒ±ve Ô¨Ålterbots robust coldstart recommendation proceeding knowledge discovery mining kdd pp yj park tuzhilin long tail recommender system leverage proceeding acm conference recommender system pp pazzani billsus learning revising user proÔ¨Åles identiÔ¨Åcation interesting web site machine learning mj pazzani billsus contentbased recommender system p brusilovsky kobsa w nejdl ed adaptive web pp chapter pazzani framework collaborative contentbased demographic Ô¨Åltering artiÔ¨Åcial intelligence reviewspecial issue mining internet perugini gon√ßalves ea fox recomender system research connectioncentric surrey journal intelligen system mc pham cao r klamma jarke clustering collaborative Ô¨Åltering recommendation social network journal universal computer science g pitsilis sj knapskog socila trust solution address sparsityinherent problem recommender system proceeding acm conference recommender system pp g pitsilis x zhang w wang clustering recommenders collaborative Ô¨Åltering explicit trust advance communication technology popescul lh ungar dm pennock lawrence probabilistic model uniÔ¨Åed collaborative contentbased recommendation sparsedata environment proceeding uai proceeding th conference uncertainty artiÔ¨Åcial intelligence pp c porcel e herreraviedma dealing incomplete fuzzy linguistic recommender disseminate university digital library knowledgebased system c porcel jm moreno e herreraviedma multidisciplinar recommender advice research resource university digital library expert system application c porcel tejedalorente martƒ± nez e herreraviedma hybrid recommender selective dissemination research resource technology transfer ofÔ¨Åce science j preece b shneiderman reader leader framework motivating technologymediated social participation ai transaction human computer interaction p pu l chen trustinspiring explanation interface recommender system knowledge system w qin l xin h liang unifying userbased itembased improve collaborative Ô¨Åltering accuracy energy procedia l ramaswamy p deepak r polavarapu k gunasekera garg k visweswariah kalyanaraman caesar contextaware social recommender lowend mobile device international conference mobile management system service middleware pp rashid g karypis j riedl learning preference new user recommender system theoretic acm sigkdd exploration newsletter vol issue pp ray mahanti strategy effective shilling attack recommender system lecture note computer science l ren l j gu w xia f wu hybrid recommender widrowhoff learning international conference future generation communication networking pp th roh kj oh han collaborative Ô¨Åltering recommendation som clusterindexing cbr expert system application ja rodrigues lf cardoso j moreira g xexeo bringing knowledge recommender system journal system software press http dxdoiorgjjss sb roy ameryahia chala g da c yu space efÔ¨Åciency group recommendation international journal large base g ruffo r schifanella peertopeer recommender base spontaneous afÔ¨Ånities acm transaction internet technology pb ryan bridge collaborative recommending formal concept knowledge system g salton automatic text processing transformation retrieval computer addisonwesley reading saranya atsuhiro hybrid recommender system latent feature proceeding international conference advanced networking application workshop pp b sarwar g karypis ja konstan j riedl itembased collaborative Ô¨Åltering recommendation algorithm th international conference world wide web pp b sarwar g karypis j konstan j riedl recommendation algorithm ecommerce acm conference electronic commerce pp b sarwar g karypis j konstan j riedl application dimensionality reduction recommender acm webkdd workshop b pp jb schafer frankowski j herlocker sen collaborative Ô¨Ålltering recommender system p brusilovsky kobsa w nejdl ed adaptive web pp chapter ai schein popescul lh ungar dm pennock method metric coldstart recommendation proceeding sigir proceeding th annual international acm sigir conference research development retrieval pp c schlieder modeling collaborative semantics geographic recommender workshop semantic conceptual issue geographic system pp j serranoguerrero e herreraviedma ja olivas cerezo fp romero google wavebased fuzzy recommender disseminate university digital library science z severac v devedzic j jovanovic adaptive neurofuzzy pedagogical recommender expert system application shepitsen j gemmell b mobasher r burke personalized recommendation social tagging system hierarchical clustering proceeding acm conference recommender system pp sk shinde u kulkami hybrid personalizad recommender centeringbunching clustering expert system application siersdorfer sergei social recommender system web folksonomies th acm conference hypertext hipermedia pp soboroff c nicholas combining content collaboration text Ô¨Åltering proceeding ijcai workshop machine learning filtering pp x su tm khoshgoftaar survey collaborative Ô¨Åltering technique advance artiÔ¨Åcial intelligence p symeonidis nanopoulus manolopoulus providing justiÔ¨Åcations recommender system ieee transaction system man cybernet p symeonidis nanopoulus manolopoulus movieexplain recommender explanation proceeding acm conference recommender system pp g tak√°cs pil√°szy b n√©meth tikk scalable collaborative Ô¨Åltering approach large recommender system journal machine learning research tan j bu ch chen x rich social medium music recommendation via hypergraph acm transaction multimedia computing communication application article n tintarev j masthoff survey explanation recommender system ieee rd international conference engineering workshop tran r cohen hybrid recommender system electronic commerce proceeding th national conference artiÔ¨Åcial intelligence aaai pp khl tsosutter lb marinho l schmidtthieme tagaware recommender system fusion collaborative Ô¨Åltering algorithm proceeding acm symposium applied computing pp vargas p castells rank relevance novelty diversity metric recommender system proceeding acm conference recommender system pp p victor ch cornelis decock trust network recommender system antalis press j bobadilla et al knowledgebased system j vig sen j riedle tagsplanations explaining recommendation tag proceeding th international conference intelligent user interface pp p victor ch cornelis decock pp dasilva gradual tust distrust recommender system fuzzy set system mg vozalis kg margaritis svd demographic enhancement generalized collaborative Ô¨Åltering science wanshiou ch hungchi jiaben locationaware recommender mobile shopping environment expert system application j wang vries reinders unifying userbased itembased collaborative Ô¨Åltering approach similarity fusion proc sigir conf pp j wang ap vries mj reinders uniÔ¨Åed relevance model rating prediction collaborative Ô¨Åltering acm transaction system lt weng xu li r nayak exploiting item taxonomy solving cold start problem recommendation making proceeding th ieee international conference tool artiÔ¨Åcial intelligence ictai pp b widrow hoff adaptive switching circuit convention record ire wescon pp p winoto ty tang role user mood movie recommendation expert system application w woerndl g groh utilizing physical social context improve recommender system ieeewicacm international conference web intelligence intelligent agent technology pp b xie p han f yang rm shen hj zeng z chen dcfla distributed collaborativeÔ¨Åltering neighborlocating science w xin q jamaliding okamoto discovering social network improve recommender group learning support international conference computational intelligence software engineering pp rr yager fuzzy logic method recommender system fuzzy set system w yang hch cheng jb dia locationaware recommender mobile shopping environment expert system application yang evaluation statistical approach text categorization retrieval z yao q zhang itembased clustering collaborative Ô¨Åltering high dimensional sparse international joint confeence computational science optimization pp z yu x zhou hao j gu tv program recommendation multiple viewer user proÔ¨Åle merging user modeling useradapted interaction w yuan guan yk lee lee sj hur improved trustaware recommender smallworldness trust network knowledge system g zacharia moukas p maes collaborative reputation mechanism electronic marketplace decision support system zaiane building recommender agent elearning system proceeding international conference computer education icce vol pp j zhan privacypreserving collaborative recommender system ieee transaction system man cybernetics f zhang hy chang collaborative Ô¨Åltering employing genetic clustering ameliorate scalability issue ieee international conference ebusiness engineering pp zhang w wang j ford f makedon singular decomposition approximation collaborative Ô¨Åltering ieee international conference ecommerce technology pp l zhen gq huang z jiang recommender system workÔ¨Çow decision support system l zhen gq huang z jiang collaborative Ô¨Åltering workÔ¨Çow space expert system application l zhen z jiang h song distributed recommender peertopeer knowledge sharing science n zheng q li recommender tag time social tagging system expert system application zheng x xie learning travel recommendation usergenerated gps trace acm transaction intelligent system technology article zheng l zhang z x xie wy recommending friend location individual location history acm transaction web article j zhong x li uniÔ¨Åed collaborative Ô¨Åltering combination latent feature expert system application rl zhu sj gong analyzing collaborative Ô¨Åltering clustering technology international colloquium computing isecs international colloquium computing communication control management pp cn ziegler sm mcnee ja konstan g lausen improving recommendation list topic diversiÔ¨Åcation proceeding th international conference world wide web pp j bobadilla et al knowledgebased system,recommender system survey knowledgebased system,recommender system,recommender system survey knowledgebased system recommender system survey knowledgebased system recommender system survey knowledgebased system recommender system recommender system recommender system survey j bobadilla f ortega hernando guti√©rrez universidad polit√©cnica de ctra de valencia km spain r c l e n f article history received october received revised form march accepted march available online april keywords recommender system collaborative Ô¨Åltering similarity measure evaluation metric prediction recommendation hybrid social internet thing coldstart b r c recommender system developed parallel web initially demo graphic contentbased collaborative Ô¨Åltering currently system incorporating social infor mation future use implicit local personal internet thing article provides overview recommender system well collaborative Ô¨Åltering method algorithm also explains evolution provides original classiÔ¨Åcation system iden tiÔ¨Åes area future implementation develops certain area selected past present future importance elsevier bv right reserved recommender system rss collect prefer ences user set item eg movie song book joke gadget application website travel destination elearning material acquired explicitly typically collecting user rating implicitly typically monitoring user behavior song heard application downloaded web site visited book read r may use demo graphic feature user like age nationality gender social like follower followed twit post commonly used web growing tend towards use infor mation internet thing eg gps location rfid realtime health signal r make use different source providing user prediction recommendation item try balance factor like accuracy novelty dispersity stability recommendation collaborative filtering cf method play important role recommendation although often used along Ô¨Ålterning technique like contentbased knowledgebased social one cf way human made decision throughout history besides experience also base decision experience knowledge reach u relatively large group acquaintance recently r implementation internet increased facilitated use diverse area com mon research paper focused movie recommendation stud y however great volume literature r centered different topic music televi sion book document e learning ecommerce application market web search among others kind Ô¨Åltering used beginning r col laborative contentbased demographic described breese et al evaluated predictive accuracy differ ent algorithm cf later classical describes base evaluating collaborative filtering r evolution r shown importance hybrid tech niques r merge different technique order get advantage survey focused hybrid r presented however deal role socialÔ¨Åltering technique become popular recent year social network neighborhoodbased cf recommendation popular beginning r herlocker et al provides set guideline designing neighborhoodbased prediction system adomavicius tuzhilin present view r Ô¨Åeld standing complex area see front matter elsevier bv right reserved httpdxdoiorgjknosys corresponding author tel fax email address jesusbobadillaupmes j bobadilla knowledgebased system content list available sciverse sciencedirect knowledgebased system journal homepage wwwelseviercomlocateknosys researcher r focus next generation r lim ited content overspecialization contentbased method coldstart sparsity cf method modelbased tech niques nonintrusiveness Ô¨Çexibility realtime customization etc researcher developing r different survey paper published summarizing important sue Ô¨Åeld view impossibility showing every de tail technique publication selects issue author felt suitable understand evolution r existing survey focus relevant method algorithm r Ô¨Åeld survey instead try enhance evolution r Ô¨Årst phase tradi tional web present second phase social web presently progressing third phase internet thing purpose useful new reader r Ô¨Åeld included survey traditional topic r foundation k nearest neighbor coldstart issue similarity measure evaluation r rest deal novel topic existing survey consider survey advanced reader r depth concept classiÔ¨Åcations approach related social informa tion social Ô¨Åltering follower followed trust reputation credi bility contentbased Ô¨Åltering social social tagging taxonomy recommending group user explaining recommendation reader interested brand new future application Ô¨Ånd survey useful since informs recent work locationaware r trend bioin spired approach also discover important issue privacy security pp internet thing use rfid health parameter surveillance teleopera tion telepresence etc according idea r tend make use different source collaborative social demographic content knowledgebased geographic sensor tag implicit explicit acquisition etc survey emphasizes hybrid architecture making recommendation different known tech nologies one designed behalf speciÔ¨Åc source much quality survey measured appro priate choice reference survey contains reference systematically obtained selected taking ac count factor like number recent citation impor tance journal published remainder article structured follows sec tion explain concisely methodology used select signiÔ¨Åcative paper r Ô¨Åeld section describes r foundation method algorithm model used provid ing recommendation tradi tional web rating demographic item cf demographic Ô¨Åltering contentbased Ô¨Åltering hybrid Ô¨Åltering section describes measure evaluating quality r prediction recommendation section show use cial web making recomendations concept like trust reputation credibility also de scribe technique contentbased social eg tag post section focusses two important area although well studied yet recommendation group user explanation recommendation section focusses recommender trend covering bioinspired approach web Ô¨Åltering locationaware r sec tion explains related work original contribution survey concluding section summarizes r history focus type used well development algorithm evaluation measure conclusion section also indicates seven new area consider likely focus r search scientiÔ¨Åc community near future methodology initial performed determine represen tative topic term r Ô¨Åeld first r paper se lected journal higher priority current oftencited article next extracted paper signiÔ¨Åcant term gave emphasis keywords less emphasis title Ô¨Ånally least emphasis abstract overlooked common word like article preposition generaluse word remaining pool selected term represented r Ô¨Åeld matrix arti cles word wherein stored importance word article generated tree relationship word fig depicts signiÔ¨Åcant section graph due space constraint entire tree shown pro vided additional material fig additionaldatapng short distance word indicate highest similarity warm color indicate greater reliability relationship size node indicates importance word function parameter n k n n number signiÔ¨Åcative word keywords title n k w n w n w number time word w appears keywords title equa tion used determine importance word w follows f w ¬º n k w n k √æ n w n log n n √æ n w n n n example consider n k keywords n word title n word length get value f factorization f matrix word factorization appears keyword title three time word matrix appear keyword contained title twice importance word f factorization ¬º √æ log √æ ¬º f matrix ¬º √æ log √æ ¬º depicted fig used identify relevant aspect r represented signiÔ¨Åcant word graph related term article referenced herein chosen following criterion tran scendence subject according importance word fig b historical contribution signiÔ¨Åcant fraction classic reference article included c number time article cited article published journal impact factor preferred conference workshop e cent article preferred article published many year ago fig show temporal distribution referenced paper use cluster word fig structure explica tions survey concept explained ob tained keywords word related according fig identiÔ¨Åed among set pa pers related set word associated concept selected subset paper deal concept giving priority high value crite ria like importance number cite tried balance number time referenced survey aiming reference paper selected j bobadilla et al knowledgebased system recommender system foundation section present relevant concept traditional r provide general description classical taxonomy algorithm method Ô¨Åltering ap proaches database etc besides show graphic depicting traditional model recommendation relation next describe coldstart problem illustrate difÔ¨Åculty making collaborative recommendation r contains small amount next describe k nn used implementing r cf finally describe different proposed similarity measure comparing user item show graphic measuring quality similarity measure fundamental process generating r recommendation combination following consideration type available database eg rating user reg istration feature content item ranked social relationship among user locationaware Ô¨Åltering used eg demographic contentbased collaborative socialbased contextaware hybrid chosen eg direct use memory generated modelbased employed technique also considered probabilistic approach bayesian network nearest neighbor bioinspired algorithm neural network genetic algorithm fuzzy model singular decomposition tech niques reduce sparsity level etc sparsity level database desired scalability performance time memory consuming objective sought considered eg prediction top n recommendation well desired quality result eg novelty coverage precision research r requires representative set public dat abases facilitate investigation technique method algorithm developed researcher Ô¨Åeld database scientiÔ¨Åc community replicate experiment validate improve technique list current public database referenced often literature lastfm delicious incorporate implicit rating social generated version released hetrec set hosted grouplens research group internal function r characterized Ô¨Åltering widely used classiÔ¨Åcation divide Ô¨Åltering algorithm collaborative Ô¨Åltering b demo graphic Ô¨Åltering c contentbased Ô¨Åltering hybrid Ô¨Åltering fig word represented recommender system research Ô¨Åeld short distance indicate higher similarity warm color indicates greater reliability size node proportional importance word fig temporal distribution referenced paper j bobadilla et al knowledgebased system contentbased Ô¨Åltering make recommendation user choice made past eg webbased ecom merce r user purchased Ô¨Åction Ô¨Ålms past r probably recommend recent Ô¨Åction Ô¨Ålm yet purchased website contentbased Ô¨Åltering also gener ate recommendation content object intended recommendation therefore certain content analyzed like text image sound similarity established object basis recommending item similar item user bought visited heard viewed ranked positively demographic Ô¨Åltering justiÔ¨Åed principle individual certain common personal attribute sex age country etc also common preference collaborative filtering allows user give rat ings set element eg video song Ô¨Ålms etc cf website way enough stored make recommendation user provided user consider common cf interesting open research Ô¨Åeld noted earlier user rating also often used memorybased recommender system public database without social social hosted grouplens movielens movielens netÔ¨Çix jester eachmovie bookcrossing ml lastfm delicious rating million million million million million million user item range implicit implicit tag na na na na na na tag assignment na na na na na na friend relation na na na na na na na item movie movie movie joke movie book movie music url fig traditional model recommendation relationship j bobadilla et al knowledgebased system implicitly acquired eg number time song heard informa tion consulted access resource widely used collaborative Ô¨Åltering k nearest neighbor knn user user version k nn executes following three task generate recommenda tions active user determine k user neighbor neighbor hood active user implement aggregation rating neighborhood item rated extract prediction step select top n recommendation hybrid Ô¨Åltering commonly us combination cf demographic Ô¨Åltering cf contentbased Ô¨Åltering exploit merit one technique hybrid Ô¨Åltering usually bioinspired probabilistic method genetic algorithm fuzzy genetic neural net work bayesian network clustering latent feature widely accepted taxonomy divide recommendation method memorybased modelbased category memorybased method memorybased method deÔ¨Åned method act matrix user rating item b use rating generated refer ral process ie result always updated memorybased method usually use similarity metric obtain distance tween two user two item ratio modelbased method use r create generates recommendation herein consider modelbased new user outdates among widely used model bayesian classiÔ¨Åers neural network fuzzy system genetic algorithm latent feature matrix factorization among others reduce problem high level sparsity r dat abases certain study used dimensionality reduction tech niques reduction method matrix factorization matrix factorization especially ade quate processing large r database providing scalable ap proaches modelbased technique latent semantic index lsi reduction singular decomposition svd typically combined svd method provide good prediction result computationally expensive deployed static offline setting known preference change time r use clustering technique improve prediction qual ity reduce coldstart problem applied hybrid Ô¨Ål tering typical form cluster item hybrid r different common us clustering item user biclustering r comprising social infor mation clustered improve following area tagging explicit social link explicit trust graph fig show signiÔ¨Åcant traditional meth od technique algorithm recommendation process well relationship grouping different section provide detail important aspect involved recommendation process may seen fig use traditional Ô¨Ål tering method contentbased demographic collaborative applied database modelbased technology genetic algo rithms neural network etc make use kind typical memorybased approach item item user user hybrid two previous main purpose mem orybased modelbased approach get accurate prediction taste user accuracy prediction may evaluated classical retrieval mea sures like mae precision recall researcher make use measure order improve r method technology coldstart coldstart problem occurs possible make reliable recommendation due initial lack rating distinguish three kind coldstart problem new com munity new item new user last kind important r already operation new community problem refers difÔ¨Åculty starting r obtaining sufÔ¨Åcient amount rating making reliable recommendation two common way used tackling problem encourage user make rating different mean take cfbased recom mendations enough user rating new item problem arises new item entered r usually initial rating therefore likely recommended turn item rec ommended go unnoticed large part community user unaware rate way enter vicious circle set item r left ratingsrecommendations process new item problem less impact r item dis covered via mean eg movie r ie ecommerce blog photo video etc common solution problem set motivated user responsible rating new item new user problem represents one great dif Ô¨Åculties faced r operation since new user r yet provided rating r receive personalized recommendation memorybased cf user enter Ô¨Årsts rating expect r offer personalized recommendation number rating introduced r usually yet sufÔ¨Åcient able make reliable cfbased recommendation therefore new user may feel r offer service expected may stop common strategy tackle new user problem consists turning additional set rating order able make recommendation available user coldstart problem often faced hybrid approach usually cfcontent r cfdemographic r cfsocial r leung et al vel contentbased hybrid make use crosslevel association rule integrate content domain item kim et al use collaborative tagging employed order grasp Ô¨Ålter user preference item explore advantage collaborative tagging sparseness coldstart user collected dataset crawling collaborative tagging delicious site weng et al combine implicit relation user item prefer ences additional taxonomic preference make better quality recommendation well alleviate coldstart prob lem loh et al represent user proÔ¨Åles ex tracted scientiÔ¨Åc publication martinez et al present hybrid r combine cf knowl edgebased one chen number common term term frequency ncttf cf demo graphic vector saranya atsuhiro hybrid r utilizes latent feature extracted item represented multiattributed record probabilistic park et al new use Ô¨Ålterbots surrogate user rate item user item attribute j bobadilla et al knowledgebased system k nearest neighbor recommendation k nearest neighbor k nn recommendation reference collaborative Ô¨Åltering recommendation process primary virtue simplicity reasonably accurate result major pitfall low scalability vulnerability sparsity r database section provides general expla nation function cf k nn conceptually simple straightforward implementation also generally produce good quality prediction recommendation however due high level sparsity r database similarity measure often encounter processing problem typically insufÔ¨Åcient mutual rating comparison user item cold start situation user item low number ranking another major problem k nn low scalabil ity database netÔ¨Çix increase size hun dreds thousand user ten thousand item hundred million ranking process generating neighborhood active user becomes slow similarity measure must processed often new user registered database item item version k nn sig niÔ¨Åcantly reduces scalability problem end neigh bors calculated item top n similarity value stored period time prediction recommendation generated stored although stored include rating previous process ingstorage outdated item less sensitive user recurrent theme cf research generating metric calcu late accuracy precision existing similarity user item traditionally series statistical metric used pearson correlation cosine constraint pearson correlation mean squared difference recently metric designed Ô¨Åt constraint peculiarity r relevance signiÔ¨Åcance concept introduced af ford importance relevant user item additionally group metric speciÔ¨Åcally designed ade quately function coldstart situation k nn similarity measure next sub section provides detail current r similarity mea sures similarity approach typically compute similarity two user x user user user item rating item item k nn version computes similarity tween two item j formal k nn may found section provide illustrative example algo rithm making recommendation following three step selected similarity measure produce set k neighbor active user k neighbor nearest k similar user u b set k user neighbor similar active calculated order obtain prediction item user one following aggregation approach often used average weighted sum adjusted weighted aggregation deviationfrommean c obtain top n recommendation choose n item provide satisfaction active user according prediction fig show user user k nn mechanism item item version k nn following three task executed determine q item neigh bors item database item ranked active user calculate prediction rating q neighbor select top n recommen dations active user typically n major prediction step executed periodically facilitates accel erated recommendation regard user user version item item user user version k nn combined take advantage positive aspect approach typically fused pro cessing similarity object similarity measure metric similarity measure sm determines similarity pair user user user cf similarity pair item item item cf purpose compare rating item rated two user user user rat ings user rated two item item item k nn essentially use traditional similarity metric statistical origin metric require source set vote made user item memorybased cf among commonly used traditional metric pearson correlation corr cosine co adjusted cosine acos constrained correlation ccorr mean squared difference msd euclidean euc describe compare representative group sm used k nn sm discussed include following variation coldstart general case b model c trust rating show classiÔ¨Åcation memorybased cf sm tested section new metric jmsd recently published side numerical rating via mean squared difference also us nonnumerical pro vided arrangement via jaccard ortega et al use pareto dominance perform preÔ¨Åltering process eliminating less representative user k neighbur selection process retaining promising one specialization memorybased cf sm appeared recently us contained vote user instead restricting rating two user com pared user user two item compared item item call sm sing singularity possibility exists create modelbased cf full set user rating order later determine similar ity pair user pair item cre ated potential advantage focus increase accuracy obtained performance time consuming achieved drawback must regularly dated order consider recently entered set rating fig user user k nn example k similarity measure mean squared difference aggregation average j bobadilla et al knowledgebased system bobadilla et al provides metric generated genetic algorithm call sm gen geneticbased increase web website internet set metric appeared use new social available friend follower followeds etc sm grouped paper related trust reputation credibility although situation also produced Ô¨Åelds metric could considered strictly mem orybased cf use additional r sense sm proposed tailored speciÔ¨Åc r small set r share structure social sm aim extract lated trust reputation user set rating memorybased cf advantage use general ized cf r drawback social ex tracted really poor call trust sm proponed jeong et al currently two new interesting sm get cov erage accuracy fig show result several evaluation measure gen erated applying sm discussed section result show rstailored sm superior compared tra ditional sm statistic processing memorybased infor mation result fig follow framework schematic published previously far research paper dealing coldstart prob lem user rating ahn present heu ristic sm named pip outperforms traditional statistical sm tested collaborative Ô¨Åltering similarity measure model modelbased trust extraction trust extraction traditional rating user item tailored coldstart user jmsd corr ccorr co acos msd euc gen tailored coldstart user pip uerror nc extended rating sing trust fig evaluation measure result obtained current similarity measure movielens database prediction result b recommendation result c novelty result trust result j bobadilla et al knowledgebased system pearson correlation cosine etc heungnam et al proposes uerror predicts Ô¨Årst actual rating subsequently identiÔ¨Åes prediction error user taking account er ror speciÔ¨Åc errorreÔ¨Çected model de signed bobadilla et al present metric neural learning modelbased cf adapted new user coldstart situ ations called nc fig show result several evaluation measure gener ated applying coldstart sm presented section result show rstailored sm superior compared traditional sm statistic since database movielens take account coldstart user removed rat ings database order achieve coldstart user indeed removed randomly rating user rated item way regard user rate item coldstart user evaluation recommender system result since r research began evaluation prediction recom mendations become important research r Ô¨Åeld requires quality measure evaluation metric know quality technique method algorithm predic tions recommendation evaluation metric evalua tion framework facilitate comparison several solution problem selection different promising line research generate better result evaluation measure r recommendation gradually tested improved representative set existing evaluation measure standard formulation group open r public database generated two advance facilitated quality comparison new proposed recommendation method previously published method thus r method algorithm research progressed continuously commonly used quality measure following prediction evaluation evaluation recommen dation set evaluation recommendation ranked list fig show result applying several evaluation mea sures set representative similarity measure evaluation metric classiÔ¨Åed predic tion metric accuracy one mean absolute error mae root mean square error rmse normalized mean average error nmae coverage b set recommendation metric precision recall receiver operating characteristic roc c rank recommendation metric halflife discounted cumulative gain diversity met rics diversity novelty recommended item validation process performed employing common cross validation technique random subsam pling kfold cross validation coldstart situation due limited number user item vote involved usual chosen carry experiment leaveone cross validation hern√°ndez gaudioso evaluation process distinction interactive noninteractive fig evaluation result obtained current coldstart similarity measure prediction result b recommendation result c novelty result trust result j bobadilla et al knowledgebased system subsystem general publication review also exist clude commonly accepted evaluation measure mean absolute error coverage precision recall derivative mean squared error normalized mean absolute error roc fallout goldberg et al focus aspect related eval uation breese et al compare predictive accuracy vari ous method set representative problem domain majority article discus attempted improvement accuracy r result rmse mae etc also common tempt improvement recommendation precision recall roc etc however additional objective considered generating greater user satisfaction topic diversi Ô¨Åcation coverage serendipity currently Ô¨Åeld growing interest generating algo rithms diverse innovative recommendation even expense accuracy precision evaluate aspect various metric proposed measure recommendation novelty diversity framework aid deÔ¨Åning standardizing method algorithm employed r well mechanism eval uate quality result among signiÔ¨Åcant paper cf framework herlocker et al evaluates following similarity weight signiÔ¨Åcance weighting variance weighting selecting neighborhood rating normaliza tion hern√°ndez gaudioso proposes framework r formed two different subsystem one guide user provide usefulinteresting item koutrika et al framework introduces level abstraction cf process making modiÔ¨Åcations r Ô¨Çexible antunes et al present evaluation framework assuming evaluation evolving process lifecicle majority r evaluation framework proposed present two deÔ¨Åciencies Ô¨Årst lack formal ization although evaluation metric well deÔ¨Åned variety detail implementation method event speciÔ¨Åed lead generation different result similar experiment second deÔ¨Åciency absence standardization evalu ation measure aspect novelty trust recommendation bobadilla et al provides complete series mathematical formalization set theory author provide set eval uation measure include quality follow ing aspect prediction recommendation novelty trust presented next representative selection r evaluation quality measure often used bibliography quality prediction mean absolute error accuracy coverage order measure accuracy result r usual use calculation common predic tion error metric amongst mean absolute error mae related metric mean squared error root mean squared error normalized mean absolute error stand deÔ¨Åne u set r user set r item r u rating user u item lack rating r u mean user u rated item p u prediction item user u let u j p u r u set item rated user u hav ing prediction value deÔ¨Åne mae rmse average user mae remark absolute dif ference prediction real j p u r u j informs error prediction mae ¬º u x u u u x u j p u r u j √∞ √æ rmse ¬º u x u u Ô¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨É u x u √∞ p u r u √æ √∞ √æ coverage could deÔ¨Åned capacity predicting metric applied speciÔ¨Åc r short calculates percent age situation least one k neighbor active user rate item rated yet active user deÔ¨Åned k u set neighbor u rated item deÔ¨Åne coverage average user coverage let c u ¬º f j r u ¬º k u g u ¬º f j r u ¬º g co v erage ¬º u x u u c u u √∞ √æ quality set recommendation precision recall f conÔ¨Ådence user certain r depend directly accuracy set possible prediction user gain conÔ¨Ådence r user agrees reduced set recommendation made r section deÔ¨Åne following three widely used recommendation quality measure precision indicates proportion relevant recommended item total number recommended item recall indicates pro portion relevant recommended item number rele vant item f combination precision recall let x u set recommendation user u z u set n recommendation user u represent evaluation precision recall f measure recommendation obtained making n test recommendation user u taking h rele vancy threshold assuming user accept n test recommendation precision ¬º u x u u f z u j r u p h g n √∞ √æ recall ¬º u x u u f z u j r u p h g f z u j r u p h g √æ z c u r u p h √∞ √æ f ¬º precision recall precision √æ recall √∞ √æ quality list recommendation rank measure number n recommended item small user give greater importance Ô¨Årst item list recommen dations mistake incurred item serious er rors last item list ranking measure consider situation among ranking measure often used following standard retrieval measure halflife assumes exponential decrease interest user move away recommenda tions top b discounted cumulative gain wherein decay logarithmic hl ¬º u x u u x n ¬º max √∞ r u p √æ √∞ √æ √∞ √æ √∞ √æ dcg k ¬º u x u u r u p √æ x k ¬º r u p log √∞ √æ √∞ √æ j bobadilla et al knowledgebased system p p n represents recommendation list r u pi represents true rating user u item p k rank eval uated item default rating number item list chance user review item novelty diversity novelty evaluation measure indicates degree differ ence item recommended known user diversity quality measure indicates degree differentia tion among recommended item currently novelty diversity measure stan dard therefore different author different metric certain author used following di v ersity z u ¬º z u √∞ z u √æ x z u x j z u j ¬Ω sim √∞ j √æ √∞ √æ v elty ¬º z u x j z u ¬Ω sim √∞ j √æ z u √∞ √æ sim j indicates item item memorybased cf similar ity measure z u indicates set n recommendation user u stability stability prediction recommendation inÔ¨Çu ences user trust towards r r stable pre dicitions provides change strongly short period time adomavicius zhang quality measure stability ma mean absolute shift measure deÔ¨Åned set known rating r set prediction un known rating p interval time user r rated subset unknown rating r make new prediction p ma deÔ¨Åned follows stability ¬º ma ¬º j p j x √∞ u √æ p j p √∞ u √æ p √∞ u √æj √∞ √æ reliability reliability prediction recommendation informs seriously may consider prediction r recommends item user prediction scale user hope satisÔ¨Åed item however prediction reÔ¨Çect certain degree r concluded user like item indeed prediction much reli able obtained mean similar user obtained two similar user hernando et al realibility measure proposed accord ing usual notion reliable prediction less lia ble wrong although reliability measure quality measure used comparing different technique r cross validation regarded quality measure associ ated prediction recommendation way r pro vides pair value prediction reliability user may balance preference example user would probably prefer option option conse quently reliability measure proposed hernando et al provides new understandable factor user may consider taking decision nevertheless use reliability measure constrained r k nn deÔ¨Ånition reliability prediction p u two numeric factor u v u u measure similar ity neighbor used making prediction p u v u measure degree disagreement neighbor rating item finally reliablity measure deÔ¨Åned follows f √∞ u √æ ¬º √æ u u ¬º x v k u sim √∞ u v √æ √∞ √æ f √∞ u √æ ¬º √æ u u ¬º x v k u sim √∞ u v √æ √∞ √æ fig recommender system evaluation process j bobadilla et al knowledgebased system f v √∞ v u √æ ¬º max min v u max min ln ln max min v max min v u ¬º p v k u sim √∞ u v √æ√∞ r v r v p u √æ r u √æ p v k u sim √∞ u v √æ √∞ √æ v respectively median value u v u speciÔ¨Åc r k u set neighbor u rated item min max discrete range rating value fig show general mechanism cross validation used generate quality result form evaluation measure base divided training test area user item Ô¨Årst phase top left side k neighbor calculated active user active user selected set test user k neighbor selected set training user aggregation phase top right side prediction calculated active user set test item final ly evaluation metric used compare prediction rec ommendations obtained real rating user accurate prediction recommendation better quality proposed recommendation social web developed r increasingly incorpo rated social eg trusted untrusted user fol lowed follower friend list post blog tag new contextual improves r social improves sparsity problem inherent memory r social reinforces traditional mem orybased user rating user connected net work trust exhibit signiÔ¨Åcantly higher similarity item metadata nonconnected user social used researcher three primary objective improve quality prediction recom mendations b generate new r c elucidate signiÔ¨Åcant relationship social collaborative process trust reputation important area research r area closely related social currently cluded r common approach generating trust reputation measurement following user trust calculate credibility user explicit informa tion rest user calculate credibility user implicit obtained social network b item trust calculate reputation item feedback user calculate reputation item studying user work item social r Ô¨Åeld user introduce label associated item set triple h user item tag form space referred folksonomies fundamentally folksonomies used following two way create tag recommendation sys tems r tag enrich recom mendation process tag contentbased Ô¨Åltering recently become important due surge social network r show clear trend allow user introduce content comment critique rating opinion label well establish social relation ship link eg followed follower like user dislike user additional increase accuracy prediction recommendation generated variety research arti cles kim et al zheng li carrerneto et al rest section deal dealt concept search two line considered previously filtering social content Ô¨Åltering social filtering social gathered explicitly implicitly identiÔ¨Åcation community network afÔ¨Ånity network individual user generate eg communication web log even rating user possible improve r result creating implicit social networking implicit explicit source combined generate recommenda tions explicit social used via trustbased cf order improve quality recommendation trust infor mation generated used different approach trust propagation mechanism follow leader personalitybased similarity measure trust network distrust dynamic trust ant colony metaphor research work us social applied r aim obtain improvement recommendation made referring extra provided social infor mation used among relevant current work us woerndl groh use social net work enhance collaborative Ô¨Åltering evaluation show social recommender outperforms traditional collaborative Ô¨Åltering algorithm used scenario arazy et al improve accuracy online social network electronic communication tool xin et al improving r exploiting learner note taking activity maintain note feature exploited collabora tive learning system order enrich extend user proÔ¨Åle improve personalized learning bonhard sasse search shown relationship adviceseeker recommender extremely important way indicating social closeness taste overlap required thus suggest drawing similarity familiarity user person rated item aid judgment decision making fengkun hong developed way increase rec ommendation effectiveness incorporating social network infor mation cf collected user preference rating social network relationship social networking web site evaluated cf performance diverse neigh bor group combining group friend nearest neighbor carmagnola et al state joining network people expose individual social dynamic inÔ¨Çuence attitude behavior preference present sonar recommending content social r sonar tar get user member social network suggesting item Ô¨Çect trend network structure inÔ¨Çuence relationship among user ramaswamy et al design social network r incorporates three feature complement derive highly targeted ad first analyze customer address book estimate level social afÔ¨Ånity among various user social afÔ¨Ånity used identify recommendation sent individual user another group research work us social cre ate enable r aim improve result particular r operation aim make possible r still exist exist social siersdorfer sergei objective construct social recommender system predict utility item user group multidimensional social environment given user mining rich set structure social relationship provides folksonomies li chen blog recommenda tion mechanism combine trust social relation j bobadilla et al knowledgebased system semantic illustrates applied presti gious online blogging jason research project applied discover social network tween mobile user collecting dataset two million user argue social network applicable generate contextbased recommendation service jyun chui pa per us trading relationship calculate level recommendation trusted online auction seller demonstrate network structure formed transactional history used expose underlying opportunistic collusive seller behavior dellamico capra user trustworthiness mea sured according one following two criterion taste similar ity ie trust agree social tie ie trust friend people friend trust argue order trusted user must well intentioned competent observation novel call social Ô¨Åltering third group work provides foundation research discover signiÔ¨Åcant relationship social informa tion collaborative process without creating proposing improving particular r research move higher level abstraction aim establishing base general prin ciples bonhard explains qualitative research con ducted date shown relationship recommender recommendee signiÔ¨Åcant impact deci sionmaking hossain fazio present exploring connection social network collaborative process focus exploring academic network position effect collaborative network deÔ¨Åning network position way develop social network us academic node within network instead published esslimani et al present new cf behavioral network us navigational pattern relationship user exploit social network tech niques golbeck kuter present experimental several type trust inference algorithm answer following question trust change far single change prop agate network large impact change relate type inference experimental result provide insight algorithm suitable certain application research Ô¨Åeld trust reputation could provide suitable starting point create social interaction among user r however relevant work subject limited use trust relationship improve quality rec ommendation service odonovan book chapter examines diversity source trust har nessed within social web application discusses high level classiÔ¨Åcation source shown harnessing creased amount upon make trust decision greatly enhances user experience social web applica tion massa avesani explain r making use trust effective term accuracy pre serving good coverage especially evident user provided rating yuan et al choose trust aware r example demonstrate advantage making use veriÔ¨Åed smallworld nature trust network li kao present r trust social network trust computing quality veracity peer produc tion service appropriately assessed experimental sults show proposed r signiÔ¨Åcantly enhance quality peer production service classiÔ¨Åes current approach address user credi bility item reputation socialbased r cf Ô¨Åeld trust user used make prediction weighting trust value say trust user important rating making prediction et al probabilistic factor framework combining rating trusted friend framework applied pure useritem rating matrix contentbased Ô¨Åltering contentbased Ô¨Åltering cbf try recommend item active user similar rated positively past concept item similar attribute rated sim ilarly example user like web page word car engine gasoline cbf recommend page related automotive world cbf becoming especially important r incorporate infor mation item user working web environment tag post opinion multimedia material two challenging problem contentbased Ô¨Åltering lim ited content overspecialization Ô¨Årst problem arises difÔ¨Åculty extracting reliable automated informa tion various content eg image video audio text greatly reduce quality recommendation sec ond problem overspecialization refers phenomenon user receive recommendation item similar item liked preferred therefore user receiving recommendation item might like unknown eg user receives recommendation Ô¨Åction Ô¨Ålms recommendation evaluated novelty cbf operate attribute item wish recom mend must extracted typically set attribute man ually deÔ¨Åned item depending domain certain instance desired recommend textual infor mation classic retrieval technique must used automatically deÔ¨Åne attribute eg term frequency inverse document frequency normalization page length fig show cbf mechanism includes following step extract attribute item recommendation compare attribute item preference active state art trust reputation user trust item trust explicit trust system credibility user calculated explicit rest user service pp usually implement technique reputation item calculated mean feedback user asked opinion ecommerce service often use technique implicit trust system credibility user calculated implicit obtained social network reputation item calculated studying user work item example number time song played memory trust credibility measure calculated taking account user rating j bobadilla et al knowledgebased system user recommend item characteristic Ô¨Åt user interest attribute item user proÔ¨Åles known key purpose cbf determine whether user like speciÔ¨Åc item task resolved traditionally heuristic method classiÔ¨Åcation algorithm u rule induction nearest neighbor method rocchios linear classiÔ¨Åers probabilistic method pure cbf several shortcoming certain domain eg music blog video complicated task generate attribute item b cbf suffers overspecialization problem nature tends recommend type item c difÔ¨Åcult acquire feedback user cbf user typically rate item cf therefore possible determine whether recommendation correct shortcoming rare Ô¨Ånd pure cbf implementation common use hybrid cbfcf burke cf solves cbfs problem function domain less affected overspecialization ac quire feedback user cbf add following quality cf improvement quality prediction calculated reduced impact coldstart sparsity problem cbf cf combined different way fig show different alternative fig show method calculate cbf cf recom mendations separately subsequently combine claypool et al use weighted average combining cbf cf prediction depending type prediction another pazzani proposes combining cbf cf recom mendation list assigning item score according position list additionally billsus pazzani tran cohen select cbf cf prediction accordance quality fig b depicts method incorporate cbf characteristic cf balabanovic shoham maintain user proÔ¨Åles content directly compare pro Ô¨Åles determine similar user cf recommendation good et al construct specialized Ô¨Ålterbots cbf technique later act neighbor cf stage melville et al add prediction cbf ratting matrix employed cf li modiÔ¨Åes ratting matrix input cf combining another matrix generated clustering item according attribute hu pu author incorporate personality characteristic cf similarity measure minimize newuser problem fig c illustrates method construct uniÔ¨Åed cbf cf characteristic basu et al cbf cf characteristic single rulebased classiÔ¨Åer popescul et al schein et al prob ability model combine cbf cf recommendation study author employ bayesian network combine cbf cf characteristic generate accu rate recommendation burke middleton et al knowledgebased technique solve cold start problem fig show method incorporate cf characteristic cbf soboroff nicholas author use lsi create user proÔ¨Åles used cbf recommendation beginning cf ratting matrix mooney roy use cf prediction input cbf current trend cbf add social item attribute tag comment opinion social net work sharing social tagging system popular allow user annotate online resource arbitrary label produce rich space folksonomies new component opened novel line r research di vided two category tag recommendation system use tag recommendation process r tag attempt provide personalized item recommenda tions user representative tag j√§chke et al author compare different mecha nisms tag recommendation marinho schmidtthi eme improve tag recommendation applying classic recommendation method additionally landia anand combine clustering cbf cf suggest new tag user method tag recommendation process increase capacity traditional r tsosutter et al generic allows tag incor porated standard cf algorithm bogers van den bosh examine incorporate tag metada ta hybrid cbfcf replacing tradi tional userbased itembased similarity measure tag overlap gemmell et al weighted hybrid recommender wherein combine graphbased tag recommendation userbased cf itembased cf gedikli jannach use tag mean express feature item user particularly like dislike gemmell et al author offer hybrid r wherein predict user preference item consulting user tagging history additional recommender system objective commercial r compete market offering best con tent quality recommendation well greatest variety service recommendation user group facilitate joint recommendation user group eg group four friend wish choose movie cf four design approach offer opportunity action acting similarity measure stage acquiring neighbor acquiring prediction generating recommendation research result indicate quality recommendation vary greatly different approach execution time dramatically reduced advance used design similarity measure group efÔ¨Åcient solution r generated recommendation valuable user must explained well simple compelling accurate manner recommendation explanation Ô¨Åeld investi gated new development r tradi tionally explanation type divided following category human style user user b item style item item c feature style item feature hybrid also employ use conversational technique incorporates geosocial recommending group user r consider group user starting expand used different area tourism music tv web given speciÔ¨Åc characteristic recommendation group appropriate establish consensus different j bobadilla et al knowledgebased system group semantics formalize agreement disagreement among user aim presenting work carried date structured way provide classiÔ¨Åcation recommendation group cf r fig graphically illustrates four basic lev el act order unify group user objective obtaining group user sim ilarity metric establishing neighborhood prediction phase determination recommended item fig individual member group represented left grey graticule represents matrix rating user horizontal item vertical graph show four representative case tackling solution recommenda tion group one matrix left Ô¨Ågure circle show key indicate cf process phase uniÔ¨Åcation performed n user group Ô¨Årst top graph uniÔ¨Åcation performed prediction phase cf process n individual prediction n user group combined one prediction group prediction aggregation used berkovsky freyne garc√≠a et al christen sen schiafÔ¨Åno second act set neighbor group user unifying one neighborhood whole group studied bobadilla et al proposing intersection large number k neighbor user group third recommendation obtained indi vidual user group merged one recommendation group baltrunas et al use rank aggregation individual list recommendation fourth us similarity metric act directly set rating group user solution one directly provides set neighbor group user exists prior previous case pro pose frontend incorporation process estimation missing dealing incomplete fuzzy lin guistic preference relation explaining recommendation important research subject r Ô¨Åeld focus provid ing explanation justify recommendation user ceived important aspect r aid maintaining higher degree user conÔ¨Ådence result gen erated type explanation used thus far classiÔ¨Åed fol low human style explanation user user example recommend movie liked user rated movie j k positively j k movie rated well active user item style explanation item item example recommend vacation destination liked vacation destination g c r g c r vacation destina tions similar rated well active user feature style explanation recommended item feature example recommend movie directed director feature actor b belongs genre g b g feature active user interested hybrid method category primarily includes following humanitem humanfeature featureitem humanfeature item additionally geosocial r foursquare google latitude etc location exists must used recommenda tion explanation mechanism geosocial r typically adopt hybrid humanitem explanation social location memorybased reference publication helpful r explanation research Ô¨Åeld published previously explore utility explanation cf r stated three key research question model technique effective supporting explanation explanation facil ities increase acceptance cf r explanation facility increase Ô¨Åltering performance cf r user answer Ô¨Årst question rating histogram indica tions past performance comparison similar rated item use domain speciÔ¨Åc content feature result experiment conducted r user support afÔ¨Årmative sponse second question third question unanswered fig contentbased Ô¨Åltering mechanism fig different alternative combining cf cbf j bobadilla et al knowledgebased system user perform Ô¨Åltering many different channel input dynamic favor mechanism r expla nation includes conversational technique ccbr conversational casebase reasoning explained mcsherry ccbr use incremental nearest neighbor process pareto dominance different dynamic also adopted employ differ ent perspective instead attempting justify particular recom mendation focus explanation help user understand recommendation opportunity remain current recommendation meet requirement generate compound critique explanation user opportunity accept critique recommendation cri tique recommendation critique act Ô¨Ålter remaining recommendation separate author differentiate con cepts promotion increasing acceptance recommended item satisfaction user satisfaction recommended item also produced better result keyword style explanation content compared neighbor style explanation human style explanation author new classiÔ¨Åcation recommendation justiÔ¨Åcations keyword style explanation contentbased r neighbor style explana tion collaborative Ô¨Åltering r inÔ¨Çuence style explanation tell user interaction r inÔ¨Çuences recommendation tintarev masthoff describe advantage making justiÔ¨Åcations recommendation trans parency scutability trustworthiness effectiveness persuasive ness efÔ¨Åciency satisfaction billus pazzani recommendation news provides keyword style justiÔ¨Åcations recom mendations weight used obtaining recom mendations wang et al describe justiÔ¨Åcations feature user preference tintarnev masthoff design recommedation Ô¨Ålms whose recommen dations justiÔ¨Åed feature vig et al mechanism justifying recommendation called tagsplanations community tag trangsplanations two key component tag relevance degree tag describes item tag preference user sentiment toward tag fahri provides framework organizing justiÔ¨Åcations used categorize explanation categorization discourse explicative theoretical pragmatic ethical moral legal aesthetic personal although theoretical framework used research literature used de sign new type explanation hernando et al present vel explanation technique visualization tree item tree provide valuable reliabil ity recommendation importance rating user made relevant investigation produce justiÔ¨Åcations recommender system include wherein author design new organization interface result grouped according tradeoff property developed trust recommender agent pareto excluding dominated category symeonidis et al Ô¨Årst con struct feature proÔ¨Åle user reveal favorite feature later group user biclusters exploit partial matching de preference group user group item additionally metric measure quality justi Ô¨Åcations explain coverage ratio symeonidis et al use prototype moviexplain put test research showed symeonidis et al hu et al use im plicit feedback derive estimate user preference like dislike item user conÔ¨Ådence useritem pair recommender system trend evolution existing r research paper Ô¨Åeld clear tendency collect integrate different type trend parallel evolution web deÔ¨Åne following three primary stage genesis web r used explicit rat ings user well demographic con tentbased included r owner web addition r collect use social fig classiÔ¨Åcation recommendation group cf r Ô¨Ågure represents four representative case approaching solution group recommendation j bobadilla et al knowledgebased system friend follower followed trusted untrusted simultaneously user aid collaborative inclusion blog tag comment photo video web internet thing contextaware informa tion variety device sensor incorporated currently geographic included expected trend gradual incorporation radio frequency identiÔ¨Åcation rfid sur veillance online health parameter food shopping habit well teleoperation telepresence contextaware recommender system focus additional contextual time location wireless sensor network contextual obtained explic itly implicitly mining mixture meth od hybrid currently mobile application increasingly use geographic enables geographic r considered locationaware r geographic r recommendation typically generated consider ing geographical position user receives recommendation section provides concept gaining popularity r research Ô¨Åeld internet thing pri vacy preservation shilling attack new framework etc provide novel classiÔ¨Åcation analyzing r concept next deal research loca tionaware r may regarded Ô¨Årst step future r web finally describe signiÔ¨Åca tive result promising research Ô¨Åeld r bioin spired model clear trend towards collection implicit instead traditional explicit evaluation item rating lastfm good example situation user rating ferred number time heard song applied number everyday situation access web address use various public transport sys tems food purchased access sport facility access learn ing resource incorporation implicit daily habit user allows r use variety used future cf process increasingly useful accurate privacy security consideration increasingly important widespread trend consent device sen sors internet thing privacy important issue r system contain large number registered user pri vacy preservation r certain level uncertainty must intro duced prediction primarily tradeoff accuracy privacy furthermore privacy preserved different r company share com bining privacy becomes important r increasingly incorporate social r often used electronic commerce unscrupulous producer may Ô¨Ånd proÔ¨Åtable shill r lying system order product recommended often competitor r experience shilling attack generate many positive rating product product competitor receive negative rating r still highly vul nerable attack knowledgebased Ô¨Åltering emerging important Ô¨Åeld r knowledge r use knowledge user product pursue knowledgebased generating recommenda tions reasoning product meet user requeri ments recommendation inference user need preference user model knowledge struc tures query preferred feature por product case casebased reasoning constraint constraintbased reason ing ontology matching metric knowledge vec tor social knowledge workÔ¨Çow current knowledge Ô¨Åeld user usersrolestasks reference describes member play role fulÔ¨Ålls task peertopeer pp network current knowl edge Ô¨Åeld user distributed existing peer set peer may need gradual incorporation different type eg ex plicit rating social relation user content location use trend knowledgebased forced r use hybrid ap proaches memorybased social locationaware method algorithm consolidated evolution r dem onstrates clear trend toward combining existing collaborative method latest research cf Ô¨Åeld generated modest improvement prediction recommendation single type eg used user rating social relation item content sults improve several algorithm combined respective type growing number publication ad dress hybrid approach use current database simulta neously incorporate memorybased social contentbased unify concept fig provides original taxon omy r taxonomy classiÔ¨Åed depending nature rather according method algorithm used core taxonomy focus classiÔ¨Åcation three factor target user item mode acquisition explicit ie rating item made user impli cit eg number time user heard song informa tion level memory content social context fig show recommender method algorithm la beled collaborative Ô¨Åltering algorithm depending type r database adopts hybrid Ô¨Åltering hybrid use appropriate subset algorithm consider processing existing coor dinated manner future development include different rec ommendation framework address common situation framework allow r incorporate cf kernel appropriate recommendation method available simple straightforward manner higher level prediction recommendation fig incorporates current evaluation quality measure diversity novelty importance measure measure developed future grow user demand novel stable less predictable recommendation locationaware recommender system due increasing use mobile device locationaware sys tems becoming widespread system show ten dency towards consolidation web service naturally lead locationaware cf locationaware r called geographic cf geographic r introduce classiÔ¨Åcation geographic cf r focus relevant section classiÔ¨Åcation obtained establishes different possibility tackling geographic r according nature rating made rating stage recommendation process followed recommendation stage user indicates rating andor recommendation made without user geographic gi j bobadilla et al knowledgebased system similarly item indicates rating andor recommendation made without item gi case la beled user g item g gi used case identiÔ¨Åed r traditional r rating recommendation made without geographical r g traditional r also contributes item geo graphical position r regarded geographic r gi play part recommendation process grs group geographic r likely become pop ular near future rating made traditional way whilst recommendation made considering geo graphical position user recommendation made representative example r restau rant user rate restaurant diverse concept include distance time voting user restaurant however user geographic r expects restaurant recommended good rating similar user k neighbor also according distance current position restaurant possible example r cinema pub supermarket cultural activity city lan guage learning center gym sport club etc grs user establish rating item weighting distance item rated type geographic r two possibility established hybrid cfdemographic Ô¨Åltering item accepts max imum one vote per user geographical posi tion issued associated geographic r item accepts one rat ing user depending geographical position rating made hybrid r respond regional national geo graphical approach recommendation established according weighting similarity vote cf origin type grs may regarded extended hybrid cfdemographic Ô¨Åltering gi given vote instead user theoretical point view type grs com plete however practical point view involve semantic difÔ¨Åculty item rating process make use difÔ¨Åcult rating item grs involves user rate item according relative distance user item way user rate restaurant home differently would rate workplace distance different rating also likely mental process would something like km restaurant rate positively travelling km go restaurant think good time user work km away restau rant could cast vote indicating consider po sitive travel km go restaurant even think good summary grs advantage accept wider variety rating also contain relative impor tance user give item according distance quired access disadvantage difÔ¨Åcult involve user particularly complex demanding rating process subsection focus grstype geographic cf r present publication regarding gibased r due great extent lack public database include rating geographic position capable combined r publication focus closely Ô¨Åeld follows martinez et al biukaghai et al example r g group schlieder novel modeling collaborative semantics geographic folksono mies multiobject tagging tag user assign composite object concept group people share common geospatial feature dictionary including deÔ¨Ånitions feature relationship common metadata schema wanshiou et al considered hybrid content basedgeographic r core hybrid content basedgeographic recommendation mechanism analyzes customer history position vendor ranked according match preference customer matyas schlieder show collaborative could situate r grs user rating taken photo downloaded web photo uploaded web photo gps address associated search k neighborhood carried recommendation process take account user position possible collect travel gps trace user use database generate recommendation travel gps trace reinforced social friend paper classiÔ¨Åed grs bioinspired approach much proposed modelbased r bioin spired approach primarily use genetic algorithm gas neural network nns model also proposed artiÔ¨Åcial immune network ains ga heuristic approach evolutionary principle natural selection survival Ô¨Åtest ga mainly used two aspect r clustering hybrid user model common technique improve fea tures r consists initially carrying clustering user way group class similar user obtained desired cf technique applied cluster obtaining similar result much shorter calculation time usual use common genetic clustering algorithm gabased k mean r hybrid user model commonly use combination cf demographic Ô¨Åltering cf content Ô¨Åltering exploit merit one technique case chromosome structure easily contain demographic charac teristics andor related contentbased Ô¨Åltering order tackle locationbased advertisement dao et al modelbased cf ga combine user preference interaction context bobadilla et al use ga create similarity metric weighting set simple similar ity measure hwang et al employ ga learn personal preference customer nn observed behavior biological neu ron intended simulate way brain process enables computer learn certain degree nn typically consists number interconnected node handle designated sphere knowledge several input network input get node learn relationship set pattern upon operational feedback molded pattern required generate required result j bobadilla et al knowledgebased system r relevant research available nn usually fo cuses hybrid r nn used learn user proÔ¨Åles nn also used clustering process r hybrid approach enable nn act additional infor mation rating ren et al hybrid rec ommender employ widrowhoff learn user proÔ¨Åle content rated item improves granularity user proÔ¨Åling christakou stafylopatis use combination contentbased cf order construct provides precise recom mendations concerning movie lee woo Ô¨Årst user segmented demographic characteristic user fig recommender system taxonomy j bobadilla et al knowledgebased system segment clustered according preference item selforganizing map som nn kohonons som type unsupervised learning goal discover underlying structure two alternative nn us presented huang et al roh et al Ô¨Årst author use training back propagation nn generating association rule mined transactional database second author pro pose combine cf two machine learning process som reasoning cbr changing unsupervised clustering problem supervised user preference reasoning problem neurofuzzy inference used sevarac et al create pedagogical rule elearning new coldstart similarity measure perfected bobadilla et al optimiza tion neural learning artiÔ¨Åcial immune system distributed adaptive system model principle derived form human immune defence protect body infection order tackle r sparsity problem make algorithm scalable acilar arslan pres ent new cf ainet previously proposed general recommendation rec ommend web site related work original contribution cf become complex different survey paper published area schafer et al introduces core concept cf theory practice rating system acquisition evaluation interaction interface privacy sue candillier et al review main cf Ô¨Åltering method compare result su khoshgoftaar present survey cf technique author introduce theory cf concisely deal main challenge sparsity scalability synonymy gray sheep shil ling attack privacy etc also expose overview cf technique park et al review paper r classiÔ¨Åes year journal publication application Ô¨Åelds mining technique additionaly categorized pa pers eight application Ô¨Åelds Ô¨Ålms music etc review r algorithm presented fo cuses explaining carefully used algorithm r work present also basic concept cf evaluation metric dimensionality reduction technique diffu sionbased method social Ô¨Åltering meta approach survey try include novel issue dealt carefully previous paper next stand outstanding feature survey us methodology selecting suitable paper r standing latest cited paper area r provides updated overview used r public database including tag friend relation study coldstart problem inherent r present novel overview informing classical similarity measure recently pro posed includes tailored metric coldstart user generalpurpose metric besides show quality measure obtained evaluating metric includes recent quality measurement beyond accuracy evaluate r novelty diversity stability additionaly include reliability measure associated prediction recommendation provides comprehensive survey social Ô¨Åltering presenting novel overview trust reputation credibility introduces contentbased Ô¨Åltering modern perspec tive standing application dealing social informa tion social tagging present summary relevant contribution r group user show novel classiÔ¨Åcation existing method deal fast growing r Ô¨Åeld locationaware r geographic section estructured help novel geographic r classiÔ¨Åcation summarizes relevant contribution use bio inspired approach describes r trend implicitally collect specially derived use internet thing provides r taxonomy classifying r three factor source traditional web social web internet thingsweb target user item extracting explicit implicit conclusion recommender system proving useful tool addressing portion overload phenomenon internet evolution accompanied evolution web Ô¨Årst generation recommender system used tradi tional website collect following three source contentbased purchased used product b demographic collected user record c mem orybased collected user item preference second generation recommender system extensively use web gathering social eg friend follower followed trusted user untrusted user third generation recom mender system use web pro vided integrated device internet use location already incorporated many recommender system followed device sensor widely used eg realtime health signal rfid food habit online local weather parameter temperature pressure Ô¨Årsts recommender system focused improving recommendation accuracy Ô¨Åltering memorybased method algorithm developed optimized context eg k nn metric aggregation approach singular decomposition diffusionbased method etc stage hybrid approach primarily collaborativedemographic collabora tivecontent Ô¨Åltering improved quality recommenda tions second stage algorithm included social previous hybrid approach adapted developed eg trustaware algorithm social adaptive ap proaches social network etc currently hybrid ensemble algorithm incorporate location exist ing recommendation algorithm evaluation prediction recommendation evolved since origin recommender system weighted prediction error accuracy heavily also recognized geographic collaborative Ô¨Åltering recommender system classiÔ¨Åcation rating stage recommendation stage user gi item item g item item g user rsgrs r r g user g grs grsgrs yes item gi yes yes j bobadilla et al knowledgebased system convenience evaluating quality top n recommenda tions set evaluation top n recommendation ranked list incorporated currently tendency assess new evaluation measure diversity novelty future research concentrate advancing existing method algorithm improve quality recommender system prediction recommendation simultaneously new line research developed Ô¨Åelds aim proper combination existing recommendation method use different type available get maximum use individual potential various sensor device internet thing acquisition integration trend related habit consumption taste individ ual user recommendation process mining r database nonrecommendation us eg market research general trend visualization differential characteristic demo graphic group enabling security privacy recom mender system process new evaluation measure developing standard nonstandardized evaluation measure designing Ô¨Çexible framework automated heterogeneous reference abbar bouzeghoub lopez contextaware recommender system service oriented proceeding rd international workshop personalized access proÔ¨Åle management context awareness database acilar arslan collaborative Ô¨Åltering artiÔ¨Åcial immune network expert system application g adomavicius tuzhilin toward next generation recommender system survey stateoftheart possible extension ieee transaction knowledge engineering g adomavicius j zhang stability recommendation algorithm acm conference recommender system pp g adomavicius tuzhilin contextaware recommender system f ricci et al ed recommender system handbook pp hj ahn new similarity measure collaborative Ô¨Åltering alleviate new user coldstarting problem science myh alshamri kk bharadwaj fuzzygenetic recommender system novel hybrid user expert system application j alsharawneh williams credibilityaware webbased social network recommender follow leader proceeding acm conference recommender system pp alonso fj cabrerizo f chiclana f herrera e herreraviedma group decision making incomplete fuzzy linguistic preference relation international journal intelligent system ansari essegaier r kohli internet recommendation system journal marketing research n antonopoulus j salter cinema screen recommender agent combining collaborative contentbased Ô¨Åltering ieee intelligent system p antunes v herskovic sf ochoa ja pino structuring dimension collaborative system evaluation acm computing survey article arazy n kumar b shapira improving social recommender system journal professional l ardissono goy g petrone segnan p torasso intrigue personalized recommendation tourist attraction desktop handset device applied artiÔ¨Åcial intelligence r baezayates b ribeironeto modern retrieval addison wesley balabanovic shoham contentbased collaborative recommendation communication acm l baltrunas makcinskas f ricci group recommendation rank aggregation collaborative Ô¨Åltering proceeding acm conference recommender system pp ab barrag√°nsmartƒ±nez e costamontenegro jc burguillo reyl√≥pez fa mikicfonte peleteiro hybrid contentbased itembased collaborative Ô¨Åltering recommend tv program enhanced singular decomposition science c basu h hirsh w cohen recommendation classiÔ¨Åcation social contentbased recommendation proceeding fifteenth national conference artiÔ¨Åcial intelligence pp p bedi r sharma trust recommender ant colony trust computation expert system application bengio grandvalet umbiased estimator variance kfold crossvalidation journal machine learning research berkovsky j freyne groupbased recipe recommendation aggregation strategy proceeding acm conference recommender system pp bilge h polat improved privacypreserving dwtbased collaborative Ô¨Åltering scheme expert system application bilgic r mooney explanation recommender system satisfaction v promotion next stage recommender system research workshop iui conference pp billsus pazzani personal news agent talk learns explains proc auton agent conf pp billsus pazzani user modeling adaptive news access user modeling useradapted interaction billsus pazzani j chen learning agent wireless news access proceeding international conference intelligent user interface pp rp biukaghai fong yainwhar design recommender mobile tourism multimedia selection nd international conference internet multimedia service architecture application imsaa pp j bobadilla f serradilla effect sparsity collaborative Ô¨Åltering metric australian database conference pp j bobadilla f serradilla hernando collaborative Ô¨Åltering adapted recommender system elearning knowledge system j bobadilla f serradilla j bernal new collaborative Ô¨Åltering metric improves behavior recommender system knowledge system j bobadilla hernando f ortega j bernal framework collaborative Ô¨Åltering recommender system expert system application j bobadilla f ortega hernando j alcal√° improving collaborative Ô¨Åltering recommender system result performance genetic algorithm knowledge system j bobadilla hernando f ortega guti√©rrez collaborative Ô¨Åltering signiÔ¨Åcances science j bobadilla f ortega hernando collaborative Ô¨Åltering similarity measure singularity processing management j bobadilla f ortega hernando j bernal collaborative Ô¨Åltering mitigate new user cold start problem knowledge system j bobadilla f ortega hernando j bernal generalization recommender system collaborative Ô¨Åltering extended group user restricted group item expert system application j bobadilla f ortega hernando arroyo balanced memorybased collaborative Ô¨Åltering similarity measure international journal intelligent system bogers van den bosch collaborative contentbased Ô¨Åltering item recommendation social bookmarking website proceeding acm conference recommender system pp p bonhard trust combining recommender system social networking better advice international conference intelligent user interface p bonhard sasse knowing knowing youusing proÔ¨Åles social networking improve recommender system bt technology journal p borzymek sydow wierbicki enriching trust prediction social network user rating similarity proceeding international conference computational aspect social network pp j breese heckerman c kadie empirical predictive algorithm collaborative Ô¨Åltering th conference uncertainty artiÔ¨Åcial intelligence pp bridge mh goker l mcginty b smyth casebased recommender system knowledge engineering review r burke encyclopedia library system kent ed vol suppl marcel dekker chapter knowledgebased recommender system r burke casebased reasoning collaborative Ô¨Åltering ewcbr pp r burke hybrid recommender system survey experiment user modeling useradapted interaction f cacheda v carneiro fern√°ndez v formoso comparison collaborative Ô¨Åltering algorithm limitation current technique proposal scalable highperformance recommender system acm transaction web article caizer u aickelin recommender idiotypic artiÔ¨Åcial immune network journal mathematics model algorithm j bobadilla et al knowledgebased system lm campos jm fern√°ndezluna jf huete ruedamorales combining contentbased collaborative recommendation hybrid bayesian network international journal approximate reasoning l candillier f meyer boull√© comparing stateoftheart collaborative Ô¨Åltering system lecture note computer sciece f carmagnola f vernero p grillo sonar social networksbased social recommender system proceeding th international conference user modeling adaptation personalization formerly um ah pp w carrerneto ml hern√°ndezalcaraz r valenciagarcƒ±a f garcƒ±a s√°nchez social knowledgebased recommender application movie domain expert system application jj castrosanchez r miguel vallejo lm l√≥pezl√≥pez highly adaptive recommender fuzzy logic bc ecommerce portal expert system application chao j balthrop forrest adaptive radio achieving consensus negative preference international acm siggroup conference supporting group work pp chen l collaborative Ô¨Åltering demographic attribute vector proceeding international conference future computer communication pp pa chirita w nejdl c zamÔ¨År preventing shilling attack online recommender system workshop web management pp j cho k kwon park qrater collaborative reputation source credibility theory expert system application sb cho jh hong mh park locationbased recommendation bayesian user preference mobile device lecture note computer science k choi yoo g kim suh hybrid onlineproduct recommendation combining implicit ratingbased collaborative Ô¨Åltering sequential pattern electronic commerce research application press doi jelerap k choi suh new similarity fuction selecting neighbor target item collaborative Ô¨Åltering knowledge system c christakou stafylopatis hybrid movie recommender neural network international conference intelligent system design application pp ia christensen schiafÔ¨Åno entertainment recommender system group user expert system application claypool gokhale miranda p murnikov netes sartin combining contentbased collaborative Ô¨Ålters online newspaper proceeding acm sigir workshop recommender system pp w cohen fast effective rule induction proceeding twelfth international conference machine learning pp condliff lewis madigan c posse bayesian mixedeffects model recommender system acm sigir workshop recommender system algorithm evaluation pp e costamontenegro ab barrag√°nsmartƒ± nez reyl√≥pez app recommender application market implementation service monitoring user interaction expert system application th dao sr jeong h ahn novel recommendation locationbased advertising contextaware collaborative Ô¨Åltering ga expert system application dellamico l capra sofia social Ô¨Åltering robust recommendation ifip advance communication technology dubois j golbeck j kleint srinivasan improving recommendation accuracy clustering social network trust proceeding acm conference recommender system pp ekstr√∂m h bj√∂rnsson c nass reputation mechanism businessto business electronic commerce account rater credibility journal organizational computing electronic commerce esslimani brun boyer social network behavioral network recommender system proceeding international conference advance social network mining pp fahri framework organizing justiÔ¨Åcations strategic use adaptive iteraction context ecis article felfernig r burke constraintbased recommender system technology research issue th international conference electronic commerce article l fengkun jl hong use social network enhance collaborative Ô¨Åltering performance expert system application lq gao c li hybrid personalizad recommended genetic international conference wireless communication network mobile computing pp gao z wu f jiang userrank itembased collaborative Ô¨Åltering recommendation processing letter garcƒ± l sebastia e onaindia design individual group recommender system tourism expert system application r garcƒ±a x amatriain weighted content method recommending connection online social network proceeding acm conference recommender system pp gavalas kenteris webbased pervasive recommendation mobile tourist guide personal ubiquitous computing f gedikli jannach rating item rating tag proceeding acm conference recommender system pp j gemmell schimoler b mobasher r burke resource recommendation social tagging multichannel hybrid proceeding acm conference recommender system pp j gemmell schimoler ramezani l christiansen b mobasher improving folkrank itembased collaborative Ô¨Åltering proceeding acm conference recommender system pp gemmis p lops g semeraro p basile integrating tag semantic contentbased recommender proceeding acm conference recommender system pp george meregu scalable collaborative Ô¨Åltering framework base coclustering ieee international conference mining icdm pp j golbeck u kuter ripple effect change trust impact social network computing social trust humancomputer interaction series part ii pp chapter k goldberg roeder gupta c perkins eigentaste constant time collaborative Ô¨Åltering retrieval r gonz√°lezcrespo sanju√°nmartƒ±nez j manuelcueva b cristinapelayo je labragayo p ordo√±ez recommendation user interaction applied intelligent electronic book computer human behavior n good jb schafer ja konstan borchers b sarwar jl herlocker j riedl proceeding sixteenth national conference artiÔ¨Åcial intelligence eleventh innovative application artiÔ¨Åcial intelligence conference innovative application artiÔ¨Åcial intelligence pp gunawardana g shani survey accuracy evaluation metric recommender task journal machine learning reearch jl herlocker ja konstan j riedl explaining collaborative Ô¨Åltering recommendation acm conference computer supported cooperative work cscw pp jl herlocker ja konstan al borchers jt riedl algorithmic framework performing collaborative Ô¨Åltering proceeding nd annual international acm sigir conference research development retrieval pp jl herlocker ja konstan jt riedl empirical design choice neighborhoodbased collaborative Ô¨Åltering algorithm retrieval jl herlocker ja konstan jt riedl lg terveen evaluating collaborative Ô¨Åltering recommender system acm transaction system f hern√°ndez e gaudioso evaluation recommender system new expert system application hernando j bobadilla f ortega j tejedor incorporating reliability measurement prediction recommender system science press doi jins hernando j bobadilla f ortega guti√©rrez tree explaining recommendation made collaborative Ô¨Åltering science k heungnam e abdulmotaleb j geunsik collaborative errorreÔ¨Çected model coldstart recommender system decision support system ho fong z yan hybrid gabased collaborative Ô¨Åltering online recommenders international conference ebusiness pp l hossain fazio social network collaborative process journal high technology management research hr hu p pu personality collaborative Ô¨Åltering new user proceeding acm conference recommender system pp hu koren ch volinsky collaborative Ô¨Åltering implicit feedback datasets ieee international conference mining icdm pp yp huang wp chuang yh ke fe sandnes backpropagation learn association rule service personalization expert system application z huang zeng h chen comparison collaborative Ô¨Åltering recommendation algorithm ecommerce ieee intelligent system n hurley zhang novelty diversity topn recommendation evaluation acm transaction internet technology j bobadilla et al knowledgebased system chs hwang ych su kch tseng genetic algorithm personalized recommendation lecture note computer science h ingoo jo kyong hr tae collaborative Ô¨Åltering recommendation som clusterindexing cbr expert system application jameson b smyth recommendation group p brusilovsky kobsa w nejdl ed adaptive web pp chapter jannach fast computation query relaxation knowledgebased recommenders ai communication r j√§schke l marinho hotho l schmidtthieme g stumme tag recommendation folksonomies proceeding th european conference principle practice knowledge discovery database pp jj jason contextualized mobile recommendation service interactive social network discovered mobile user expert system application b jeong j lee h cho user credit collaborative Ô¨Åltering expert system application joachim text categorization support vector machine learning many relevant feature european conference machine learning pp j√∏sang r ismail c boyd survey trust reputation system online service provision decision support system chw jyun chch chui recommending trusted online auction seller social network expert system application c kaleli h polat privacypreserving sombased recommendation horizontally distributed knowledge system hn kim alkhaldi ae saddik g jo collaborative user modeling usergenerated tag social recommender system expert system application hn kim ji ha g jo collaborative Ô¨Åltering collaborative tagging enhancing quality recommendation electronic commerce research application j kim b lee shaw h chang w nelson application decisiontree induction technique personalized advertisement internet storefront international journal electronic commerce k kim h ahn clustering genetic support customer segmentation personalizad recommender system proceeding th international conference ai simulation planning high autonomy system pp k kim h ahn recommender ga kmeans clustering online shopping market expert system application kitisin c neuman reputationbased trustaware recommender securecomm workshop pp f kong x sun ye comparison several algorithm collaborative Ô¨Åltering startup stage ieee transaction network sensing control koren r bell ch volinsky matrix factorization technique dor recommender system ieee computer g koutrika b bercovitz h garcia flexrecs expressing combining Ô¨Çexible recommendation proceeding th sigmod international conference management pp b krulwich lifestyle Ô¨Ånder intelligent user proÔ¨Åling largescale demographic artiÔ¨Åcial intelligence magazine k kwon j cho park multidimensional credibility neighbor selection collaborative recommendation expert system application sk lam j riedl shilling recommender system fun proÔ¨Åt international conference world wide web pp xn lam vu td le ad duong addressing coldstart problem recommendation system conference ubiquitous management communication pp n landia s anand personalised tag recommendation proceeding acm conference recommender system pp k lang newsweeder learning Ô¨Ålter netnews proceeding th international conference machine learning pp dh lee p brusilovsky trust inÔ¨Çuence similarity proceeding acm conference recommender system pp lee woo hybrid recommender combining collaborative Ô¨Åltering neural network lecture note computer science sk lee yh cho sh kim collaborative Ô¨Åltering ordinal scalebased implicit rating mobile music recommendation science cw leung sc chan fl chung empirical crosslevel association rule mining coldstart recommendation knowledge system q li clustering hybrid recommender proceeding ieeewic international conference web intelligence pp ym li chw chen synthetical blog recommendation combining trust social relation semantic an√°lisis expert system application ym li chp kao trepps trustbased recommender peer production service expert system application ym li tf liao chy lai social recommender mechanism improving knowledge sharing online forum processing management press doi jipm loh f lorenzi r granada lichtnow lk wife jp oliveira identifying similar user scientiÔ¨Åc publication reduce cold start recommender system proceeding th international conference web system technology webist pp l l√º medo chh yeung ych zhang zk zhang zhou recommender system physic report x luo xia q zhu incremental collaborative Ô¨Åltering recommender regularizad matrix factorization knowledgebased system x luo xia q zhu applying learning rate adaptation matrix factorization collaborative Ô¨Åltering knowledge system h king mr lyu learning recommend explicit implicit social relation acm transaction intelligent system technology article h ch zhou mr lyu king improving recommender system incorporating social contextual acm transaction system article machanavajjhala korolova ad sharma personalized social recommendation accurate private proceeding vldb endowment vol issue pp lb marinho l schmidtthieme collaborative tag recommendation proceeding st annual conference german classiÔ¨Åcation society pp l martinez lg perez mj barranco incomplete preference relation smooth coldstart collaborative recommender system proceeding th north american fuzzy processing society annual conference nafips pp l martinez rm rodriguez espinilla reja georeferenced hybrid recommender restaurant ieeewicacm international joint conference web intelligence intelligent agent technonolgy wiiat b pp p massa p avesani trustaware collaborative Ô¨Åltering recommender system lecture note computer science p massa p avesani trustaware recommender system proceeding acm conference recommender system pp c matyas c schlieder spatial user similarity measure geographic recommender system proceeding rd international conference geospatial semantics pp k mccarthy j reilly l mcginty b smyth thinking positivelyexplanatory feedback conversational recommender system european conference casebased reasoning eccbr pp k mcnally mp omahony coyle p briggs b smyth collaboration reputation social web search acm transaction intelligent system technology article mcsherry explanation recommender system artiÔ¨Åcial intelligence review f mcsherry mironov differentially private recommender system building privacy netÔ¨Çix prize contender proceeding th acm sigkdd international conference knowledge discovery mining kdd pp p melville rj mooney r nagarajan contentboosted collaborative Ô¨Åltering improved recommendation proceeding eighteenth national conference artiÔ¨Åcial intelligence pp r meteren someren contentbased Ô¨Åltering recommendation proceeding ecml workshop maching learning age pp se middleton nr shadbolt dc de roure ontological user proÔ¨Åling recommender system acm transaction system tois rj mooney l roy contentbased book recommending learning text categorization proceeding fifth acm conference digital library pp morrison u aickelin artiÔ¨Åcial immune recommender web site international conference artiÔ¨Åcial immune system pp nanolopoulus rafailidis p symeonidis manolopoulus music box personalizad music recommendation cubic social tag ieee transaction audio speech language processing k nehring c puppe theory diversity econometrica er n√∫√±ezvald√©z jm cuevalovelle sanju√°nmartƒ±nez v garcƒ± adƒ±az p ordo√±ez ce montenegromarƒ± n implicit feedback technique recommender system applied electronic book computer human behavior j bobadilla et al knowledgebased system j odonovan capturing trust social web application j golbeck ed computing social trust pp j odonovan b smyth trust recommender system international conference intelligent user interface pp k oku r kotera k sumiya geographical recommender interaction map operation category selection workshop heterogeneity fusion recommender system pp j ortega j bobadilla hernando guti√©rrez incorporating group recommendation recommender system alternative performance processing management httpdxdoiorg jipm j ortega jl s√°nchez j bobadilla guti√©rrez improving collaborative Ô¨Ålteringbased recommender system result pareto dominance science httpdxdoiorgjins papadimitriou p symeonidid manolopoulus generalized taxonomy explanation style traditional social recommender system minning knowledge discovery dh park hk kim iy choi jk kim literature review classiÔ¨Åcation recommender system research expert system application st park w chu pairwise preference regression coldstart recommendation proceeding acm conference recommender system pp st park dm pennock madani n good coste naƒ±ve Ô¨Ålterbots robust coldstart recommendation proceeding knowledge discovery mining kdd pp yj park tuzhilin long tail recommender system leverage proceeding acm conference recommender system pp pazzani billsus learning revising user proÔ¨Åles identiÔ¨Åcation interesting web site machine learning mj pazzani billsus contentbased recommender system p brusilovsky kobsa w nejdl ed adaptive web pp chapter pazzani framework collaborative contentbased demographic Ô¨Åltering artiÔ¨Åcial intelligence reviewspecial issue mining internet perugini gon√ßalves ea fox recomender system research connectioncentric surrey journal intelligen system mc pham cao r klamma jarke clustering collaborative Ô¨Åltering recommendation social network journal universal computer science g pitsilis sj knapskog socila trust solution address sparsityinherent problem recommender system proceeding acm conference recommender system pp g pitsilis x zhang w wang clustering recommenders collaborative Ô¨Åltering explicit trust advance communication technology popescul lh ungar dm pennock lawrence probabilistic model uniÔ¨Åed collaborative contentbased recommendation sparsedata environment proceeding uai proceeding th conference uncertainty artiÔ¨Åcial intelligence pp c porcel e herreraviedma dealing incomplete fuzzy linguistic recommender disseminate university digital library knowledgebased system c porcel jm moreno e herreraviedma multidisciplinar recommender advice research resource university digital library expert system application c porcel tejedalorente martƒ± nez e herreraviedma hybrid recommender selective dissemination research resource technology transfer ofÔ¨Åce science j preece b shneiderman reader leader framework motivating technologymediated social participation ai transaction human computer interaction p pu l chen trustinspiring explanation interface recommender system knowledge system w qin l xin h liang unifying userbased itembased improve collaborative Ô¨Åltering accuracy energy procedia l ramaswamy p deepak r polavarapu k gunasekera garg k visweswariah kalyanaraman caesar contextaware social recommender lowend mobile device international conference mobile management system service middleware pp rashid g karypis j riedl learning preference new user recommender system theoretic acm sigkdd exploration newsletter vol issue pp ray mahanti strategy effective shilling attack recommender system lecture note computer science l ren l j gu w xia f wu hybrid recommender widrowhoff learning international conference future generation communication networking pp th roh kj oh han collaborative Ô¨Åltering recommendation som clusterindexing cbr expert system application ja rodrigues lf cardoso j moreira g xexeo bringing knowledge recommender system journal system software press http dxdoiorgjjss sb roy ameryahia chala g da c yu space efÔ¨Åciency group recommendation international journal large base g ruffo r schifanella peertopeer recommender base spontaneous afÔ¨Ånities acm transaction internet technology pb ryan bridge collaborative recommending formal concept knowledge system g salton automatic text processing transformation retrieval computer addisonwesley reading saranya atsuhiro hybrid recommender system latent feature proceeding international conference advanced networking application workshop pp b sarwar g karypis ja konstan j riedl itembased collaborative Ô¨Åltering recommendation algorithm th international conference world wide web pp b sarwar g karypis j konstan j riedl recommendation algorithm ecommerce acm conference electronic commerce pp b sarwar g karypis j konstan j riedl application dimensionality reduction recommender acm webkdd workshop b pp jb schafer frankowski j herlocker sen collaborative Ô¨Ålltering recommender system p brusilovsky kobsa w nejdl ed adaptive web pp chapter ai schein popescul lh ungar dm pennock method metric coldstart recommendation proceeding sigir proceeding th annual international acm sigir conference research development retrieval pp c schlieder modeling collaborative semantics geographic recommender workshop semantic conceptual issue geographic system pp j serranoguerrero e herreraviedma ja olivas cerezo fp romero google wavebased fuzzy recommender disseminate university digital library science z severac v devedzic j jovanovic adaptive neurofuzzy pedagogical recommender expert system application shepitsen j gemmell b mobasher r burke personalized recommendation social tagging system hierarchical clustering proceeding acm conference recommender system pp sk shinde u kulkami hybrid personalizad recommender centeringbunching clustering expert system application siersdorfer sergei social recommender system web folksonomies th acm conference hypertext hipermedia pp soboroff c nicholas combining content collaboration text Ô¨Åltering proceeding ijcai workshop machine learning filtering pp x su tm khoshgoftaar survey collaborative Ô¨Åltering technique advance artiÔ¨Åcial intelligence p symeonidis nanopoulus manolopoulus providing justiÔ¨Åcations recommender system ieee transaction system man cybernet p symeonidis nanopoulus manolopoulus movieexplain recommender explanation proceeding acm conference recommender system pp g tak√°cs pil√°szy b n√©meth tikk scalable collaborative Ô¨Åltering approach large recommender system journal machine learning research tan j bu ch chen x rich social medium music recommendation via hypergraph acm transaction multimedia computing communication application article n tintarev j masthoff survey explanation recommender system ieee rd international conference engineering workshop tran r cohen hybrid recommender system electronic commerce proceeding th national conference artiÔ¨Åcial intelligence aaai pp khl tsosutter lb marinho l schmidtthieme tagaware recommender system fusion collaborative Ô¨Åltering algorithm proceeding acm symposium applied computing pp vargas p castells rank relevance novelty diversity metric recommender system proceeding acm conference recommender system pp p victor ch cornelis decock trust network recommender system antalis press j bobadilla et al knowledgebased system j vig sen j riedle tagsplanations explaining recommendation tag proceeding th international conference intelligent user interface pp p victor ch cornelis decock pp dasilva gradual tust distrust recommender system fuzzy set system mg vozalis kg margaritis svd demographic enhancement generalized collaborative Ô¨Åltering science wanshiou ch hungchi jiaben locationaware recommender mobile shopping environment expert system application j wang vries reinders unifying userbased itembased collaborative Ô¨Åltering approach similarity fusion proc sigir conf pp j wang ap vries mj reinders uniÔ¨Åed relevance model rating prediction collaborative Ô¨Åltering acm transaction system lt weng xu li r nayak exploiting item taxonomy solving cold start problem recommendation making proceeding th ieee international conference tool artiÔ¨Åcial intelligence ictai pp b widrow hoff adaptive switching circuit convention record ire wescon pp p winoto ty tang role user mood movie recommendation expert system application w woerndl g groh utilizing physical social context improve recommender system ieeewicacm international conference web intelligence intelligent agent technology pp b xie p han f yang rm shen hj zeng z chen dcfla distributed collaborativeÔ¨Åltering neighborlocating science w xin q jamaliding okamoto discovering social network improve recommender group learning support international conference computational intelligence software engineering pp rr yager fuzzy logic method recommender system fuzzy set system w yang hch cheng jb dia locationaware recommender mobile shopping environment expert system application yang evaluation statistical approach text categorization retrieval z yao q zhang itembased clustering collaborative Ô¨Åltering high dimensional sparse international joint confeence computational science optimization pp z yu x zhou hao j gu tv program recommendation multiple viewer user proÔ¨Åle merging user modeling useradapted interaction w yuan guan yk lee lee sj hur improved trustaware recommender smallworldness trust network knowledge system g zacharia moukas p maes collaborative reputation mechanism electronic marketplace decision support system zaiane building recommender agent elearning system proceeding international conference computer education icce vol pp j zhan privacypreserving collaborative recommender system ieee transaction system man cybernetics f zhang hy chang collaborative Ô¨Åltering employing genetic clustering ameliorate scalability issue ieee international conference ebusiness engineering pp zhang w wang j ford f makedon singular decomposition approximation collaborative Ô¨Åltering ieee international conference ecommerce technology pp l zhen gq huang z jiang recommender system workÔ¨Çow decision support system l zhen gq huang z jiang collaborative Ô¨Åltering workÔ¨Çow space expert system application l zhen z jiang h song distributed recommender peertopeer knowledge sharing science n zheng q li recommender tag time social tagging system expert system application zheng x xie learning travel recommendation usergenerated gps trace acm transaction intelligent system technology article zheng l zhang z x xie wy recommending friend location individual location history acm transaction web article j zhong x li uniÔ¨Åed collaborative Ô¨Åltering combination latent feature expert system application rl zhu sj gong analyzing collaborative Ô¨Åltering clustering technology international colloquium computing isecs international colloquium computing communication control management pp cn ziegler sm mcnee ja konstan g lausen improving recommendation list topic diversiÔ¨Åcation proceeding th international conference world wide web pp j bobadilla et al knowledgebased system,3,et al and collaborative Ô¨Åltering in bobadilla et
Creating synthetic datasets for collaborative filtering recommender systems using generative adversarial networks.pdf,Knowledge-Based Systems | Creating synthetic datasets for collaborative filtering recommender systems | using generative adversarial networks,Recommender systems,"Knowledge-Based Systems 280 (2023) 111016 Available online 23 September 2023 0950-7051/¬© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ). Contents lists available at ScienceDirect Knowledge-Based Systems journal homepage: www.elsevier.com/locate/knosys Creating synthetic datasets for collaborative filtering recommender systems using generative adversarial networks Jes√∫s Bobadilla a , Abraham Guti√©rrez a , Raciel Yera b , Luis Mart√≠nez b , ‚àó a Departamento de Sistemas Inform√°ticos, ETSI Sistemas Inform√°ticos, Universidad Polit√©cnica de Madrid, C/ Alan Turing s/n, 28031, Madrid, Spain b Departamento de Inform√°tica, Universidad of Ja√©n, Ja√©n, Spain A R T I C L E I N F O Keywords: Recommender systems Generative adversarial networks Deep learning Collaborative filtering A B S T R A C T Research and education in machine learning requires diverse, representative, and open datasets that contain sufficient samples to handle the necessary training, validation, and testing tasks. Currently, the Recommender Systems area includes a large number of subfields in which accuracy and beyond-accuracy quality measures are continuously being improved. To feed this research variety, it is both necessary and convenient to reinforce the existing datasets with synthetic ones. This paper proposes a Generative Adversarial Network (GAN)-based method to generate collaborative filtering datasets in a parameterized way by selecting their preferred number of users, items, samples, and stochastic variability. This parameterization cannot be performed using regular GANs. Our GAN model is fed with dense, short, and continuous embedding representations of items and users, instead of sparse, large, and discrete vectors, to ensure fast and accurate learning, as compared to the traditional approach based on large and sparse input vectors. The proposed architecture includes a DeepMF model to extract the dense user and item embeddings and a clustering process to convert the dense GAN generated samples to the discrete and sparse samples necessary to create each required synthetic dataset. The results from three different source datasets show adequate distributions and expected quality values and evolutions in the generated datasets compared to the source datasets. Synthetic datasets and source codes are available to researchers. 1. Introduction Recommender systems (RS) are a relevant area in artificial intel- ligence due to the growing popularity of social networks. The big companies that extensively use RSs are TripAdvisor, Netflix, Spotify, YouTube Music, TikTok, YouTube and Amazon [ 1 ]. These companies make use of the RS models to recommend to users similar items (music, videos, trips, news) to those that they have already consumed; some other companies, such as Facebook, work hard to collect customer activity to provide personalized advertising rather than personalized products or services. RSs are usually classified according to their filter- ing approach [ 2 ]; content-based RSs select the recommended items by looking for similar content [ 3 ]; since most item contents is text, natural language processing models are used. Reviews [ 4 ] and tweets [ 5 ] are two common types of content-based filtered data. Product images can also be processed to make recommendations; convolutional neural networks are the most commonly used models to perform this task [ 6 ]. Social filtering has been extensively used to improve social-based rec- ommendations. This type of filtering uses data such as tags, followers, ‚àó Corresponding author. E-mail addresses: jesus.bobadilla@upm.es (J. Bobadilla), abraham.gutierrez@upm.es (A. Guti√©rrez), ryera@ujaen.es (R. Yera), martin@ujaen.es (L. Mart√≠nez). and being followed, and makes use of the concepts of reputation and trust [ 7 ]. Geographic information, such as GPS coordinates and POI, is mainly used to support context-aware filtering [ 8 ]. Demographic filtering (age, gender, country, etc.) is commonly combined with other types of filtering, implementing recommendation ensembles [ 9 ]. Be- yond the previous filtering strategies, collaborative filtering (CF) [ 10 ] is the most important approach for implementing RSs, since it provides superior accuracy, particularly when combined with some other types of filtering. Effective RS research makes use of innovative models, adequate quality measures, and representative datasets. The historical evolution of CF begins with the use of memory-based models, mainly the K-Nearest Neighbors algorithm [ 11 ]. Memory- based approaches were replaced by model-based machine learning approaches due to their overall performance: they are superior in accu- racy of results, also in time to obtain predictions (once the model has learned); and their output is capable of being explained through post- hoc techniques [ 12 ]. Matrix Factorization (MF) [ 13 ] is the most widely used machine learning model to implement collaborative filtering; it performs a dimensional reduction of users and items, capturing the https://doi.org/10.1016/j.knosys.2023.111016 Received 17 December 2022; Received in revised form 12 September 2023; Accepted 15 September 2023 Knowledge-Based Systems 280 (2023) 111016 2 J. Bobadilla et al. main patterns that relate them to the votes cast. Additionally, by using Non-Negative Matrix Factorization (NFM) [ 14 ], semantic meanings can be assigned to latent factors. Bayesian NMF [ 15 ] allows clustering users and making predictions simultaneously, which opens the door to effective recommendations to user groups and social clustering appli- cations [ 16 ]. Nowadays, CF research is mainly developed by deep learning models, where DeepMF [ 17 ] is the basis for modern approaches . DeepMF is the model that we use in this paper, in which users are coded in a latent space by means of an embedding layer, whereas items are coded in a different latent space by means of a second embedding layer; finally, predictions are made by making the dot product of both, item and user embeddings. DeepMF improves MF due to the inherent competence of neural networks to capture the non-linear relations hips between samples. Neural Collaborative Filtering (NCF) [ 18 ] is extensively used to implement CF; this model replaces the DeepMF dot layer with a Multi-Layer Perceptron (MLP) and outperforms DeepMF when applied to large and complex datasets. Beyond accuracy, deep learning models are emerging to perform some innovative tasks, such as improving fairness, where the DeepFair model [ 19 ] achieves a trade-off between equity and precision; green computing [ 20 ]; results explanation via latent space visualization [ 21 ] and efficient neighborhood identifica- tion [ 22 ]. The adversarial network-based recommendation has recently been introduced in the RS area [ 23 ] and we will focus on it in the ‚ÄôRelated work‚Äô section. Generative Adversarial Networks (GAN) [ 24 ] are responsible for the popular fake faces and fake videos that flood social networks. Their architecture has two separate neural networks that compete against each other (‚Äôadversarial‚Äô), such as an art forger competing against an art expert, ensuring that both improve their work. The GAN ‚Äòforger‚Äô is a generator model that creates fake samples from random noise vectors, while the GAN ‚Äòexpert‚Äô is a discriminator model implemented as a simple binary classifier: fake, non-fake. However, while RS research is mainly focused on proposing novel recommendation models, this paper tries to make progress in CF datasets . In this respect, it is essential to identify quality measures as a key element to carry out adequate research, since they allow the baselines of the state of the art to be compared with the proposed algorithms, methods and models. Beyond the usual prediction and recommendation quality measures (MAE, MSD, precision, recall, F1, NDCG, etc.), some other measures, such as novelty and diversity [ 25 ], have recently acquired growing importance. Of these, diversity is cur- rently the main focus of researchers‚Äô attention, due to the risks of inappropriate recommendations in social networks, such as those that exhibit a lack of variability and promote prefixed ideas and behaviors. Diversity and reliability in RS have been improved by introducing diversity-enhancing constraints in the MF model [ 26 ]; additionally, a deep learning classification model [ 27 ] is proposed to obtain the recommendation reliability values from the softmax output layer of the neural network. Quality values are obtained when a model or method is tested on balanced CF datasets. To obtain balanced training and testing sets, with respect to their user and item distributions, deterministic strategies are proposed in [ 28 ]. Most of the RS research makes use of popular CF datasets such as MovieLens, FilmTrust, MyAnimeList or CiteSeer; CF datasets include different domains such as music, movies, POIs, tourism, news, research papers, tagged data, etc. Some of these datasets have been filled with explicit votes from users, while others contain implicit interactions between users and systems. There are also datasets filled with crawled Web pages or academic PDFs [ 29 ] and some others are enriched with social tags that researchers add to the ar- ticles [ 30 ]. A selection of relevant social CF datasets is provided in [ 31 ] and related to some articles using them. Recently, an educational news dataset [ 32 ] was released; which included contextualized information: time and location. Finally, an RS dataset has also been provided that contains artificial intelligence research data [ 33 ] to obtain segmented information, clustering, and geographical locations. Beyond these works, it is particularly relevant that parameterized synthetic datasets have not yet been used, so consequently the CF research does not benefit from the flexibility that parameterization provides in the experiment design: different dataset sizes, number of users and items, and so on. This paper aims to fill the gap by proposing a procedure, coined as GANRS, which focuses on the use of GANs to generate collaborative filtering recommender systems datasets in a parameterized way. Please note that current RS GAN-based models cannot simultaneously set the number of generated users, items, and rating distributions. Regarding our contribution, two main overall approaches can be identified in the state-of-art: statistical and generative. The main ad- vantage of the statistical approach is that several relevant parameters can be simultaneously set: number of users, number of items, dataset size, etc. The main drawback of this approach is its poor accuracy. On the other hand, current model-based generative approaches improve accuracy compared to statistical frameworks, but they lack flexibility, since parameterization is very limited. In fact, current GAN designs are focused on user profiles, and they can generate as many new fake users as required, but other relevant parameters cannot be set, such as the number of items that is fixed in the source set of user vectors and then, also, in the fake generated set of user vectors. This can be explained with an example: when we run a regular GAN to generate fake images, the synthetic images have the same shape (resolution and number of channels) as the source images. In the RS field, the synthetic user vectors contain the same number of items as the real user vectors. Following the example, there are some specific GAN designs that return ‚Äòsuper-resolution‚Äô images (they can increase resolution), but to our knowledge there are no RS GANs designed to generate fake users containing more items (or fewer items). Our proposed method is designed to simultaneously set some CF relevant parameters, such as the number of users and items. The rest of the paper has been structured as follows: related work is introduced in Section 2 , focusing on the most recent uses of the GAN models applied to RS. Section 3 explains the proposed model and its formalization. Section 4 presents the design, result, and discussion of the experiments. Finally, Section 5 contains the main conclusions of the article and discusses future work. 2. Background 2.1. Basics on generative adversarial networks GANs are designed to generate data from scratch [ 24 ]. They have been commonly used to create fake images, although their use has been spreading to many other domains: music, medicine, financial data, etc. The GAN architecture composes of two deep network models: generator and discriminator. The generator model learns to create samples as similar as possible to those in a dataset (e.g., a dataset with human faces images), whereas the discriminator model learns to detect fake samples (those samples created by the generator). To better understand the GANs we can consider the example of a painting forger and a forgery expert: the more imitations the forger paints, the better their results, and the better the expert‚Äôs ability to detect fake paintings. Both people successively improve their abilities. When the learning begins, the GAN discriminator (the forgery expert, in our example) has an easy job, since the generator does not have the painting patterns. After thousands of learning epochs, the generator has learnt the patterns well enough to confuse the discriminator, who is forced to tune their weights. If the learning loop iterates enough times, both the generator and the discriminator models are well designed and the painting in the dataset contains suitable patterns, the generator will be able to create synthetic (fake) samples that are difficult to distinguish from the originals. Fig. 1 shows the GAN architecture [ 24 ]; the discriminator model makes a binary classification between fake and real samples. The generator model updates its weights (learns) when the discriminator correctly classifies a fake sample. The discriminator model updates its weights when it incorrectly classifies a sample. Note that the generator takes a random noise distribution as input to generate samples; then, Knowledge-Based Systems 280 (2023) 111016 3 J. Bobadilla et al. Fig. 1. Generative Adversarial Networks architecture. once it has learnt, for each input random noise vector that feeds the generator a sample is created with the patterns of the dataset samples. For this reason, by providing random noise vectors we can create as many samples as required, which means that, in our context, we can create fake CF datasets of any size by creating fake profiles. To measure GAN loss, we use cross-entropy. The discriminator ( ùê∑ ) loss can be expressed as the sum of the expectations: ùëöùëéùë• ùê∑ ùëâ ( ùê∑ ) = ùê∏ ùë• ‚àº ùëù ùëëùëéùë°ùëé ( ùë• ) [ ùëôùëúùëîùê∑ ( ùë• )] + ùê∏ ùëß ‚àº ùëù ùëß ( ùëß ) [ ùëôùëúùëî (1 ‚àí ùê∑ ( ùê∫ ( ùëß )))] (1) Where the first term of the equation is used to recognize real images, and the second term recognizes generated images. ùëç represents the noisy vector, ùê∫ is the generator, and ùê∫ ( ùëç ) is the generated sample. ùê∑ ( ùê∫ ( ùëß )) is the classification result of the discriminator when its input is a fake sample. ùê∑ ( ùë• ) is the classification result of the discriminator when its input is a real sample. The generator loss is designed to learn when the discriminator correctly classifies (the true label is 1, and the fake label is 0). Its equation is: ùëöùëñùëõ ùê∫ ùëâ ( ùê∫ ) = ùê∏ ùë• ‚àº ùëù ùëëùëéùë°ùëé ( ùë• ) [ ùëôùëúùëî (1 ‚àí ùê∑ ( ùê∫ ( ùëß )))] (2) The GAN is a minimax in which ùê∫ wants to minimize ùëâ while ùê∑ wants to maximize it: ùëöùëñùëõ ùê∫ ùëöùëéùë• ùê∑ ùëâ ( ùê∑, ùê∫ ) = ùê∏ ùë• ‚àº ùëù ùëëùëéùë°ùëé ( ùë• ) [ ùëôùëúùëîùê∑ ( ùë• )] + ùê∏ ùëß ‚àº ùëù ùëß ( ùëß ) [ ùëôùëúùëî (1 ‚àí ùê∑ ( ùê∫ ( ùëß )))] (3) As in the previous example, GAN models act on non sparse values (e.g., pixels in a picture), but they are not designed to work with sparse vectors or matrices. Our problem here is that CF datasets contain extraordinarily sparse matrices of ratings (users only vote or consume a very limited number of the available items). Using the regular GAN architecture is not an adequate approach to addressing CF-based RS. This paper proposes an extended GAN architecture where embeddings are introduced to code the sparse and discrete vectors of votes to dense and continuous vectors. This innovation makes it possible to use a regular GAN to generate dense and continuous vectors efficiently and accurately. This compression stage forces us to design the corre- sponding stage to decompress the generated dense vectors. The adopted solution makes it possible to set both the number of users and items in the generated dataset, which is a relevant innovation in the state-of-art. 2.2. Related works Generative deep learning is an innovative field in the CF RS area. Although some variational autoencoder approaches have been pub- lished [ 34 , 35 ], current research is mainly focused on GAN models [ 36 ]. A CF subfield where GANs are used is the attack/defense strate- gies [ 37 ], where these models can reinforce security in RS. Neverthe- less, the most extended uses of CF GANs are: (a) to solve the issue of noisy data, and (b) to tackle the data sparsity problem, and implement a data augmentation framework by capturing the distribution of real data. CFGAN [ 38 ] is a model that generates purchase vectors rather than the IDs of items and then uses the generated fake purchase vectors to augment the real vectors. The Wasserstein version of CFGAN is the unified GAN (UGAN) [ 39 ] and reports improvements compared to CFGAN. To prioritize long and short-term RS information (inter- actions between users and items that change quickly or slowly), the PLASTIC [ 40 ] model trains a generator and uses it as a reinforcement learning agent. The recurrent GAN: RecGAN [ 41 ], learns temporal patterns in ratings; combining GAN and recurrent neural networks (RNNs) models. To capture negative sampling information in the CF datasets, IPGAN [ 42 ] implements two different generative models: one for positive instances and another for negative instances. IPGAN considers the relations between the positive ratings sampled and the negative ones selected. Currently, the DCGAN model [ 43 ] combines GAN and reinforcement learning models to catch the information of the RS sessions, rather than the traditional historical matrices of votes from users to items. Session information includes the responses of users to current recommenda- tions. The user‚Äôs immediate feedback is managed by the reinforcement learning model combined with the GAN. The NCGAN [ 44 ] incorporates a neural network to extract nonlinear features from users, and a GAN to guide the recommendation training; the generator model makes user recommendations, whereas the discriminator model measures distances between real and generated distributions. An innovative method to improve the information flow from generator to discriminator [ 45 ] reduces the discrepancies between both models in the CF GAN. A regularization Wasserstein GAN model is used in [ 46 ], combined with an autoencoder acting as a generator, reporting accuracy improvement when applied to high-dimensional and sparse CF matrices. A CGAN (Conditional GAN) is used [ 47 ] to improve CF recommendations, and the sizes of the rating vectors can be set, simplifying the generator and discriminator tasks. Additionally, it allows conditional rating gen- eration to be established. For datasets that do not follow standard Gaussian distributions, a missing data imputation based on GAN [ 48 ] is proposed; results show improved quality in several representative clas- sification data sets. Trust information is used in [ 49 ] to make effective recommendations. They propose a GAN where the discriminator is an MLP model, and the generator is a long-short term memory network (LSTM) model [ 50 ]. Finally, CF datasets are usually imbalanced due to their social data collection (e.g: more young people than old people). To address this limitation, [ 51 ] proposes a Wasserstein GAN model in the generator, and the PacGAN concept in the discriminator [ 52 ], to minimize the mode collapse problem. A platform for multi-agent RS simulation is the probabilistic-based RecSim [ 53 ], which generates synthetic profiles of users and items, and uses Markov chains and recurrent neural networks. The Virtual- Taobao [ 54 ] is a multiagent reinforcement learning system designed to improve search in the social Taobao website; it makes use of a Knowledge-Based Systems 280 (2023) 111016 4 J. Bobadilla et al. GAN to simulate internal distributions. A simple matrix factorization is used [ 55 ] to inject topic diversification into the recommendation pro- cess. The DataGenCars [ 56 ] is a Java-based generator of RS synthetic data; it contains a statistical basement that provides flexibility, but it returns low accuracy compared to deep learning generative models. Finally, the SynEvaRec framework [ 57 ] provides the generation of synthetic RS datasets using the Synthetic Data Vault (SVD) library. This library models multivariate distributions using copula functions; its CTGAN sub-library includes GAN models. The main advantage of SynEvaRec, compared to previous frameworks, is that it can use different RSs as a source; its main drawbacks are the poor quality of the results in most of the cases, and the excessive time it takes to perform the training stage. Previous research mainly focuses on improving different objectives such as noise reduction, recommendation quality, prediction values, defense against attacks, or balancing data. To make this happen, many different approaches and information sources have been combined: the use of GAN, CGAN, Wasserstein GAN, etc. GAN models have been combined with Recurrent Neural Networks [ 58 ] and LSTM net- works [ 50 ], and reinforcement learning has been introduced in the GAN-based architectures. Long and short data have been introduced to the proposed models, in addition to trust information, session logs, including responses of the users to previous recommendations, and inferred negative votes. The pure generation of synthetic datasets does not seem to be a goal in this novel field of GAN applied to CF RS, which is currently focused on improving prediction and recommendation quality results by means of data augmentation based on the inherent ability of the GAN model to capture the complex nonlinear patterns of high-dimensional and sparse CF datasets. The innovation of our proposal is to generate representative and useful CF synthetic datasets, rather than to improve the existing results that are of varying quality. Additionally, it allows representative parameters to be set and a whole ‚Äòfamily‚Äô of synthetic datasets to be obtained, taking real datasets as a source, such as Movielens, Netflix, or MyAnimeList. These parameters are the number of users, the number of items, the number of samples and the variability of the generated data. By varying the parameter values, we can generate different versions of the same CF pattern, such as a Movielens-based dataset containing 8000 users and 3000 items, or another that contains 2000 users and 1000 items, among others. In this way, we can test the accuracy and performance impact of the dataset size, its sparsity, its number of users and items, as well as check the improvement of the MAE when the number of users increases. As far as we know, there are no published methods or models for creating, in a parameterized deep learning model, accurate and scalable synthetic datasets from diverse sources. 3. The generative adversarial networks-based approach for data- sets building in collaborative filtering As previously mentioned in the Introduction section, our research problem is defined as obtaining a larger, scalable synthetic dataset from an original RS dataset that synthesizes similar user behavior and valuation patterns in relation to the original dataset. In addition, it is desirable that such generation be parameterized, allowing the number of users, items, samples and variability of the distribution to be controlled. Next, this section proposes the GANRS method, which uses a GAN network to generate synthetic CF datasets; the GAN is fed with a real CF dataset and the model learns its internal patterns. The most innovative contribution is to feed the GAN with dense and small embedding representations of users and items, instead of the traditional approach where the GAN inputs are large and comprise sparse vectors containing the votes cast for each user. The main advantage of the GANRS method is that it greatly reduces the complexity of the GAN architecture, its convergence speed, and its performance. The traditional and sparse-based GAN architectures deal with very large input vectors: as large as the number of items in the dataset, which can be in the tens of thousands, and require a very large dense layer in the model to hold this huge amount of data. What is more, between 97% to 99% of the data is usually missing, since users only vote for or consume a tiny proportion of the available products or services, hence the extraordinary sparsity in the CF datasets. Following the huge dense layer, in classical GAN architectures, it is necessary to stack a large multilayer perceptron to reduce dimensionality. By comparison, the proposed model replaces the large dense layer with two embeddings, one to code users and the other to code items (bor- rowed from the DeepMF model in the first stage of the proposed method). Embedding layers are specifically designed to deal with sparse data; they receive integer values (user and item IDs, in our case), and they provide small embedding representations (typically 5 to 15 float values in the CF scenarios). Related users or items share similar embedding representations, and this feature allows for extraordinarily simplification of the model. Overall, the proposed architecture is much smaller than traditional architectures, it contains far fewer parameters, and consequently, learns faster. Additionally, it better captures the complex nonlinear relations between items and users, in the same way that non-GAN RS models do to improve predictions. The formalization of the GANRS method is presented and structured according to the following seven stages, also illustrated in Fig. 2 : ‚Ä¢ Stage 0. CF definitions 1 Let ùëà be the set of users who make use of a CF RS. 2 Let ùêº be the set of items available for voting in the CF RS. 3 Let ùëâ be the range of allowed votes; usually ùëâ = {1 , 2 , 3 , 4 , 5} . 4 Let ùëÜ be the set of samples contained in the CF dataset; in which ùëÅ = | ùëÜ | = ùë°‚Ñéùëíùë°ùëúùë°ùëéùëôùëõùë¢ùëöùëèùëíùëüùëúùëìùë£ùëúùë°ùëíùë†ùëêùëéùë†ùë° . 5 ùëÜ = { ‚ü® ùë¢, ùëñ, ùë£ ‚ü© 1 , ‚ü® ùë¢, ùëñ, ùë£ ‚ü© 2 , ‚Ä¶ ., ‚ü® ùë¢, ùëñ, ùë£ ‚ü© ùëÅ }; where each ùë¢ ‚àà {1 , ‚Ä¶ , | ùëà | } , each ùëñ ‚àà{1 , ‚Ä¶ , | ùêº | } , and each ùë£ ‚àà{1 , ‚Ä¶ , | ùëâ | } . ‚Ä¢ Stage 1. DeepMF training 6 Let E be the size of two neural layer embeddings used to vectorize each user and each item belonging to ùëà and ùêº , respectively. 7 Let ùëì ùëíùë¢ ( ùë¢ ) = [ ùëí ùë¢ 0 , ùëí ùë¢ 1 , ‚Ä¶ , ùëí ùë¢ ùê∏ ] , where ùëì ùëíùë¢ is the embedding layer output of the users, where ùë¢ ‚àà{1 , ‚Ä¶ , | ùëà | } . 8 Let ùëì ùëíùëñ ( ùëñ ) = [ ùëí ùëñ 0 , ùëí ùëñ 1 , ‚Ä¶ , ùëí ùëñ ùê∏ ] , where ùëì ùëíùëñ is the embedding layer output of the items, where ùëñ ‚àà{1 , ‚Ä¶ , | ùêº | } . By com- bining both dense vectors of user and item embeddings: ( [ ùëí ùë¢ 0 , ùëí ùë¢ 1 , ‚Ä¶ , ùëí ùë¢ ùê∏ ] and [ ùëí ùëñ 0 , ùëí ùëñ 1 , ‚Ä¶ , ùëí ùëñ ùê∏ ] ), we can make rating pre- dictions in the DeepMF training stage. The dot product of the user embedding and the item embedding in each ‚ü® ùë¢, ùëñ, ùë£ ‚ü© ùëó ‚àà ùëÜ provides its rating prediction: 9 ÃÇùë¶ ùëó = ùëì ùëíùë¢ ( ùë¢ ) ‚ãÖ ùëì ùëíùëñ ( ùëñ ) = [ ùëí ùë¢ 0 , ùëí ùë¢ 1 , ‚Ä¶ , ùëí ùë¢ ùê∏ ] ‚ãÖ [ ùëí ùëñ 0 , ùëí ùëñ 1 , ‚Ä¶ , ùëí ùëñ ùê∏ ] 10 1 2 ( ùë¶ ùëó ‚àí ÃÇùë¶ ùëó ) 2 is the output error used in the DeepMF neural network to start the backpropagation algorithm, where the neural weights are iteratively improved from the ùõø ùëó values: ‚ñµ ùë§ ùëóùëñ = ùõºùë¶ ùëó ùëì ‚Ä≤ ( ùëÅùëíùë° ùëñ ) ‚àë ùëò ùë§ ùëñùëò ùõø ùëò , when ùëò is a hidden layer, and ‚ñµ ùë§ ùëóùëñ = ùõºùë¶ ùëñ ùëì ‚Ä≤ ( ùëÅùëíùë° ùëñ ) 1 2 ( ùë¶ ùëò ‚àí ÃÇùë¶ ùëò ) 2 , if ùëò is the output layer. i, j, and k are successive sequential layers. ùëÅùëíùë° ùëñ represents the cumulative input received for an artificial neuron, ùëÅùëíùë° ùëñ = ‚àë ùëó ùë¶ ùëó ‚àó ùë§ ùëó , where ùëó is the index of the neurons in the layer preceding the current neuron. ‚Ä¢ Stage 2. DeepFM feedforward Once the DeepMF has learned, we can collect the embedding representation of each user and each item in the CF RS. 11 Let ùê∏ ‚àó = { ‚ü® ùë¢, [ ùëí ùë¢ 0 , ùëí ùë¢ 1 , ‚Ä¶ , ùëí ùë¢ ùê∏ ] ‚ü© , ‚àÄ ùë¢ ‚àà ùëà } , be the set of embeddings for all the RS users. ( ùë¢ ‚àà[1 ... # ùëà ] , one to u) 12 Let ùê∏ ‚àó ( ùë¢ ) = [ ùëí ùë¢ 0 , ùëí ùë¢ 1 , ‚Ä¶ , ùëí ùë¢ ùê∏ ] Knowledge-Based Systems 280 (2023) 111016 5 J. Bobadilla et al. Fig. 2. The stages of the proposed GANRS method. 13 Let ùê∏ ‚àó‚àó = { ‚ü® ùëñ, [ ùëí ùëñ 0 , ùëí ùëñ 1 , ‚Ä¶ , ùëí ùëñ ùê∏ ] ‚ü© , ‚àÄ ùëñ ‚àà ùêº } , be the set of embed- dings for all the RS items. ( ùëñ ‚àà[1 ... # ùêº ] , one to i) 14 Let ùê∏ ‚àó‚àó ( ùëñ ) = [ ùëí ùëñ 0 , ùëí ùëñ 1 , ‚Ä¶ , ùëí ùëñ ùê∏ ] ‚Ä¢ Stage 3. Setting the dataset of embeddings 15 Let ùëÖ = [ ‚ü® ùê∏ ‚àó ( ùë¢ ) , ùê∏ ‚àó‚àó ( ùëñ ) , ùë£ ‚ü© ] , ‚àÄ ‚ü® ùë¢, ùëñ, ùë£ ‚ü© ùëó ‚àà ùëÜ be the embedding- based dataset of real samples. ‚Ä¢ Stage 4. GAN training 16 Let ùëì ùê∑ be the discriminator D model belonging to a GAN model. 17 Let ùëì ùê∫ be the generator G model belonging to a GAN model. 18 Let ùëì ùê∫ùê∑ be the optimization function of the GAN model; ùëì ùê∫ùê∑ = ùëÄùëñùëõ ùê∫ ùëÄùëéùë• ùê∑ ùëì ( ùê∑, ùê∫ ) = ùê∏ ùëÖ [ ùëôùëúùëî ( ùê∑ ( ùëÖ ))] + ùê∏ ùëß [ ùëôùëúùëî (1 ‚àí ùê∑ ( ùê∫ ( ùëß )))] , where ùê∏ ùëÖ is the expected value for real samples, ùëß is the random noise that feeds the generator ùê∫ , and ùê∏ ùëß is the expected value for the generated fake profiles ùê∫ ( ùëß ) . Note that ùëÖ refers to [15]. ‚Ä¢ Stage 5. GAN generation 19 Let ùêπ = ùëì ùê∫ ( ùëß ) be the generated dataset of fake samples from different random noise vectors ùëß . ‚Ä¢ Stage 6. Clustering of items and users. 20 Let ùêæ ‚àó be the number of clusters used to group the embed- dings of the users. 21 Let ùêæ ‚àó‚àó be the number of clusters used to group the embeddings of the items. 22 Let ‚Ñé ‚àó ( ùë¢ ) = ùëê | ùëê ‚àà{1 , ‚Ä¶ , ùêæ ‚àó } , be the clustering operation that assigns a centroid to each user. 23 Let ‚Ñé ‚àó‚àó ( ùëñ ) = ùëê | ùëê ‚àà{1 , ‚Ä¶ , ùêæ ‚àó‚àó } , be the clustering operation that assigns a centroid to each item. ‚Ä¢ Stage 7. Setting dataset of item IDs and user IDs 24 Let H be the item IDs and users IDs discrete dataset ob- tained from the embedding-based dataset F of fake sam- ples. ùêª = { ‚ü® ‚Ñé ‚àó ( ùë¢ ) , ‚Ñé ‚àó‚àó ( ùëñ ) , ùë£ ‚ü©| ‚àÄ ‚ü® ùê∏ ‚àó ( ùë¢ ) , ùê∏ ‚àó‚àó ( ùëñ ) , ùë£ ‚ü© ‚àà ùêπ } 25 Let ùëÜ = { ùêª } be the synthetic generated dataset version of H where duplicated samples are removed. 26 Let ùê∫ ‚Ä≤ = { ‚ü® ‚Ñé ‚àó ( ùë¢ ) , ‚Ñé ‚àó‚àó ( ùëñ ) , ùë£ ‚ü© ‚àà ùêª | ‚àÑ ‚ü® ‚Ñé ‚àó ( ùë¢ ‚Ä≤ ) , ‚Ñé ‚àó‚àó ( ùëñ ‚Ä≤ ) , ùë£ ‚Ä≤ ‚ü© ‚àà ùêª where ‚Ñé ‚àó ( ùë¢ ) = ‚Ñé ‚àó ( ùë¢ ‚Ä≤ ) ‚àß ‚Ñé ‚àó ( ùëñ ) = ‚Ñé ‚àó‚àó ( ùëñ ) ‚àß ùë£ ‚â† ùë£ ‚Ä≤ } Fig. 2 shows the seven designed stages to generate different syn- thetic datasets from real datasets (Movielens, Netflix, etc.). Stage 1 (top left graph in Fig. 2 ) shows the training of a DeepMF model used to set both the embedding layer of users and the embedding layer of items. Basically, embedding layers in a neural network efficiently convert an input from a sparse representation into an output dense representation. For each input sample ‚ü® ùë¢ùë†ùëíùëü, ùëñùë°ùëíùëö, ùëüùëéùë°ùëñùëõùëî ‚ü© in the training set, the output dot layer combines the embedding layer values to predict the rating value and to obtain the output error ‚Äò‚Äò(rating - prediction)‚Äô‚Äô that will we backpropagated to update the learning parameters. Steps 6 to 10 formalize these concepts. Once the DeepMF model has learned, Stage 2 (top right graph in Fig. 2 ) shows the DeepMF feedforward process where each item ID (from one to the number of items in the dataset, range [1 ... # ùêº ] ) feeds the item embedding, which outputs the item ID dense representation; usually, CF embedding vectors have a size from 5 to 10. The same applies to user IDs as input and their output dense representations. Please note that the number of items in the dataset will be different from the number of users. Steps 11 to 14 explain this second stage. The purpose of the third stage is to convert the source sparse CF dataset into its dense representation. To accomplish the task, for each source ‚ü® ùë¢ùë†ùëíùëü, ùëñùë°ùëíùëö, ùëüùëéùë°ùëñùëõùëî ‚ü© sample in the dataset (e.g.: ‚ü® 8920 , 345 , 4 ‚ü© ) we replace the user ID (8920 in this example) with its related dense representation; the same applies for the item ID. Using embeddings of size 5, the result in the example could be such as: Knowledge-Based Systems 280 (2023) 111016 6 J. Bobadilla et al. Table 1 Example of samples representation. Sparse Dense < ùüñùüóùüé , 47 , 5 > < [ ùüé . ùüéùüë , ùüé . ùüóùüí , ùüè . ùüéùüê , ùüé . ùüñùüï , ‚àí ùüé . ùüïùüñ ] , [‚àí1 . 23 , 0 . 99 , 1 . 02 , 0 . 65 , ‚àí0 . 48] , 5 > < ùüñùüóùüé , ùüëùüè , 4 > < [ ùüé . ùüéùüê , ùüé . ùüóùüì , ùüé . ùüóùüó , ùüé . ùüñùüè , ‚àí ùüé . ùüîùüó ] , [ ùüé . ùüíùüì , ‚àí ùüé . ùüïùüñ , ùüé . ùüñùüë , ‚àí ùüé . ùüèùüì , ùüé . ùüéùüó ] , 4 > < 968 , ùüëùüè , 4 > < [‚àí1 . 04 , 0 . 04 , 0 . 66 , ‚àí0 . 67 , 0 . 11] , [ ùüé . ùüíùüê , ‚àí ùüé . ùüïùüè , ùüé . ùüñùüé , ‚àí ùüé . ùüèùüé , ùüé . ùüèùüí ] , 4 > < 123 , ùüëùüè , 2 > < [1 . 56 , ‚àí1 . 12 , 0 . 33 , 1 . 22 , ‚àí0 . 87] , [ ùüé . ùüíùüë , ‚àí ùüé . ùüïùüì , ùüé . ùüñùüé , ‚àí ùüé . ùüèùüè , ùüé . ùüéùüî ] , 2 > ‚ü® [0 . 03 , 0 . 94 , 1 . 02 , 0 . 87 , ‚àí0 . 78] , [‚àí1 . 23 , 0 . 99 , 1 . 02 , 0 . 65 , ‚àí0 . 48] , 4 ‚ü© . Stage 3 in Fig. 2 shows an illustrative example. Step 15 formalizes the operation. The dense dataset obtained will be used in Stage 4 to train a GAN capable of generating fake user and item profiles, as well as their associated rating values, which will be, even at this stage, the ratings that will be in the dataset generated at the end of the proposal. Our GAN will use the Stage 3 dense dataset to train the discriminator by providing it with the necessary real samples. The GAN generator takes Gaussian random noise as input and iteratively learns how to generate increasingly good fake profiles capable of cheating the discriminator model. Once the generator and the discriminator have learnt, the generator can convert input noise vectors into dense samples that mimic the patterns of the real dataset provided in stage 3. Stage 4 is formalized in steps 16 to 18 . The last stage in Fig. 2 (bottom left graph) uses the trained GAN generator model (Stage 4) to generate as many fake samples as desired. We feed the generator with successive vectors of random noise values following a Gaussian distribution, and the generator outputs successive fake dense samples following the patterns of the real dataset (obtained in Stage 3). The higher the standard deviation of the Gaussian distribu- tion, the higher the variety of individual values in the generated dense fake samples. As an example, a low standard deviation value in the ran- dom noise Gaussian distribution leads to a higher proportion of votes ‚Äò3‚Äô (ranging from 1 to 5), while choosing a high standard deviation value will produce a higher density of votes ‚Äò5‚Äô and ‚Äò1‚Äô. Ratings are generated in the same way as items and users: they are coded in the dense embedding generated by the GAN. Synthetic ratings are continuous values, whereas real ratings are discrete, usually in the range {1 , ‚Ä¶ , 5} . To make this conversion, a function assigns the maximum value in the range (usually ‚Äò5‚Äô) to the synthetic continuous values greater than it; analogously the function assigns the minimum value (usually ‚Äò1‚Äô) to the continuous values lower than it. Finally, a round function is performed to ensure discrete values. Step 19 formalizes the generation of fake samples. Although the GANRS method could be considered complete, this is not the case because our goal is to generate fake datasets of sparse samples (such as Movielens or Netflix); it is then necessary to convert from the obtained dense representation in Stage 5 to the usual sparse representation seen in Stage 1. The process is not straightforward, since all the dense representations of the fake samples are different from each other; this will be better explained using the example in Table 1 : it can be observed that user 890 (two first rows) has very similar dense embedding values, but there are not identical, since the GAN generator is not able to create the same exact values from the noise input vectors. The same situation occurs in Table 1 for the item with ID 31. Consequently, the GANRS method provides a way to ‚Äògroup‚Äô similar dense embeddings into a unique ID; that is, to convert the dense bold vectors of the user in Table 1 into a unique user ID (need not be 890), and the dense bold vectors of the item into a unique item ID (need not be 31, either). To group similar dense embeddings into a unique ID, a K-Means clustering [ 59 ] has been chosen. This algorithm has the relevant feature that a number K of clusters must be chosen a priori, and it is very con- venient in this context, since, in this way, we will have the opportunity to establish the number of users and the number of items in the GANRS synthetic generated dataset. Stage 6 of Fig. 2 shows this concept, where Table 2 Main parameter values of the tested datasets. Dataset #users #items #ratings Scores Sparsity Movielens 100K 943 1682 99,831 1 to 5 93.71 Netflix* 23,012 1,750 535,421 1 to 5 98.68 MyAnimeList 19,179 2,692 548,967 1 to 10 98.94 ùêæ ‚àó has been selected as number of users and ùêæ ‚àó‚àó has been selected as number of items. Two separate K-Means processes are run: one to group user embeddings, and the other to group item embeddings. Steps 20 to 23 formalize these two clustering processes. To better understand this stage, we can consider an example where one million fake samples have been generated and we want to create a synthetic dataset containing two thousand fake users and one thousand fake items. To accomplish this task, we should obtain two thousand groups collected from the one million user vectors (the same for the one thousand item groups). On average, five hundred user vectors could be assigned to each user group (and, analogously, one thousand item vectors to each item group), but we know that this depends on the user and item vector patterns. To adequately accomplish the grouping task, machine learning provides us with clustering algorithms, of which the k-means allow us to set the number of desired groups (two thousand for users and one thousand for items, in our example). Running both clustering processes (one for users and the other for items) we can assign a fake user ID to all the fake user vectors in each cluster. Please note that the ID number can be assigned at random to each of the two thousand clusters (the same for the one thousand item IDs). Fig. 3 illustrates the concept where graphs at the top show the two k-means clustering processing performed in the proposed model: one to group item vectors (yellow circles), and the other one to group user vectors (orange circles). Gray ellipses represent the k-means clustering groups. All the fake user vectors in each cluster collapse into the same user vector, which codes a sample representative of its group, and is different from the samples in the rest of the clusters (same for items). In this way, we obtain the selected representative K* users and K** items. The graphs at the bottom in Fig. 3 show the final stages of the proposed method; Stage 6 draws the K* clusters of users and the K** clusters of items, from the previous clustering with blue circles. Each of the K* clusters (of users) groups a set of user vectors (columns of orange squares), and each of the K** clusters (of items) groups a set of item vectors (columns of yellow squares). Each cluster of user vectors collapses into a representative user: at the bottom of Stage 6 graph (the same for items). Once the representative users and items are set, we can generate the fake dataset of embeddings by translating each generated embedding sample (bottom-right graph) to its equivalent representative concatenated embedding of representative (collapsed) users and items (at the bottom of the Stage 6 graph). Previously, we illustrated a case where a generated sample collapses its item vector in the ‚Äò‚Äòitem 3‚Äô‚Äô representative code (vector of red squares), and it collapses its user vector in the ‚Äò‚Äòuser 1‚Äô‚Äô representative code (vector of brown squares). In stage 7 the complete embedding, and the translation to the ‚ü® 1 , 3 , 5 ‚ü© sparse tuple codification can be seem. This is also true for the following fake embedding, which collapses in the ‚Äò‚Äòitem 1‚Äô‚Äô (green) and ‚Äò‚Äòuser 3‚Äô‚Äô (blue), generating the sparse tuple < 3,2,4>. Note that the GAN- generated profiles (bottom-right in Fig. 3 ) are not limited to a fixed number of users and items, whereas their Stage 7 version (bottom-left in Fig. 3 ) are limited to the ranges {1 , ‚Ä¶ , ùêæ ‚àó} , and {1 , ‚Ä¶ , ùêæ ‚àó‚àó} , making it possible to preset the number of users and items of the synthetic dataset. The seventh stage in Fig. 2 converts dense fake samples (coming from Stage 5) into sparse samples ‚ü® ùë¢ùë†ùëíùëü, ùëñùë°ùëíùëö, ùëüùëéùë°ùëñùëõùëî ‚ü© . To accomplish this task, for each sample in the dense representation we replace its user vector with its centroid number (from 1 to ùêæ ‚àó ) and its item vector with its centroid number (from 1 to ùêæ ‚àó‚àó ); the rating value remains the same as that already generated by the framework in Stages 4‚Äì5. Knowledge-Based Systems 280 (2023) 111016 7 J. Bobadilla et al. Fig. 3. Top graphs: clustering process to collapse user and item similar vectors into their representative user and item representations. Bottom graphs: translation from unlimited fake limited profiles to profiles in the range ‚ü® {1 ‚Ä¶ ùêæ ‚àó } , {1 ..ùêæ ‚àó‚àó } , ùëüùëéùë°ùëñùëõùëî ‚ü© . Fig. 2 shows an example of this operation, formalized in Step 24 . Please note that repeated samples will appear in the previous discretization process, since the GAN generator can create very similar dense samples that will be converted to the same discrete encoding. There are several factors that modulate the number of repeated samples, such as the number of generated samples, the embedding size, the size of the noise vector and the standard deviation of the Gaussian distribution, but the most relevant factor is the number of chosen users or items ( ùêæ ‚àó and ùêæ ‚àó‚àó ): the lower the ùêæ , the higher the number of repeated samples. When the number of users or items is low, the average number of samples grouped in each cluster is high. Step 25 formalizes the process of removing repeated discrete samples. Finally, the GANRS method can generate a small proportion of samples in which different votes are cast from the same user to the same item; e.g.: ‚ü® 879 , 56 , 4 ‚ü© , ‚ü® 879 , 56 , 5 ‚ü© . This could be considered as a convenient behavior: code a higher range of votes (4.5 in the example) or express a change in the user‚Äôs opinion. These cases can be unchanged, changed, or removed. Step 26 formalizes their removal operation. Overall, it is important to keep in mind that new rating values are initially calculated in the context of Stage 4 of the proposal, where GAN is used for generating the fake samples of pairs ‚ü® ùë¢ùë†ùëíùëü, ùëñùë°ùëíùëö, ùëüùëéùë°ùëñùëõùëî ‚ü© , using the user and item embeddings obtained in the previous stages as a base. Afterward, our methodology refines the obtained data to assure consistency (Stages 5‚Äì7). Appendix A ( Table 4 ) shows the main parameter and hyperparam- eter values used to design both the models DeepMF and GAN involved in the proposed GANRS method. 4. Experiments and results Evaluating the quality of the generated datasets and comparing them with state-of-art synthetic datasets is not straightforward, since the traditional measures only cover distribution probabilities. This is the case of the Kullback‚ÄìLeibler (KL) divergence ùê∑ ùêæùêø ( ùëÉ ‚à• ùëÑ ), where ùëÉ and ùëÑ are two probability distributions. In our context, we face two main drawbacks to applying the KL divergence or any similar divergence measure: 1) ùëÉ and ùëÑ are not distribution probabilities; they are datasets, and (2) a low ùê∑ ùêæùêø value does not mean that ùëÑ (the generated dataset) is a good synthetic dataset obtained from ùëÉ (the source dataset). In fact, if ùê∑ ùêæùêø = 0 , usually ùëÉ = ùëÑ , which is not a useful result. Of course, each CF dataset contains a reduced number of representative distribution probabilities, including: rating, user, and item distributions ( ùëÑ ùë¢ , ùëÑ ùëñ , ùëÑ ùëü ); but comparing each distribution of the generated dataset with the corresponding distribution of the source dataset has the same intrinsic problem as explained above: ùê∑ ùêæùêø ( ùëÉ ùë¢ ‚à• ùëÑ ùë¢ ) = 0 , ùê∑ ùêæùêø ( ùëÉ ùëñ ‚à• ùëÑ ùëñ ) = 0 , ùê∑ ùêæùêø ( ùëÉ ùëü ‚à• ùëÑ ùëü ) = 0 , does not mean that ùëÑ is a suitable synthetic dataset with regard to ùëÉ , indeed ùëÑ must have a certain degree of variability regard to ùëÉ . A common alternative approach that is used to deal with these situations is testing the quality results in the specific domain; in our case MAE, precision, recall, etc. Results should be interpreted according to graph trends rather than absolute values, since better results just mean that ùëÑ patterns are less complicated than ùëÉ ones, and worse results tell us that ùëÑ patterns are more complicated than ùëÉ ones. Which scenario is better? It depends on the objectives of the scientist that generates the synthetic datasets. Addressing the concerns explained, we provide a complete set of comparative graphs between the source ( ùëÉ ) and generated datasets ( ùëÑ ), including probability distributions of the user, item, rating, and precision and recall trends. Designing specific quality measures that maximize each scientist‚Äôs objectives (required distribution variability, required complexity in the resulting patterns, etc.) is challenging re- search, and would help compare state-of-art generative approaches, but this is out of the scope of this paper. In this paper we evaluate the suitability of the presented procedure focused on building synthetic datasets. First, the traditional data sets to be used as a starting point for the present procedure are presented, as well as a description of the experiments to be performed. Subsequently, the obtained results are presented and discussed. 4.1. Experiments To test the behavior of the proposed GANRS method, we will use three representative and open datasets in the CF field: Movielens [ 60 ], Netflix and MyAnimeList. We have chosen the 100K version of Movie- lens and a reduced version of the complete Netflix dataset: Netflix*, available in [ 61 ]. Table 2 shows the main parameter values for these datasets. A complete set of experiments has been run using Netflix*, whereas only a subset of these experiments is shown for Movielens and MyAnimeList, to reduce the size of the paper. Results from the Movielens and MyAnimeList tests are summarized at the end of this section. Each of the three source datasets is used to generate its corre- sponding synthetic version: setting different numbers of users, items, and samples, and changing the standard deviation of the Gaussian random noise. Knowledge-Based Systems 280 (2023) 111016 8 J. Bobadilla et al. Table 3 Parameter values of the synthetic datasets generated by GAN. Source: Netflix*. # std #users #items # std #users #items # std #users #items #samples 1 2.0 100 4000 6 2.5 100 4000 11 3.0 100 4000 1.5M 2 2.0 1000 4000 7 2.5 1000 4000 12 3.0 1000 4000 3 2.0 2000 4000 8 2.5 2000 4000 13 3.0 2000 4000 4 2.0 4000 4000 9 2.5 4000 4000 14 3.0 4000 4000 5 2.0 8000 4000 10 2.5 8000 4000 15 3.0 8000 4000 16 1.5 4000 2000 17 1.5 4000 8000 18 1.2 2000 4000 150K 19 1.2 2000 4000 500K 20 1.2 2000 4000 1M 21 1.2 2000 4000 3M Experiments have been carried out using the neural DeepMF model. Training, validation, and testing sets have been obtained for all the real datasets (Netflix*, MyAnimeList, and Movielens 100K), and their corresponding synthetic datasets. The source code to train the model and test the results is the same for both the real and generated datasets; ensuring the consistency of the graphs in the comparative figures ( Figs. 4 a, 4 b, 7 b, 7 e, 8 b and 7 e). Table 3 shows the GAN generated synthetic datasets used to test the proposed GANRS method, using Netflix* as source data. The ‚Äô#‚Äô columns show the number of the generated datasets; ‚Äòstd‚Äô is the stan- dard deviation used in the random noise Gaussian distribution; #users and #items are the total number of users and items chosen to generate each dataset; #samples is the number of fake samples created by the GAN generator. Please note that the final number of samples contained in each of the datasets is lower than #samples, due to the removing process of repeated samples. Cases 1 to 15 in Table 3 are used to test the effect of changing standard deviation and number of users. Cases 16 and 17 test the consequences of increasing the number of items. Finally, cases 18, 19 and 20 test the behavior of the synthetic datasets when they have different sizes (number of samples). All generated datasets and the source code of the proposed GANRS method are fully available in http://suleiman.ujaen.es:8061/gitlab-instance-981c80cc/ ganrs . Additionally, Appendix B ( Fig. 9 ) shows an example of the dis- tribution graphs obtained for each of the synthetic datasets. Following the link provided, each generated dataset is located in its specific directory where a ‚Äôreadme.txt‚Äô file is provided along the synthetic dataset distribution graphs. Using the parameter values of Table 3 , a variety of experiments have been conducted. The classification of the experiments is as follows: 1. Number of users (a) Distribution of users versus ratings (b) Distribution of the user ratings (c) Number of repeated samples (d) Proportion of samples with the same user and item (e) MAE and accuracy of the data set (f) Users‚Äô precision and recall 2. Number of items (a) MAE and accuracy of the dataset (b) Item‚Äôs precision and recall 3. Number of samples (a) Number of samples generated (b) Precision and Recall These experiments refer to well-known metrics in collaborative filtering. Precision is focused on measuring the proportion of relevant rec- ommendations (i.e. the user rated the item with a rating value equal or greater than a threshold ùúÉ ) among the top ùëÅ items recommended to the user ùë¢ , collected in the list ùëá ùëÅ ùë¢ (Eq. (4) ). On the other hand, Recall mea- sures the proportion of correctly predicted relevant recommendations among the total number of relevant votes of each user; therefore, recall is sensitive to the existing proportions of relevant ratings (Eq. (5) ). ùëÉùëüùëíùëêùëñùë†ùëñùëúùëõ = 1 # ùëà ‚àë ùë¢ ‚àà ùëà | { ùëñ ‚àà ùëá ùëÅ ùë¢ | ùëü ùë¢ùëñ ‚â• ùúÉ } | ùëÅ (4) ùëÖùëíùëêùëéùëôùëô = 1 # ùëà ‚àë ùë¢ ‚àà ùëà | { ùëñ ‚àà ùëá ùëÅ ùë¢ | ùëü ùë¢ùëñ ‚â• ùúÉ } | | { ùëñ ‚àà ùëá ùëÅ ùë¢ | ùëü ùë¢ùëñ ‚â• ùúÉ } | + | { ùëñ ‚àâ ùëá ùëÅ ùë¢ | ùëü ùë¢ùëñ ‚â• ùúÉ } | (5) Where ùëà is the set of training users, ùëü ùë¢ùëñ is the rating of the training user ùë¢ for the item ùëñ , ùëÅ is the number of recommendations, and ùëá ùëÅ ùë¢ is the set of ùëÅ recommendations for the test user ùë¢ : ùëÅ highest predictions of the user ùë¢ above the relevancy threshold ùúÉ . Please note that Precision measures the proportion of recommenda- tion hits (hits with respect to number of recommendations), whereas Recall measures the proportion of recommendation hits with respect to the total number of relevant items. Precision takes into consideration the number of true positives, whereas Recall combines both the true positives and the false negatives. The importance of the precision and the recall quality measures largely depends on the scenario in which they are applied, e.g. Recall seems to be crucial in medicine, where a false negative is a serious mistake (i.e. not detecting cancer). Nevertheless, Recall is less important in RS since missing a relevant film (false negative) is not serious; the objective is to maximize a correctly recommended film (true positives). The F1 quality measure combines both Precision and Recall (Eq. (6) ). ùêπ 1 = 2 ‚àó ùëÉùëüùëíùëêùëñùë†ùëñùëúùëõ ‚àó ùëÖùëíùëêùëéùëôùëô ùëÉùëüùëíùëêùëñùë†ùëñùëúùëõ + ùëÖùëíùëêùëéùëôùëô (6) Finally, this paper also tests accuracy (Eq. (7) ), where true negatives are also considered. In this case both the positive and the negative hits contribute to the results (to positively recommend relevant items and to negatively recommend non relevant items). ùê¥ùëêùëêùë¢ùëüùëéùëêùë¶ = | { ùëñ ‚àà ùëÜ ùë° | ùëù ùë¢ùëñ ‚â• ùúÉ ‚àß ùëü ùë¢ùëñ ‚â• ùúÉ } | + | { ùëñ ‚àà ùëÜ ùë° | ùëù ùë¢ùëñ < ùúÉ ‚àß ùëü ùë¢ùëñ < ùúÉ } | | ùëÜ ùë° | (7) Where ùëÜ ùë° is the set of test samples, and each sample is the tuple ‚ü® ùë¢, ùëñ, ùëü ‚ü© containing the user ID, item ID and rating of the user u for the item ùëñ ( ùëü ùë¢ùëñ ). The model prediction of the rating is ùëù ùë¢ùëñ . Two values of the threshold ùúÉ will be explored across the experimen- tal scenario when precision, recall, F1, and accuracy quality measures are tested Note that the accuracy quality measure does not use the term ùëá ùëÅ ùë¢ since the typical RS does not include negative recommendations. Accordingly, this accuracy formulation does not average users‚Äô results and acts on the entire training data, such as we have done with the Mean Absolute Error (Eq. (8) ). ùëÄùê¥ùê∏ = 1 | ùëÜ ùë° | ‚àë ùë† ‚àà ùëÜ ùë° | ùëù ùë¢ùëñ ‚àí ùëü ùë¢ùëñ | , ùë¢, ùëñ ‚àà ùëÜ (8) Knowledge-Based Systems 280 (2023) 111016 9 J. Bobadilla et al. Fig. 4. (a) Distribution of users versus ratings. Number of items: 4000. Datasets 8 and 10 in Table 3 ;(b) Distribution of user ratings. Number of users: 2000; number of items: 4000. Datasets 3, 8 and 13 in Table 3 ;(c) Number of samples remaining after removing the repeated ones. items: 4000. Datasets 6 to 10 in Table 3 ;(d) Proportion of samples in which the same user has cast different votes for the same item. items: 4000. Datasets 6 to 10 in Table 3 ;(e) MAE and accuracy. Number of users: 2000; number of items: 4000; ‚Äòstd‚Äô is the standard deviation of the Gaussian random noise distribution. Datasets 1 to 15 in Table 3 ;(f) Precision, recall, and F1. Standard deviation of the random noise Gaussian distribution: 2.5. Number of recommendations ùëÅ = [2,4,6,8,10]. Datasets 6 to 10 in Table 3 . 4.2. Results This subsection shows the graphs obtained when the designed ex- periments (previous subsection) are run. The synthetic datasets de- scribed in Table 3 are used to obtain results that allow us: (1) to compare the distributions of users, items and ratings belonging to the source datasets, in relation to those obtained using the synthetic datasets, (2) to measure the number of repeated samples returned in the clustering stage, and (3) to test the prediction and recommendation qualities and trends obtained by running the proposed RSGAN method and comparing them to those shown by the source datasets. 4.2.1. Experiment 1a. Number of users: Distribution of users versus ratings Fig. 4 a shows the density of users (y-axis) that have cast different numbers of votes (x-axis). (Selected datasets: 8 and 10 in Table 3 ). As expected, for a fixed number of ratings in the dataset, we can observe that the higher the number of users, the lower the number of ratings. If the fixed number of samples in the dataset is distributed among a high number of users, each user centroid in the clustering stage receives a lower number of samples. Please, note that Netflix* contains around 23,000 users. 4.2.2. Experiment 1b. Distribution of the user ratings Fig. 4 b shows the proportion of each rating 1,...,5 (x-axis) when different random noise Gaussian distributions are applied. (Selected datasets: 3, 8 and 13). It can be observed that the standard deviation 2.5 generates a more similar distribution of votes, compared to the Netflix* original, than the adjacent standard distributions 2 and 2.5. Fig. 4 b also shows the impact of the Gaussian standard deviation in the layout of the individual values of the GAN-generated samples. 4.2.3. Experiment 1c. Number of repeated samples As explained in the ‚ÄòMethod‚Äô section, the trained GAN generator predicts from random noise vectors as many dense samples as we want; all these samples are then converted from continuous dense values to discrete sparse ones. In the discretization process, repeated samples will appear that must be removed ( Table 1 contains an example). Fig. 4 c shows the number of samples remaining in the dataset after the removal process. The lower the number of users, the higher the number of samples assigned to each user (to its centroid in the clustering process), and therefore the higher the probability of repeating discrete samples. Overall, the smaller the number of users, the smaller the number of remaining samples. Selected datasets: 6 to 10 in Table 3 . 4.2.4. Experiment 1d. Proportion of samples with the same user and item The GANRS generated datasets possess one attribute that does not exist in the source datasets (Movielens, etc.): they contain a proportion of samples where the same user has cast different votes for the same item; e.g.: ‚ü® 348 , 90 , 5 ‚ü© , ‚ü® 348 , 90 , 4 ‚ü© , as explained in the ‚ÄòMethod‚Äô section. This can be seen as a mechanism to allow intermediate votes (4.5 in the example) or to allow users to change their minds. This makes sense if, the number of repeated votes is two or three. The rare cases of four or five repeated votes should be removed, just as we have done in all the generated datasets. From the standard quality metrics to measure the accuracy of predictions: Mean Absolute Error (MAE) and Root Mean Square Error (RMSE), we have chosen the former since it is the most widely used in RS state-of-art research. Some papers provide both measures, but experimental research shows that in the CF field, results for RMSE and MAE are very similar. This is because the distribution of the errors in the CF field usually has little variance. The MAE returns the absolute difference between the predicted values and the real values in the testing set: ùëÄùê¥ùê∏ = 1 ùëõ ‚àë ùëñ | ùë¶ ùëñ ‚àí ÃÇùë¶ ùëñ | . The lower the MAE, the better the model fits a dataset. The RMSE uses the square of the error instead of the absolute value: ùëÄùê¥ùê∏ = 1 ùëõ ‚àë ùëñ ( ùë¶ ùëñ ‚àí ÃÇùë¶ ùëñ ) 2 ; therefore, the RMSE is more sensitive to observations that are further from the mean, and this is not the case in CF. Fig. 4 d shows that for regular CF RS (1000 or more users), the proportion of four or five repetitions is not significant, and as the number of users increases, the proportion of repetitions drops very fast. 4.2.5. Experiment 1e. MAE and accuracy of the dataset Whereas the previous experiments analyze the internal composition and distribution of the synthetic datasets, this experiment and the Knowledge-Based Systems 280 (2023) 111016 10 J. Bobadilla et al. following experiment test the behavior of the generated datasets on the prediction and recommendation tasks. Fig. 4 e shows the prediction quality (MAE) and the accuracy of the recommendation obtained from each set of individual samples in Datasets 1 to 15 in Table 3 . Please note that these measures are not obtained by analyzing and averaging the results of users. The graphs in Fig. 4 e show an improvement in accuracy (and its corresponding decrease in MAE error) as the number of users increases. This behavior is expected in the CF RS, where a high number of users leads to better predictions, and it tells us that the GAN- generated samples follow a CF convenient pattern. The MAE values in the top graph of Fig. 4 e are closely related to the distribution of ratings for each of the standard deviations 2.0, 2.5 and 3.0. MAE/accuracy results can be used to select the most appropriate standard deviation; in this case: std = 2.5. 4.2.6. Experiment 1f. Users‚Äô precision and recall This experiment provides the most significant results to test the generated datasets: we extract the values and evolutions of two repre- sentative recommendation quality measures: precision and recall. The top graphs in Fig. 4 f show the quality values obtained testing several numbers of recommendations N: [2,4,6,8,10] (x-axis), two different relevancy thresholds ùúÉ : [4,5], and two number of users: 2000 (green lines), and 8000 (blue lines). The standard deviation of the Gaussian random noise has been set to 2.5. Selected datasets: 6 to 10 in Table 3 . The values and evolutions obtained from the synthetic datasets fit with the source dataset: Netflix* (black lines). Additionally, as expected, the overall results of the dataset generated by 8000 users outperform those of the 2000 users and are closer to the Netflix* reference (please note that Netflix* contains around 23,000 users). The two bottom graphs in Fig. 4 f represent the F1 combination of precision and recall; they clearly show the similarity in the behavior of the generated datasets compared to the source dataset. 4.2.7. Experiment 2a. MAE and accuracy when the number of items varies. Experiment 1e tested MAE and accuracy quality measures on datasets with different numbers of users. Now we will test both quality measures on datasets with different numbers of items: [100, 1K, 2K, 4K, 8K]. The results in Fig. 5 show adequate values for both MAE and accuracy, and consistent evolutions where accuracy increases and MAE decreases as the number of items (x-axis) increases. Thus, the higher the number of items, the better the accuracy: this shows that the GAN generator can enrich the data. The Netflix * source dataset contains 1750 items and we can observe in Fig. 5 a how the improvement slows down around this value (x-axis). Selected datasets: 16 and 17 in Table 3 , and the 100, 1000, 4000 user versions not included in Table 3 . 4.2.8. Experiment 2b. Items‚Äô precision and recall Experiment 2b is similar to Experiment 1f; now we will test the behavior of datasets that contain different numbers of items (instead of different numbers of users). Fig. 5 b shows the performance of Netflix* (1750 items), represented using black lines, and compares it with the 2000 item dataset (green lines) and the 8000 item dataset (blue lines). We can observe that evolutions and values are consistent with the source datasets (black lines); furthermore, both the 2K and 4K items versions perform well: the first one conveniently captures the Neflix* patterns of items, since both contain a similar number of items. The dataset generated second (8K items) can enrich the data and show better accuracy than the 2K items version. Selected datasets: 16 and 17 in Table 3 , and the 100, 1000, 4000 user versions not included in Table 3 . 4.2.9. Experiment 3a. Number of samples generated in datasets with differ- ent sizes Here we will test the number of samples that the GANRS method obtains when different numbers of generated samples and different numbers of users have been set. For this purpose, we define four different numbers of samples: 150K, 500K, 1M and 3M (Datasets 18 to 21 in Table 3 , and their equivalent datasets for 100, 1000, 4000 and 8000 users) in the GAN generation process. The number of items is fixed at 4K for all experiments. In Fig. 6 a we can observe that the smaller the number of users, the smaller the number of generated samples; this is due to the fact that the smaller the number of users, the higher the number of samples assigned to each user (to each centroid in the clustering stage), and therefore the higher the probability of repeated samples that will be removed. As an example, Fig. 6 shows that the 8K user dataset preserves, approximately, 1M samples from the GAN generated (version 3M), and 600K in version 1M. 4.2.10. Experiment 3b. Precision and recall on datasets with different sizes This experiment shows the impact of increasing the number of samples in datasets with fixed parameters, in this case: 2000 users, 4000 items, and a standard deviation of 1.2 ( Table 3 ; Datasets 18, 19 and 21). It is important to realize that we are using the same source dataset Netflix* to generate the three cases shown in Fig. 6 b: 150K samples (yellow lines), 500K samples (magenta lines), and 3M samples (red lines). Please note that 150K, 500K and 3M samples refer to the dense and continuously generated samples, prior to the removal stage to convert them into their sparse, discrete version. Fig. 6 a shows the final sizes of the datasets in the 2000 user data (x-axis). Fig. 6 b compares the precision and recall values obtained in the Netflix* dataset (black lines) with the generated values. Overall: (1) precision increases and recall decreases; (2) the bigger the generated dataset, the better its precision; (3) the higher the dataset, the lower its recall. Precision results improve when using large datasets, as there are more relevant samples to choose from, and therefore it is easier to succeed in the fixed number ùëÅ of recommended predictions. On the other hand, recall gets worse using large datasets because they contain more variability in the samples, particularly when large standard devi- ations have been chosen for the random noise Gaussian distribution. Unlike precision, whose denominator is the constant ùëÅ (number of recommendations), the recall quality measure depends on the variable: ‚Äònumber of relevant votes‚Äô in the set of test items for each user tested. As the number of samples increases, the number of user votes also increases (and, from them, the number of relevant votes); this is the reason why recall is lower in the 3M synthetic dataset in Fig. 6 b, and higher in the 150K version. Figs. 7 and 8 show, respectively, the results obtained from the MyAnimeList and Movielens 100K test datasets. Graph ‚Äô(a)‚Äô compares the rating distribution of each source dataset (in blue) with the gen- erated rating distributions obtained by setting different values of the Gaussian random noise standard deviation. We have chosen the stan- dard deviation value of 1.2 for MyAnimeList, and the standard devia- tion value of 2.5 for Movielens 100K, since the obtained distributions of ratings are closest to their respective baselines. Results ‚Äò(b)‚Äô, ‚Äò(c)‚Äô and ‚Äò(e)‚Äô are obtained using the selected standard deviation values. Graph ‚Äò(b)‚Äô shows the distribution of users according to their number of casted ratings (x-axis). As expected, they follow the same pattern as the one in Netflix*. To compare results, please note that MyAnimelist dataset contains 19,179 users, and Movielens 100K contains 943 users. Graph ‚Äò(c)‚Äô shows the number of samples left after removing repeated instances. The higher the number of users, the lower the probability of generating samples containing the same user ID, item ID, and rating. In the MyAnimeList case, we started with 1.5 million generated samples, whereas for Movielens we selected 1 million generated samples. Graph ‚Äò(d)‚Äô refers to MAE error and accuracy values obtained by processing the individual samples contained in each dataset. As usual in the CF context, the higher the number of users, the lower the error, and the higher the accuracy. Finally, Graphs ‚Äò(e)‚Äô tests the recommendations obtained by processing the users in each dataset. As is with Netflix*, compared to baselines, precision improves and recall gets worse. Knowledge-Based Systems 280 (2023) 111016 11 J. Bobadilla et al. Fig. 5. (a) MAE and accuracy obtained from the dataset samples when the number of items varies. Number of users: 4000. Standard deviation of the Gaussian random noise: 1.5. Datasets 16 and 17 in Table 3 ;(b) Precision, recall, and F1 when the number of items varies. Standard deviation of the random noise Gaussian distribution: 1.5. Number of recommendations ùëÅ = [2, 4, 6, 8, 10]. Datasets 16 and 17 in Table 3 . Fig. 6. (a) Number of generated samples using different number of users (x axis) and different number of GAN generated samples (legend). Standard deviation of the random noise Gaussian distribution: 1.2. Number of items: 4000. Datasets 18 to 21 in Table 3 ;(b) Precision and recall using a different number of recommendations (x axis) and a different number of GAN generated samples (legend). Standard deviation of the random noise Gaussian distribution: 1.2. Datasets 18, 19 and 21 in Table 3 . The results obtained in this section highlight the importance of those that test the performance of the synthetic datasets against the source datasets, particularly when specific RS metrics are used. To check the consistency between synthetic and real data, two types of Knowledge-Based Systems 280 (2023) 111016 12 J. Bobadilla et al. Fig. 7. MyAnimeList. 1.5 million generated samples, (a) distribution of the MyAnimeList ratings 1 to 10, (b) distribution of users according to their number of casted ratings, (c) number of samples after the removing process of the repeated ones, (d) error and accuracy by processing the samples of the dataset, (e) CF precision and recall (by testing the dataset users). The GANRS std = 1.2 value has been set to test experiments (b) to (e). experiments have been conducted: direct and indirect. In direct com- parisons, rating distributions have been obtained and compared from both source datasets and their synthetic versions. Figs. 4 b and 4 c show the Netflix* results by varying the number of generated users and the standard deviation of the random Gaussian distribution used to feed the proposed GAN. Figs. 7 b and 8 b show, respectively, comparison of the MyAnimeList and the Movielens 100K datasets, in this case by varying the number of users in the synthetic datasets versus their equivalent source counterparts. Indirect experiments tested and compared the recommendation performance on both the synthetic and the source datasets. We have chosen the recommendation quality measures of pre- cision, recall and F1, obtained using the classical neural model DeepMF. Results can be found in Fig. 4 f (Netflix* vs. its synthetic version), Fig. 7 e (MyAnimeList vs. its synthetic version), and Fig. 8 e (Movielens 100K vs. its synthetic version). Overall, as expected, the results show that synthetic datasets behave like their source datasets. The more similar the results are, the more suitable the generated datasets will be, as this means that the original datasets can be effectively replaced by synthetic ones. 4.3. Comparison of the proposed framework with previous work The Related Works section identifies some previous work focused on data generation methods for recommender systems. In this subsection, a brief analysis will be performed, which will focus on showing how this previous work is not truly comparable with our current proposal in a fair way, since it is focused on different objectives and also generates data of a different nature. ‚Ä¢ Mladenov et al. [ 53 ] presented RecSim NG, an architecture cen- tered on the generation of synthetic profiles of users and items as part of the recommendation environment. Overall, the goal of the work is the development of a configurable platform for both authoring and learning RS simulation environments. The aim of this simulation is to evaluate existing RS policies, or generate data to train new policies (in either a tightly coupled online fashion, or in batch mode). Furthermore, this paper lacks information about the presented method, and therefore does not allow reproducibility. ‚Ä¢ Shi et al. [ 54 ] introduce a multi-agent reinforcement learning architecture tailored to Taobao-specific website search improve- ment, and uses a GAN to simulate the internal rating distribu- tion. Therefore, considering that it is focused on data generation for a specific context, it is not comparable with the framework proposed in the current paper. ‚Ä¢ Del Carmen et al. [ 56 ] introduce DataGenCars, a Java-based generator of RS synthetic data. Here it is important to remark that this work is specifically focused on the context-aware recom- mendation scenario. In this sense, even though the proposed tool supports the generation of synthetic datasets of users, items, con- texts, and ratings; this generation always relies on context-related characteristics through criteria introduced throughout the work, such as the uncertainty of the content, the user‚Äôs expectations or the item‚Äôs attributes. As result, this work is not comparable with the methodology presented in our current paper, which mainly uses rating values as input and does not consider datasets with contextual information. Knowledge-Based Systems 280 (2023) 111016 13 J. Bobadilla et al. Fig. 8. Movielens 100K results. 1 million generated samples, (a) Distribution of the Movielens 100K ratings 1 to 5, (b) Distribution of users according to their number of casted ratings, (c) Number of samples after the removal process of the repeated ones, (d) error and accuracy by processing the samples of the dataset, (e) CF precision and recall (by testing the dataset users). The GANRS std = 2.5 value has been set to test experiments (b) to (e). ‚Ä¢ Provalov et al. [ 57 ] introduce the SynEvaRec framework, focused on the presentation of a novel paradigm for evaluating recom- mendations based on the generation of synthetic RS datasets. In contrast to our current paper, this approach is mainly focused on generating synthetic user and item profiles that are internally used by SynEvaRec to guarantee user privacy protection, mitigate the data insufficiency problem, and measure the effect of the no-free-lunch problem. Regarding the aim of the architecture proposed in Provalov et al. [ 57 ] is not the proper retrieval of the whole synthetic rating datasets to be used in further evaluations (i.e. an evaluation protocol is presented rather than a dataset generation method), a major transformation of their work is needed to make it comparable with this paper. A fair comparison is then not possible at this stage. 4.4. Overall discussion A large number of synthetic datasets have been generated to test the performance of the proposed GANRS method. These datasets have been created setting different values for the main parameters of the method: number of users, number of items, Gaussian random noise variation, and number of generated samples. To generalize the conclusions of this paper, three open and representative CF datasets have been used as sources for the generative process. Finally, a variety of quality measures have been tested on the generated datasets; of these, precision and recall are the most relevant. A key issue is that we are not able to visually test the quality of the generated samples, as can be done, for example, with the popular fake faces; in fact, in the CF context, we only can adequately test the generated datasets by comparing their CF quality results with those typically obtained in real CF datasets. For this reason, we have focused on the designed experiments in which the quality measures of precision and recall are tested: using datasets containing different numbers of users, different numbers of items, and different numbers of samples (sizes). In all cases, comparatively, we obtain excellent precision results and moderate recall values. Overall, it can be considered positive in the CF context, where precision errors are serious and recall errors are less important: it is worse to recommend a trip you will not like (sorry, no refunds!) than not to recommend a trip that you probably would enjoy. Please note that it is the opposite for a deep learning model detecting malignant tumors: it is worse to make precision errors (no early detection of the tumor) than making recall errors (to erroneously detect a tumor). Additionally, experiments show the relevant impact of the standard deviation on the quality of the results. The GAN network learning has been based on a vector containing noise values that serves as a seed to generate the different samples in the synthetic dataset. Each ‚Äòfake‚Äô sample is generated from the list of random values in the ‚Äònoise‚Äô vector. As usual in the GAN context, random values have been created from Knowledge-Based Systems 280 (2023) 111016 14 J. Bobadilla et al. a Gaussian distribution with a mean of 0 and a standard deviation of 1. Each generated sample contains a dense item representation, a dense user representation, and an individual value that codes the user‚Äôs rating of the item. Once the GAN has learned, its generative model can be used, in a feedforward process, to generate as many samples as we want, starting from a different random noise vector for each sample generated. Experimental results show that using a Gaussian distribution with a standard deviation of 1 leads to many ratings in the middle of the voting range: rating 3 and closest in the 1 to 5 voting range (Movielens and Netflix), and rating 5 and closests in 1 to 10 voting range (MyAnimeList). Several experiments in this section demonstrate that we can modulate the standard deviation of the Gaussian distribution of random noise to generate a wider range of ratings using feedforward. As expected, when the standard deviation increases, the range of ratings also increases proportionally. Finally, the experiments presented include the existing relationship between the number of fake samples generated for the GAN and the number of samples that the dataset will eventually contain. As explained in the ‚ÄòMethod‚Äô section, the conversion from dense and continuous values to sparse and discrete values leads to a probability of sample repetitions. Results show that, as expected, the larger the number of users and items in the synthetic dataset, the lower the number of repeated samples. It has also been shown that for a typical number of users, say 4000 or more, the probability of more than two different ratings from one user for the same item can be considered negligible. 5. Conclusions This paper provides an innovative method for generating synthetic parameterized collaborative filtering datasets from real datasets. Syn- thetic datasets can be generated by selecting different numbers of users, items, samples, and distribution variability. This means that comparative experiments can be designed on the basis of a whole ‚Äòfamily‚Äô of generated datasets, for example, to test the accuracy of a new matrix factorization model when the number of users increases. A GAN is used to obtain ‚Äòfake‚Äô samples from real samples, benefitting from the inherent capacity of GAN networks to capture complex patterns in the source datasets. The GAN learns from dense and continuous embedding representations of items and users, rather than the sparse and discrete representations of the collaborative filtering datasets. The effect is a fast and accurate learning process. The proposed GANRS method contains a clustering stage to convert from the dense generated ‚Äòfake‚Äô samples to the sparse and discrete values necessary to fill the generated dataset. This clustering stage implements a k-means algorithm to group items and another k-means to group users. In a natural way, both ‚Äòk‚Äô parameters set the chosen num- ber of users and items in the dataset. A drawback of the discretization process is the generation of identical samples that our method merely removes. A complete set of experiments have been made using three representative source datasets. We have tested the distribution values and evolutions of the results, as well as prediction and recommendation qualities. Although precision tends to improve, while recall tends to worsen, overall accuracy can be considered correct, since precision is more relevant than recall in the RS context. The results show that the generated datasets conveniently mimic the behavior of the source datasets Movielens, MyAnimeList, etc. The source code for the proposed GANRS method is available to ensure the reproducibility of the experiments. Similarly, a complete set of generated datasets has been made available for research. This paper and its related documentation open the door to address some future work, such as designing alternative options to the clustering stage, implementing the PacGAN concept in the GAN discriminator, testing generated datasets using a complete range of machine learning and deep learning collaborative filtering models, replacing the GAN model with a CGAN one, generating demographically balanced datasets, and performing an in-depth study of the impact of the random noise vector variations in the generated set of samples. CRediT authorship contribution statement Jes√∫s Bobadilla: Conceptualization, Validation, Formal analysis, Investigation, Software, Writing ‚Äì original draft, Writing ‚Äì review & editing, Visualization. Abraham Guti√©rrez: Conceptualization, Valida- tion, Formal analysis, Investigation, Software, Writing ‚Äì original draft, Visualization. Raciel Yera: Methodology, Validation, Formal analysis, Writing ‚Äì original draft , Visualization. Luis Mart√≠nez: Methodology, Validation, Writing ‚Äì original draft. Declaration of competing interest The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability The link to the data and code has been shared in the manuscript. Acknowledgments This work was partially supported by Ministerio de Ciencia e Inno- vaci√≥n of Spain under the project PID2019-106493RB-I00 (DL-CEMG); the Comunidad de Madrid, Spain under Convenio Plurianual with the Universidad Polit√©cnica de Madrid, Spain in the actuation line of Programa de Excelencia para el Profesorado Universitario; and the Plan Andaluz de Investigaci√≥n, Desarrollo e Innovaci√≥n (PAIDI 2020), Spain under the project PROYEXCEL_00257. Appendix A See Table 4 . Table 4 Main parameter and hyperparameter values set for the neural models involved in the RSGAN method. DeepMF values Embedding size (both for users an items) 5 Optimizer Adam Loss function Mean squared error Epochs 20 GAN generator Input shape, noise vector size 100 Block 1 dense layer #neurons 10 Block 1 activation function LeakyRelu, alpha 0.2 Block 1 normalization BatchNormalization, momentum 0.8 Block 2 dense layer #neurons 20 Block 2 activation function LeakyRelu, alpha 0.2 Block 2 regularization Dropout 0.2 Block 3 dense layer #neurons 2 ‚àó ùëíùëöùëèùëíùëëùëëùëñùëõùëîùë†ùëñùëßùëí + 1 Block 3 activation function linear GAN discriminator Input: shape 2 ‚àó ùëíùëöùëèùëíùëëùëëùëñùëõùëîùë†ùëñùëßùëí + 1 Block 1 dense layer #neurons 6 Block 1 activation function LeakyRelu, alpha 0.2 Block 2 dense layer 1 Block 2 activation function Sigmoid GAN train Epochs 20 Batch size 64 Stochastic noise Gaussian (0,1) Loss function ( ùëüùëíùëéùëôùë†ùëéùëöùëùùëôùëíùë†ùëôùëúùë†ùë† + ùëìùëéùëòùëíùë†ùëéùëöùëùùëôùëíùë†ùëôùëúùë†ùë† )‚àï2 Knowledge-Based Systems 280 (2023) 111016 15 J. Bobadilla et al. Appendix B See Fig. 9 . Fig. 9. Main distributions of the data in the synthetic dataset generated from Movielens 100K compared to the distributions of the data in the source dataset. Number of users: 8000, number of items: 4000, initial number of samples: 800,000, standard deviation of the Gaussian noise: 2.5. Graph (a) shows the distribution of the fake users (y axis) versus the number of ratings belonging to each of the users (x axis). Graph (b) shows the distribution of the fake items (y axis) versus the number of ratings belonging to each of the items (x axis). Graph (c) shows the percentage of ratings (y axis) for each of the available vote values 1, 2, 3, 4, 5 (x axis) in the dataset. References [1] Z. Fang, L. Zhang, K. Chen, A behavior mining based hybrid recommender system, in: 2016 IEEE International Conference on Big Data Analysis, ICBDA, IEEE, 2016, pp. 1‚Äì5. [2] R. Yera, L. Mart√≠nez, Fuzzy tools in recommender systems: A survey, Int. J. Comput. Intell. Syst. 10 (1) (2017) 776‚Äì803. [3] R. Yera, A.A. Alzahrani, L. Mart√≠nez, A fuzzy content-based group recommender system with dynamic selection of the aggregation functions, Internat. J. Approx. Reason. 150 (2022) 273‚Äì296. [4] L. Zheng, V. Noroozi, P.S. Yu, Joint deep modeling of users and items using reviews for recommendation, in: Proceedings of the Tenth ACM International Conference on Web Search and Data Mining, 2017, pp. 425‚Äì434. [5] Y. Gong, Q. Zhang, Hashtag recommendation using attention-based convolutional neural network., in: IJCAI, 2016, pp. 2782‚Äì2788. [6] H. Kanwal, M. Assam, A. Jabbar, S. Khan, et al., Convolutional neural network and topic modeling based hybrid recommender system, Int. J. Adv. Comput. Sci. Appl. 11 (7) (2020). [7] K. McNally, M.P. O‚ÄôMahony, B. Smyth, A comparative study of collaboration- based reputation models for social recommender systems, User Model. User-Adapt. Interact. 24 (3) (2014) 219‚Äì260. [8] N.M. Villegas, C. S√°nchez, J. D√≠az-Cely, G. Tamura, Characterizing context-aware recommender systems: A systematic literature review, Knowl.-Based Syst. 140 (2018) 173‚Äì200. [9] M. Moradi, J. Hamidzadeh, Ensemble-based top-k recommender system considering incomplete data, J. AI Data Min. 7 (3) (2019) 393‚Äì402. [10] M. Jalili, S. Ahmadian, M. Izadi, P. Moradi, M. Salehi, Evaluating collaborative filtering recommender algorithms: a survey, IEEE Access 6 (2018) 74003‚Äì74024. [11] B. Zhu, R. Hurtado, J. Bobadilla, F. Ortega, An efficient recommender system method based on the numerical relevances and the non-numerical structures of the ratings, IEEE Access 6 (2018) 49935‚Äì49954. [12] R. Yera, A.A. Alzahrani, L. Mart√≠nez, Exploring post-hoc agnostic models for explainable cooking recipe recommendations, Knowl.-Based Syst. 251 (2022) 109216. [13] E. D‚ÄôAmico, G. Gabbolini, C. Bernardis, P. Cremonesi, Analyzing and improving stability of matrix factorization for recommender systems, J. Intell. Inf. Syst. 58 (2) (2022) 255‚Äì285. [14] M.H. Aghdam, A novel constrained non-negative matrix factorization method based on users and items pairwise relationship for recommender systems, Expert Syst. Appl. 195 (2022) 116593. [15] G. Ayci, A. K√∂ksal, M.M. Mutlu, B. Suyunu, A.T. Cemgil, Active learning with Bayesian nonnegative matrix factorization for recommender systems, in: 2019 27th Signal Processing and Communications Applications Conference, SIU, IEEE, 2019, pp. 1‚Äì4. [16] J. Bobadilla, R. Bojorque, A.H. Esteban, R. Hurtado, Recommender systems clustering using Bayesian non negative matrix factorization, IEEE Access 6 (2017) 3549‚Äì3564. [17] H.-J. Xue, X. Dai, J. Zhang, S. Huang, J. Chen, Deep matrix factorization models for recommender systems, in: IJCAI, Vol. 17, Melbourne, Australia, 2017, pp. 3203‚Äì3209. [18] X. He, L. Liao, H. Zhang, L. Nie, X. Hu, T.-S. Chua, Neural collaborative filtering, in: Proceedings of the 26th International Conference on World Wide Web, 2017, pp. 173‚Äì182. [19] J. Bobadilla, R. Lara-Cabrera, A. Gonzalez-Prieto, F. Ortega, DeepFair: Deep learning for improving fairness in recommender systems., Int. J. Interact. Multimed. Artif. Intell. 6 (6) (2021) 86‚Äì95. [20] Y. Himeur, A. Alsalemi, A. Al-Kababji, F. Bensaali, A. Amira, C. Sardianos, G. Dimitrakopoulos, I. Varlamis, A survey of recommender systems for energy efficiency in buildings: Principles, challenges and prospects, Inf. Fusion 72 (2021) 1‚Äì21. [21] J. Bobadilla, J. Due√±as, A. Guti√©rrez, F. Ortega, Deep variational embedding representation on neural collaborative filtering recommender systems, Appl. Sci. 12 (9) (2022) 4168. [22] J. Bobadilla, √Å. Gonz√°lez-Prieto, F. Ortega, R. Lara-Cabrera, Deep learning approach to obtain collaborative filtering neighborhoods, Neural Comput. Appl. 34 (4) (2022) 2939‚Äì2951. [23] S. Zhang, L. Yao, A. Sun, Y. Tay, Deep learning based recommender system: A survey and new perspectives, ACM Comput. Surv. 52 (1) (2019) 1‚Äì38. [24] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, Y. Bengio, Generative adversarial networks, Commun. ACM 63 (11) (2020) 139‚Äì144. [25] D. Sacharidis, Diversity and novelty in social-based collaborative filtering, in: Proceedings of the 27th ACM Conference on User Modeling, Adaptation and Personalization, 2019, pp. 139‚Äì143. [26] A. Gogna, A. Majumdar, DiABlO: Optimization based design for improving diversity in recommender system, Inform. Sci. 378 (2017) 59‚Äì74. [27] J. Bobadilla, A. Gutierrez, S. Alonso, √Å. Gonz√°lez-Prieto, Neural collaborative filtering classification model to obtain prediction reliabilities, Int. J. Interact. Multimed. Artif. Intell. 7 (4) (2022) 18‚Äì26. Knowledge-Based Systems 280 (2023) 111016 16 J. Bobadilla et al. [28] F. Pajuelo-Holguera, J.A. G√≥mez-Pulido, F. Ortega, Evaluating strategies for selecting test datasets in recommender systems, in: International Conference on Hybrid Artificial Intelligence Systems, Springer, 2019, pp. 243‚Äì253. [29] K.D. Bollacker, S. Lawrence, C.L. Giles, CiteSeer: An autonomous web agent for automatic retrieval and identification of interesting publications, in: Proceedings of the Second International Conference on Autonomous Agents, 1998, pp. 116‚Äì123. [30] W. Choochaiwattana, Usage of tagging for research paper recommendation, in: 2010 3rd International Conference on Advanced Computer Theory and Engineering, Vol. 2, ICACTE, IEEE, 2010, pp. V2‚Äì439. [31] J. Shokeen, C. Rana, Social recommender systems: techniques, domains, metrics, datasets and future scope, J. Intell. Inf. Syst. 54 (3) (2020) 633‚Äì667. [32] Y. Xing, I. Mohallick, J.A. Gulla, √ñ. √ñzg√∂bek, L. Zhang, An educational news dataset for recommender systems, in: Joint European Conference on Machine Learning and Knowledge Discovery in Databases, Springer, 2020, pp. 562‚Äì570. [33] F. Ortega, J. Bobadilla, A. Guti√©rrez, R. Hurtado, X. Li, Artificial intelligence scientific documentation dataset for recommender systems, IEEE Access 6 (2018) 48543‚Äì48555. [34] D. Liang, R.G. Krishnan, M.D. Hoffman, T. Jebara, Variational autoencoders for collaborative filtering, in: Proceedings of the 2018 World Wide Web Conference, 2018, pp. 689‚Äì698. [35] S. Zamany, D. Li, H. Fei, P. Li, Towards deeper understanding of variational auto-encoders for binary collaborative filtering, in: Proceedings of the 2022 ACM SIGIR International Conference on Theory of Information Retrieval, 2022, pp. 254‚Äì263. [36] M. Gao, J. Zhang, J. Yu, J. Li, J. Wen, Q. Xiong, Recommender systems based on generative adversarial networks: A problem-driven perspective, Inform. Sci. 546 (2021) 1166‚Äì1185. [37] Y. Deldjoo, T.D. Noia, F.A. Merra, A survey on adversarial recommender systems: from attack/defense strategies to generative adversarial networks, ACM Comput. Surv. 54 (2) (2021) 1‚Äì38. [38] D.-K. Chae, J.-S. Kang, S.-W. Kim, J.-T. Lee, Cfgan: A generic collaborative filtering framework based on generative adversarial networks, in: Proceedings of the 27th ACM International Conference on Information and Knowledge Management, 2018, pp. 137‚Äì146. [39] Z. Wang, M. Gao, X. Wang, J. Yu, J. Wen, Q. Xiong, A minimax game for generative and discriminative sample models for recommendation, in: Pacific- Asia Conference on Knowledge Discovery and Data Mining, Springer, 2019, pp. 420‚Äì431. [40] W. Zhao, B. Wang, J. Ye, Y. Gao, M. Yang, X. Chen, Plastic: Prioritize long and short-term information in top-n recommendation using adversarial training, in: Ijcai, 2018, pp. 3676‚Äì3682. [41] H. Bharadhwaj, H. Park, B.Y. Lim, Recgan: recurrent generative adversarial net- works for recommendation systems, in: Proceedings of the 12th ACM Conference on Recommender Systems, 2018, pp. 372‚Äì376. [42] G. Guo, H. Zhou, B. Chen, Z. Liu, X. Xu, X. Chen, Z. Dong, X. He, IPGAN: Generating informative item pairs by adversarial sampling, IEEE Trans. Neural Netw. Learn. Syst. (2020). [43] J. Zhao, H. Li, L. Qu, Q. Zhang, Q. Sun, H. Huo, M. Gong, DCFGAN: An adver- sarial deep reinforcement learning framework with improved negative sampling for session-based recommender systems, Inform. Sci. 596 (2022) 222‚Äì235. [44] J. Sun, B. Liu, H. Ren, W. Huang, NCGAN:: A neural adversarial collaborative filtering for recommender system, J. Intell. Fuzzy Systems 42 (4) (2022) 2915‚Äì2923. [45] Y. Lin, Z. Xie, B. Xu, K. Xu, H. Lin, Info-flow enhanced GANs for recommender, in: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2021, pp. 1703‚Äì1707. [46] Q. Wang, Q. Huang, K. Ma, X. Zhang, A recommender system based on model regularization wasserstein generative adversarial network, in: 2021 IEEE International Conference on Systems, Man, and Cybernetics, SMC, IEEE, 2021, pp. 2043‚Äì2048. [47] J. Wen, X.-R. Zhu, C.-D. Wang, Z. Tian, A framework for personalized recom- mendation with conditional generative adversarial networks, Knowl. Inf. Syst. 64 (10) (2022) 2637‚Äì2660. [48] G. Deng, C. Han, D.S. Matteson, Extended missing data imputation via GANs for ranking applications, Data Min. Knowl. Discov. (2022) 1‚Äì23. [49] H. Chen, S. Wang, N. Jiang, Z. Li, N. Yan, L. Shi, Trust-aware generative adversarial network with recurrent neural network for recommender systems, Int. J. Intell. Syst. 36 (2) (2021) 778‚Äì795. [50] G. Van Houdt, C. Mosquera, G. N√°poles, A review on the long short-term memory model, Artif. Intell. Rev. 53 (2020) 5929‚Äì5955. [51] W. Shafqat, Y.-C. Byun, A hybrid GAN-based approach to solve imbalanced data problem in recommendation systems, IEEE Access 10 (2022) 11036‚Äì11047. [52] Z. Lin, A. Khetan, G. Fanti, S. Oh, Pacgan: the power of two samples in generative adversarial networks, in: Proceedings of the 32nd International Conference on Neural Information Processing Systems, 2018, pp. 1505‚Äì1514. [53] M. Mladenov, C.-w. Hsu, V. Jain, E. Ie, C. Colby, N. Mayoraz, H. Pham, D. Tran, I. Vendrov, C. Boutilier, Demonstrating principled uncertainty modeling for recommender ecosystems with RecSim NG, in: Fourteenth ACM Conference on Recommender Systems, 2020, pp. 591‚Äì593. [54] J.-C. Shi, Y. Yu, Q. Da, S.-Y. Chen, A.-X. Zeng, Virtual-taobao: Virtualizing real- world online retail environment for reinforcement learning, in: Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33‚Äì01, 2019, pp. 4902‚Äì4909. [55] C.-N. Ziegler, S.M. McNee, J.A. Konstan, G. Lausen, Improving recommendation lists through topic diversification, in: Proceedings of the 14th International Conference on World Wide Web, 2005, pp. 22‚Äì32. [56] M. del Carmen Rodr√≠guez-Hern√°ndez, S. Ilarri, R. Hermoso, R. Trillo-Lado, DataGenCARS: A generator of synthetic data for the evaluation of context-aware recommendation systems, Pervasive Mob. Comput. 38 (2017) 516‚Äì541. [57] V. Provalov, E. Stavinova, P. Chunaev, SynEvaRec: A framework for evalu- ating recommender systems on synthetic data classes, in: 2021 International Conference on Data Mining Workshops, ICDMW, IEEE, 2021, pp. 55‚Äì64. [58] A. Cossu, A. Carta, V. Lomonaco, D. Bacciu, Continual learning for recurrent neural networks: an empirical evaluation, Neural Netw. 143 (2021) 607‚Äì627. [59] M. Ahmed, R. Seraj, S.M.S. Islam, The k-means algorithm: A comprehensive survey and performance evaluation, Electronics 9 (8) (2020) 1295. [60] F.M. Harper, J.A. Konstan, The movielens datasets: History and context, ACM Trans. Interact. Intell. Syst. (TIIS) 5 (4) (2015) 1‚Äì19. [61] F. Ortega, B. Zhu, J. Bobadilla, A. Hernando, CF4j: Collaborative filtering for java, Knowl.-Based Syst. 152 (2018) 94‚Äì99.",knowledgebased system available online september author published elsevier bv open access article cc license httpcreativecommonsorglicensesby content list available sciencedirect knowledgebased system journal homepage wwwelseviercomlocateknosys creating synthetic datasets collaborative filtering recommender system generative adversarial network jes√∫s bobadilla abraham guti√©rrez raciel yera b luis mart√≠nez b departamento de sistemas inform√°ticos etsi sistemas inform√°ticos universidad polit√©cnica de c alan turing sn spain b departamento de inform√°tica universidad ja√©n ja√©n spain r c l e n f keywords recommender system generative adversarial network deep learning collaborative filtering b r c research education machine learning requires diverse representative open datasets contain sufficient sample handle necessary training validation testing task currently recommender system area includes large number subfields accuracy beyondaccuracy quality measure continuously improved feed research variety necessary convenient reinforce existing datasets synthetic one proposes generative adversarial network ganbased generate collaborative filtering datasets parameterized way selecting preferred number user item sample stochastic variability parameterization performed regular gans gan fed dense short continuous embedding representation item user instead sparse large discrete vector ensure fast accurate learning compared traditional large sparse input vector proposed architecture includes deepmf extract dense user item embeddings clustering process convert dense gan generated sample discrete sparse sample necessary create required synthetic dataset result three different source datasets show adequate distribution expected quality value evolution generated datasets compared source datasets synthetic datasets source code available researcher recommender system r relevant area artificial intel ligence due growing popularity social network big company extensively use rss tripadvisor netflix spotify youtube music tiktok youtube amazon company make use r model recommend user similar item music video trip news already consumed company facebook work hard collect customer activity provide personalized advertising rather personalized product service rss usually classified according filter ing contentbased rss select recommended item looking similar content since item content text natural language processing model used review tweet two common type contentbased filtered product image also processed make recommendation convolutional neural network commonly used model perform task social filtering extensively used improve socialbased rec ommendations type filtering us tag follower corresponding author email address jesusbobadillaupmes j bobadilla abrahamgutierrezupmes guti√©rrez ryeraujaenes r yera martinujaenes l mart√≠nez followed make use concept reputation trust geographic gps coordinate poi mainly used support contextaware filtering demographic filtering age gender country etc commonly combined type filtering implementing recommendation ensemble yond previous filtering strategy collaborative filtering cf important implementing rss since provides superior accuracy particularly combined type filtering effective r research make use innovative model adequate quality measure representative datasets historical evolution cf begin use memorybased model mainly knearest neighbor memory approach replaced modelbased machine learning approach due overall performance superior accu racy result also time obtain prediction learned output capable explained post hoc technique matrix factorization mf widely used machine learning implement collaborative filtering performs dimensional reduction user item capturing httpsdoiorgjknosys received december received revised form september accepted september knowledgebased system j bobadilla et al main pattern relate vote cast additionally nonnegative matrix factorization nfm semantic meaning assigned latent factor bayesian nmf allows clustering user making prediction simultaneously open door effective recommendation user group social clustering appli cation nowadays cf research mainly developed deep learning model deepmf basis modern approach deepmf use user coded latent space mean embedding layer whereas item coded different latent space mean second embedding layer finally prediction made making dot product item user embeddings deepmf improves mf due inherent competence neural network capture nonlinear relation hip sample neural collaborative filtering ncf extensively used implement cf replaces deepmf dot layer multilayer perceptron mlp outperforms deepmf applied large complex datasets beyond accuracy deep learning model emerging perform innovative task improving fairness deepfair achieves tradeoff equity precision green computing result explanation via latent space visualization efficient neighborhood identifica tion adversarial networkbased recommendation recently introduced r area focus related work section generative adversarial network gan responsible popular fake face fake video flood social network architecture two separate neural network compete adversarial art forger competing art expert ensuring improve work gan forger generator creates fake sample random noise vector gan expert discriminator implemented simple binary classifier fake nonfake however r research mainly focused proposing novel recommendation model try make progress cf datasets respect essential identify quality measure key element carry adequate research since allow baseline state art compared proposed algorithm method model beyond usual prediction recommendation quality measure mae msd precision recall f ndcg etc measure novelty diversity recently acquired growing importance diversity cur rently main focus researcher attention due risk inappropriate recommendation social network exhibit lack variability promote prefixed idea behavior diversity reliability r improved introducing diversityenhancing constraint mf additionally deep learning classification proposed obtain recommendation reliability value softmax output layer neural network quality value obtained tested balanced cf datasets obtain balanced training testing set respect user item distribution deterministic strategy proposed r research make use popular cf datasets movielens filmtrust myanimelist citeseer cf datasets include different domain music movie poi tourism news research paper tagged etc datasets filled explicit vote user others contain implicit interaction user system also datasets filled crawled web page academic pdfs others enriched social tag researcher add ar ticles selection relevant social cf datasets provided related article recently educational news dataset released included contextualized time location finally r dataset also provided contains artificial intelligence research obtain segmented clustering geographical location beyond work particularly relevant parameterized synthetic datasets yet used consequently cf research benefit flexibility parameterization provides experiment design different dataset size number user item aim fill gap proposing procedure coined ganrs focus use gans generate collaborative filtering recommender system datasets parameterized way please note current r ganbased model simultaneously set number generated user item rating distribution regarding contribution two main overall approach identified stateofart statistical generative main ad vantage statistical several relevant parameter simultaneously set number user number item dataset size etc main drawback poor accuracy hand current modelbased generative approach improve accuracy compared statistical framework lack flexibility since parameterization limited fact current gan design focused user profile generate many new fake user required relevant parameter set number item fixed source set user vector also fake generated set user vector explained example run regular gan generate fake image synthetic image shape resolution number channel source image r field synthetic user vector contain number item real user vector following example specific gan design return superresolution image increase resolution knowledge r gans designed generate fake user containing item fewer item proposed designed simultaneously set cf relevant parameter number user item rest structured follows related work introduced section focusing recent us gan model applied r section explains proposed formalization section present design discussion experiment finally section contains main conclusion article discusses future work background basic generative adversarial network gans designed generate scratch commonly used create fake image although use spreading many domain music medicine financial etc gan architecture composes two deep network model generator discriminator generator learns create sample similar possible dataset eg dataset human face image whereas discriminator learns detect fake sample sample created generator better understand gans consider example painting forger forgery expert imitation forger paint better result better expert ability detect fake painting people successively improve ability learning begin gan discriminator forgery expert example easy job since generator painting pattern thousand learning epoch generator learnt pattern well enough confuse discriminator forced tune weight learning loop iterates enough time generator discriminator model well designed painting dataset contains suitable pattern generator able create synthetic fake sample difficult distinguish original fig show gan architecture discriminator make binary classification fake real sample generator update weight learns discriminator correctly classifies fake discriminator update weight incorrectly classifies note generator take random noise distribution input generate sample knowledgebased system j bobadilla et al fig generative adversarial network architecture learnt input random noise vector feed generator created pattern dataset sample reason providing random noise vector create many sample required mean context create fake cf datasets size creating fake profile measure gan loss use crossentropy discriminator ùê∑ loss expressed sum expectation ùëöùëéùë• ùê∑ ùëâ ùê∑ ùê∏ ùë• ùëù ùëëùëéùë°ùëé ùë• ùëôùëúùëîùê∑ ùë• ùê∏ ùëß ùëù ùëß ùëß ùëôùëúùëî ùê∑ ùê∫ ùëß first term equation used recognize real image second term recognizes generated image ùëç represents noisy vector ùê∫ generator ùê∫ ùëç generated ùê∑ ùê∫ ùëß classification discriminator input fake ùê∑ ùë• classification discriminator input real generator loss designed learn discriminator correctly classifies true label fake label equation ùëöùëñùëõ ùê∫ ùëâ ùê∫ ùê∏ ùë• ùëù ùëëùëéùë°ùëé ùë• ùëôùëúùëî ùê∑ ùê∫ ùëß gan minimax ùê∫ want minimize ùëâ ùê∑ want maximize ùëöùëñùëõ ùê∫ ùëöùëéùë• ùê∑ ùëâ ùê∑ ùê∫ ùê∏ ùë• ùëù ùëëùëéùë°ùëé ùë• ùëôùëúùëîùê∑ ùë• ùê∏ ùëß ùëù ùëß ùëß ùëôùëúùëî ùê∑ ùê∫ ùëß previous example gan model act non sparse value eg pixel picture designed work sparse vector matrix problem cf datasets contain extraordinarily sparse matrix rating user vote consume limited number available item regular gan architecture adequate addressing cfbased r proposes extended gan architecture embeddings introduced code sparse discrete vector vote dense continuous vector innovation make possible use regular gan generate dense continuous vector efficiently accurately compression stage force u design corre sponding stage decompress generated dense vector adopted solution make possible set number user item generated dataset relevant innovation stateofart related work generative deep learning innovative field cf r area although variational autoencoder approach pub lished current research mainly focused gan model cf subfield gans used attackdefense strate gy model reinforce security r neverthe less extended us cf gans solve issue noisy b tackle sparsity problem implement augmentation framework capturing distribution real cfgan generates purchase vector rather id item us generated fake purchase vector augment real vector wasserstein version cfgan unified gan ugan report improvement compared cfgan prioritize long shortterm r inter action user item change quickly slowly plastic train generator us reinforcement learning agent recurrent gan recgan learns temporal pattern rating combining gan recurrent neural network rnns model capture negative sampling cf datasets ipgan implement two different generative model one positive instance another negative instance ipgan considers relation positive rating sampled negative one selected currently dcgan combine gan reinforcement learning model catch r session rather traditional historical matrix vote user item session includes response user current recommenda tions user immediate feedback managed reinforcement learning combined gan ncgan incorporates neural network extract nonlinear feature user gan guide recommendation training generator make user recommendation whereas discriminator measure distance real generated distribution innovative improve flow generator discriminator reduces discrepancy model cf gan regularization wasserstein gan used combined autoencoder acting generator reporting accuracy improvement applied highdimensional sparse cf matrix cgan conditional gan used improve cf recommendation size rating vector set simplifying generator discriminator task additionally allows conditional rating gen eration established datasets follow standard gaussian distribution missing imputation gan proposed result show improved quality several representative clas sification set trust used make effective recommendation gan discriminator mlp generator longshort term memory network lstm finally cf datasets usually imbalanced due social collection eg young people old people address limitation proposes wasserstein gan generator pacgan concept discriminator minimize mode collapse problem platform multiagent r simulation probabilisticbased recsim generates synthetic profile user item us markov chain recurrent neural network virtual taobao multiagent reinforcement learning designed improve search social taobao website make use knowledgebased system j bobadilla et al gan simulate internal distribution simple matrix factorization used inject topic diversification recommendation pro cess datagencars javabased generator r synthetic contains statistical basement provides flexibility return low accuracy compared deep learning generative model finally synevarec framework provides generation synthetic r datasets synthetic vault svd library library model multivariate distribution copula function ctgan sublibrary includes gan model main advantage synevarec compared previous framework use different rss source main drawback poor quality result case excessive time take perform training stage previous research mainly focus improving different objective noise reduction recommendation quality prediction value defense attack balancing make happen many different approach source combined use gan cgan wasserstein gan etc gan model combined recurrent neural network lstm net work reinforcement learning introduced ganbased architecture long short introduced proposed model addition trust session log including response user previous recommendation inferred negative vote pure generation synthetic datasets seem goal novel field gan applied cf r currently focused improving prediction recommendation quality result mean augmentation inherent ability gan capture complex nonlinear pattern highdimensional sparse cf datasets innovation proposal generate representative useful cf synthetic datasets rather improve existing result varying quality additionally allows representative parameter set whole family synthetic datasets obtained taking real datasets source movielens netflix myanimelist parameter number user number item number sample variability generated varying parameter value generate different version cf pattern movielensbased dataset containing user item another contains user item among others way test accuracy performance impact dataset size sparsity number user item well check improvement mae number user increase far know published method model creating parameterized deep learning accurate scalable synthetic datasets diverse source generative adversarial networksbased set building collaborative filtering previously mentioned section research problem defined obtaining larger scalable synthetic dataset original r dataset synthesizes similar user behavior valuation pattern relation original dataset addition desirable generation parameterized allowing number user item sample variability distribution controlled next section proposes ganrs us gan network generate synthetic cf datasets gan fed real cf dataset learns internal pattern innovative contribution feed gan dense small embedding representation user item instead traditional gan input large comprise sparse vector containing vote cast user main advantage ganrs greatly reduces complexity gan architecture convergence speed performance traditional sparsebased gan architecture deal large input vector large number item dataset ten thousand require large dense layer hold huge amount usually missing since user vote consume tiny proportion available product service hence extraordinary sparsity cf datasets following huge dense layer classical gan architecture necessary stack large multilayer perceptron reduce dimensionality comparison proposed replaces large dense layer two embeddings one code user code item bor rowed deepmf first stage proposed embedding layer specifically designed deal sparse receive integer value user item id provide small embedding representation typically float value cf scenario related user item share similar embedding representation feature allows extraordinarily simplification overall proposed architecture much smaller traditional architecture contains far fewer parameter consequently learns faster additionally better capture complex nonlinear relation item user way nongan r model improve prediction formalization ganrs presented structured according following seven stage also illustrated fig stage cf definition let ùëà set user make use cf r let ùêº set item available voting cf r let ùëâ range allowed vote usually ùëâ let ùëÜ set sample contained cf dataset ùëÅ ùëÜ ùë°‚Ñéùëíùë°ùëúùë°ùëéùëôùëõùë¢ùëöùëèùëíùëüùëúùëìùë£ùëúùë°ùëíùë†ùëêùëéùë†ùë° ùëÜ ùë¢ ùëñ ùë£ ùë¢ ùëñ ùë£ ùë¢ ùëñ ùë£ ùëÅ ùë¢ ùëà ùëñ ùêº ùë£ ùëâ stage deepmf training let e size two neural layer embeddings used vectorize user item belonging ùëà ùêº respectively let ùëì ùëíùë¢ ùë¢ ùëí ùë¢ ùëí ùë¢ ùëí ùë¢ ùê∏ ùëì ùëíùë¢ embedding layer output user ùë¢ ùëà let ùëì ùëíùëñ ùëñ ùëí ùëñ ùëí ùëñ ùëí ùëñ ùê∏ ùëì ùëíùëñ embedding layer output item ùëñ ùêº com bining dense vector user item embeddings ùëí ùë¢ ùëí ùë¢ ùëí ùë¢ ùê∏ ùëí ùëñ ùëí ùëñ ùëí ùëñ ùê∏ make rating pre diction deepmf training stage dot product user embedding item embedding ùë¢ ùëñ ùë£ ùëó ùëÜ provides rating prediction ùë¶ ùëó ùëì ùëíùë¢ ùë¢ ùëì ùëíùëñ ùëñ ùëí ùë¢ ùëí ùë¢ ùëí ùë¢ ùê∏ ùëí ùëñ ùëí ùëñ ùëí ùëñ ùê∏ ùë¶ ùëó ùë¶ ùëó output error used deepmf neural network start backpropagation neural weight iteratively improved ùõø ùëó value ùë§ ùëóùëñ ùõºùë¶ ùëó ùëì ùëÅùëíùë° ùëñ ùëò ùë§ ùëñùëò ùõø ùëò ùëò hidden layer ùë§ ùëóùëñ ùõºùë¶ ùëñ ùëì ùëÅùëíùë° ùëñ ùë¶ ùëò ùë¶ ùëò ùëò output layer j k successive sequential layer ùëÅùëíùë° ùëñ represents cumulative input received artificial neuron ùëÅùëíùë° ùëñ ùëó ùë¶ ùëó ùë§ ùëó ùëó index neuron layer preceding current neuron stage deepfm feedforward deepmf learned collect embedding representation user item cf r let ùê∏ ùë¢ ùëí ùë¢ ùëí ùë¢ ùëí ùë¢ ùê∏ ùë¢ ùëà set embeddings r user ùë¢ ùëà one u let ùê∏ ùë¢ ùëí ùë¢ ùëí ùë¢ ùëí ùë¢ ùê∏ knowledgebased system j bobadilla et al fig stage proposed ganrs let ùê∏ ùëñ ùëí ùëñ ùëí ùëñ ùëí ùëñ ùê∏ ùëñ ùêº set embed ding r item ùëñ ùêº one let ùê∏ ùëñ ùëí ùëñ ùëí ùëñ ùëí ùëñ ùê∏ stage setting dataset embeddings let ùëÖ ùê∏ ùë¢ ùê∏ ùëñ ùë£ ùë¢ ùëñ ùë£ ùëó ùëÜ embedding dataset real sample stage gan training let ùëì ùê∑ discriminator belonging gan let ùëì ùê∫ generator g belonging gan let ùëì ùê∫ùê∑ optimization function gan ùëì ùê∫ùê∑ ùëÄùëñùëõ ùê∫ ùëÄùëéùë• ùê∑ ùëì ùê∑ ùê∫ ùê∏ ùëÖ ùëôùëúùëî ùê∑ ùëÖ ùê∏ ùëß ùëôùëúùëî ùê∑ ùê∫ ùëß ùê∏ ùëÖ expected real sample ùëß random noise feed generator ùê∫ ùê∏ ùëß expected generated fake profile ùê∫ ùëß note ùëÖ refers stage gan generation let ùêπ ùëì ùê∫ ùëß generated dataset fake sample different random noise vector ùëß stage clustering item user let ùêæ number cluster used group embed ding user let ùêæ number cluster used group embeddings item let ‚Ñé ùë¢ ùëê ùëê ùêæ clustering operation assigns centroid user let ‚Ñé ùëñ ùëê ùëê ùêæ clustering operation assigns centroid item stage setting dataset item id user id let h item id user id discrete dataset ob tained embeddingbased dataset f fake sam ples ùêª ‚Ñé ùë¢ ‚Ñé ùëñ ùë£ ùê∏ ùë¢ ùê∏ ùëñ ùë£ ùêπ let ùëÜ ùêª synthetic generated dataset version h duplicated sample removed let ùê∫ ‚Ñé ùë¢ ‚Ñé ùëñ ùë£ ùêª ‚Ñé ùë¢ ‚Ñé ùëñ ùë£ ùêª ‚Ñé ùë¢ ‚Ñé ùë¢ ‚Ñé ùëñ ‚Ñé ùëñ ùë£ ùë£ fig show seven designed stage generate different syn thetic datasets real datasets movielens netflix etc stage top left graph fig show training deepmf used set embedding layer user embedding layer item basically embedding layer neural network efficiently convert input sparse representation output dense representation input ùë¢ùë†ùëíùëü ùëñùë°ùëíùëö ùëüùëéùë°ùëñùëõùëî training set output dot layer combine embedding layer value predict rating obtain output error rating prediction backpropagated update learning parameter step formalize concept deepmf learned stage top right graph fig show deepmf feedforward process item id one number item dataset range ùêº feed item embedding output item id dense representation usually cf embedding vector size applies user id input output dense representation please note number item dataset different number user step explain second stage purpose third stage convert source sparse cf dataset dense representation accomplish task source ùë¢ùë†ùëíùëü ùëñùë°ùëíùëö ùëüùëéùë°ùëñùëõùëî dataset eg replace user id example related dense representation applies item id embeddings size example could knowledgebased system j bobadilla et al example sample representation sparse dense stage fig show illustrative example step formalizes operation dense dataset obtained used stage train gan capable generating fake user item profile well associated rating value even stage rating dataset generated end proposal gan use stage dense dataset train discriminator providing necessary real sample gan generator take gaussian random noise input iteratively learns generate increasingly good fake profile capable cheating discriminator generator discriminator learnt generator convert input noise vector dense sample mimic pattern real dataset provided stage stage formalized step last stage fig bottom left graph us trained gan generator stage generate many fake sample desired feed generator successive vector random noise value following gaussian distribution generator output successive fake dense sample following pattern real dataset obtained stage higher standard deviation gaussian distribu tion higher variety individual value generated dense fake sample example low standard deviation ran dom noise gaussian distribution lead higher proportion vote ranging choosing high standard deviation produce higher density vote rating generated way item user coded dense embedding generated gan synthetic rating continuous value whereas real rating discrete usually range make conversion function assigns maximum range usually synthetic continuous value greater analogously function assigns minimum usually continuous value lower finally round function performed ensure discrete value step formalizes generation fake sample although ganrs could considered complete goal generate fake datasets sparse sample movielens netflix necessary convert obtained dense representation stage usual sparse representation seen stage process straightforward since dense representation fake sample different better explained example observed user two first row similar dense embedding value identical since gan generator able create exact value noise input vector situation occurs item id consequently ganrs provides way group similar dense embeddings unique id convert dense bold vector user unique user id need dense bold vector item unique item id need either group similar dense embeddings unique id kmeans clustering chosen relevant feature number k cluster must chosen priori con venient context since way opportunity establish number user number item ganrs synthetic generated dataset stage fig show concept main parameter value tested datasets dataset user item rating score sparsity movielens k netflix myanimelist ùêæ selected number user ùêæ selected number item two separate kmeans process run one group user embeddings group item embeddings step formalize two clustering process better understand stage consider example one million fake sample generated want create synthetic dataset containing two thousand fake user one thousand fake item accomplish task obtain two thousand group collected one million user vector one thousand item group average five hundred user vector could assigned user group analogously one thousand item vector item group know depends user item vector pattern adequately accomplish grouping task machine learning provides u clustering algorithm kmeans allow u set number desired group two thousand user one thousand item example running clustering process one user item assign fake user id fake user vector cluster please note id number assigned random two thousand cluster one thousand item id fig illustrates concept graph top show two kmeans clustering processing performed proposed one group item vector yellow circle one group user vector orange circle gray ellipsis represent kmeans clustering group fake user vector cluster collapse user vector code representative group different sample rest cluster item way obtain selected representative k user k item graph bottom fig show final stage proposed stage draw k cluster user k cluster item previous clustering blue circle k cluster user group set user vector column orange square k cluster item group set item vector column yellow square cluster user vector collapse representative user bottom stage graph item representative user item set generate fake dataset embeddings translating generated embedding bottomright graph equivalent representative concatenated embedding representative collapsed user item bottom stage graph previously illustrated generated collapse item vector item representative code vector red square collapse user vector user representative code vector brown square stage complete embedding translation sparse tuple codification seem also true following fake embedding collapse item green user blue generating sparse tuple note gan generated profile bottomright fig limited fixed number user item whereas stage version bottomleft fig limited range ùêæ ùêæ making possible preset number user item synthetic dataset seventh stage fig convert dense fake sample coming stage sparse sample ùë¢ùë†ùëíùëü ùëñùë°ùëíùëö ùëüùëéùë°ùëñùëõùëî accomplish task dense representation replace user vector centroid number ùêæ item vector centroid number ùêæ rating remains already generated framework stage knowledgebased system j bobadilla et al fig top graph clustering process collapse user item similar vector representative user item representation bottom graph translation unlimited fake limited profile profile range ùêæ ùêæ ùëüùëéùë°ùëñùëõùëî fig show example operation formalized step please note repeated sample appear previous discretization process since gan generator create similar dense sample converted discrete encoding several factor modulate number repeated sample number generated sample embedding size size noise vector standard deviation gaussian distribution relevant factor number chosen user item ùêæ ùêæ lower ùêæ higher number repeated sample number user item low average number sample grouped cluster high step formalizes process removing repeated discrete sample finally ganrs generate small proportion sample different vote cast user item eg could considered convenient behavior code higher range vote example express change user opinion case unchanged changed removed step formalizes removal operation overall important keep mind new rating value initially calculated context stage proposal gan used generating fake sample pair ùë¢ùë†ùëíùëü ùëñùë°ùëíùëö ùëüùëéùë°ùëñùëõùëî user item embeddings obtained previous stage base afterward methodology refines obtained assure consistency stage appendix show main parameter hyperparam eter value used design model deepmf gan involved proposed ganrs experiment result evaluating quality generated datasets comparing stateofart synthetic datasets straightforward since traditional measure cover distribution probability kullbackleibler kl divergence ùê∑ ùêæùêø ùëÉ ùëÑ ùëÉ ùëÑ two probability distribution context face two main drawback applying kl divergence similar divergence measure ùëÉ ùëÑ distribution probability datasets low ùê∑ ùêæùêø mean ùëÑ generated dataset good synthetic dataset obtained ùëÉ source dataset fact ùê∑ ùêæùêø usually ùëÉ ùëÑ useful course cf dataset contains reduced number representative distribution probability including rating user item distribution ùëÑ ùë¢ ùëÑ ùëñ ùëÑ ùëü comparing distribution generated dataset corresponding distribution source dataset intrinsic problem explained ùê∑ ùêæùêø ùëÉ ùë¢ ùëÑ ùë¢ ùê∑ ùêæùêø ùëÉ ùëñ ùëÑ ùëñ ùê∑ ùêæùêø ùëÉ ùëü ùëÑ ùëü mean ùëÑ suitable synthetic dataset regard ùëÉ indeed ùëÑ must certain degree variability regard ùëÉ common alternative used deal situation testing quality result specific domain mae precision recall etc result interpreted according graph trend rather absolute value since better result mean ùëÑ pattern less complicated ùëÉ one worse result tell u ùëÑ pattern complicated ùëÉ one scenario better depends objective scientist generates synthetic datasets addressing concern explained provide complete set comparative graph source ùëÉ generated datasets ùëÑ including probability distribution user item rating precision recall trend designing specific quality measure maximize scientist objective required distribution variability required complexity resulting pattern etc challenging search would help compare stateofart generative approach scope evaluate suitability presented procedure focused building synthetic datasets first traditional set used starting point present procedure presented well description experiment performed subsequently obtained result presented discussed experiment test behavior proposed ganrs use three representative open datasets cf field movielens netflix myanimelist chosen k version movie lens reduced version complete netflix dataset netflix available show main parameter value datasets complete set experiment run netflix whereas subset experiment shown movielens myanimelist reduce size result movielens myanimelist test summarized end section three source datasets used generate corre sponding synthetic version setting different number user item sample changing standard deviation gaussian random noise knowledgebased system j bobadilla et al parameter value synthetic datasets generated gan source netflix std user item std user item std user item sample k k experiment carried neural deepmf training validation testing set obtained real datasets netflix myanimelist movielens k corresponding synthetic datasets source code train test result real generated datasets ensuring consistency graph comparative figure fig b b e b e show gan generated synthetic datasets used test proposed ganrs netflix source column show number generated datasets std stan dard deviation used random noise gaussian distribution user item total number user item chosen generate dataset sample number fake sample created gan generator please note final number sample contained datasets lower sample due removing process repeated sample case used test effect changing standard deviation number user case test consequence increasing number item finally case test behavior synthetic datasets different size number sample generated datasets source code proposed ganrs fully available httpsuleimanujaenesgitlabinstanceccc ganrs additionally appendix b fig show example dis tribution graph obtained synthetic datasets following link provided generated dataset located specific directory readmetxt file provided along synthetic dataset distribution graph parameter value variety experiment conducted classification experiment follows number user distribution user versus rating b distribution user rating c number repeated sample proportion sample user item e mae accuracy set f user precision recall number item mae accuracy dataset b item precision recall number sample number sample generated b precision recall experiment refer wellknown metric collaborative filtering precision focused measuring proportion relevant rec ommendations ie user rated item rating equal greater threshold ùúÉ among top ùëÅ item recommended user ùë¢ collected list ùëá ùëÅ ùë¢ eq hand recall mea sures proportion correctly predicted relevant recommendation among total number relevant vote user therefore recall sensitive existing proportion relevant rating eq ùëÉùëüùëíùëêùëñùë†ùëñùëúùëõ ùëà ùë¢ ùëà ùëñ ùëá ùëÅ ùë¢ ùëü ùë¢ùëñ ùúÉ ùëÅ ùëÖùëíùëêùëéùëôùëô ùëà ùë¢ ùëà ùëñ ùëá ùëÅ ùë¢ ùëü ùë¢ùëñ ùúÉ ùëñ ùëá ùëÅ ùë¢ ùëü ùë¢ùëñ ùúÉ ùëñ ùëá ùëÅ ùë¢ ùëü ùë¢ùëñ ùúÉ ùëà set training user ùëü ùë¢ùëñ rating training user ùë¢ item ùëñ ùëÅ number recommendation ùëá ùëÅ ùë¢ set ùëÅ recommendation test user ùë¢ ùëÅ highest prediction user ùë¢ relevancy threshold ùúÉ please note precision measure proportion recommenda tion hit hit respect number recommendation whereas recall measure proportion recommendation hit respect total number relevant item precision take consideration number true positive whereas recall combine true positive false negative importance precision recall quality measure largely depends scenario applied eg recall seems crucial medicine false negative serious mistake ie detecting cancer nevertheless recall less important r since missing relevant film false negative serious objective maximize correctly recommended film true positive f quality measure combine precision recall eq ùêπ ùëÉùëüùëíùëêùëñùë†ùëñùëúùëõ ùëÖùëíùëêùëéùëôùëô ùëÉùëüùëíùëêùëñùë†ùëñùëúùëõ ùëÖùëíùëêùëéùëôùëô finally also test accuracy eq true negative also considered positive negative hit contribute result positively recommend relevant item negatively recommend non relevant item ùê¥ùëêùëêùë¢ùëüùëéùëêùë¶ ùëñ ùëÜ ùë° ùëù ùë¢ùëñ ùúÉ ùëü ùë¢ùëñ ùúÉ ùëñ ùëÜ ùë° ùëù ùë¢ùëñ ùúÉ ùëü ùë¢ùëñ ùúÉ ùëÜ ùë° ùëÜ ùë° set test sample tuple ùë¢ ùëñ ùëü containing user id item id rating user u item ùëñ ùëü ùë¢ùëñ prediction rating ùëù ùë¢ùëñ two value threshold ùúÉ explored across experimen tal scenario precision recall f accuracy quality measure tested note accuracy quality measure use term ùëá ùëÅ ùë¢ since typical r include negative recommendation accordingly accuracy formulation average user result act entire training done mean absolute error eq ùëÄùê¥ùê∏ ùëÜ ùë° ùë† ùëÜ ùë° ùëù ùë¢ùëñ ùëü ùë¢ùëñ ùë¢ ùëñ ùëÜ knowledgebased system j bobadilla et al fig distribution user versus rating number item datasets b distribution user rating number user number item datasets c number sample remaining removing repeated one item datasets proportion sample user cast different vote item item datasets e mae accuracy number user number item std standard deviation gaussian random noise distribution datasets f precision recall f standard deviation random noise gaussian distribution number recommendation ùëÅ datasets result subsection show graph obtained designed ex periments previous subsection run synthetic datasets de scribed used obtain result allow u compare distribution user item rating belonging source datasets relation obtained synthetic datasets measure number repeated sample returned clustering stage test prediction recommendation quality trend obtained running proposed rsgan comparing shown source datasets experiment number user distribution user versus rating fig show density user yaxis cast different number vote xaxis selected datasets expected fixed number rating dataset observe higher number user lower number rating fixed number sample dataset distributed among high number user user centroid clustering stage receives lower number sample please note netflix contains around user experiment b distribution user rating fig b show proportion rating xaxis different random noise gaussian distribution applied selected datasets observed standard deviation generates similar distribution vote compared netflix original adjacent standard distribution fig b also show impact gaussian standard deviation layout individual value gangenerated sample experiment c number repeated sample explained section trained gan generator predicts random noise vector many dense sample want sample converted continuous dense value discrete sparse one discretization process repeated sample appear must removed contains example fig c show number sample remaining dataset removal process lower number user higher number sample assigned user centroid clustering process therefore higher probability repeating discrete sample overall smaller number user smaller number remaining sample selected datasets experiment proportion sample user item ganrs generated datasets possess one attribute exist source datasets movielens etc contain proportion sample user cast different vote item eg explained section seen mechanism allow intermediate vote example allow user change mind make sense number repeated vote two three rare case four five repeated vote removed done generated datasets standard quality metric measure accuracy prediction mean absolute error mae root mean square error rmse chosen former since widely used r stateofart research paper provide measure experimental research show cf field result rmse mae similar distribution error cf field usually little variance mae return absolute difference predicted value real value testing set ùëÄùê¥ùê∏ ùëõ ùëñ ùë¶ ùëñ ùë¶ ùëñ lower mae better fit dataset rmse us square error instead absolute ùëÄùê¥ùê∏ ùëõ ùëñ ùë¶ ùëñ ùë¶ ùëñ therefore rmse sensitive observation mean cf fig show regular cf r user proportion four five repetition significant number user increase proportion repetition drop fast experiment e mae accuracy dataset whereas previous experiment analyze internal composition distribution synthetic datasets experiment knowledgebased system j bobadilla et al following experiment test behavior generated datasets prediction recommendation task fig e show prediction quality mae accuracy recommendation obtained set individual sample datasets please note measure obtained analyzing averaging result user graph fig e show improvement accuracy corresponding decrease mae error number user increase behavior expected cf r high number user lead better prediction tell u gan generated sample follow cf convenient pattern mae value top graph fig e closely related distribution rating standard deviation maeaccuracy result used select appropriate standard deviation std experiment f user precision recall experiment provides significant result test generated datasets extract value evolution two repre sentative recommendation quality measure precision recall top graph fig f show quality value obtained testing several number recommendation n xaxis two different relevancy threshold ùúÉ two number user green line blue line standard deviation gaussian random noise set selected datasets value evolution obtained synthetic datasets fit source dataset netflix black line additionally expected overall result dataset generated user outperform user closer netflix reference please note netflix contains around user two bottom graph fig f represent f combination precision recall clearly show similarity behavior generated datasets compared source dataset experiment mae accuracy number item varies experiment e tested mae accuracy quality measure datasets different number user test quality measure datasets different number item k k k k result fig show adequate value mae accuracy consistent evolution accuracy increase mae decrease number item xaxis increase thus higher number item better accuracy show gan generator enrich netflix source dataset contains item observe fig improvement slows around xaxis selected datasets user version included experiment b item precision recall experiment b similar experiment f test behavior datasets contain different number item instead different number user fig b show performance netflix item represented black line compare item dataset green line item dataset blue line observe evolution value consistent source datasets black line furthermore k k item version perform well first one conveniently capture neflix pattern item since contain similar number item dataset generated second k item enrich show better accuracy k item version selected datasets user version included experiment number sample generated datasets differ ent size test number sample ganrs obtains different number generated sample different number user set purpose define four different number sample k k datasets equivalent datasets user gan generation process number item fixed k experiment fig observe smaller number user smaller number generated sample due fact smaller number user higher number sample assigned user centroid clustering stage therefore higher probability repeated sample removed example fig show k user dataset preserve approximately sample gan generated version k version experiment b precision recall datasets different size experiment show impact increasing number sample datasets fixed parameter user item standard deviation datasets important realize source dataset netflix generate three case shown fig b k sample yellow line k sample magenta line sample red line please note k k sample refer dense continuously generated sample prior removal stage convert sparse discrete version fig show final size datasets user xaxis fig b compare precision recall value obtained netflix dataset black line generated value overall precision increase recall decrease bigger generated dataset better precision higher dataset lower recall precision result improve large datasets relevant sample choose therefore easier succeed fixed number ùëÅ recommended prediction hand recall get worse large datasets contain variability sample particularly large standard devi ations chosen random noise gaussian distribution unlike precision whose denominator constant ùëÅ number recommendation recall quality measure depends variable number relevant vote set test item user tested number sample increase number user vote also increase number relevant vote reason recall lower synthetic dataset fig b higher k version fig show respectively result obtained myanimelist movielens k test datasets graph compare rating distribution source dataset blue gen erated rating distribution obtained setting different value gaussian random noise standard deviation chosen stan dard deviation myanimelist standard devia tion movielens k since obtained distribution rating closest respective baseline result b c e obtained selected standard deviation value graph b show distribution user according number casted rating xaxis expected follow pattern one netflix compare result please note myanimelist dataset contains user movielens k contains user graph c show number sample left removing repeated instance higher number user lower probability generating sample containing user id item id rating myanimelist started million generated sample whereas movielens selected million generated sample graph refers mae error accuracy value obtained processing individual sample contained dataset usual cf context higher number user lower error higher accuracy finally graph e test recommendation obtained processing user dataset netflix compared baseline precision improves recall get worse knowledgebased system j bobadilla et al fig mae accuracy obtained dataset sample number item varies number user standard deviation gaussian random noise datasets b precision recall f number item varies standard deviation random noise gaussian distribution number recommendation ùëÅ datasets fig number generated sample different number user x axis different number gan generated sample legend standard deviation random noise gaussian distribution number item datasets b precision recall different number recommendation x axis different number gan generated sample legend standard deviation random noise gaussian distribution datasets result obtained section highlight importance test performance synthetic datasets source datasets particularly specific r metric used check consistency synthetic real two type knowledgebased system j bobadilla et al fig myanimelist million generated sample distribution myanimelist rating b distribution user according number casted rating c number sample removing process repeated one error accuracy processing sample dataset e cf precision recall testing dataset user ganrs std set test experiment b e experiment conducted direct indirect direct com parisons rating distribution obtained compared source datasets synthetic version fig b c show netflix result varying number generated user standard deviation random gaussian distribution used feed proposed gan fig b b show respectively comparison myanimelist movielens k datasets varying number user synthetic datasets versus equivalent source counterpart indirect experiment tested compared recommendation performance synthetic source datasets chosen recommendation quality measure pre cision recall f obtained classical neural deepmf result found fig f netflix v synthetic version fig e myanimelist v synthetic version fig e movielens k v synthetic version overall expected result show synthetic datasets behave like source datasets similar result suitable generated datasets mean original datasets effectively replaced synthetic one comparison proposed framework previous work related work section identifies previous work focused generation method recommender system subsection brief performed focus showing previous work truly comparable current proposal fair way since focused different objective also generates different nature mladenov et al presented recsim ng architecture cen tered generation synthetic profile user item part recommendation environment overall goal work development configurable platform authoring learning r simulation environment aim simulation evaluate existing r policy generate train new policy either tightly coupled online fashion batch mode furthermore lack presented therefore allow reproducibility shi et al introduce multiagent reinforcement learning architecture tailored taobaospecific website search improve ment us gan simulate internal rating distribu tion therefore considering focused generation specific context comparable framework proposed current del carmen et al introduce datagencars javabased generator r synthetic important remark work specifically focused contextaware recom mendation scenario sense even though proposed tool support generation synthetic datasets user item con text rating generation always relies contextrelated characteristic criterion introduced throughout work uncertainty content user expectation item attribute work comparable methodology presented current mainly us rating value input consider datasets contextual knowledgebased system j bobadilla et al fig movielens k result million generated sample distribution movielens k rating b distribution user according number casted rating c number sample removal process repeated one error accuracy processing sample dataset e cf precision recall testing dataset user ganrs std set test experiment b e provalov et al introduce synevarec framework focused presentation novel paradigm evaluating recom mendations generation synthetic r datasets contrast current mainly focused generating synthetic user item profile internally used synevarec guarantee user privacy protection mitigate insufficiency problem measure effect nofreelunch problem regarding aim architecture proposed provalov et al proper retrieval whole synthetic rating datasets used evaluation ie evaluation protocol presented rather dataset generation major transformation work needed make comparable fair comparison possible stage overall discussion large number synthetic datasets generated test performance proposed ganrs datasets created setting different value main parameter number user number item gaussian random noise variation number generated sample generalize conclusion three open representative cf datasets used source generative process finally variety quality measure tested generated datasets precision recall relevant key issue able visually test quality generated sample done example popular fake face fact cf context adequately test generated datasets comparing cf quality result typically obtained real cf datasets reason focused designed experiment quality measure precision recall tested datasets containing different number user different number item different number sample size case comparatively obtain excellent precision result moderate recall value overall considered positive cf context precision error serious recall error less important worse recommend trip like sorry refund recommend trip probably would enjoy please note opposite deep learning detecting malignant tumor worse make precision error early detection tumor making recall error erroneously detect tumor additionally experiment show relevant impact standard deviation quality result gan network learning vector containing noise value serf seed generate different sample synthetic dataset fake generated list random value noise vector usual gan context random value created knowledgebased system j bobadilla et al gaussian distribution mean standard deviation generated contains dense item representation dense user representation individual code user rating item gan learned generative used feedforward process generate many sample want starting different random noise vector generated experimental result show gaussian distribution standard deviation lead many rating middle voting range rating closest voting range movielens netflix rating closests voting range myanimelist several experiment section demonstrate modulate standard deviation gaussian distribution random noise generate wider range rating feedforward expected standard deviation increase range rating also increase proportionally finally experiment presented include existing relationship number fake sample generated gan number sample dataset eventually contain explained section conversion dense continuous value sparse discrete value lead probability repetition result show expected larger number user item synthetic dataset lower number repeated sample also shown typical number user say probability two different rating one user item considered negligible conclusion provides innovative generating synthetic parameterized collaborative filtering datasets real datasets syn thetic datasets generated selecting different number user item sample distribution variability mean comparative experiment designed basis whole family generated datasets example test accuracy new matrix factorization number user increase gan used obtain fake sample real sample benefitting inherent capacity gan network capture complex pattern source datasets gan learns dense continuous embedding representation item user rather sparse discrete representation collaborative filtering datasets effect fast accurate learning process proposed ganrs contains clustering stage convert dense generated fake sample sparse discrete value necessary fill generated dataset clustering stage implement kmeans group item another kmeans group user natural way k parameter set chosen num ber user item dataset drawback discretization process generation identical sample merely remove complete set experiment made three representative source datasets tested distribution value evolution result well prediction recommendation quality although precision tends improve recall tends worsen overall accuracy considered correct since precision relevant recall r context result show generated datasets conveniently mimic behavior source datasets movielens myanimelist etc source code proposed ganrs available ensure reproducibility experiment similarly complete set generated datasets made available research related documentation open door address future work designing alternative option clustering stage implementing pacgan concept gan discriminator testing generated datasets complete range machine learning deep learning collaborative filtering model replacing gan cgan one generating demographically balanced datasets performing indepth impact random noise vector variation generated set sample credit authorship contribution statement jes√∫s bobadilla conceptualization validation formal investigation software writing original draft writing review editing visualization abraham guti√©rrez conceptualization valida tion formal investigation software writing original draft visualization raciel yera methodology validation formal writing original draft visualization luis mart√≠nez methodology validation writing original draft declaration competing interest author declare known competing finan cial interest personal relationship could appeared influence work reported availability link code shared manuscript acknowledgment work partially supported ministerio de ciencia e inno vaci√≥n spain project pidrbi dlcemg comunidad de spain convenio plurianual universidad polit√©cnica de spain actuation line programa de excelencia para el profesorado universitario plan andaluz de investigaci√≥n desarrollo e innovaci√≥n paidi spain project proyexcel_ appendix see main parameter hyperparameter value set neural model involved rsgan deepmf value embedding size user item optimizer adam loss function mean squared error epoch gan generator input shape noise vector size block dense layer neuron block activation function leakyrelu alpha block normalization batchnormalization momentum block dense layer neuron block activation function leakyrelu alpha block regularization dropout block dense layer neuron ùëíùëöùëèùëíùëëùëëùëñùëõùëîùë†ùëñùëßùëí block activation function linear gan discriminator input shape ùëíùëöùëèùëíùëëùëëùëñùëõùëîùë†ùëñùëßùëí block dense layer neuron block activation function leakyrelu alpha block dense layer block activation function sigmoid gan train epoch batch size stochastic noise gaussian loss function ùëüùëíùëéùëôùë†ùëéùëöùëùùëôùëíùë†ùëôùëúùë†ùë† ùëìùëéùëòùëíùë†ùëéùëöùëùùëôùëíùë†ùëôùëúùë†ùë† knowledgebased system j bobadilla et al appendix b see fig fig main distribution synthetic dataset generated movielens k compared distribution source dataset number user number item initial number sample standard deviation gaussian noise graph show distribution fake user axis versus number rating belonging user x axis graph b show distribution fake item axis versus number rating belonging item x axis graph c show percentage rating axis available vote value x axis dataset reference z fang l zhang k chen behavior mining hybrid recommender ieee international conference big icbda ieee pp r yera l mart√≠nez fuzzy tool recommender system survey int j comput intell syst r yera aa alzahrani l mart√≠nez fuzzy contentbased group recommender dynamic selection aggregation function internat j approx reason l zheng v noroozi p yu joint deep modeling user item review recommendation proceeding tenth acm international conference web search mining pp gong q zhang hashtag recommendation attentionbased convolutional neural network ijcai pp h kanwal assam jabbar khan et al convolutional neural network topic modeling hybrid recommender int j adv comput sci appl k mcnally mp omahony b smyth comparative collaboration reputation model social recommender system user useradapt interact nm villegas c s√°nchez j d√≠azcely g tamura characterizing contextaware recommender system systematic literature review knowlbased syst moradi j hamidzadeh ensemblebased topk recommender considering incomplete j ai min jalili ahmadian izadi p moradi salehi evaluating collaborative filtering recommender algorithm survey ieee access b zhu r hurtado j bobadilla f ortega efficient recommender numerical relevance nonnumerical structure rating ieee access r yera aa alzahrani l mart√≠nez exploring posthoc agnostic model explainable cooking recipe recommendation knowlbased syst e damico g gabbolini c bernardis p cremonesi analyzing improving stability matrix factorization recommender system j intell inf syst mh aghdam novel constrained nonnegative matrix factorization user item pairwise relationship recommender system expert syst appl g ayci k√∂ksal mm mutlu b suyunu cemgil active learning bayesian nonnegative matrix factorization recommender system th signal processing communication application conference siu ieee pp j bobadilla r bojorque ah esteban r hurtado recommender system clustering bayesian non negative matrix factorization ieee access hj xue x dai j zhang huang j chen deep matrix factorization model recommender system ijcai vol melbourne australia pp x l liao h zhang l nie x hu t chua neural collaborative filtering proceeding th international conference world wide web pp j bobadilla r laracabrera gonzalezprieto f ortega deepfair deep learning improving fairness recommender system int j interact multimed artif intell himeur alsalemi alkababji f bensaali amira c sardianos g dimitrakopoulos varlamis survey recommender system energy efficiency building principle challenge prospect inf fusion j bobadilla j due√±as guti√©rrez f ortega deep variational embedding representation neural collaborative filtering recommender system appl sci j bobadilla √° gonz√°lezprieto f ortega r laracabrera deep learning obtain collaborative filtering neighborhood neural comput appl zhang l yao sun tay deep learning recommender survey new perspective acm comput surv goodfellow j pougetabadie mirza b xu wardefarley ozair courville bengio generative adversarial network commun acm sacharidis diversity novelty socialbased collaborative filtering proceeding th acm conference user modeling adaptation personalization pp gogna majumdar diablo optimization design improving diversity recommender inform sci j bobadilla gutierrez alonso √° gonz√°lezprieto neural collaborative filtering classification obtain prediction reliability int j interact multimed artif intell knowledgebased system j bobadilla et al f pajueloholguera ja g√≥mezpulido f ortega evaluating strategy selecting test datasets recommender system international conference hybrid artificial intelligence system springer pp kd bollacker lawrence cl giles citeseer autonomous web agent automatic retrieval identification interesting publication proceeding second international conference autonomous agent pp w choochaiwattana usage tagging research recommendation rd international conference advanced computer theory engineering vol icacte ieee pp v j shokeen c rana social recommender system technique domain metric datasets future scope j intell inf syst xing mohallick ja gulla √∂ √∂zg√∂bek l zhang educational news dataset recommender system joint european conference machine learning knowledge discovery database springer pp f ortega j bobadilla guti√©rrez r hurtado x li artificial intelligence scientific documentation dataset recommender system ieee access liang rg krishnan md hoffman jebara variational autoencoders collaborative filtering proceeding world wide web conference pp zamany li h fei p li towards deeper understanding variational autoencoders binary collaborative filtering proceeding acm sigir international conference theory retrieval pp gao j zhang j yu j li j wen q xiong recommender system generative adversarial network problemdriven perspective inform sci deldjoo td noia fa merra survey adversarial recommender system attackdefense strategy generative adversarial network acm comput surv dk chae j kang sw kim jt lee cfgan generic collaborative filtering framework generative adversarial network proceeding th acm international conference knowledge management pp z wang gao x wang j yu j wen q xiong minimax game generative discriminative model recommendation pacific asia conference knowledge discovery mining springer pp w zhao b wang j ye gao yang x chen plastic prioritize long shortterm topn recommendation adversarial training ijcai pp h bharadhwaj h park lim recgan recurrent generative adversarial net work recommendation system proceeding th acm conference recommender system pp g guo h zhou b chen z liu x xu x chen z dong x ipgan generating informative item pair adversarial sampling ieee trans neural netw learn syst j zhao h li l qu q zhang q sun h huo gong dcfgan adver sarial deep reinforcement learning framework improved negative sampling sessionbased recommender system inform sci j sun b liu h ren w huang ncgan neural adversarial collaborative filtering recommender j intell fuzzy system lin z xie b xu k xu h lin infoflow enhanced gans recommender proceeding th international acm sigir conference research development retrieval pp q wang q huang k x zhang recommender regularization wasserstein generative adversarial network ieee international conference system man cybernetics smc ieee pp j wen xr zhu cd wang z tian framework personalized recom mendation conditional generative adversarial network knowl inf syst g deng c han d matteson extended missing imputation via gans ranking application min knowl discov h chen wang n jiang z li n yan l shi trustaware generative adversarial network recurrent neural network recommender system int j intell syst g van houdt c mosquera g n√°poles review long shortterm memory artif intell rev w shafqat yc byun hybrid ganbased solve imbalanced problem recommendation system ieee access z lin khetan g fanti oh pacgan power two sample generative adversarial network proceeding nd international conference neural processing system pp mladenov cw hsu v jain e ie c colby n mayoraz h pham tran vendrov c boutilier demonstrating principled uncertainty modeling recommender ecosystem recsim ng fourteenth acm conference recommender system pp jc shi yu q da sy chen ax zeng virtualtaobao virtualizing real world online retail environment reinforcement learning proceeding aaai conference artificial intelligence vol pp cn ziegler sm mcnee ja konstan g lausen improving recommendation list topic diversification proceeding th international conference world wide web pp del carmen rodr√≠guezhern√°ndez ilarri r hermoso r trillolado datagencars generator synthetic evaluation contextaware recommendation system pervasive mob comput v provalov e stavinova p chunaev synevarec framework evalu ating recommender system synthetic class international conference mining workshop icdmw ieee pp cossu carta v lomonaco bacciu continual learning recurrent neural network empirical evaluation neural netw ahmed r seraj sm islam kmeans comprehensive survey performance evaluation electronics fm harper ja konstan movielens datasets history context acm trans interact intell syst tiis f ortega b zhu j bobadilla hernando cfj collaborative filtering java knowlbased syst,knowledgebased system creating synthetic datasets collaborative filtering recommender system generative adversarial network,recommender system,knowledgebased system creating synthetic datasets collaborative filtering recommender system generative adversarial network knowledgebased system creating synthetic datasets collaborative filtering recommender system generative adversarial network knowledgebased system creating synthetic datasets collaborative filtering recommender system generative adversarial network recommender system recommender system knowledgebased system available online september author published elsevier bv open access article cc license httpcreativecommonsorglicensesby content list available sciencedirect knowledgebased system journal homepage wwwelseviercomlocateknosys creating synthetic datasets collaborative filtering recommender system generative adversarial network jes√∫s bobadilla abraham guti√©rrez raciel yera b luis mart√≠nez b departamento de sistemas inform√°ticos etsi sistemas inform√°ticos universidad polit√©cnica de c alan turing sn spain b departamento de inform√°tica universidad ja√©n ja√©n spain r c l e n f keywords recommender system generative adversarial network deep learning collaborative filtering b r c research education machine learning requires diverse representative open datasets contain sufficient sample handle necessary training validation testing task currently recommender system area includes large number subfields accuracy beyondaccuracy quality measure continuously improved feed research variety necessary convenient reinforce existing datasets synthetic one proposes generative adversarial network ganbased generate collaborative filtering datasets parameterized way selecting preferred number user item sample stochastic variability parameterization performed regular gans gan fed dense short continuous embedding representation item user instead sparse large discrete vector ensure fast accurate learning compared traditional large sparse input vector proposed architecture includes deepmf extract dense user item embeddings clustering process convert dense gan generated sample discrete sparse sample necessary create required synthetic dataset result three different source datasets show adequate distribution expected quality value evolution generated datasets compared source datasets synthetic datasets source code available researcher recommender system r relevant area artificial intel ligence due growing popularity social network big company extensively use rss tripadvisor netflix spotify youtube music tiktok youtube amazon company make use r model recommend user similar item music video trip news already consumed company facebook work hard collect customer activity provide personalized advertising rather personalized product service rss usually classified according filter ing contentbased rss select recommended item looking similar content since item content text natural language processing model used review tweet two common type contentbased filtered product image also processed make recommendation convolutional neural network commonly used model perform task social filtering extensively used improve socialbased rec ommendations type filtering us tag follower corresponding author email address jesusbobadillaupmes j bobadilla abrahamgutierrezupmes guti√©rrez ryeraujaenes r yera martinujaenes l mart√≠nez followed make use concept reputation trust geographic gps coordinate poi mainly used support contextaware filtering demographic filtering age gender country etc commonly combined type filtering implementing recommendation ensemble yond previous filtering strategy collaborative filtering cf important implementing rss since provides superior accuracy particularly combined type filtering effective r research make use innovative model adequate quality measure representative datasets historical evolution cf begin use memorybased model mainly knearest neighbor memory approach replaced modelbased machine learning approach due overall performance superior accu racy result also time obtain prediction learned output capable explained post hoc technique matrix factorization mf widely used machine learning implement collaborative filtering performs dimensional reduction user item capturing httpsdoiorgjknosys received december received revised form september accepted september knowledgebased system j bobadilla et al main pattern relate vote cast additionally nonnegative matrix factorization nfm semantic meaning assigned latent factor bayesian nmf allows clustering user making prediction simultaneously open door effective recommendation user group social clustering appli cation nowadays cf research mainly developed deep learning model deepmf basis modern approach deepmf use user coded latent space mean embedding layer whereas item coded different latent space mean second embedding layer finally prediction made making dot product item user embeddings deepmf improves mf due inherent competence neural network capture nonlinear relation hip sample neural collaborative filtering ncf extensively used implement cf replaces deepmf dot layer multilayer perceptron mlp outperforms deepmf applied large complex datasets beyond accuracy deep learning model emerging perform innovative task improving fairness deepfair achieves tradeoff equity precision green computing result explanation via latent space visualization efficient neighborhood identifica tion adversarial networkbased recommendation recently introduced r area focus related work section generative adversarial network gan responsible popular fake face fake video flood social network architecture two separate neural network compete adversarial art forger competing art expert ensuring improve work gan forger generator creates fake sample random noise vector gan expert discriminator implemented simple binary classifier fake nonfake however r research mainly focused proposing novel recommendation model try make progress cf datasets respect essential identify quality measure key element carry adequate research since allow baseline state art compared proposed algorithm method model beyond usual prediction recommendation quality measure mae msd precision recall f ndcg etc measure novelty diversity recently acquired growing importance diversity cur rently main focus researcher attention due risk inappropriate recommendation social network exhibit lack variability promote prefixed idea behavior diversity reliability r improved introducing diversityenhancing constraint mf additionally deep learning classification proposed obtain recommendation reliability value softmax output layer neural network quality value obtained tested balanced cf datasets obtain balanced training testing set respect user item distribution deterministic strategy proposed r research make use popular cf datasets movielens filmtrust myanimelist citeseer cf datasets include different domain music movie poi tourism news research paper tagged etc datasets filled explicit vote user others contain implicit interaction user system also datasets filled crawled web page academic pdfs others enriched social tag researcher add ar ticles selection relevant social cf datasets provided related article recently educational news dataset released included contextualized time location finally r dataset also provided contains artificial intelligence research obtain segmented clustering geographical location beyond work particularly relevant parameterized synthetic datasets yet used consequently cf research benefit flexibility parameterization provides experiment design different dataset size number user item aim fill gap proposing procedure coined ganrs focus use gans generate collaborative filtering recommender system datasets parameterized way please note current r ganbased model simultaneously set number generated user item rating distribution regarding contribution two main overall approach identified stateofart statistical generative main ad vantage statistical several relevant parameter simultaneously set number user number item dataset size etc main drawback poor accuracy hand current modelbased generative approach improve accuracy compared statistical framework lack flexibility since parameterization limited fact current gan design focused user profile generate many new fake user required relevant parameter set number item fixed source set user vector also fake generated set user vector explained example run regular gan generate fake image synthetic image shape resolution number channel source image r field synthetic user vector contain number item real user vector following example specific gan design return superresolution image increase resolution knowledge r gans designed generate fake user containing item fewer item proposed designed simultaneously set cf relevant parameter number user item rest structured follows related work introduced section focusing recent us gan model applied r section explains proposed formalization section present design discussion experiment finally section contains main conclusion article discusses future work background basic generative adversarial network gans designed generate scratch commonly used create fake image although use spreading many domain music medicine financial etc gan architecture composes two deep network model generator discriminator generator learns create sample similar possible dataset eg dataset human face image whereas discriminator learns detect fake sample sample created generator better understand gans consider example painting forger forgery expert imitation forger paint better result better expert ability detect fake painting people successively improve ability learning begin gan discriminator forgery expert example easy job since generator painting pattern thousand learning epoch generator learnt pattern well enough confuse discriminator forced tune weight learning loop iterates enough time generator discriminator model well designed painting dataset contains suitable pattern generator able create synthetic fake sample difficult distinguish original fig show gan architecture discriminator make binary classification fake real sample generator update weight learns discriminator correctly classifies fake discriminator update weight incorrectly classifies note generator take random noise distribution input generate sample knowledgebased system j bobadilla et al fig generative adversarial network architecture learnt input random noise vector feed generator created pattern dataset sample reason providing random noise vector create many sample required mean context create fake cf datasets size creating fake profile measure gan loss use crossentropy discriminator ùê∑ loss expressed sum expectation ùëöùëéùë• ùê∑ ùëâ ùê∑ ùê∏ ùë• ùëù ùëëùëéùë°ùëé ùë• ùëôùëúùëîùê∑ ùë• ùê∏ ùëß ùëù ùëß ùëß ùëôùëúùëî ùê∑ ùê∫ ùëß first term equation used recognize real image second term recognizes generated image ùëç represents noisy vector ùê∫ generator ùê∫ ùëç generated ùê∑ ùê∫ ùëß classification discriminator input fake ùê∑ ùë• classification discriminator input real generator loss designed learn discriminator correctly classifies true label fake label equation ùëöùëñùëõ ùê∫ ùëâ ùê∫ ùê∏ ùë• ùëù ùëëùëéùë°ùëé ùë• ùëôùëúùëî ùê∑ ùê∫ ùëß gan minimax ùê∫ want minimize ùëâ ùê∑ want maximize ùëöùëñùëõ ùê∫ ùëöùëéùë• ùê∑ ùëâ ùê∑ ùê∫ ùê∏ ùë• ùëù ùëëùëéùë°ùëé ùë• ùëôùëúùëîùê∑ ùë• ùê∏ ùëß ùëù ùëß ùëß ùëôùëúùëî ùê∑ ùê∫ ùëß previous example gan model act non sparse value eg pixel picture designed work sparse vector matrix problem cf datasets contain extraordinarily sparse matrix rating user vote consume limited number available item regular gan architecture adequate addressing cfbased r proposes extended gan architecture embeddings introduced code sparse discrete vector vote dense continuous vector innovation make possible use regular gan generate dense continuous vector efficiently accurately compression stage force u design corre sponding stage decompress generated dense vector adopted solution make possible set number user item generated dataset relevant innovation stateofart related work generative deep learning innovative field cf r area although variational autoencoder approach pub lished current research mainly focused gan model cf subfield gans used attackdefense strate gy model reinforce security r neverthe less extended us cf gans solve issue noisy b tackle sparsity problem implement augmentation framework capturing distribution real cfgan generates purchase vector rather id item us generated fake purchase vector augment real vector wasserstein version cfgan unified gan ugan report improvement compared cfgan prioritize long shortterm r inter action user item change quickly slowly plastic train generator us reinforcement learning agent recurrent gan recgan learns temporal pattern rating combining gan recurrent neural network rnns model capture negative sampling cf datasets ipgan implement two different generative model one positive instance another negative instance ipgan considers relation positive rating sampled negative one selected currently dcgan combine gan reinforcement learning model catch r session rather traditional historical matrix vote user item session includes response user current recommenda tions user immediate feedback managed reinforcement learning combined gan ncgan incorporates neural network extract nonlinear feature user gan guide recommendation training generator make user recommendation whereas discriminator measure distance real generated distribution innovative improve flow generator discriminator reduces discrepancy model cf gan regularization wasserstein gan used combined autoencoder acting generator reporting accuracy improvement applied highdimensional sparse cf matrix cgan conditional gan used improve cf recommendation size rating vector set simplifying generator discriminator task additionally allows conditional rating gen eration established datasets follow standard gaussian distribution missing imputation gan proposed result show improved quality several representative clas sification set trust used make effective recommendation gan discriminator mlp generator longshort term memory network lstm finally cf datasets usually imbalanced due social collection eg young people old people address limitation proposes wasserstein gan generator pacgan concept discriminator minimize mode collapse problem platform multiagent r simulation probabilisticbased recsim generates synthetic profile user item us markov chain recurrent neural network virtual taobao multiagent reinforcement learning designed improve search social taobao website make use knowledgebased system j bobadilla et al gan simulate internal distribution simple matrix factorization used inject topic diversification recommendation pro cess datagencars javabased generator r synthetic contains statistical basement provides flexibility return low accuracy compared deep learning generative model finally synevarec framework provides generation synthetic r datasets synthetic vault svd library library model multivariate distribution copula function ctgan sublibrary includes gan model main advantage synevarec compared previous framework use different rss source main drawback poor quality result case excessive time take perform training stage previous research mainly focus improving different objective noise reduction recommendation quality prediction value defense attack balancing make happen many different approach source combined use gan cgan wasserstein gan etc gan model combined recurrent neural network lstm net work reinforcement learning introduced ganbased architecture long short introduced proposed model addition trust session log including response user previous recommendation inferred negative vote pure generation synthetic datasets seem goal novel field gan applied cf r currently focused improving prediction recommendation quality result mean augmentation inherent ability gan capture complex nonlinear pattern highdimensional sparse cf datasets innovation proposal generate representative useful cf synthetic datasets rather improve existing result varying quality additionally allows representative parameter set whole family synthetic datasets obtained taking real datasets source movielens netflix myanimelist parameter number user number item number sample variability generated varying parameter value generate different version cf pattern movielensbased dataset containing user item another contains user item among others way test accuracy performance impact dataset size sparsity number user item well check improvement mae number user increase far know published method model creating parameterized deep learning accurate scalable synthetic datasets diverse source generative adversarial networksbased set building collaborative filtering previously mentioned section research problem defined obtaining larger scalable synthetic dataset original r dataset synthesizes similar user behavior valuation pattern relation original dataset addition desirable generation parameterized allowing number user item sample variability distribution controlled next section proposes ganrs us gan network generate synthetic cf datasets gan fed real cf dataset learns internal pattern innovative contribution feed gan dense small embedding representation user item instead traditional gan input large comprise sparse vector containing vote cast user main advantage ganrs greatly reduces complexity gan architecture convergence speed performance traditional sparsebased gan architecture deal large input vector large number item dataset ten thousand require large dense layer hold huge amount usually missing since user vote consume tiny proportion available product service hence extraordinary sparsity cf datasets following huge dense layer classical gan architecture necessary stack large multilayer perceptron reduce dimensionality comparison proposed replaces large dense layer two embeddings one code user code item bor rowed deepmf first stage proposed embedding layer specifically designed deal sparse receive integer value user item id provide small embedding representation typically float value cf scenario related user item share similar embedding representation feature allows extraordinarily simplification overall proposed architecture much smaller traditional architecture contains far fewer parameter consequently learns faster additionally better capture complex nonlinear relation item user way nongan r model improve prediction formalization ganrs presented structured according following seven stage also illustrated fig stage cf definition let ùëà set user make use cf r let ùêº set item available voting cf r let ùëâ range allowed vote usually ùëâ let ùëÜ set sample contained cf dataset ùëÅ ùëÜ ùë°‚Ñéùëíùë°ùëúùë°ùëéùëôùëõùë¢ùëöùëèùëíùëüùëúùëìùë£ùëúùë°ùëíùë†ùëêùëéùë†ùë° ùëÜ ùë¢ ùëñ ùë£ ùë¢ ùëñ ùë£ ùë¢ ùëñ ùë£ ùëÅ ùë¢ ùëà ùëñ ùêº ùë£ ùëâ stage deepmf training let e size two neural layer embeddings used vectorize user item belonging ùëà ùêº respectively let ùëì ùëíùë¢ ùë¢ ùëí ùë¢ ùëí ùë¢ ùëí ùë¢ ùê∏ ùëì ùëíùë¢ embedding layer output user ùë¢ ùëà let ùëì ùëíùëñ ùëñ ùëí ùëñ ùëí ùëñ ùëí ùëñ ùê∏ ùëì ùëíùëñ embedding layer output item ùëñ ùêº com bining dense vector user item embeddings ùëí ùë¢ ùëí ùë¢ ùëí ùë¢ ùê∏ ùëí ùëñ ùëí ùëñ ùëí ùëñ ùê∏ make rating pre diction deepmf training stage dot product user embedding item embedding ùë¢ ùëñ ùë£ ùëó ùëÜ provides rating prediction ùë¶ ùëó ùëì ùëíùë¢ ùë¢ ùëì ùëíùëñ ùëñ ùëí ùë¢ ùëí ùë¢ ùëí ùë¢ ùê∏ ùëí ùëñ ùëí ùëñ ùëí ùëñ ùê∏ ùë¶ ùëó ùë¶ ùëó output error used deepmf neural network start backpropagation neural weight iteratively improved ùõø ùëó value ùë§ ùëóùëñ ùõºùë¶ ùëó ùëì ùëÅùëíùë° ùëñ ùëò ùë§ ùëñùëò ùõø ùëò ùëò hidden layer ùë§ ùëóùëñ ùõºùë¶ ùëñ ùëì ùëÅùëíùë° ùëñ ùë¶ ùëò ùë¶ ùëò ùëò output layer j k successive sequential layer ùëÅùëíùë° ùëñ represents cumulative input received artificial neuron ùëÅùëíùë° ùëñ ùëó ùë¶ ùëó ùë§ ùëó ùëó index neuron layer preceding current neuron stage deepfm feedforward deepmf learned collect embedding representation user item cf r let ùê∏ ùë¢ ùëí ùë¢ ùëí ùë¢ ùëí ùë¢ ùê∏ ùë¢ ùëà set embeddings r user ùë¢ ùëà one u let ùê∏ ùë¢ ùëí ùë¢ ùëí ùë¢ ùëí ùë¢ ùê∏ knowledgebased system j bobadilla et al fig stage proposed ganrs let ùê∏ ùëñ ùëí ùëñ ùëí ùëñ ùëí ùëñ ùê∏ ùëñ ùêº set embed ding r item ùëñ ùêº one let ùê∏ ùëñ ùëí ùëñ ùëí ùëñ ùëí ùëñ ùê∏ stage setting dataset embeddings let ùëÖ ùê∏ ùë¢ ùê∏ ùëñ ùë£ ùë¢ ùëñ ùë£ ùëó ùëÜ embedding dataset real sample stage gan training let ùëì ùê∑ discriminator belonging gan let ùëì ùê∫ generator g belonging gan let ùëì ùê∫ùê∑ optimization function gan ùëì ùê∫ùê∑ ùëÄùëñùëõ ùê∫ ùëÄùëéùë• ùê∑ ùëì ùê∑ ùê∫ ùê∏ ùëÖ ùëôùëúùëî ùê∑ ùëÖ ùê∏ ùëß ùëôùëúùëî ùê∑ ùê∫ ùëß ùê∏ ùëÖ expected real sample ùëß random noise feed generator ùê∫ ùê∏ ùëß expected generated fake profile ùê∫ ùëß note ùëÖ refers stage gan generation let ùêπ ùëì ùê∫ ùëß generated dataset fake sample different random noise vector ùëß stage clustering item user let ùêæ number cluster used group embed ding user let ùêæ number cluster used group embeddings item let ‚Ñé ùë¢ ùëê ùëê ùêæ clustering operation assigns centroid user let ‚Ñé ùëñ ùëê ùëê ùêæ clustering operation assigns centroid item stage setting dataset item id user id let h item id user id discrete dataset ob tained embeddingbased dataset f fake sam ples ùêª ‚Ñé ùë¢ ‚Ñé ùëñ ùë£ ùê∏ ùë¢ ùê∏ ùëñ ùë£ ùêπ let ùëÜ ùêª synthetic generated dataset version h duplicated sample removed let ùê∫ ‚Ñé ùë¢ ‚Ñé ùëñ ùë£ ùêª ‚Ñé ùë¢ ‚Ñé ùëñ ùë£ ùêª ‚Ñé ùë¢ ‚Ñé ùë¢ ‚Ñé ùëñ ‚Ñé ùëñ ùë£ ùë£ fig show seven designed stage generate different syn thetic datasets real datasets movielens netflix etc stage top left graph fig show training deepmf used set embedding layer user embedding layer item basically embedding layer neural network efficiently convert input sparse representation output dense representation input ùë¢ùë†ùëíùëü ùëñùë°ùëíùëö ùëüùëéùë°ùëñùëõùëî training set output dot layer combine embedding layer value predict rating obtain output error rating prediction backpropagated update learning parameter step formalize concept deepmf learned stage top right graph fig show deepmf feedforward process item id one number item dataset range ùêº feed item embedding output item id dense representation usually cf embedding vector size applies user id input output dense representation please note number item dataset different number user step explain second stage purpose third stage convert source sparse cf dataset dense representation accomplish task source ùë¢ùë†ùëíùëü ùëñùë°ùëíùëö ùëüùëéùë°ùëñùëõùëî dataset eg replace user id example related dense representation applies item id embeddings size example could knowledgebased system j bobadilla et al example sample representation sparse dense stage fig show illustrative example step formalizes operation dense dataset obtained used stage train gan capable generating fake user item profile well associated rating value even stage rating dataset generated end proposal gan use stage dense dataset train discriminator providing necessary real sample gan generator take gaussian random noise input iteratively learns generate increasingly good fake profile capable cheating discriminator generator discriminator learnt generator convert input noise vector dense sample mimic pattern real dataset provided stage stage formalized step last stage fig bottom left graph us trained gan generator stage generate many fake sample desired feed generator successive vector random noise value following gaussian distribution generator output successive fake dense sample following pattern real dataset obtained stage higher standard deviation gaussian distribu tion higher variety individual value generated dense fake sample example low standard deviation ran dom noise gaussian distribution lead higher proportion vote ranging choosing high standard deviation produce higher density vote rating generated way item user coded dense embedding generated gan synthetic rating continuous value whereas real rating discrete usually range make conversion function assigns maximum range usually synthetic continuous value greater analogously function assigns minimum usually continuous value lower finally round function performed ensure discrete value step formalizes generation fake sample although ganrs could considered complete goal generate fake datasets sparse sample movielens netflix necessary convert obtained dense representation stage usual sparse representation seen stage process straightforward since dense representation fake sample different better explained example observed user two first row similar dense embedding value identical since gan generator able create exact value noise input vector situation occurs item id consequently ganrs provides way group similar dense embeddings unique id convert dense bold vector user unique user id need dense bold vector item unique item id need either group similar dense embeddings unique id kmeans clustering chosen relevant feature number k cluster must chosen priori con venient context since way opportunity establish number user number item ganrs synthetic generated dataset stage fig show concept main parameter value tested datasets dataset user item rating score sparsity movielens k netflix myanimelist ùêæ selected number user ùêæ selected number item two separate kmeans process run one group user embeddings group item embeddings step formalize two clustering process better understand stage consider example one million fake sample generated want create synthetic dataset containing two thousand fake user one thousand fake item accomplish task obtain two thousand group collected one million user vector one thousand item group average five hundred user vector could assigned user group analogously one thousand item vector item group know depends user item vector pattern adequately accomplish grouping task machine learning provides u clustering algorithm kmeans allow u set number desired group two thousand user one thousand item example running clustering process one user item assign fake user id fake user vector cluster please note id number assigned random two thousand cluster one thousand item id fig illustrates concept graph top show two kmeans clustering processing performed proposed one group item vector yellow circle one group user vector orange circle gray ellipsis represent kmeans clustering group fake user vector cluster collapse user vector code representative group different sample rest cluster item way obtain selected representative k user k item graph bottom fig show final stage proposed stage draw k cluster user k cluster item previous clustering blue circle k cluster user group set user vector column orange square k cluster item group set item vector column yellow square cluster user vector collapse representative user bottom stage graph item representative user item set generate fake dataset embeddings translating generated embedding bottomright graph equivalent representative concatenated embedding representative collapsed user item bottom stage graph previously illustrated generated collapse item vector item representative code vector red square collapse user vector user representative code vector brown square stage complete embedding translation sparse tuple codification seem also true following fake embedding collapse item green user blue generating sparse tuple note gan generated profile bottomright fig limited fixed number user item whereas stage version bottomleft fig limited range ùêæ ùêæ making possible preset number user item synthetic dataset seventh stage fig convert dense fake sample coming stage sparse sample ùë¢ùë†ùëíùëü ùëñùë°ùëíùëö ùëüùëéùë°ùëñùëõùëî accomplish task dense representation replace user vector centroid number ùêæ item vector centroid number ùêæ rating remains already generated framework stage knowledgebased system j bobadilla et al fig top graph clustering process collapse user item similar vector representative user item representation bottom graph translation unlimited fake limited profile profile range ùêæ ùêæ ùëüùëéùë°ùëñùëõùëî fig show example operation formalized step please note repeated sample appear previous discretization process since gan generator create similar dense sample converted discrete encoding several factor modulate number repeated sample number generated sample embedding size size noise vector standard deviation gaussian distribution relevant factor number chosen user item ùêæ ùêæ lower ùêæ higher number repeated sample number user item low average number sample grouped cluster high step formalizes process removing repeated discrete sample finally ganrs generate small proportion sample different vote cast user item eg could considered convenient behavior code higher range vote example express change user opinion case unchanged changed removed step formalizes removal operation overall important keep mind new rating value initially calculated context stage proposal gan used generating fake sample pair ùë¢ùë†ùëíùëü ùëñùë°ùëíùëö ùëüùëéùë°ùëñùëõùëî user item embeddings obtained previous stage base afterward methodology refines obtained assure consistency stage appendix show main parameter hyperparam eter value used design model deepmf gan involved proposed ganrs experiment result evaluating quality generated datasets comparing stateofart synthetic datasets straightforward since traditional measure cover distribution probability kullbackleibler kl divergence ùê∑ ùêæùêø ùëÉ ùëÑ ùëÉ ùëÑ two probability distribution context face two main drawback applying kl divergence similar divergence measure ùëÉ ùëÑ distribution probability datasets low ùê∑ ùêæùêø mean ùëÑ generated dataset good synthetic dataset obtained ùëÉ source dataset fact ùê∑ ùêæùêø usually ùëÉ ùëÑ useful course cf dataset contains reduced number representative distribution probability including rating user item distribution ùëÑ ùë¢ ùëÑ ùëñ ùëÑ ùëü comparing distribution generated dataset corresponding distribution source dataset intrinsic problem explained ùê∑ ùêæùêø ùëÉ ùë¢ ùëÑ ùë¢ ùê∑ ùêæùêø ùëÉ ùëñ ùëÑ ùëñ ùê∑ ùêæùêø ùëÉ ùëü ùëÑ ùëü mean ùëÑ suitable synthetic dataset regard ùëÉ indeed ùëÑ must certain degree variability regard ùëÉ common alternative used deal situation testing quality result specific domain mae precision recall etc result interpreted according graph trend rather absolute value since better result mean ùëÑ pattern less complicated ùëÉ one worse result tell u ùëÑ pattern complicated ùëÉ one scenario better depends objective scientist generates synthetic datasets addressing concern explained provide complete set comparative graph source ùëÉ generated datasets ùëÑ including probability distribution user item rating precision recall trend designing specific quality measure maximize scientist objective required distribution variability required complexity resulting pattern etc challenging search would help compare stateofart generative approach scope evaluate suitability presented procedure focused building synthetic datasets first traditional set used starting point present procedure presented well description experiment performed subsequently obtained result presented discussed experiment test behavior proposed ganrs use three representative open datasets cf field movielens netflix myanimelist chosen k version movie lens reduced version complete netflix dataset netflix available show main parameter value datasets complete set experiment run netflix whereas subset experiment shown movielens myanimelist reduce size result movielens myanimelist test summarized end section three source datasets used generate corre sponding synthetic version setting different number user item sample changing standard deviation gaussian random noise knowledgebased system j bobadilla et al parameter value synthetic datasets generated gan source netflix std user item std user item std user item sample k k experiment carried neural deepmf training validation testing set obtained real datasets netflix myanimelist movielens k corresponding synthetic datasets source code train test result real generated datasets ensuring consistency graph comparative figure fig b b e b e show gan generated synthetic datasets used test proposed ganrs netflix source column show number generated datasets std stan dard deviation used random noise gaussian distribution user item total number user item chosen generate dataset sample number fake sample created gan generator please note final number sample contained datasets lower sample due removing process repeated sample case used test effect changing standard deviation number user case test consequence increasing number item finally case test behavior synthetic datasets different size number sample generated datasets source code proposed ganrs fully available httpsuleimanujaenesgitlabinstanceccc ganrs additionally appendix b fig show example dis tribution graph obtained synthetic datasets following link provided generated dataset located specific directory readmetxt file provided along synthetic dataset distribution graph parameter value variety experiment conducted classification experiment follows number user distribution user versus rating b distribution user rating c number repeated sample proportion sample user item e mae accuracy set f user precision recall number item mae accuracy dataset b item precision recall number sample number sample generated b precision recall experiment refer wellknown metric collaborative filtering precision focused measuring proportion relevant rec ommendations ie user rated item rating equal greater threshold ùúÉ among top ùëÅ item recommended user ùë¢ collected list ùëá ùëÅ ùë¢ eq hand recall mea sures proportion correctly predicted relevant recommendation among total number relevant vote user therefore recall sensitive existing proportion relevant rating eq ùëÉùëüùëíùëêùëñùë†ùëñùëúùëõ ùëà ùë¢ ùëà ùëñ ùëá ùëÅ ùë¢ ùëü ùë¢ùëñ ùúÉ ùëÅ ùëÖùëíùëêùëéùëôùëô ùëà ùë¢ ùëà ùëñ ùëá ùëÅ ùë¢ ùëü ùë¢ùëñ ùúÉ ùëñ ùëá ùëÅ ùë¢ ùëü ùë¢ùëñ ùúÉ ùëñ ùëá ùëÅ ùë¢ ùëü ùë¢ùëñ ùúÉ ùëà set training user ùëü ùë¢ùëñ rating training user ùë¢ item ùëñ ùëÅ number recommendation ùëá ùëÅ ùë¢ set ùëÅ recommendation test user ùë¢ ùëÅ highest prediction user ùë¢ relevancy threshold ùúÉ please note precision measure proportion recommenda tion hit hit respect number recommendation whereas recall measure proportion recommendation hit respect total number relevant item precision take consideration number true positive whereas recall combine true positive false negative importance precision recall quality measure largely depends scenario applied eg recall seems crucial medicine false negative serious mistake ie detecting cancer nevertheless recall less important r since missing relevant film false negative serious objective maximize correctly recommended film true positive f quality measure combine precision recall eq ùêπ ùëÉùëüùëíùëêùëñùë†ùëñùëúùëõ ùëÖùëíùëêùëéùëôùëô ùëÉùëüùëíùëêùëñùë†ùëñùëúùëõ ùëÖùëíùëêùëéùëôùëô finally also test accuracy eq true negative also considered positive negative hit contribute result positively recommend relevant item negatively recommend non relevant item ùê¥ùëêùëêùë¢ùëüùëéùëêùë¶ ùëñ ùëÜ ùë° ùëù ùë¢ùëñ ùúÉ ùëü ùë¢ùëñ ùúÉ ùëñ ùëÜ ùë° ùëù ùë¢ùëñ ùúÉ ùëü ùë¢ùëñ ùúÉ ùëÜ ùë° ùëÜ ùë° set test sample tuple ùë¢ ùëñ ùëü containing user id item id rating user u item ùëñ ùëü ùë¢ùëñ prediction rating ùëù ùë¢ùëñ two value threshold ùúÉ explored across experimen tal scenario precision recall f accuracy quality measure tested note accuracy quality measure use term ùëá ùëÅ ùë¢ since typical r include negative recommendation accordingly accuracy formulation average user result act entire training done mean absolute error eq ùëÄùê¥ùê∏ ùëÜ ùë° ùë† ùëÜ ùë° ùëù ùë¢ùëñ ùëü ùë¢ùëñ ùë¢ ùëñ ùëÜ knowledgebased system j bobadilla et al fig distribution user versus rating number item datasets b distribution user rating number user number item datasets c number sample remaining removing repeated one item datasets proportion sample user cast different vote item item datasets e mae accuracy number user number item std standard deviation gaussian random noise distribution datasets f precision recall f standard deviation random noise gaussian distribution number recommendation ùëÅ datasets result subsection show graph obtained designed ex periments previous subsection run synthetic datasets de scribed used obtain result allow u compare distribution user item rating belonging source datasets relation obtained synthetic datasets measure number repeated sample returned clustering stage test prediction recommendation quality trend obtained running proposed rsgan comparing shown source datasets experiment number user distribution user versus rating fig show density user yaxis cast different number vote xaxis selected datasets expected fixed number rating dataset observe higher number user lower number rating fixed number sample dataset distributed among high number user user centroid clustering stage receives lower number sample please note netflix contains around user experiment b distribution user rating fig b show proportion rating xaxis different random noise gaussian distribution applied selected datasets observed standard deviation generates similar distribution vote compared netflix original adjacent standard distribution fig b also show impact gaussian standard deviation layout individual value gangenerated sample experiment c number repeated sample explained section trained gan generator predicts random noise vector many dense sample want sample converted continuous dense value discrete sparse one discretization process repeated sample appear must removed contains example fig c show number sample remaining dataset removal process lower number user higher number sample assigned user centroid clustering process therefore higher probability repeating discrete sample overall smaller number user smaller number remaining sample selected datasets experiment proportion sample user item ganrs generated datasets possess one attribute exist source datasets movielens etc contain proportion sample user cast different vote item eg explained section seen mechanism allow intermediate vote example allow user change mind make sense number repeated vote two three rare case four five repeated vote removed done generated datasets standard quality metric measure accuracy prediction mean absolute error mae root mean square error rmse chosen former since widely used r stateofart research paper provide measure experimental research show cf field result rmse mae similar distribution error cf field usually little variance mae return absolute difference predicted value real value testing set ùëÄùê¥ùê∏ ùëõ ùëñ ùë¶ ùëñ ùë¶ ùëñ lower mae better fit dataset rmse us square error instead absolute ùëÄùê¥ùê∏ ùëõ ùëñ ùë¶ ùëñ ùë¶ ùëñ therefore rmse sensitive observation mean cf fig show regular cf r user proportion four five repetition significant number user increase proportion repetition drop fast experiment e mae accuracy dataset whereas previous experiment analyze internal composition distribution synthetic datasets experiment knowledgebased system j bobadilla et al following experiment test behavior generated datasets prediction recommendation task fig e show prediction quality mae accuracy recommendation obtained set individual sample datasets please note measure obtained analyzing averaging result user graph fig e show improvement accuracy corresponding decrease mae error number user increase behavior expected cf r high number user lead better prediction tell u gan generated sample follow cf convenient pattern mae value top graph fig e closely related distribution rating standard deviation maeaccuracy result used select appropriate standard deviation std experiment f user precision recall experiment provides significant result test generated datasets extract value evolution two repre sentative recommendation quality measure precision recall top graph fig f show quality value obtained testing several number recommendation n xaxis two different relevancy threshold ùúÉ two number user green line blue line standard deviation gaussian random noise set selected datasets value evolution obtained synthetic datasets fit source dataset netflix black line additionally expected overall result dataset generated user outperform user closer netflix reference please note netflix contains around user two bottom graph fig f represent f combination precision recall clearly show similarity behavior generated datasets compared source dataset experiment mae accuracy number item varies experiment e tested mae accuracy quality measure datasets different number user test quality measure datasets different number item k k k k result fig show adequate value mae accuracy consistent evolution accuracy increase mae decrease number item xaxis increase thus higher number item better accuracy show gan generator enrich netflix source dataset contains item observe fig improvement slows around xaxis selected datasets user version included experiment b item precision recall experiment b similar experiment f test behavior datasets contain different number item instead different number user fig b show performance netflix item represented black line compare item dataset green line item dataset blue line observe evolution value consistent source datasets black line furthermore k k item version perform well first one conveniently capture neflix pattern item since contain similar number item dataset generated second k item enrich show better accuracy k item version selected datasets user version included experiment number sample generated datasets differ ent size test number sample ganrs obtains different number generated sample different number user set purpose define four different number sample k k datasets equivalent datasets user gan generation process number item fixed k experiment fig observe smaller number user smaller number generated sample due fact smaller number user higher number sample assigned user centroid clustering stage therefore higher probability repeated sample removed example fig show k user dataset preserve approximately sample gan generated version k version experiment b precision recall datasets different size experiment show impact increasing number sample datasets fixed parameter user item standard deviation datasets important realize source dataset netflix generate three case shown fig b k sample yellow line k sample magenta line sample red line please note k k sample refer dense continuously generated sample prior removal stage convert sparse discrete version fig show final size datasets user xaxis fig b compare precision recall value obtained netflix dataset black line generated value overall precision increase recall decrease bigger generated dataset better precision higher dataset lower recall precision result improve large datasets relevant sample choose therefore easier succeed fixed number ùëÅ recommended prediction hand recall get worse large datasets contain variability sample particularly large standard devi ations chosen random noise gaussian distribution unlike precision whose denominator constant ùëÅ number recommendation recall quality measure depends variable number relevant vote set test item user tested number sample increase number user vote also increase number relevant vote reason recall lower synthetic dataset fig b higher k version fig show respectively result obtained myanimelist movielens k test datasets graph compare rating distribution source dataset blue gen erated rating distribution obtained setting different value gaussian random noise standard deviation chosen stan dard deviation myanimelist standard devia tion movielens k since obtained distribution rating closest respective baseline result b c e obtained selected standard deviation value graph b show distribution user according number casted rating xaxis expected follow pattern one netflix compare result please note myanimelist dataset contains user movielens k contains user graph c show number sample left removing repeated instance higher number user lower probability generating sample containing user id item id rating myanimelist started million generated sample whereas movielens selected million generated sample graph refers mae error accuracy value obtained processing individual sample contained dataset usual cf context higher number user lower error higher accuracy finally graph e test recommendation obtained processing user dataset netflix compared baseline precision improves recall get worse knowledgebased system j bobadilla et al fig mae accuracy obtained dataset sample number item varies number user standard deviation gaussian random noise datasets b precision recall f number item varies standard deviation random noise gaussian distribution number recommendation ùëÅ datasets fig number generated sample different number user x axis different number gan generated sample legend standard deviation random noise gaussian distribution number item datasets b precision recall different number recommendation x axis different number gan generated sample legend standard deviation random noise gaussian distribution datasets result obtained section highlight importance test performance synthetic datasets source datasets particularly specific r metric used check consistency synthetic real two type knowledgebased system j bobadilla et al fig myanimelist million generated sample distribution myanimelist rating b distribution user according number casted rating c number sample removing process repeated one error accuracy processing sample dataset e cf precision recall testing dataset user ganrs std set test experiment b e experiment conducted direct indirect direct com parisons rating distribution obtained compared source datasets synthetic version fig b c show netflix result varying number generated user standard deviation random gaussian distribution used feed proposed gan fig b b show respectively comparison myanimelist movielens k datasets varying number user synthetic datasets versus equivalent source counterpart indirect experiment tested compared recommendation performance synthetic source datasets chosen recommendation quality measure pre cision recall f obtained classical neural deepmf result found fig f netflix v synthetic version fig e myanimelist v synthetic version fig e movielens k v synthetic version overall expected result show synthetic datasets behave like source datasets similar result suitable generated datasets mean original datasets effectively replaced synthetic one comparison proposed framework previous work related work section identifies previous work focused generation method recommender system subsection brief performed focus showing previous work truly comparable current proposal fair way since focused different objective also generates different nature mladenov et al presented recsim ng architecture cen tered generation synthetic profile user item part recommendation environment overall goal work development configurable platform authoring learning r simulation environment aim simulation evaluate existing r policy generate train new policy either tightly coupled online fashion batch mode furthermore lack presented therefore allow reproducibility shi et al introduce multiagent reinforcement learning architecture tailored taobaospecific website search improve ment us gan simulate internal rating distribu tion therefore considering focused generation specific context comparable framework proposed current del carmen et al introduce datagencars javabased generator r synthetic important remark work specifically focused contextaware recom mendation scenario sense even though proposed tool support generation synthetic datasets user item con text rating generation always relies contextrelated characteristic criterion introduced throughout work uncertainty content user expectation item attribute work comparable methodology presented current mainly us rating value input consider datasets contextual knowledgebased system j bobadilla et al fig movielens k result million generated sample distribution movielens k rating b distribution user according number casted rating c number sample removal process repeated one error accuracy processing sample dataset e cf precision recall testing dataset user ganrs std set test experiment b e provalov et al introduce synevarec framework focused presentation novel paradigm evaluating recom mendations generation synthetic r datasets contrast current mainly focused generating synthetic user item profile internally used synevarec guarantee user privacy protection mitigate insufficiency problem measure effect nofreelunch problem regarding aim architecture proposed provalov et al proper retrieval whole synthetic rating datasets used evaluation ie evaluation protocol presented rather dataset generation major transformation work needed make comparable fair comparison possible stage overall discussion large number synthetic datasets generated test performance proposed ganrs datasets created setting different value main parameter number user number item gaussian random noise variation number generated sample generalize conclusion three open representative cf datasets used source generative process finally variety quality measure tested generated datasets precision recall relevant key issue able visually test quality generated sample done example popular fake face fact cf context adequately test generated datasets comparing cf quality result typically obtained real cf datasets reason focused designed experiment quality measure precision recall tested datasets containing different number user different number item different number sample size case comparatively obtain excellent precision result moderate recall value overall considered positive cf context precision error serious recall error less important worse recommend trip like sorry refund recommend trip probably would enjoy please note opposite deep learning detecting malignant tumor worse make precision error early detection tumor making recall error erroneously detect tumor additionally experiment show relevant impact standard deviation quality result gan network learning vector containing noise value serf seed generate different sample synthetic dataset fake generated list random value noise vector usual gan context random value created knowledgebased system j bobadilla et al gaussian distribution mean standard deviation generated contains dense item representation dense user representation individual code user rating item gan learned generative used feedforward process generate many sample want starting different random noise vector generated experimental result show gaussian distribution standard deviation lead many rating middle voting range rating closest voting range movielens netflix rating closests voting range myanimelist several experiment section demonstrate modulate standard deviation gaussian distribution random noise generate wider range rating feedforward expected standard deviation increase range rating also increase proportionally finally experiment presented include existing relationship number fake sample generated gan number sample dataset eventually contain explained section conversion dense continuous value sparse discrete value lead probability repetition result show expected larger number user item synthetic dataset lower number repeated sample also shown typical number user say probability two different rating one user item considered negligible conclusion provides innovative generating synthetic parameterized collaborative filtering datasets real datasets syn thetic datasets generated selecting different number user item sample distribution variability mean comparative experiment designed basis whole family generated datasets example test accuracy new matrix factorization number user increase gan used obtain fake sample real sample benefitting inherent capacity gan network capture complex pattern source datasets gan learns dense continuous embedding representation item user rather sparse discrete representation collaborative filtering datasets effect fast accurate learning process proposed ganrs contains clustering stage convert dense generated fake sample sparse discrete value necessary fill generated dataset clustering stage implement kmeans group item another kmeans group user natural way k parameter set chosen num ber user item dataset drawback discretization process generation identical sample merely remove complete set experiment made three representative source datasets tested distribution value evolution result well prediction recommendation quality although precision tends improve recall tends worsen overall accuracy considered correct since precision relevant recall r context result show generated datasets conveniently mimic behavior source datasets movielens myanimelist etc source code proposed ganrs available ensure reproducibility experiment similarly complete set generated datasets made available research related documentation open door address future work designing alternative option clustering stage implementing pacgan concept gan discriminator testing generated datasets complete range machine learning deep learning collaborative filtering model replacing gan cgan one generating demographically balanced datasets performing indepth impact random noise vector variation generated set sample credit authorship contribution statement jes√∫s bobadilla conceptualization validation formal investigation software writing original draft writing review editing visualization abraham guti√©rrez conceptualization valida tion formal investigation software writing original draft visualization raciel yera methodology validation formal writing original draft visualization luis mart√≠nez methodology validation writing original draft declaration competing interest author declare known competing finan cial interest personal relationship could appeared influence work reported availability link code shared manuscript acknowledgment work partially supported ministerio de ciencia e inno vaci√≥n spain project pidrbi dlcemg comunidad de spain convenio plurianual universidad polit√©cnica de spain actuation line programa de excelencia para el profesorado universitario plan andaluz de investigaci√≥n desarrollo e innovaci√≥n paidi spain project proyexcel_ appendix see main parameter hyperparameter value set neural model involved rsgan deepmf value embedding size user item optimizer adam loss function mean squared error epoch gan generator input shape noise vector size block dense layer neuron block activation function leakyrelu alpha block normalization batchnormalization momentum block dense layer neuron block activation function leakyrelu alpha block regularization dropout block dense layer neuron ùëíùëöùëèùëíùëëùëëùëñùëõùëîùë†ùëñùëßùëí block activation function linear gan discriminator input shape ùëíùëöùëèùëíùëëùëëùëñùëõùëîùë†ùëñùëßùëí block dense layer neuron block activation function leakyrelu alpha block dense layer block activation function sigmoid gan train epoch batch size stochastic noise gaussian loss function ùëüùëíùëéùëôùë†ùëéùëöùëùùëôùëíùë†ùëôùëúùë†ùë† ùëìùëéùëòùëíùë†ùëéùëöùëùùëôùëíùë†ùëôùëúùë†ùë† knowledgebased system j bobadilla et al appendix b see fig fig main distribution synthetic dataset generated movielens k compared distribution source dataset number user number item initial number sample standard deviation gaussian noise graph show distribution fake user axis versus number rating belonging user x axis graph b show distribution fake item axis versus number rating belonging item x axis graph c show percentage rating axis available vote value x axis dataset reference z fang l zhang k chen behavior mining hybrid recommender ieee international conference big icbda ieee pp r yera l mart√≠nez fuzzy tool recommender system survey int j comput intell syst r yera aa alzahrani l mart√≠nez fuzzy contentbased group recommender dynamic selection aggregation function internat j approx reason l zheng v noroozi p yu joint deep modeling user item review recommendation proceeding tenth acm international conference web search mining pp gong q zhang hashtag recommendation attentionbased convolutional neural network ijcai pp h kanwal assam jabbar khan et al convolutional neural network topic modeling hybrid recommender int j adv comput sci appl k mcnally mp omahony b smyth comparative collaboration reputation model social recommender system user useradapt interact nm villegas c s√°nchez j d√≠azcely g tamura characterizing contextaware recommender system systematic literature review knowlbased syst moradi j hamidzadeh ensemblebased topk recommender considering incomplete j ai min jalili ahmadian izadi p moradi salehi evaluating collaborative filtering recommender algorithm survey ieee access b zhu r hurtado j bobadilla f ortega efficient recommender numerical relevance nonnumerical structure rating ieee access r yera aa alzahrani l mart√≠nez exploring posthoc agnostic model explainable cooking recipe recommendation knowlbased syst e damico g gabbolini c bernardis p cremonesi analyzing improving stability matrix factorization recommender system j intell inf syst mh aghdam novel constrained nonnegative matrix factorization user item pairwise relationship recommender system expert syst appl g ayci k√∂ksal mm mutlu b suyunu cemgil active learning bayesian nonnegative matrix factorization recommender system th signal processing communication application conference siu ieee pp j bobadilla r bojorque ah esteban r hurtado recommender system clustering bayesian non negative matrix factorization ieee access hj xue x dai j zhang huang j chen deep matrix factorization model recommender system ijcai vol melbourne australia pp x l liao h zhang l nie x hu t chua neural collaborative filtering proceeding th international conference world wide web pp j bobadilla r laracabrera gonzalezprieto f ortega deepfair deep learning improving fairness recommender system int j interact multimed artif intell himeur alsalemi alkababji f bensaali amira c sardianos g dimitrakopoulos varlamis survey recommender system energy efficiency building principle challenge prospect inf fusion j bobadilla j due√±as guti√©rrez f ortega deep variational embedding representation neural collaborative filtering recommender system appl sci j bobadilla √° gonz√°lezprieto f ortega r laracabrera deep learning obtain collaborative filtering neighborhood neural comput appl zhang l yao sun tay deep learning recommender survey new perspective acm comput surv goodfellow j pougetabadie mirza b xu wardefarley ozair courville bengio generative adversarial network commun acm sacharidis diversity novelty socialbased collaborative filtering proceeding th acm conference user modeling adaptation personalization pp gogna majumdar diablo optimization design improving diversity recommender inform sci j bobadilla gutierrez alonso √° gonz√°lezprieto neural collaborative filtering classification obtain prediction reliability int j interact multimed artif intell knowledgebased system j bobadilla et al f pajueloholguera ja g√≥mezpulido f ortega evaluating strategy selecting test datasets recommender system international conference hybrid artificial intelligence system springer pp kd bollacker lawrence cl giles citeseer autonomous web agent automatic retrieval identification interesting publication proceeding second international conference autonomous agent pp w choochaiwattana usage tagging research recommendation rd international conference advanced computer theory engineering vol icacte ieee pp v j shokeen c rana social recommender system technique domain metric datasets future scope j intell inf syst xing mohallick ja gulla √∂ √∂zg√∂bek l zhang educational news dataset recommender system joint european conference machine learning knowledge discovery database springer pp f ortega j bobadilla guti√©rrez r hurtado x li artificial intelligence scientific documentation dataset recommender system ieee access liang rg krishnan md hoffman jebara variational autoencoders collaborative filtering proceeding world wide web conference pp zamany li h fei p li towards deeper understanding variational autoencoders binary collaborative filtering proceeding acm sigir international conference theory retrieval pp gao j zhang j yu j li j wen q xiong recommender system generative adversarial network problemdriven perspective inform sci deldjoo td noia fa merra survey adversarial recommender system attackdefense strategy generative adversarial network acm comput surv dk chae j kang sw kim jt lee cfgan generic collaborative filtering framework generative adversarial network proceeding th acm international conference knowledge management pp z wang gao x wang j yu j wen q xiong minimax game generative discriminative model recommendation pacific asia conference knowledge discovery mining springer pp w zhao b wang j ye gao yang x chen plastic prioritize long shortterm topn recommendation adversarial training ijcai pp h bharadhwaj h park lim recgan recurrent generative adversarial net work recommendation system proceeding th acm conference recommender system pp g guo h zhou b chen z liu x xu x chen z dong x ipgan generating informative item pair adversarial sampling ieee trans neural netw learn syst j zhao h li l qu q zhang q sun h huo gong dcfgan adver sarial deep reinforcement learning framework improved negative sampling sessionbased recommender system inform sci j sun b liu h ren w huang ncgan neural adversarial collaborative filtering recommender j intell fuzzy system lin z xie b xu k xu h lin infoflow enhanced gans recommender proceeding th international acm sigir conference research development retrieval pp q wang q huang k x zhang recommender regularization wasserstein generative adversarial network ieee international conference system man cybernetics smc ieee pp j wen xr zhu cd wang z tian framework personalized recom mendation conditional generative adversarial network knowl inf syst g deng c han d matteson extended missing imputation via gans ranking application min knowl discov h chen wang n jiang z li n yan l shi trustaware generative adversarial network recurrent neural network recommender system int j intell syst g van houdt c mosquera g n√°poles review long shortterm memory artif intell rev w shafqat yc byun hybrid ganbased solve imbalanced problem recommendation system ieee access z lin khetan g fanti oh pacgan power two sample generative adversarial network proceeding nd international conference neural processing system pp mladenov cw hsu v jain e ie c colby n mayoraz h pham tran vendrov c boutilier demonstrating principled uncertainty modeling recommender ecosystem recsim ng fourteenth acm conference recommender system pp jc shi yu q da sy chen ax zeng virtualtaobao virtualizing real world online retail environment reinforcement learning proceeding aaai conference artificial intelligence vol pp cn ziegler sm mcnee ja konstan g lausen improving recommendation list topic diversification proceeding th international conference world wide web pp del carmen rodr√≠guezhern√°ndez ilarri r hermoso r trillolado datagencars generator synthetic evaluation contextaware recommendation system pervasive mob comput v provalov e stavinova p chunaev synevarec framework evalu ating recommender system synthetic class international conference mining workshop icdmw ieee pp cossu carta v lomonaco bacciu continual learning recurrent neural network empirical evaluation neural netw ahmed r seraj sm islam kmeans comprehensive survey performance evaluation electronics fm harper ja konstan movielens datasets history context acm trans interact intell syst tiis f ortega b zhu j bobadilla hernando cfj collaborative filtering java knowlbased syst,0,number and synthetic datasets in random noise
Deep variational models for collaborative filtering-based recommender systems.pdf,Deep variational models for collaborative filtering-based | recommender systems,Recommender systems  Collaborative Ô¨Åltering  Variational enrichment  Deep learning,"ORIGINAL ARTICLE Deep variational models for collaborative filtering-based recommender systems Jesu¬¥s Bobadilla 1,2 ‚Ä¢ Fernando Ortega 1,2 ‚Ä¢ Abraham Gutie¬¥rrez 1,2 ‚Ä¢ A ¬¥ ngel Gonza¬¥lez-Prieto 2,3,4 Received: 16 September 2022 / Accepted: 22 November 2022 / Published online: 9 December 2022  The Author(s) 2022 Abstract Deep learning provides accurate collaborative Ô¨Åltering models to improve recommender system results. Deep matrix factorization and their related collaborative neural networks are the state of the art in the Ô¨Åeld; nevertheless, both models lack the necessary stochasticity to create the robust, continuous, and structured latent spaces that variational autoencoders exhibit. On the other hand, data augmentation through variational autoencoder does not provide accurate results in the collaborative Ô¨Åltering Ô¨Åeld due to the high sparsity of recommender systems. Our proposed models apply the variational concept to inject stochasticity in the latent space of the deep architecture, introducing the variational technique in the neural collaborative Ô¨Åltering Ô¨Åeld. This method does not depend on the particular model used to generate the latent representation. In this way, this approach can be applied as a plugin to any current and future speciÔ¨Åc models. The proposed models have been tested using four representative open datasets, three different quality measures, and state-of-the-art baselines. The results show the superiority of the proposed approach in scenarios where the variational enrichment exceeds the injected noise effect. Additionally, a framework is provided to enable the reproducibility of the conducted experiments. Keywords Recommender systems  Collaborative Ô¨Åltering  Variational enrichment  Deep learning 1 Introduction Recommender Systems (RSs) are an artiÔ¨Åcial intelligence Ô¨Åeld that provides methods and models to predict and recommend items to users (e.g., Ô¨Ålms to persons, e-com- merce products to costumers, services to companies, Quality of Service (QoS) to Internet of Things (IoT) devices, etc.) [ 1 ]. Current popular RSs are Spotify, NetÔ¨Çix, TripAdvisor, Amazon, etc. RSs are usually categorized attending to their Ô¨Åltering strategy, mainly demo- graphic [ 2 ], content-based [ 3 ], context-aware [ 4 ], social [ 5 ], Collaborative Filtering (CF) [ 1 , 6 ] and Ô¨Åltering ensembles [ 7 , 8 ]. CF is the most accurate and widely used Ô¨Åltering approach to implement RSs. CF models have evolved from the K-Nearest Neighbors (KNN) algorithm to the Probabilistic Matrix Factorization (PMF) [ 9 ], the non- Negative Matrix Factorization (NMF) [ 10 ] and the Baye- sian non-Negative Matrix Factorization (BNMF) [ 11 ]. Currently, deep learning research approaches are growing in strength: they provide improvement in accuracy com- pared to the Machine Learning (ML)-based Matrix Fac- torization (MF) models [ 12 ]. Additionally, deep learning architectures are usually more Ô¨Çexible than the MF-based ones, introducing combined deep and shallow learn- ing [ 13 ], integrated content-based ensembles [ 14 ], gener- ative approaches [ 15 , 16 ], among others. Deep Matrix Factorization (DeepMF) [ 17 ] is a neural network model that implements the popular MF concept. DeepMF was designed to take as input a user-item matrix with explicit ratings and nonpreference implicit feedback, & A ¬¥ ngel Gonza¬¥lez-Prieto angelgonzalezprieto@ucm.es 1 Departamento de Sistemas Informa¬¥ticos, ETSI Sistemas Informa¬¥ticos, Universidad Polite¬¥cnica de Madrid, C. de Alan Turing, s/n, Madrid, 28031 Madrid, Spain 2 KNODIS Research Group, Universidad Polite¬¥cnica de Madrid, C. de Alan Turing, s/n, Madrid, 28031 Madrid, Spain 3 Departamento de A ¬¥ lgebra, Geometrƒ±¬¥a y Topologƒ±¬¥a, Universidad Complutense de Madrid, Plaza Ciencias 3, Madrid, 28040 Madrid, Spain 4 Instituto de Ciencias Matema¬¥ticas (CSIC-UAM-UCM- UC3M), C/ Nicola¬¥s Cabrera, 13-15, Madrid, 28049 Madrid, Spain Neural Computing and Applications (2023) 35:7817‚Äì7831 https://doi.org/10.1007/s00521-022-08088-2 (0123456789().,-volV) (0123456789(). ,- volV) although current implementations use two embedding layers whose inputs are, respectively, user and items. The experimental results evidence the DeepMF superiority over the traditional approaches based on ML-focused RS, par- ticularly the most used MF models: PMF, NMF, and BNMF. Currently, DeepMF is a popular model that is rapidly replacing the traditional MF models based on classical ML. Additionally, DeepMF has been used in the RS Ô¨Åeld to combine social behaviors (clicks, ratings,...) with images [ 18 ], and a social trust-aware RS has been implemented by using DeepMF to extract features from the user-item rating matrix for improving the initialization accuracy [ 19 ]. QoS predictions have also been addressed by using DeepMF [ 20 ]. To learn attribute representations, a DeepMF model has been used that creates a low-dimen- sional representation of a dataset that lends itself to a clustering interpretation [ 21 ]. Finally, the classical matrix completion task has been addressed by using the DeepMF approach [ 22 ]. The not so widely spread Neural Collaborative Filtering (NCF) model [ 13 ] may be seen as an augmented DeepMF model, where deeper layers are added to the ‚Äò Dot ‚Äô one. Additionally, the ‚Äò Dot ‚Äô layer can be replaced by a ‚Äò Concatenate ‚Äô layer. Figure 1 shows the explained concepts. NCF slightly outperforms the DeepMF accuracy results, but it increases the required runtime to train the model and to run the forward process: it is necessary to execute the ‚Äòextra‚Äô Multi-Layer Perceptron (MLP) on top of the ‚Äò Dot ‚Äô or ‚Äò Concatenate ‚Äô layers. Moreover, compared to DeepMF, the NCF architecture adds new hyper-parameters to set: mainly the number of hidden layers (depth) and their size (number of neurons in each layer) of the MLP architecture. The hypothesis of the paper is that we can improve the existing CF neural models by adding a variational stage that borrows its operative from the Variational Autoen- coders (VAE). VAEs not only improve latent factor-based models, but they also manage nonlinear probabilistic latent-variable models. While VAEs have been extensively used in the image-generative area, they have rarely been covered in the CF Ô¨Åeld. Autoencoders perform a nonlinear PCA, and VAEs improve their results by performing a nonlinear factor analysis. Unfortunately, regular autoen- coders do not ensure the regularity of the latent space; this is the reason why, in image processing, they do not perform Ô¨Åne producing new content from random encodings: Without explicit regularization, some combinations of the latent space are meaningless once decoded. The VAEs superiority comes from their ‚Äòvariational‚Äô behavior, which allows to make suitable regularizations such as in the statistic variational method. Using VAEs, inputs are encoded as distributions instead of single points, making it possible to naturally express latent space regularization. The CF improvement using VAEs is because the item and the user latent factor distributions are regularized in the training stage, ensuring that their latent spaces have good properties and conveniently generalize RS predictions. The VAEs regularization has two main properties: (1) com- pleteness: points sampled in the latent space give mean- ingful content once decoded, and (2) continuity: close points in the latent space provide similar contents when they are decoded. To accomplish these properties, usually regularization is done by enforcing distributions to be close to a centered and reduced standard normal distribution. Regularization involves a higher reconstruction error that can be balanced using the Kullback‚ÄìLeibler divergence. The use of VAE in the CF Ô¨Åeld provides a better Fig. 1 Deep Matrix Factorization (DeepMF) versus Neural Collaborative Filtering (NCF) 7818 Neural Computing and Applications (2023) 35:7817‚Äì7831 generalization; it not only can improve recommendations, but it also makes easier to use the latent codiÔ¨Åcations of items and users to make clustering, to explain recommen- dations, and to generate augmented datasets. The com- pleteness and continuity properties make possible these additional beneÔ¨Åts of the VAEs in the CF area. The rest of the paper has been structured as follows: In Sect. 2 , we describe the main ideas involved in our pro- posal, as well as its differences with the related work in variational CF-based recommender systems. In Sect. 3 , the proposed model is explained. Section 4 shows the experi- ments‚Äô design, results and their discussions. Finally, Sect. 5 contains the main conclusions of the paper and the future works. 2 Fundamentals and related work 2.1 VAEs as generative models Variational Autoencoders (VAEs) act as regular autoen- coders; they aim to compress the input raw values into a latent space representation by means of an encoder neural network, whereas the decoder neural network makes the opposite operation seeking to decompress from latent space to output raw values. The main difference between clas- sical autoencoders and VAEs is the latent space design, meaning, and operation. Classical autoencoders do not generate structured latent spaces, whereas VAEs introduce a statistical process that forces them to learn continuous and structured latent spaces. In this way, VAEs turn the samples into parameters of a statistical distribution, usually the means and variance of a Gaussian distribution. From the parameters in the multivariate distribution, we draw a random sample and a latent space sample is obtained for each training input. This operation procedure is represented in Fig. 2 . The stochasticity of the random sampling improves the robustness and forces the encoding of continuous and meaningful latent space representations, as it can be seen in Fig. 3 , where it is shown the VAE latent space represen- tation and its cumulative normal distribution. Due to their properties, VAEs have been used as gen- erative deep learning models in the image processing Ô¨Åeld. Reconstruction of a multispectral image has been per- formed by means of a VAE [ 23 ] that parameterizes the latent space of Gaussian distribution parameters. VAEs have been also used to create superresolution images as in [ 24 ], where a model is proposed to encode low-resolution images in a dense latent space vector that can be decoded for target high resolution image denoising. The blur image problem using VAE is tackled in [ 25 ] by adding a condi- tional sampling mechanism that narrows down the latent space, making it possible to reconstruct high resolution images. Moreover, in [ 26 ], the authors propose a Ô¨Çexible autoencoder model able to adapt to varying data patterns with time. By importing the VAE concept from image processing, several papers have used these models to improve RS results. For instance, denoising and variational autoencoders are tested in [ 27 ], where the authors reported the superiority of the VAE option against other models, or in [ 28 ], where variational autoencoders are combined with social information to improve the quality of the recommendations. 2.2 Our proposal: Deep variational models The aim of this paper is to propose a neural architecture that joins the best of the DeepMF and NCF models with the VAE concept. This novel models will be called, respec- tively, Variational Deep Matrix Factorization (VDeepMF) and Variational Neural Collaborative Filtering (VNCF). In contrast with the autoencoder and Generative Adversarial Network (GAN) approaches in the CF Ô¨Åeld [ 16 , 29 , 30 ], we shall not use the generative decoder stage and we maintain the regression output layer presented in the DeepMF and the NCF models. The main advantage in the use of the VAE operation is the robustness that it confers to the latent representation. This robustness can be seen by observing Fig. 3 . If we consider each dot drawn as a train sample representation in the latent space, then test samples are most likely to be correctly classiÔ¨Åed in the VAE model (right graph in Fig. 3 ) than being correctly classiÔ¨Åed in the regular autoencoder model (left graph in Fig. 3 ). In short, the variational approach stochastically ‚Äòspreads‚Äô the sam- ples in the latent space, improving the chances of classi- fying correctly the training samples. In our proposed RS CF scenario, we expect that rating values can be better predicted when a variational latent space has been learnt, because this space covers a wider, more robust, and more representative latent area. Whereas with a traditional autoencoders each sample would be coded as a value in the latent space (white circle in Fig. 4 ), the VAE encodes the parameters of a multivariate distri- bution (e.g., mean and variance of both the blue and the orange Gaussian distributions in Fig. 4 ). From the learnt distribution parameters, random sampling is carried out to generate stochastic latent space values (gray circles in Fig. 4 ). Each epoch in the learning process generates a new set of latent space values. Once the proposed model has been trained, when a h user, item i tuple is presented to the model, the obtained latent space value (green circle in Fig. 4 ) can be better predicted in the VAE scenario than in the regular autoencoder scenario: the random sampled values (gray circles) of the enriched latent space will help to associate the predicted sample (green circle) with their Neural Computing and Applications (2023) 35:7817‚Äì7831 7819 associated training samples (white circle), making the prediction process much more robust and accurate. From the above explanations, the VAE operation can be deÔ¨Åned following Fig. 2 in its ‚ÄòVariational layers‚Äô stage: Ô¨Årst, two dense layers code the normal distribution parameters that set the mean and variance of the latent factors. In the CF scenario, two dense layers are arranged to code the normal distribution parameters of the items, and two other different dense layers are used to code the normal distribution parameters of the users. This variational approach regularizes the latent factors and makes it pos- sible to reach the explained completeness and continuity goals. Once the distribution parameter layers are regular- ized, it is necessary to obtain a single latent factor point to code each user or item in the dataset; that is, for each user and item in the input of the model we need to combine its mean and variance. A normal random function is used to generate the latent factor point, coding the item (or the user) in the model input. Then, each latent factor point is obtained by combining: the normal random value, its item mean (or its user mean) and its item variance (or its user variance). This operation is usually performed using a neural ‚ÄòLambda‚Äô layer. Each Lambda layer result can be seen as a regularized version of the DeepMF nonvariational Fig. 2 Operation of a trained Variational Autoencoder (VAE) model. When a new sample is presented to the encoder stage (the handwritten digit ‚Äô2‚Äô in this example), the model produces in the latent space a probability distribution. Typically, this distribution belongs to a known family (a multivariate normal distribution in this example), so its shape is determined by some numerical parameters (mean and standard deviation in our case). With this information, the decoder stage generates an instance by sampling this distribution (getting a slightly different digit ‚Äô2‚Äô in this example). This introduces a stochastic component in the generation procedure that enriches the latent space and variability of the generative model Fig. 3 Representation of a VAE latent space for the MNIST dataset (left side) and its cumulative normal distribution (right side) 7820 Neural Computing and Applications (2023) 35:7817‚Äì7831 approach. Finally, we obtain the prediction of the rating of the user to the item by combining the ‚ÄòLambda‚Äô user and item factors using a dot product. In short, our variational approach incorporates the following substages: (1) Con- verting the input embedding factors to normal distribution values; and thus, making a regularization to generate continuous and complete latent factor codes, (2) Combin- ing the normal distribution latent factor codes to obtain single latent factor values, and (3) Predicting ratings by making the dot product of the regularized latent factor values. 2.3 VAEs for recommender systems Current CF-based variational autoencoders usually obtain raw augmented data. One strategy is to synthetize ratings from user to items or generated relevant versus not relevant votes from users to items [ 16 , 27 , 31 ], and another approach is to pre-train a VAE model to map data vectors into the latent space, an idea that has been intensively studied in several variants [ 32 ‚Äì 36 ]. In any case, these strategies force practitioners to sequentially run two separated models: the generative model (GAN or VAE) that provides augmented data, and the regression CF model that makes predictions and rec- ommendations. This approach presents three main draw- backs: (1) complexity, as two separate models are necessary, (2) large time consumption, and (3) sparsity management. As we will explain deeper in the following section, our proposed model does not generate raw aug- mented data. On the contrary, its innovation is based on the use of a single model to internally manage both augmen- tation and prediction aims. Particularly signiÔ¨Åcant is the way in which the proposed model addresses the sparsity problem: we do not make augmentation on the sparse raw data (ratings cast from users to item), but an internal ‚Äòaugmentation‚Äô process in the dense latent space of the model (Figs. 3 and 4 ). Each sample that is randomly gen- erated from the latent space feeds the model regression layers. Thereby, we propose a model that Ô¨Årst generates stochastic variational samples in a dense latent space, and then, these generated samples act as inputs of the regres- sion stage of the model. To test these ideas, the hypothesis considered in this paper is that the augmented samples will be more accurate and effective if they are generated in an inner and dense latent space rather than in a very sparse input space. It is important to realize that enriching the inner latent space can improve the recommendation results, but it also injects noise to the latent space that may potentially worsen the results. It is expected that the proposed approach will work better with poor latent spaces, whereas when it is applied to rich spaces, the spurious entropy added by the variational stage could worsen recommendations. Thus, medium-size CF datasets, or large and complex ones are better candi- dates to improve their results when the variational proposal is applied, whereas large datasets with predictable data distributions will probably not beneÔ¨Åt from the noise injection of the variational architecture. 3 Proposed model The proposed neural architecture will mix the VAE and the DeepMF (or the NCF) models. From the VAE, we take the encoder stage and its variational process, and from the DeepMF or the NCF model, we use its regression layers. This is an innovative approach in the RS Ô¨Åeld, since the VAE and GAN neural networks have only been used as a posteriori stage to make data augmentation, i.e., to obtain enriched input datasets to feed the CF DeepMF or NCF models. Hence, the traditional approach needs to separately train two models, Ô¨Årst the VAE and then the DeepMF/NCF networks. As discussed in Sect. 2.3 , these combined solu- tions present important disadvantages in terms of model complexity, time consumption and poor sparsity management. In sharp contrast, our proposed approach efÔ¨Åciently joins the VAE and the Deep CF regression concepts to obtain improved predictions with a single training process. In the learning stage, the training samples feed the model (left hand side of Fig. 5 ). Each training sample consists of the tuple h user, item, rating i (rating casted by the user to the item). In the DeepMF/NCF architecture, each user is represented by his/her vector of voted ratings, and each item is represented by its vector of received ratings. The model learns the ratings (third element in the tuples) casted by the users to the items (Ô¨Årst and second elements in the Fig. 4 Latent space representation of the proposed variational model. From the learnt means and variances of the multivariate Gaussian distribution, a random sampling process is run to spread the latent space sample values (gray circles) that will help to accurately predict the unknown sample rating values (green circle) Neural Computing and Applications (2023) 35:7817‚Äì7831 7821 tuples). In other words, the ratings are outputs of the neural network (right hand side of Fig. 5 ). Thanks to this architecture, the variational stage is nat- urally embedded into the model, so it can be Ô¨Çexibly used to inject variability into the samples. It is worth mentioning that this stage is also trained simultaneously to the pre- dictive part of the model, mutually inÔ¨Çuencing each other, which we expect will lead to better results than a simple separate learning. 3.1 Formalization of the model The architectural details of the proposed models are shown in Fig. 6 . For simplicity, only the Variational Deep Matrix Factorization (VDeepMF) architecture is shown in this Ô¨Ågure. The corresponding model for NCF, named Varia- tional Neural Collaborative Filtering (VNCF), is analogous to the VDeepMF one: it has the same ‚Äò Embedding ‚Äô and ‚Äò Variational ‚Äô layers and we should only replace the ‚Äò Dot ‚Äô layer of DeepMF by a ‚Äò Concatenate ‚Äô layer fol- lowed by a MLP. To Ô¨Åx the notation, let us suppose that our dataset contains U users and I items. In general, the aim of any deep learning model for CF-based prediction is to train a (stochastic) neural network that implements a function h : R U  R I ! R : This function h operates as follows. Let us codify the u -th user of the dataset (resp. the i -th item) using one-hot-en- coding as the u -th canonical basis vector e u (resp. the i -th canonical basis vector e i ). Then, we have that the outcome of the model is the following h √∞ e u ; e i √û 2 R ¬º Prediction of the score that the u 0th user would assign to the i 0th item : To train this function h , in the learning phase the neural network is fed with a set X ¬º h u ; i ; r i f g of training tuples h u ; i ; r i of a user u that rated item i with a score r . The function h is trained to minimize the error E √∞ h √û ¬º X h u ; i ; r i2 X d √∞ h √∞ e u ; e i √û ; r √û : √∞ 1 √û Here, d : R  R ! R is any metric on R . Typical choices are the so-called Mean Squared Error (MSE) and Mean Absolute Error (MAE), respectively, given by d MSE √∞ x ; y √û ¬º √∞ x  y √û 2 ; d MAE √∞ x ; y √û ¬º j x  y j : Our proposal for the VDeepMF consist on decomposing h has a combination of a ‚Äò Embedding ‚Äô, followed by a ‚Äò Variational ‚Äô stage and a Ô¨Ånal ‚Äò Dot ‚Äô layer, as shown in Fig. 6 ), that is h ¬º Dot  Variational  Embedding : Notice that, at the end of the day, h is a deep leaning model with novel customary layers designed for the RS problem. In this way, h can be trained to reduce the error E √∞ h √û of Eq. ( 1 ) with the standard Deep Learning (DL) methods, such as the backpropagation algorithm. 3.2 The embedding layer The Ô¨Årst ‚Äò Embedding ‚Äô layer (left hand side of Fig. 6 ) is borrowed from the Natural Language Processing (NLP) [ 13 ]. The idea is that this layers provides a fast translation of users and items into their respective Fig. 5 Proposed VDeepMF/ NCF approach. CF samples are encoded in the latent space by means of a variational process and then predictions are obtained by using a regression neural network 7822 Neural Computing and Applications (2023) 35:7817‚Äì7831 representations in the latent spaces. To be precise, this layer implements a linear map Embedding : R U  R I ! R L  R L ; that maps a pair √∞ e u ; e i √û into a pair of dense vectors √∞ v u ; w i √û 2 R L  R L that represents the u -th user and the i -th item, being L [ 0 the dimension of the representations. For our purpose, we implement the ‚Äò Embedding ‚Äô layer as a regular MLP dense layer, in sharp contrast with other approaches in NLP such as word2vec [ 37 , 38 ], GloVe [ 39 ] or ELMo [ 40 ], among others. The reason is that these later approaches seek to Ô¨Ånd an embedding preserving some metric information of the words, typically, the likelihood of Ô¨Ånding two words together or their semantic similarity. However, in our case, since we perform context-free CF prediction, no a priori information about the similarity between users or items is available. Indeed, this is precisely the ultimate goal of the RS: to Ô¨Ånd an appropriate repre- sentations of these users and items in the latent space. For this reason, we decided not to add any extra mechanism that could bias this training process, so the ‚Äò Embedding ‚Äô layer will act as a regular dense layer to be trained in parallel during the learning process. Finally, we would like to point out that, even though from a conceptual point of view the ‚Äò Embedding ‚Äô layer is just a dense layer, to save time and space, these ‚Äò Embedding ‚Äô layers are typically implemented through lookup tables. In this way, instead of feeding the network with the one-hot encoding of the user u (resp. the item i ), we input it via its ID as user (resp. as item). The lookup table efÔ¨Åciently recovers the u -th (resp. i -th) column of the embedding matrix that contains v u (resp. w i ) so that the translation can be conducted in a more efÔ¨Åcient way than with a standard MLP layer by exploiting the sparsity of the input. 3.3 The variational layer The variational process is carried out by the ‚Äò Varia- tional ‚Äô stage (labeled as ‚Äòvariational layers‚Äô at the middle of Fig. 6 ). This is the core of our proposed model. From the latent space representation √∞ v u ; w i √û 2 R L  R L of the u -th user and the i -th item, two separated dense layers return the mean and variance parameters of two Gaussian multivariate distribution. In this way, if Ô¨Åx a latent space dimension K [ 0, the Ô¨Årst part of this ‚Äò Variational ‚Äô stage (left part of the middle rectangle of Fig. 6 ) computes a map S √∞ v u ; w i √û ¬º √∞ l 1 √∞ v u √û ; r 2 1 √∞ v u √û ; l 2 √∞ w i √û ; r 2 √∞ w i √û√û 2 R 4 K : The outputs l 1 √∞ v u √û ; l 2 √∞ w i √û of S will be interpreted as the means of two Gaussian distributions to the user and the item, respectively, whereas r 2 1 √∞ v u √û ; r 2 √∞ w i √û will represent variance. The second part of the ‚Äò Variational ‚Äô stage (left right of the middle rectangle of Fig. 6 ) is ruled by a pair of random vectors √∞ P l 1 √∞ v u √û ; r 2 1 √∞ v u √û ; Q l 2 √∞ w i √û ; r 2 √∞ w i √û √û where P  N √∞ l 1 √∞ v u √û ; diag r 2 1 √∞ v u √û√û ; Q  N √∞ l 2 √∞ w u √û ; diag r 2 2 √∞ w i √û√û : Here, N √∞ l ; R √û denotes a K -dimensional multivariate nor- mal distribution of mean vector l and diagonal covariance matrix R , i.e., whose probability density function is Fig. 6 Proposed VDeepMF architecture. The NCF architecture will have identical ‚ÄòEmbedding‚Äô and ‚ÄòVariational‚Äô layers to the VDeepMF one; it will just replace the ‚ÄòDot‚Äô layer for a ‚ÄòConcatenate‚Äô layer, followed by an MLP Neural Computing and Applications (2023) 35:7817‚Äì7831 7823 f √∞ s √û ¬º 1 Ô¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨É √∞ 2 p √û K det R q exp  1 2 √∞ s  l √û t R  1 √∞ s  l √û   : Notice that, in our case, the covariance matrix is always diagonal. In this setting, the task of the ‚Äò Variational ‚Äô stage is just to sample P and Q . In this manner Variational √∞ v u ; w i √û ¬º √∞ p ; q √û 2 R K  R K ; where p is a sample of P ¬º P √∞ S √∞ v u ; w i √û√û  N √∞ l 1 √∞ v u √û ; diag r 2 1 √∞ v u √û√û and q is a sample of Q ¬º Q √∞ S √∞ v u ; w i √û√û  N √∞ l 2 √∞ w u √û ; diag r 2 2 √∞ w i √û√û . This pair represents the stochastic latent representations associated with √∞ v u ; w i √û . 3.4 The join layer This is the only layer that depends on the particular choice of the architecture. In the case of the Variational Deep Matrix Factorization (VDeepMF) architecture, this Ô¨Ånal layer is a ‚Äò Dot ‚Äô layer (labeled as ‚Äòregression layer‚Äô at right hand side of Fig. 6 ). It is just a linear layer that simply computes the dot product of the latent vectors p and q . Therefore Dot √∞ p ; q √û ¬º p  q : In the case of VNCF, this simple layer is replaced by a fully connected MLP H : R K ! R K ! R that extracts the nonlinear relations from p and q . Therefore, summarizing the process, the proposed VDeepMF model h computes h √∞ e u ; e i √û ¬º Dot  Variational  Embedding √∞ e u ; e i √û ¬º P l 1 √∞ v u √û ; r 2 1 √∞ v u √û  Q l 2 √∞ w i √û ; r 2 √∞ w i √û : Analogously, the VNCF model returns the proposed VDeepMF model h computes h √∞ e u ; e i √û ¬º H  Variational  Embedding √∞ e u ; e i √û ¬º H √∞ P l 1 √∞ v u √û ; r 2 1 √∞ v u √û ; Q l 2 √∞ w i √û ; r 2 √∞ w i √û √û : In both cases, h √∞ e u ; e i √û is a random variable that, when sampled, returns a natural number that should be inter- preted as the predicted rating by h for the user u regarding item i . 4 Empirical evaluation In this section, we describe the empirical experiments carried out to evaluate the performance of the variational approach in the DeepMF and NCF models. 4.1 Experimental setup The experimental evaluation has been performed over four different datasets to measure the performance of the pro- posed method over different environments. The selected datasets are: FilmTrust [ 41 ], an small dataset that contains the ratings of thousands of items to movies; MovieLens 1 M [ 42 ], the gold standard dataset in CF-based RS; MyAnimeList [ 43 ], a dataset extracted from Kaggle 1 that contains the ratings of thousands of users to anime comics; and NetÔ¨Çix [ 44 ], a popular dataset with hundred of millions ratings used in the NetÔ¨Çix Prize competition. Table 1 shows the main parameters of these datasets. The corpus of these datasets has been randomly splitted into training ratings (80% of the ratings) and test ratings (20% of the ratings). The evaluation of the proposed method has been ana- lyzed from three different points of view: the quality of the predictions [ 45 ], the quality of the recommendations [ 46 ], and the quality of the recommendation lists [ 47 ]. To measure the quality of the predictions, we have compared the real rating r u ; i of an user u to an item i of the test split R test with the predicted one, ^ r u ; i . These compar- isons have been carried out in three ways: using the MAE as in Eq. ( 2 ), using the MSE as in Eq. ( 3 ) and computing the proportion of the explained variance R 2 as in Eq. ( 4 ). Notice that, in Eq. ( 4 ),  r denotes the mean of the ratings contained in the test split. MAE ¬º 1 # R test X h u ; i i2 R test j r u ; i  ^ r u ; i j ; √∞ 2 √û MSE ¬º 1 # R test X h u ; i i2 R test r u ; i  ^ r u ; i   2 ; √∞ 3 √û R 2 ¬º 1  X h u ; i i2 R test r u ; i  ^ r u ; i   2 X h u ; i i2 R test r u ; i   r   2 : √∞ 4 √û To measure the quality of the recommendations, we have analyzed the impact of the top N recommended items to the user u , collected in the list T N u . Using precision Eq. ( 5 ), we measure the proportion of relevant recommendations (i.e., the user rated the item with a rated equal or greater than a threshold h ) among the top N . Here, U denotes the set of user in the test split. In a similar vein, using recall Eq. ( 6 ), we measure the proportion of the test items rated by the user u , R test u , that were relevant to him or her and were included into the recommended items T N u . For the con- ducted experiments, the used thresholds are h ¬º 3 for FilmTrust, h ¬º 4 for MovieLens and NetÔ¨Çix, and h ¬º 8 for MyAnimeList. These thresholds were chosen in agreement 1 www.kaggle.com . 7824 Neural Computing and Applications (2023) 35:7817‚Äì7831 with the results of [ 48 ], where it was shown that these values represent a fair trade-off between provided coverage of the dataset and prediction accuracy. Precision ¬º 1 # U X u 2 U f i 2 T N u j r u ; i  h g N ; √∞ 5 √û Recall ¬º 1 # U X u 2 U f i 2 T N u j r u ; i  h g f i 2 R test u j r u ; i  h g : √∞ 6 √û Additionally, we have measure the quality of the recom- mendations using the harmonic mean of the precision and the recall using F1 score Eq. ( 7 ). F1 ¬º 2  Precision  Recall Precision √æ Recall √∞ 7 √û However, evaluating the quality of recommendations based solely on user ratings provides a biased view of the rec- ommender‚Äôs performance. Therefore, we have also deter- mined the novelty Eq. ( 8 ) of the recommendations. Novelty [ 49 ] is calculated by assigning more weight to those items that have received fewer ratings. In other words, the nov- elty of an item is inversely proportional to the number of ratings received for an item ( # R i ) with respect to the total number of votes in the recommender system ( # R ). Novelty ¬º 1 # U X u 2 U P i 2 T N u  log 2 # R i # R   N : √∞ 8 √û Finally, to measure the quality of the recommendation lists, we use the normalized Discounted Cumulative Gain (nDCG). Suppose that the recommendation list of the user u , T N u , is sorted decreasingly so that the items predicted as more relevant are placed in the Ô¨Årst positions. Given i 2 T N u , let pos T N u √∞ i √û be the position of the item i in the recommendation list. Analogously, suppose that the real top N recommendations to user u , R N u , as sorted decreas- ingly and denote by pos R Nu √∞ i √û the position of the item i 2 R N u in the list. In this setting, the Discounted Cumulative Gain (DCG) and the Ideal Cumulative Gain (IDCG) of the user u 2 U are deÔ¨Åned as in Eq. ( 9 ). DCG u ¬º X i 2 T N u 2 r u ; i  1 log 2 pos T Nu √∞ i √û √æ 1   ; IDCG u ¬º X i 2 R N u 2 r u ; i  1 log 2 pos R Nu √∞ i √û √æ 1   : √∞ 9 √û In this way, nDCG is given by the mean of the ratio between DCG and IDCG as in Eq. ( 10 ). nDCG ¬º 1 # U X u 2 U DCG u IDCG u : √∞ 10 √û Due to the stochastic nature of the variational embedded space of the proposed method, the test predictions used to evaluate the proposed method have been computed as the average of the 10 predictions performed for each pair of user u and item i . Overall, the proposed variational architecture ade- quately improves simple models such as the DeepMF one, approaching their results to larger models such as the NCF. This tendency can be observed in both predictions and recommendation quality measures. Additionally, shorter running times are needed to train the proposed variational approach compared to baselines. This is the expected behavior in the hypothesis of the paper, but a remarkable constraint must be considered: the variational stage works particularly well when applied to not too large datasets, whereas using large datasets, the variational approach could not be necessary. The key idea is the ability of the Table 1 Main parameters of the datasets used in the experiments Dataset N users N items N ratings Scores Sparsity (%) FilmTrust 1508 2071 35,494 0.5 to 4.0 98.86 MovieLens 6040 3706 1,000,209 1 to 5 95.53 MyAnimeList 69,600 9927 6,337,234 1 to 10 99.08 NetÔ¨Çix 480,189 17,770 100,480,507 1 to 5 98.82 Table 2 Quality of the predictions FilmTrust MovieLens MyAnimeList NetÔ¨Çix (a) Mean Absolute Error. The lower the better. VDeepMF 0.6567. 0.6827 0.8722 0.7176 DeepMF 0.7957 0.6993 0.9044 0.6830 VNCF 0.6410 0.7263 0.9281 0.7474 NCF 0.6361 0.7021 0.8874 0.6903 (b) Mean Squared Error. The lower the better. VDeepMF 0.7324 0.7529 1.3453 0.8581 DeepMF 1.2046 0.7939 1.5017 0.7789 VNCF 0.6844 0.8179 1.4605 0.8952 NCF 0.6743 0.7908 1.3674. 0.7774 (c) R 2 score. The higher the better. VDeepMF 0.1438 0.3980 0.4549 0.2711 DeepMF - 0.4082 0.3652 0.3916 0.3384 VNCF 0.1999 0.3460 0.4083 0.2396 NCF 0.2118 0.3677 0.4460. 0.3397 The best results for each quality measure are highlighted in bold Neural Computing and Applications (2023) 35:7817‚Äì7831 7825 proposed model to deal with entropy: The variational stage increases entropy by generating stochastic latent factors and then enriching the latent space and making it more robust to the input sample variability. The intrinsic com- pleteness and continuity properties of the VAE are the foundations on which the variational approach gets robust, continuous, and structured latent spaces. These enriched spaces provide the improved results obtained in the experiments. 4.2 Experimental results Table 2 includes the quality of the predictions performed by the proposed model. Best values for each dataset are highlighted in bold. Table 2 a contains the MAE Eq. ( 2 ), Table 2 b contains the MSE Eq. ( 3 ), and Table 2 c contains the R 2 score Eq. ( 4 ). We can observe that the proposed variational approach improves the prediction capability of DeepMF in all datasets except of NetÔ¨Çix and reports worse predictions when it is applied to NCF. We justify these results by taking into account the fea- tures of the deep learning models used and the properties of each dataset. On the one hand, the larger the size of the dataset, the less necessary it is to enrich the votes with the proposed variational approach. In other words, when the dataset is small, the amount of Shannon entropy [ 50 ] that it contains might be quite limited. By using a variational method to generate new samples, we add some extra entropy that enriches the dataset, giving the chance to the regressive part of exploiting this extra data. However, large datasets usually present a large entropy in such a way that the regressive models can effectively extract very subtle information from them. In this setting, if we add a varia- tional stage, instead of adding new relevant variability to the dataset, we only add noise that muddies the underlying patterns. For this reason, the variational approach is of no beneÔ¨Åt in huge datasets like NetÔ¨Çix. On the other hand, the NCF model is more complex than the DeepMF one, so data enrichment has less impact for complex models that are able to Ô¨Ånd more sophisticated relationships between data than simpler models. In fact, Fig. 7 Quality of the recommendations measured by precision and recall. The higher the better 7826 Neural Computing and Applications (2023) 35:7817‚Äì7831 based on these results, we can assert that including the variational approach into a simple model such as DeepMF is equivalent to using a more complex model such as NCF. Furthermore, Figs. 7 and 8 show the quality of the recommendations using precision Eq. ( 5 ), recall Eq. ( 6 ) and F1 Eq. ( 7 ) quality measures. In FilmTrust (Figs. 7 a and 8 a), MovieLens (Figs. 7 b and 8 b) and MyAnimeList (Figs. 7 c and 8 c), we can observe that the proposed variational approach reports a beneÔ¨Åt for the DeepMF model and it worsens the results of the NCF model. In addition, VDeepMF model is the model that computes the best recommendations for these datasets. In contrast, in NetÔ¨Çix (Figs. 7 d and 8 d), the proposed variational approach does not improve the quality of the recommen- dations, with NCF being the model that provides the best recommendations for this dataset. These results are con- sistent with those analyzed when measuring the quality of the predictions. Consequently, it is evident that the pro- posed variational approach works adequately when the dataset is not too large and the model used is not too complex. Fig. 9 contains the quality of recommendations regard- ing novelty Eq. ( 8 ). It is observed that, when the variational stage is added to the DeepMF model, a signiÔ¨Åcant improvement of the novelty of the recommendations in small datasets is achieved. As the dataset becomes larger, the impact of the variational step is detrimental to the model. Thus, the variational stage has a positive impact on the FilmTrust (Fig. 9 a) and MovieLens (Fig. 9 b) datasets and a negative impact on the MyAnimeList (Fig. 9 c) and NetÔ¨Çix (Fig. 9 d) datasets. On the contrary, when a varia- tional stage is added to the NCF model, its impact on novelty is practically zero regardless of the dataset size. This experiment, like the previous ones, reafÔ¨Årms the conclusion that a variational step improves the results of simple models on small datasets. In addition, Fig. 10 contains the nDCG results. From it, we can observe the same trends as those shown in previous experiments: in FilmTrust (Fig. 10 a), the quality of the recommendation lists do not vary independently of whether the variational approach is used or not; in MovieLens (Fig. 10 b) and MyAnimeList (Fig. 10 c), the combination of the variational approach with simple modeling such as DeepMF, provides the best results; and in NetÔ¨Çix (Fig. 10 d), the variational approach signiÔ¨Åcantly worsens the quality of the recommendation lists. Fig. 8 Quality of the recommendations measured by F1. The higher the better Neural Computing and Applications (2023) 35:7817‚Äì7831 7827 5 Conclusions In the latest trends, accuracy of RSs is being improved by using deep learning models such as deep matrix factor- ization and neural collaborative Ô¨Åltering. However, these models do not incorporate stochasticity in their design, unlike variational autoencoders do. Variational random sampling has been used to create augmented input raw data in the collaborative Ô¨Åltering context, but the inherent col- laborative Ô¨Åltering data sparsity makes it difÔ¨Åcult to get accurate results. This paper applies the variational concept not to generate augmented sparse data, but to create aug- mented samples in the latent space codiÔ¨Åed at the dense inner layers of the proposed neural network. This is an innovative approach trying to combine the potential of the variational stochasticity with the augmentation concept. Augmented samples are generated in the dense latent space of the neural network model. In this way, we avoid the sparse scenario in the variational process. Observe that the proposed model in this paper also encodes the intrinsic locality of the users and items in the latent space. Recall that regular MF models capture the similarity of users and items in the latent space since pre- dictions are constructed via inner product, a continuous function. In the same spirit, our variational models also preserve this locality since the output is still computed through a continuous function: the feed-forward neural network, a much more complicated function, but eventu- ally continuous. Moreover, since the probability distribu- tions representing each user and item in the latent space depend on continuous parameters (the mean and standard deviation of a Gaussian distribution), small variations in these parameters, corresponding to similar items or users, are also encoded as almost equal distributions, and thus, their samples tend to be also close in the distributional sense. Thanks to these ideas, the results of the experimental analyses conducted in this paper show an important improvement when the proposed models are applied to middle-size representative collaborative Ô¨Åltering datasets, compared to the state-of-the-art baselines, testing both prediction and recommendation quality measures. In sharp contrast, testing on the huge NetÔ¨Çix dataset not only leads to no improvement, but the recommendation quality Fig. 9 Quality of the recommendations measured by novelty. The higher the better 7828 Neural Computing and Applications (2023) 35:7817‚Äì7831 actually gets worse. In this manner, increasing the Shannon entropy in rich latent spaces causes that the negative effect of the introduced noise exceeds its beneÔ¨Åt. Therefore, the proposed deep variational models should be applied to seek to a fair balance between their positive enrichment and their negative noise injection. To emphasize this idea, in Table 3, we show the total time and epochs required by each model to be Ô¨Åtted to each dataset using a Quadro RTX 8000 GPU. Best time for each dataset is in bold. We can observe that including a varia- tional layer to the model signiÔ¨Åcantly reduces the required time for Ô¨Åtting. Variational models are able to generate Shannon entropy that is transferred to the regression stage, leading to a more effective training that requires fewer epochs to be Ô¨Åtted. Therefore, the Ô¨Åtting time needed to reach acceptable results is substantially lower. The results presented in this work can be considered as generalizable, since they were analyzed in four represen- tative and open CF datasets. Researchers can reproduce our experiments and easily create their own models by using the provided framework referenced in Sect. 3 . The authors of this work are committed to reproducible science, so the code used in these experiments is publicly available. Among the most promising future works, we propose the following: (1) introducing the variational process in the alternative inner layers of the relevant architectures in the collaborative Ô¨Åltering area, (2) screening the learning evolution in the training process, since it is faster than the classical models but it also requires early stopping in the Fig. 10 Quality of the recommendations lists measured by NDCG. The higher the better Table 3 Fitting time using a Quadro RTX 8000 FilmTrust MovieLens MyAnimeList NetÔ¨Çix VDeepMF 61s (15 epochs) 601s (6 epochs) 7629s (9 epochs) 12655s (3 epochs). DeepMF 75s (25 epochs) 677s (10 epochs) 13217s (20 epochs) 15697s (4 epochs) VNCF 35s (7 epochs) 1030s (9 epochs) 9945s (9 epochs) 12650s (3 epochs) NCF 56s (15 epochs) 876s (10 epochs) 12111s (15 epochs) 16896s (4 epochs) Best Ô¨Åtting times for each datased in bold Neural Computing and Applications (2023) 35:7817‚Äì7831 7829 training stage, (3) providing further theoretical explana- tions of the properties of the CF datasets, in terms of Shannon entropy or other statistical features, that ensure a good performance of the proposed models, (4) applying probabilistic deep learning models in the CF Ô¨Åeld to cap- ture complex nonlinear stochastic relationships between random variables, and (5) testing the impact of the pro- posed concept when recommendations are made to groups of users. Acknowledgements A ¬¥ . G.-P. acknowledges the hospitality of the Department of Mathematics at Universidad Auto¬¥noma de Madrid where part of this work was developed. This work was partially supported by Ministerio de Ciencia e Innovacio¬¥n of Spain under the project PID2019-106493RB-I00 (DL-CEMG) and the Comunidad de Madrid under Convenio Plurianual with the Universidad Polite¬¥cnica de Madrid in the actuation line of Programa de Excelencia para el Profesorado Universitario . The forth author has been partially sup- ported by the Madrid Government (Comunidad de Madrid ‚Äì Spain) under the Multiannual Agreement with the Universidad Complutense de Madrid in the line Research Incentive for Young PhDs, in the context of the V PRICIT (Regional Programme of Research and Technological Innovation) through the project PR27/21-029. Funding Open Access funding provided thanks to the CRUE-CSIC agreement with Springer Nature. Data availability The datasets analyzed during the current study are available in the repositories referred in the references [ 41 ‚Äì 44 ]. Declarations Conflict of interest The authors declare that they have no conflict of interest. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article‚Äôs Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article‚Äôs Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons. org/licenses/by/4.0/ . References 1. Beel J, Langer S, Genzmehr M, Gipp B, Breitinger C, Nu¬®rnberger A (2013) Research paper recommender system evaluation: a quantitative literature survey. In: Proceedings of the international workshop on reproducibility and replication in recommender systems evaluation, pp 15‚Äì22 2. Bobadilla J, Gonza¬¥lez-Prieto A ¬¥ , Ortega F, Lara-Cabrera R (2021) Deep learning feature selection to unhide demographic recom- mender systems factors. Neural Comput Appl 33(12):7291‚Äì7308 3. Deldjoo Y, Schedl M, Cremonesi P, Pasi G (2020) Recommender systems leveraging multimedia content. ACM Comput Surveys (CSUR) 53(5):1‚Äì38 4. Kulkarni S, Rodd SF (2020) Context aware recommendation systems: a review of the state of the art techniques. Comput Sci Rev 37:100255 5. Shokeen J, Rana C (2020) A study on features of social recom- mender systems. Artif Intell Rev 53(2):965‚Äì988 6. Bobadilla J, Alonso S, Hernando A (2020) Deep learning archi- tecture for collaborative Ô¨Åltering recommender systems. Appl Sci 10(7):2441 7. Forouzandeh S, Berahmand K, Rostami M (2021) Presentation of a recommender system with ensemble learning and graph embedding: a case on movielens. Multimed Tools Appl 80(5):7805‚Äì7832 8. C¬∏ ano E, Morisio M (2017) Hybrid recommender systems: a systematic literature review. Intell Data Anal 21(6):1487‚Äì1524 9. Mnih A, Salakhutdinov RR (2007) Probabilistic matrix factor- ization. Adv Neural Inf Process Syst 20:1257‚Äì1264 10. Fe¬¥votte C, Idier J (2011) Algorithms for nonnegative matrix factorization with the b -divergence. Neural Comput 23(9):2421‚Äì2456 11. Hernando A, Bobadilla J, Ortega F (2016) A non negative matrix factorization for collaborative Ô¨Åltering recommender systems based on a bayesian probabilistic model. Knowl-Based Syst 97:188‚Äì202 12. Rendle S, Krichene W, Zhang L, Anderson J (2020) Neural collaborative Ô¨Åltering vs. matrix factorization revisited. In: Fourteenth ACM conference on recommender systems, pp 240‚Äì248 13. He X, Liao L, Zhang H, Nie L, Hu X, Chua T-S (2017) Neural collaborative Ô¨Åltering. In: Proceedings of the 26th international conference on world wide web, pp 173‚Äì182 14. Narang S, Taneja N (2018) Deep content-collaborative recom- mender system (dccrs). In: 2018 international conference on advances in computing, communication control and networking (ICACCCN), pp 110‚Äì116. IEEE 15. Bobadilla J, Lara-Cabrera R, Gonza¬¥lez-Prieto A ¬¥ , Ortega F (2021) Deepfair: deep learning for improving fairness in recommender systems. Int J Interact Multimed Artif Intell 6(6):86‚Äì94 16. Gao M, Zhang J, Yu J, Li J, Wen J, Xiong Q (2021) Recom- mender systems based on generative adversarial networks: a problem-driven perspective. Inf Sci 546:1166‚Äì1185 17. Xue H-J, Dai X, Zhang J, Huang S, Chen J (2017) Deep matrix factorization models for recommender systems. In: IJCAI, Mel- bourne, Australia, vol 17, pp 3203‚Äì3209 18. Wen J, She J, Li X, Mao H (2018) Visual background recom- mendation for dance performances using deep matrix factoriza- tion. ACM Trans Multimed Comput Commun Appl (TOMM) 14(1):1‚Äì19 19. Wan L, Xia F, Kong X, Hsu C-H, Huang R, Ma J (2020) Deep matrix factorization for trust-aware recommendation in social networks. IEEE Trans Network Sci Eng 8(1):511‚Äì528 20. Zou G, Chen J, He Q, Li K-C, Zhang B, Gan Y (2020) Ndmf: Neighborhood-integrated deep matrix factorization for service qos prediction. IEEE Trans Netw Serv Manage 17(4):2717‚Äì2730 21. Trigeorgis G, Bousmalis K, Zafeiriou S, Schuller BW (2016) A deep matrix factorization method for learning attribute repre- sentations. IEEE Trans Pattern Anal Mach Intell 39(3):417‚Äì429 22. Fan J, Cheng J (2018) Matrix completion by deep matrix fac- torization. Neural Netw 98:34‚Äì41 23. Liu X, Gherbi A, Wei Z, Li W, Cheriet M (2020) Multispectral image reconstruction from color images using enhanced varia- tional autoencoder and generative adversarial network. IEEE Access 9:1666‚Äì1679 7830 Neural Computing and Applications (2023) 35:7817‚Äì7831 24. Liu Z-S, Siu W-C, Wang L-W, Li C-T, Cani M-P (2020) Unsupervised real image super-resolution via generative varia- tional autoencoder. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops, pp 442‚Äì443 25. Liu Z-S, Siu W-C, Chan Y-L (2020) Photo-realistic image super- resolution via variational autoencoders. IEEE Trans Circ Syst Video Technol 31(4):1351‚Äì1365 26. Zhang S-s, Liu J-w, Zuo X, Lu R-k, Lian S-m (2021) Online deep learning based on auto-encoder. Appl Intell 51(8):5420‚Äì5439 27. Liang D, Krishnan RG, Hoffman MD, Jebara T (2018) Varia- tional autoencoders for collaborative Ô¨Åltering. In: Proceedings of the 2018 world wide web conference, pp 689‚Äì698 28. Nisha C, Mohan A (2019) A social recommender system using deep architecture and network embedding. Appl Intell 49(5):1937‚Äì1953 29. Rama K, Kumar P, Bhasker B (2021) Deep autoencoders for feature learning with embeddings for recommendations: a novel recommender system solution. Neural Comput Appl 33(21):14167‚Äì14177 30. Tahmasebi H, Ravanmehr R, Mohamadrezaei R (2021) Social movie recommender system based on deep autoencoder network using twitter data. Neural Comput Appl 33(5):1607‚Äì1623 31. Li X, She J (2017) Collaborative variational autoencoder for recommender systems. In: Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining, pp 305‚Äì314 32. He M, Meng Q, Zhang S (2019) Collaborative additional varia- tional autoencoder for top-n recommender systems. IEEE Access 7:5707‚Äì5713 33. Nahta R, Meena YK, Gopalani D, Chauhan GS (2021) Two-step hybrid collaborative Ô¨Åltering using deep variational bayesian autoencoders. Inf Sci 562:136‚Äì154 34. Shenbin I, Alekseev A, Tutubalina E, Malykh V, Nikolenko SI (2020) Recvae: a new variational autoencoder for top-n recom- mendations with implicit feedback. In: Proceedings of the 13th international conference on web search and data mining, pp. 528‚Äì536 35. Wang K, Xu L, Huang L, Wang C-D, Lai J-H (2019) Sddrs: stacked discriminative denoising auto-encoder based recom- mender system. Cogn Syst Res 55:164‚Äì174 36. Liu Y, Wang S, Khan MS, He J (2018) A novel deep hybrid recommender system based on auto-encoder with neural collab- orative Ô¨Åltering. Big Data Mining Anal 1(3):211‚Äì221 37. Mikolov T, Sutskever I, Chen K, Corrado GS, Dean J (2013) Distributed representations of words and phrases and their com- positionality. Adv Neural Inform Process Syst 26 38. Mikolov T, Chen K, Corrado G, Dean J (2013) EfÔ¨Åcient esti- mation of word representations in vector space. arXiv preprint arXiv:1301.3781 39. Pennington J, Socher R, Manning CD (2014) Glove: Global vectors for word representation. In: Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pp 1532‚Äì1543 40. Peters M, Neumann M, Iyyer M, Gardner M, Clark C, Lee K, Zettlemoyer L (1802) Deep contextualized word representations. 2018. arXiv preprint arXiv:1802.05365 41. Guo G, Zhang J, Yorke-Smith N (2013) A novel bayesian simi- larity measure for recommender systems. In: Proceedings of the 23rd international joint conference on artiÔ¨Åcial intelligence (IJCAI), pp 2619‚Äì2625 42. Harper FM, Konstan JA (2015) The movielens datasets: history and context. Acm Trans Interact Intell Syst (tiis) 5(4):1‚Äì19 43. Azathoth: MyAnimeList Dataset. https://www.kaggle.com/aza thoth42/myanimelist . [Online; accessed 06-July-2021] (2018) 44. Bennett J, Lanning S et al (2007) The netÔ¨Çix prize. In: Pro- ceedings of KDD Cup and Workshop, New York, NY, USA, vol 2007, p 35. 45. Bobadilla J, Hernando A, Ortega F, Bernal J (2011) A framework for collaborative Ô¨Åltering recommender systems. Expert Syst Appl 38(12):14609‚Äì14623 46. Herlocker J-L, Konstan J-A, Terveen L-G, Riedl J-T (2004) Evaluating collaborative Ô¨Åltering recommender systems. ACM Trans Inf Syst 22(1):5‚Äì53 47. Gunawardana A, Shani G (2015) Evaluating recommender sys- tems. Handbook, Boston, MA 48. Ortega F, Lara-Cabrera R, Gonza¬¥lez-Prieto A ¬¥ , Bobadilla J (2021) Providing reliability in recommender systems through bernoulli matrix factorization. Inf Sci 553:110‚Äì128 49. Castells P, Vargas S, Wang J (2011) Novelty and diversity metrics for recommender systems: choice, discovery and rele- vance. In: Proceedings of the 33rd European conference on information retrieval (ECIR‚Äô11) 50. Shannon CE, Weaver W (1949) The mathematical theory of communication. University of Illinois Press, Urbana Publisher‚Äôs Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional afÔ¨Åliations. Neural Computing and Applications (2023) 35:7817‚Äì7831 7831",original article deep variational model collaborative filteringbased recommender system jesus bobadilla fernando ortega abraham gutierrez ngel gonzalezprieto received september accepted november published online december author deep learning provides accurate collaborative Ô¨Åltering model improve recommender result deep matrix factorization related collaborative neural network state art Ô¨Åeld nevertheless model lack necessary stochasticity create robust continuous structured latent space variational autoencoders exhibit hand augmentation variational autoencoder provide accurate result collaborative Ô¨Åltering Ô¨Åeld due high sparsity recommender system proposed model apply variational concept inject stochasticity latent space deep architecture introducing variational technique neural collaborative Ô¨Åltering Ô¨Åeld depend particular used generate latent representation way applied plugin current future speciÔ¨Åc model proposed model tested four representative open datasets three different quality measure stateoftheart baseline result show superiority proposed scenario variational enrichment exceeds injected noise effect additionally framework provided enable reproducibility conducted experiment keywords recommender system collaborative Ô¨Åltering variational enrichment deep learning recommender system rss artiÔ¨Åcial intelligence Ô¨Åeld provides method model predict recommend item user eg Ô¨Ålms person ecom merce product costumer service company quality service qos internet thing iot device etc current popular rss spotify netÔ¨Çix tripadvisor amazon etc rss usually categorized attending Ô¨Åltering strategy mainly demo graphic contentbased contextaware social collaborative filtering cf Ô¨Åltering ensemble cf accurate widely used Ô¨Åltering implement rss cf model evolved knearest neighbor knn probabilistic matrix factorization pmf non negative matrix factorization nmf baye sian nonnegative matrix factorization bnmf currently deep learning research approach growing strength provide improvement accuracy com pared machine learning mlbased matrix fac torization mf model additionally deep learning architecture usually Ô¨Çexible mfbased one introducing combined deep shallow learn ing integrated contentbased ensemble gener ative approach among others deep matrix factorization deepmf neural network implement popular mf concept deepmf designed take input useritem matrix explicit rating nonpreference implicit feedback ngel gonzalezprieto angelgonzalezprietoucmes departamento de sistemas informaticos etsi sistemas informaticos universidad politecnica de c de alan turing sn spain knodis research group universidad politecnica de c de alan turing sn spain departamento de lgebra geometrƒ±a topologƒ±a universidad complutense de plaza ciencias spain instituto de ciencias matematicas csicuamucm ucm c nicolas cabrera spain neural computing application httpsdoiorgs volv volv although current implementation use two embedding layer whose input respectively user item experimental result evidence deepmf superiority traditional approach mlfocused r par ticularly used mf model pmf nmf bnmf currently deepmf popular rapidly replacing traditional mf model classical ml additionally deepmf used r Ô¨Åeld combine social behavior click rating image social trustaware r implemented deepmf extract feature useritem rating matrix improving initialization accuracy qos prediction also addressed deepmf learn attribute representation deepmf used creates lowdimen sional representation dataset lends clustering interpretation finally classical matrix completion task addressed deepmf widely spread neural collaborative filtering ncf may seen augmented deepmf deeper layer added dot one additionally dot layer replaced concatenate layer show explained concept ncf slightly outperforms deepmf accuracy result increase required runtime train run forward process necessary execute extra multilayer perceptron mlp top dot concatenate layer moreover compared deepmf ncf architecture add new hyperparameters set mainly number hidden layer depth size number neuron layer mlp architecture hypothesis improve existing cf neural model adding variational stage borrows operative variational autoen coder vae vaes improve latent factorbased model also manage nonlinear probabilistic latentvariable model vaes extensively used imagegenerative area rarely covered cf Ô¨Åeld autoencoders perform nonlinear pca vaes improve result performing nonlinear factor unfortunately regular autoen coder ensure regularity latent space reason image processing perform Ô¨Åne producing new content random encoding without explicit regularization combination latent space meaningless decoded vaes superiority come variational behavior allows make suitable regularization statistic variational vaes input encoded distribution instead single point making possible naturally express latent space regularization cf improvement vaes item user latent factor distribution regularized training stage ensuring latent space good property conveniently generalize r prediction vaes regularization two main property com pleteness point sampled latent space give mean ingful content decoded continuity close point latent space provide similar content decoded accomplish property usually regularization done enforcing distribution close centered reduced standard normal distribution regularization involves higher reconstruction error balanced kullbackleibler divergence use vae cf Ô¨Åeld provides better fig deep matrix factorization deepmf versus neural collaborative filtering ncf neural computing application generalization improve recommendation also make easier use latent codiÔ¨Åcations item user make clustering explain recommen dations generate augmented datasets com pleteness continuity property make possible additional beneÔ¨Åts vaes cf area rest structured follows sect describe main idea involved pro posal well difference related work variational cfbased recommender system sect proposed explained section show experi ments design result discussion finally sect contains main conclusion future work fundamental related work vaes generative model variational autoencoders vaes act regular autoen coder aim compress input raw value latent space representation mean encoder neural network whereas decoder neural network make opposite operation seeking decompress latent space output raw value main difference clas sical autoencoders vaes latent space design meaning operation classical autoencoders generate structured latent space whereas vaes introduce statistical process force learn continuous structured latent space way vaes turn sample parameter statistical distribution usually mean variance gaussian distribution parameter multivariate distribution draw random latent space obtained training input operation procedure represented fig stochasticity random sampling improves robustness force encoding continuous meaningful latent space representation seen fig shown vae latent space represen tation cumulative normal distribution due property vaes used gen erative deep learning model image processing Ô¨Åeld reconstruction multispectral image per formed mean vae parameterizes latent space gaussian distribution parameter vaes also used create superresolution image proposed encode lowresolution image dense latent space vector decoded target high resolution image denoising blur image problem vae tackled adding condi tional sampling mechanism narrow latent space making possible reconstruct high resolution image moreover author Ô¨Çexible autoencoder able adapt varying pattern time importing vae concept image processing several paper used model improve r result instance denoising variational autoencoders tested author reported superiority vae option model variational autoencoders combined social improve quality recommendation proposal deep variational model aim neural architecture join best deepmf ncf model vae concept novel model called respec tively variational deep matrix factorization vdeepmf variational neural collaborative filtering vncf contrast autoencoder generative adversarial network gan approach cf Ô¨Åeld shall use generative decoder stage maintain regression output layer presented deepmf ncf model main advantage use vae operation robustness confers latent representation robustness seen observing fig consider dot drawn train representation latent space test sample likely correctly classiÔ¨Åed vae right graph fig correctly classiÔ¨Åed regular autoencoder left graph fig short variational stochastically spread sam ples latent space improving chance classi fying correctly training sample proposed r cf scenario expect rating value better predicted variational latent space learnt space cover wider robust representative latent area whereas traditional autoencoders would coded latent space white circle fig vae encodes parameter multivariate distri bution eg mean variance blue orange gaussian distribution fig learnt distribution parameter random sampling carried generate stochastic latent space value gray circle fig epoch learning process generates new set latent space value proposed trained h user item tuple presented obtained latent space green circle fig better predicted vae scenario regular autoencoder scenario random sampled value gray circle enriched latent space help associate predicted green circle neural computing application associated training sample white circle making prediction process much robust accurate explanation vae operation deÔ¨Åned following fig variational layer stage Ô¨Årst two dense layer code normal distribution parameter set mean variance latent factor cf scenario two dense layer arranged code normal distribution parameter item two different dense layer used code normal distribution parameter user variational regularizes latent factor make po sible reach explained completeness continuity goal distribution parameter layer regular ized necessary obtain single latent factor point code user item dataset user item input need combine mean variance normal random function used generate latent factor point coding item user input latent factor point obtained combining normal random item mean user mean item variance user variance operation usually performed neural lambda layer lambda layer seen regularized version deepmf nonvariational fig operation trained variational autoencoder vae new presented encoder stage handwritten digit example produce latent space probability distribution typically distribution belongs known family multivariate normal distribution example shape determined numerical parameter mean standard deviation decoder stage generates instance sampling distribution getting slightly different digit example introduces stochastic component generation procedure enriches latent space variability generative fig representation vae latent space mnist dataset left side cumulative normal distribution right side neural computing application finally obtain prediction rating user item combining lambda user item factor dot product short variational incorporates following substages con verting input embedding factor normal distribution value thus making regularization generate continuous complete latent factor code combin ing normal distribution latent factor code obtain single latent factor value predicting rating making dot product regularized latent factor value vaes recommender system current cfbased variational autoencoders usually obtain raw augmented one strategy synthetize rating user item generated relevant versus relevant vote user item another pretrain vae map vector latent space idea intensively studied several variant strategy force practitioner sequentially run two separated model generative gan vae provides augmented regression cf make prediction rec ommendations present three main draw back complexity two separate model necessary large time consumption sparsity management explain deeper following section proposed generate raw aug mented contrary innovation use single internally manage augmen tation prediction aim particularly signiÔ¨Åcant way proposed address sparsity problem make augmentation sparse raw rating cast user item internal augmentation process dense latent space fig randomly gen erated latent space feed regression layer thereby Ô¨Årst generates stochastic variational sample dense latent space generated sample act input regres sion stage test idea hypothesis considered augmented sample accurate effective generated inner dense latent space rather sparse input space important realize enriching inner latent space improve recommendation result also injects noise latent space may potentially worsen result expected proposed work better poor latent space whereas applied rich space spurious entropy added variational stage could worsen recommendation thus mediumsize cf datasets large complex one better candi date improve result variational proposal applied whereas large datasets predictable distribution probably beneÔ¨Åt noise injection variational architecture proposed proposed neural architecture mix vae deepmf ncf model vae take encoder stage variational process deepmf ncf use regression layer innovative r Ô¨Åeld since vae gan neural network used posteriori stage make augmentation ie obtain enriched input datasets feed cf deepmf ncf model hence traditional need separately train two model Ô¨Årst vae deepmfncf network discussed sect combined solu tions present important disadvantage term complexity time consumption poor sparsity management sharp contrast proposed efÔ¨Åciently join vae deep cf regression concept obtain improved prediction single training process learning stage training sample feed left hand side fig training consists tuple h user item rating rating casted user item deepmfncf architecture user represented hisher vector voted rating item represented vector received rating learns rating third element tuples casted user item Ô¨Årst second element fig latent space representation proposed variational learnt mean variance multivariate gaussian distribution random sampling process run spread latent space value gray circle help accurately predict unknown rating value green circle neural computing application tuples word rating output neural network right hand side fig thanks architecture variational stage nat urally embedded Ô¨Çexibly used inject variability sample worth mentioning stage also trained simultaneously pre dictive part mutually inÔ¨Çuencing expect lead better result simple separate learning formalization architectural detail proposed model shown fig simplicity variational deep matrix factorization vdeepmf architecture shown Ô¨Ågure corresponding ncf named varia tional neural collaborative filtering vncf analogous vdeepmf one embedding variational layer replace dot layer deepmf concatenate layer fol lowed mlp Ô¨Åx notation let u suppose dataset contains u user item general aim deep learning cfbased prediction train stochastic neural network implement function h r u r r function h operates follows let u codify u th user dataset resp th item onehoten coding u th canonical basis vector e u resp th canonical basis vector e outcome following h √∞ e u e √æ r ¬º prediction score u th user would assign th item train function h learning phase neural network fed set x ¬º h u r f g training tuples h u r user u rated item score r function h trained minimize error e √∞ h √æ ¬º x h u r x √∞ h √∞ e u e √æ r √æ √∞ √æ r r r metric r typical choice socalled mean squared error mse mean absolute error mae respectively given mse √∞ x √æ ¬º √∞ x √æ mae √∞ x √æ ¬º j x j proposal vdeepmf consist decomposing h combination embedding followed variational stage Ô¨Ånal dot layer shown fig h ¬º dot variational embedding notice end day h deep leaning novel customary layer designed r problem way h trained reduce error e √∞ h √æ eq standard deep learning dl method backpropagation embedding layer Ô¨Årst embedding layer left hand side fig borrowed natural language processing nlp idea layer provides fast translation user item respective fig proposed vdeepmf ncf cf sample encoded latent space mean variational process prediction obtained regression neural network neural computing application representation latent space precise layer implement linear map embedding r u r r l r l map pair √∞ e u e √æ pair dense vector √∞ v u w √æ r l r l represents u th user th item l dimension representation purpose implement embedding layer regular mlp dense layer sharp contrast approach nlp wordvec glove elmo among others reason later approach seek Ô¨Ånd embedding preserving metric word typically likelihood Ô¨Ånding two word together semantic similarity however since perform contextfree cf prediction priori similarity user item available indeed precisely ultimate goal r Ô¨Ånd appropriate repre sentations user item latent space reason decided add extra mechanism could bias training process embedding layer act regular dense layer trained parallel learning process finally would like point even though conceptual point view embedding layer dense layer save time space embedding layer typically implemented lookup table way instead feeding network onehot encoding user u resp item input via id user resp item lookup efÔ¨Åciently recovers u th resp th column embedding matrix contains v u resp w translation conducted efÔ¨Åcient way standard mlp layer exploiting sparsity input variational layer variational process carried varia tional stage labeled variational layer middle fig core proposed latent space representation √∞ v u w √æ r l r l u th user th item two separated dense layer return mean variance parameter two gaussian multivariate distribution way Ô¨Åx latent space dimension k Ô¨Årst part variational stage left part middle rectangle fig computes map √∞ v u w √æ ¬º √∞ l √∞ v u √æ r √∞ v u √æ l √∞ w √æ r √∞ w √æ√æ r k output l √∞ v u √æ l √∞ w √æ interpreted mean two gaussian distribution user item respectively whereas r √∞ v u √æ r √∞ w √æ represent variance second part variational stage left right middle rectangle fig ruled pair random vector √∞ p l √∞ v u √æ r √∞ v u √æ q l √∞ w √æ r √∞ w √æ √æ p n √∞ l √∞ v u √æ diag r √∞ v u √æ√æ q n √∞ l √∞ w u √æ diag r √∞ w √æ√æ n √∞ l r √æ denotes k dimensional multivariate mal distribution mean vector l diagonal covariance matrix r ie whose probability density function fig proposed vdeepmf architecture ncf architecture identical embedding variational layer vdeepmf one replace dot layer concatenate layer followed mlp neural computing application f √∞ √æ ¬º Ô¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨É √∞ p √æ k det r q exp √∞ l √æ r √∞ l √æ notice covariance matrix always diagonal setting task variational stage p q manner variational √∞ v u w √æ ¬º √∞ p q √æ r k r k p p ¬º p √∞ √∞ v u w √æ√æ n √∞ l √∞ v u √æ diag r √∞ v u √æ√æ q q ¬º q √∞ √∞ v u w √æ√æ n √∞ l √∞ w u √æ diag r √∞ w √æ√æ pair represents stochastic latent representation associated √∞ v u w √æ join layer layer depends particular choice architecture variational deep matrix factorization vdeepmf architecture Ô¨Ånal layer dot layer labeled regression layer right hand side fig linear layer simply computes dot product latent vector p q therefore dot √∞ p q √æ ¬º p q vncf simple layer replaced fully connected mlp h r k r k r extract nonlinear relation p q therefore summarizing process proposed vdeepmf h computes h √∞ e u e √æ ¬º dot variational embedding √∞ e u e √æ ¬º p l √∞ v u √æ r √∞ v u √æ q l √∞ w √æ r √∞ w √æ analogously vncf return proposed vdeepmf h computes h √∞ e u e √æ ¬º h variational embedding √∞ e u e √æ ¬º h √∞ p l √∞ v u √æ r √∞ v u √æ q l √∞ w √æ r √∞ w √æ √æ case h √∞ e u e √æ random variable sampled return natural number inter preted predicted rating h user u regarding item empirical evaluation section describe empirical experiment carried evaluate performance variational deepmf ncf model experimental setup experimental evaluation performed four different datasets measure performance pro posed different environment selected datasets filmtrust small dataset contains rating thousand item movie movielens gold standard dataset cfbased r myanimelist dataset extracted kaggle contains rating thousand user anime comic netÔ¨Çix popular dataset hundred million rating used netÔ¨Çix prize competition show main parameter datasets corpus datasets randomly splitted training rating rating test rating rating evaluation proposed ana lyzed three different point view quality prediction quality recommendation quality recommendation list measure quality prediction compared real rating r u user u item test split r test predicted one r u compar isons carried three way mae eq mse eq computing proportion explained variance r eq notice eq r denotes mean rating contained test split mae ¬º r test x h u r test j r u r u j √∞ √æ mse ¬º r test x h u r test r u r u √∞ √æ r ¬º x h u r test r u r u x h u r test r u r √∞ √æ measure quality recommendation analyzed impact top n recommended item user u collected list n u precision eq measure proportion relevant recommendation ie user rated item rated equal greater threshold h among top n u denotes set user test split similar vein recall eq measure proportion test item rated user u r test u relevant included recommended item n u con ducted experiment used threshold h ¬º filmtrust h ¬º movielens netÔ¨Çix h ¬º myanimelist threshold chosen agreement wwwkagglecom neural computing application result shown value represent fair tradeoff provided coverage dataset prediction accuracy precision ¬º u x u u f n u j r u h g n √∞ √æ recall ¬º u x u u f n u j r u h g f r test u j r u h g √∞ √æ additionally measure quality recom mendations harmonic mean precision recall f score eq f ¬º precision recall precision √æ recall √∞ √æ however evaluating quality recommendation solely user rating provides biased view rec ommenders performance therefore also deter mined novelty eq recommendation novelty calculated assigning weight item received fewer rating word nov elty item inversely proportional number rating received item r respect total number vote recommender r novelty ¬º u x u u p n u log r r n √∞ √æ finally measure quality recommendation list use normalized discounted cumulative gain ndcg suppose recommendation list user u n u sorted decreasingly item predicted relevant placed Ô¨Årst position given n u let po n u √∞ √æ position item recommendation list analogously suppose real top n recommendation user u r n u sorted decreas ingly denote po r nu √∞ √æ position item r n u list setting discounted cumulative gain dcg ideal cumulative gain idcg user u u deÔ¨Åned eq dcg u ¬º x n u r u log po nu √∞ √æ √æ idcg u ¬º x r n u r u log po r nu √∞ √æ √æ √∞ √æ way ndcg given mean ratio dcg idcg eq ndcg ¬º u x u u dcg u idcg u √∞ √æ due stochastic nature variational embedded space proposed test prediction used evaluate proposed computed average prediction performed pair user u item overall proposed variational architecture ade quately improves simple model deepmf one approaching result larger model ncf tendency observed prediction recommendation quality measure additionally shorter running time needed train proposed variational compared baseline expected behavior hypothesis remarkable constraint must considered variational stage work particularly well applied large datasets whereas large datasets variational could necessary key idea ability main parameter datasets used experiment dataset n user n item n rating score sparsity filmtrust movielens myanimelist netÔ¨Çix quality prediction filmtrust movielens myanimelist netÔ¨Çix mean absolute error lower better vdeepmf deepmf vncf ncf b mean squared error lower better vdeepmf deepmf vncf ncf c r score higher better vdeepmf deepmf vncf ncf best result quality measure highlighted bold neural computing application proposed deal entropy variational stage increase entropy generating stochastic latent factor enriching latent space making robust input variability intrinsic com pleteness continuity property vae foundation variational get robust continuous structured latent space enriched space provide improved result obtained experiment experimental result includes quality prediction performed proposed best value dataset highlighted bold contains mae eq b contains mse eq c contains r score eq observe proposed variational improves prediction capability deepmf datasets except netÔ¨Çix report worse prediction applied ncf justify result taking account fea tures deep learning model used property dataset one hand larger size dataset less necessary enrich vote proposed variational word dataset small amount shannon entropy contains might quite limited variational generate new sample add extra entropy enriches dataset giving chance regressive part exploiting extra however large datasets usually present large entropy way regressive model effectively extract subtle setting add varia tional stage instead adding new relevant variability dataset add noise muddies underlying pattern reason variational beneÔ¨Åt huge datasets like netÔ¨Çix hand ncf complex deepmf one enrichment less impact complex model able Ô¨Ånd sophisticated relationship simpler model fact fig quality recommendation measured precision recall higher better neural computing application result assert including variational simple deepmf equivalent complex ncf furthermore fig show quality recommendation precision eq recall eq f eq quality measure filmtrust fig movielens fig b b myanimelist fig c c observe proposed variational report beneÔ¨Åt deepmf worsens result ncf addition vdeepmf computes best recommendation datasets contrast netÔ¨Çix fig proposed variational improve quality recommen dations ncf provides best recommendation dataset result con sistent analyzed measuring quality prediction consequently evident pro posed variational work adequately dataset large used complex fig contains quality recommendation regard ing novelty eq observed variational stage added deepmf signiÔ¨Åcant improvement novelty recommendation small datasets achieved dataset becomes larger impact variational step detrimental thus variational stage positive impact filmtrust fig movielens fig b datasets negative impact myanimelist fig c netÔ¨Çix fig datasets contrary varia tional stage added ncf impact novelty practically zero regardless dataset size experiment like previous one reafÔ¨Årms variational step improves result simple model small datasets addition fig contains ndcg result observe trend shown previous experiment filmtrust fig quality recommendation list vary independently whether variational used movielens fig b myanimelist fig c combination variational simple modeling deepmf provides best result netÔ¨Çix fig variational signiÔ¨Åcantly worsens quality recommendation list fig quality recommendation measured f higher better neural computing application conclusion latest trend accuracy rss improved deep learning model deep matrix factor ization neural collaborative Ô¨Åltering however model incorporate stochasticity design unlike variational autoencoders variational random sampling used create augmented input raw collaborative Ô¨Åltering context inherent col laborative Ô¨Åltering sparsity make difÔ¨Åcult get accurate result applies variational concept generate augmented sparse create aug mented sample latent space codiÔ¨Åed dense inner layer proposed neural network innovative trying combine potential variational stochasticity augmentation concept augmented sample generated dense latent space neural network way avoid sparse scenario variational process observe proposed also encodes intrinsic locality user item latent space recall regular mf model capture similarity user item latent space since pre diction constructed via inner product continuous function spirit variational model also preserve locality since output still computed continuous function feedforward neural network much complicated function eventu ally continuous moreover since probability distribu tions representing user item latent space depend continuous parameter mean standard deviation gaussian distribution small variation parameter corresponding similar item user also encoded almost equal distribution thus sample tend also close distributional sense thanks idea result experimental analysis conducted show important improvement proposed model applied middlesize representative collaborative Ô¨Åltering datasets compared stateoftheart baseline testing prediction recommendation quality measure sharp contrast testing huge netÔ¨Çix dataset lead improvement recommendation quality fig quality recommendation measured novelty higher better neural computing application actually get worse manner increasing shannon entropy rich latent space cause negative effect introduced noise exceeds beneÔ¨Åt therefore proposed deep variational model applied seek fair balance positive enrichment negative noise injection emphasize idea show total time epoch required Ô¨Åtted dataset quadro rtx gpu best time dataset bold observe including varia tional layer signiÔ¨Åcantly reduces required time Ô¨Åtting variational model able generate shannon entropy transferred regression stage leading effective training requires fewer epoch Ô¨Åtted therefore Ô¨Åtting time needed reach acceptable result substantially lower result presented work considered generalizable since analyzed four represen tative open cf datasets researcher reproduce experiment easily create model provided framework referenced sect author work committed reproducible science code used experiment publicly available among promising future work following introducing variational process alternative inner layer relevant architecture collaborative Ô¨Åltering area screening learning evolution training process since faster classical model also requires early stopping fig quality recommendation list measured ndcg higher better fitting time quadro rtx filmtrust movielens myanimelist netÔ¨Çix vdeepmf epoch epoch epoch epoch deepmf epoch epoch epoch epoch vncf epoch epoch epoch epoch ncf epoch epoch epoch epoch best Ô¨Åtting time datased bold neural computing application training stage providing theoretical explana tions property cf datasets term shannon entropy statistical feature ensure good performance proposed model applying probabilistic deep learning model cf Ô¨Åeld cap ture complex nonlinear stochastic relationship random variable testing impact pro posed concept recommendation made group user acknowledgement gp acknowledges hospitality department mathematics universidad autonoma de part work developed work partially supported ministerio de ciencia e innovacion spain project pidrbi dlcemg comunidad de convenio plurianual universidad politecnica de actuation line programa de excelencia para el profesorado universitario forth author partially sup ported government comunidad de spain multiannual agreement universidad complutense de line research incentive young phd context v pricit regional programme research technological innovation project pr funding open access funding provided thanks cruecsic agreement springer nature availability datasets analyzed current available repository referred reference declaration conflict interest author declare conflict interest open access article licensed creative common attribution international license permit use sharing adaptation distribution reproduction medium format long give appropriate credit original author source provide link creative common licence indicate change made image third party material article included article creative common licence unless indicated otherwise credit line material material included article creative common licence intended use permitted statutory regulation exceeds permitted use need obtain permission directly copyright holder view copy licence visit httpcreativecommons orglicensesby reference beel j langer genzmehr gipp b breitinger c nurnberger research recommender evaluation quantitative literature survey proceeding international workshop reproducibility replication recommender system evaluation pp bobadilla j gonzalezprieto ortega f laracabrera r deep learning feature selection unhide demographic recom mender system factor neural comput appl deldjoo schedl cremonesi p pasi g recommender system leveraging multimedia content acm comput survey csur kulkarni rodd sf context aware recommendation system review state art technique comput sci rev shokeen j rana c feature social recom mender system artif intell rev bobadilla j alonso hernando deep learning archi tecture collaborative Ô¨Åltering recommender system appl sci forouzandeh berahmand k rostami presentation recommender ensemble learning graph embedding movielens multimed tool appl c ano e morisio hybrid recommender system systematic literature review intell anal mnih salakhutdinov rr probabilistic matrix factor ization adv neural inf process syst fevotte c idier j algorithm nonnegative matrix factorization b divergence neural comput hernando bobadilla j ortega f non negative matrix factorization collaborative Ô¨Åltering recommender system bayesian probabilistic knowlbased syst rendle krichene w zhang l anderson j neural collaborative Ô¨Åltering v matrix factorization revisited fourteenth acm conference recommender system pp x liao l zhang h nie l hu x chua t neural collaborative Ô¨Åltering proceeding th international conference world wide web pp narang taneja n deep contentcollaborative recom mender dccrs international conference advance computing communication control networking icacccn pp ieee bobadilla j laracabrera r gonzalezprieto ortega f deepfair deep learning improving fairness recommender system int j interact multimed artif intell gao zhang j yu j li j wen j xiong q recom mender system generative adversarial network problemdriven perspective inf sci xue hj dai x zhang j huang chen j deep matrix factorization model recommender system ijcai mel bourne australia vol pp wen j j li x mao h visual background recom mendation dance performance deep matrix factoriza tion acm trans multimed comput commun appl tomm wan l xia f kong x hsu ch huang r j deep matrix factorization trustaware recommendation social network ieee trans network sci eng zou g chen j q li kc zhang b gan ndmf neighborhoodintegrated deep matrix factorization service qos prediction ieee trans netw serv manage trigeorgis g bousmalis k zafeiriou schuller bw deep matrix factorization learning attribute repre sentations ieee trans pattern anal mach intell fan j cheng j matrix completion deep matrix fac torization neural netw liu x gherbi wei z li w cheriet multispectral image reconstruction color image enhanced varia tional autoencoder generative adversarial network ieee access neural computing application liu z siu wc wang lw li ct cani mp unsupervised real image superresolution via generative varia tional autoencoder proceeding ieeecvf conference computer vision pattern recognition workshop pp liu z siu wc chan yl photorealistic image super resolution via variational autoencoders ieee trans circ syst video technol zhang s liu jw zuo x lu rk lian sm online deep learning autoencoder appl intell liang krishnan rg hoffman md jebara varia tional autoencoders collaborative Ô¨Åltering proceeding world wide web conference pp nisha c mohan social recommender deep architecture network embedding appl intell rama k kumar p bhasker b deep autoencoders feature learning embeddings recommendation novel recommender solution neural comput appl tahmasebi h ravanmehr r mohamadrezaei r social movie recommender deep autoencoder network twitter neural comput appl li x j collaborative variational autoencoder recommender system proceeding rd acm sigkdd international conference knowledge discovery mining pp meng q zhang collaborative additional varia tional autoencoder topn recommender system ieee access nahta r meena yk gopalani chauhan g twostep hybrid collaborative Ô¨Åltering deep variational bayesian autoencoders inf sci shenbin alekseev tutubalina e malykh v nikolenko si recvae new variational autoencoder topn recom mendations implicit feedback proceeding th international conference web search mining pp wang k xu l huang l wang cd lai jh sddrs stacked discriminative denoising autoencoder recom mender cogn syst re liu wang khan m j novel deep hybrid recommender autoencoder neural collab orative Ô¨Åltering big mining anal mikolov sutskever chen k corrado g dean j distributed representation word phrase com positionality adv neural inform process syst mikolov chen k corrado g dean j efÔ¨Åcient esti mation word representation vector space arxiv preprint arxiv pennington j socher r manning cd glove global vector word representation proceeding conference empirical method natural language processing emnlp pp peter neumann iyyer gardner clark c lee k zettlemoyer l deep contextualized word representation arxiv preprint arxiv guo g zhang j yorkesmith n novel bayesian simi larity measure recommender system proceeding rd international joint conference artiÔ¨Åcial intelligence ijcai pp harper fm konstan ja movielens datasets history context acm trans interact intell syst tiis azathoth myanimelist dataset httpswwwkagglecomaza thothmyanimelist online accessed july bennett j lanning et al netÔ¨Çix prize pro ceedings kdd cup workshop new york ny usa vol p bobadilla j hernando ortega f bernal j framework collaborative Ô¨Åltering recommender system expert syst appl herlocker jl konstan ja terveen lg riedl jt evaluating collaborative Ô¨Åltering recommender system acm trans inf syst gunawardana shani g evaluating recommender sys tems handbook boston ortega f laracabrera r gonzalezprieto bobadilla j providing reliability recommender system bernoulli matrix factorization inf sci castells p vargas wang j novelty diversity metric recommender system choice discovery rele vance proceeding rd european conference retrieval ecir shannon ce weaver w mathematical theory communication university illinois press urbana publisher note springer nature remains neutral regard jurisdictional claim published map institutional afÔ¨Åliations neural computing application,deep variational model collaborative filteringbased recommender system,recommender system collaborative Ô¨Åltering variational enrichment deep learning,deep variational model collaborative filteringbased recommender system deep variational model collaborative filteringbased recommender system deep variational model collaborative filteringbased recommender system recommender system collaborative Ô¨Åltering variational enrichment deep learning recommender system collaborative Ô¨Åltering variational enrichment deep learning original article deep variational model collaborative filteringbased recommender system jesus bobadilla fernando ortega abraham gutierrez ngel gonzalezprieto received september accepted november published online december author deep learning provides accurate collaborative Ô¨Åltering model improve recommender result deep matrix factorization related collaborative neural network state art Ô¨Åeld nevertheless model lack necessary stochasticity create robust continuous structured latent space variational autoencoders exhibit hand augmentation variational autoencoder provide accurate result collaborative Ô¨Åltering Ô¨Åeld due high sparsity recommender system proposed model apply variational concept inject stochasticity latent space deep architecture introducing variational technique neural collaborative Ô¨Åltering Ô¨Åeld depend particular used generate latent representation way applied plugin current future speciÔ¨Åc model proposed model tested four representative open datasets three different quality measure stateoftheart baseline result show superiority proposed scenario variational enrichment exceeds injected noise effect additionally framework provided enable reproducibility conducted experiment keywords recommender system collaborative Ô¨Åltering variational enrichment deep learning recommender system rss artiÔ¨Åcial intelligence Ô¨Åeld provides method model predict recommend item user eg Ô¨Ålms person ecom merce product costumer service company quality service qos internet thing iot device etc current popular rss spotify netÔ¨Çix tripadvisor amazon etc rss usually categorized attending Ô¨Åltering strategy mainly demo graphic contentbased contextaware social collaborative filtering cf Ô¨Åltering ensemble cf accurate widely used Ô¨Åltering implement rss cf model evolved knearest neighbor knn probabilistic matrix factorization pmf non negative matrix factorization nmf baye sian nonnegative matrix factorization bnmf currently deep learning research approach growing strength provide improvement accuracy com pared machine learning mlbased matrix fac torization mf model additionally deep learning architecture usually Ô¨Çexible mfbased one introducing combined deep shallow learn ing integrated contentbased ensemble gener ative approach among others deep matrix factorization deepmf neural network implement popular mf concept deepmf designed take input useritem matrix explicit rating nonpreference implicit feedback ngel gonzalezprieto angelgonzalezprietoucmes departamento de sistemas informaticos etsi sistemas informaticos universidad politecnica de c de alan turing sn spain knodis research group universidad politecnica de c de alan turing sn spain departamento de lgebra geometrƒ±a topologƒ±a universidad complutense de plaza ciencias spain instituto de ciencias matematicas csicuamucm ucm c nicolas cabrera spain neural computing application httpsdoiorgs volv volv although current implementation use two embedding layer whose input respectively user item experimental result evidence deepmf superiority traditional approach mlfocused r par ticularly used mf model pmf nmf bnmf currently deepmf popular rapidly replacing traditional mf model classical ml additionally deepmf used r Ô¨Åeld combine social behavior click rating image social trustaware r implemented deepmf extract feature useritem rating matrix improving initialization accuracy qos prediction also addressed deepmf learn attribute representation deepmf used creates lowdimen sional representation dataset lends clustering interpretation finally classical matrix completion task addressed deepmf widely spread neural collaborative filtering ncf may seen augmented deepmf deeper layer added dot one additionally dot layer replaced concatenate layer show explained concept ncf slightly outperforms deepmf accuracy result increase required runtime train run forward process necessary execute extra multilayer perceptron mlp top dot concatenate layer moreover compared deepmf ncf architecture add new hyperparameters set mainly number hidden layer depth size number neuron layer mlp architecture hypothesis improve existing cf neural model adding variational stage borrows operative variational autoen coder vae vaes improve latent factorbased model also manage nonlinear probabilistic latentvariable model vaes extensively used imagegenerative area rarely covered cf Ô¨Åeld autoencoders perform nonlinear pca vaes improve result performing nonlinear factor unfortunately regular autoen coder ensure regularity latent space reason image processing perform Ô¨Åne producing new content random encoding without explicit regularization combination latent space meaningless decoded vaes superiority come variational behavior allows make suitable regularization statistic variational vaes input encoded distribution instead single point making possible naturally express latent space regularization cf improvement vaes item user latent factor distribution regularized training stage ensuring latent space good property conveniently generalize r prediction vaes regularization two main property com pleteness point sampled latent space give mean ingful content decoded continuity close point latent space provide similar content decoded accomplish property usually regularization done enforcing distribution close centered reduced standard normal distribution regularization involves higher reconstruction error balanced kullbackleibler divergence use vae cf Ô¨Åeld provides better fig deep matrix factorization deepmf versus neural collaborative filtering ncf neural computing application generalization improve recommendation also make easier use latent codiÔ¨Åcations item user make clustering explain recommen dations generate augmented datasets com pleteness continuity property make possible additional beneÔ¨Åts vaes cf area rest structured follows sect describe main idea involved pro posal well difference related work variational cfbased recommender system sect proposed explained section show experi ments design result discussion finally sect contains main conclusion future work fundamental related work vaes generative model variational autoencoders vaes act regular autoen coder aim compress input raw value latent space representation mean encoder neural network whereas decoder neural network make opposite operation seeking decompress latent space output raw value main difference clas sical autoencoders vaes latent space design meaning operation classical autoencoders generate structured latent space whereas vaes introduce statistical process force learn continuous structured latent space way vaes turn sample parameter statistical distribution usually mean variance gaussian distribution parameter multivariate distribution draw random latent space obtained training input operation procedure represented fig stochasticity random sampling improves robustness force encoding continuous meaningful latent space representation seen fig shown vae latent space represen tation cumulative normal distribution due property vaes used gen erative deep learning model image processing Ô¨Åeld reconstruction multispectral image per formed mean vae parameterizes latent space gaussian distribution parameter vaes also used create superresolution image proposed encode lowresolution image dense latent space vector decoded target high resolution image denoising blur image problem vae tackled adding condi tional sampling mechanism narrow latent space making possible reconstruct high resolution image moreover author Ô¨Çexible autoencoder able adapt varying pattern time importing vae concept image processing several paper used model improve r result instance denoising variational autoencoders tested author reported superiority vae option model variational autoencoders combined social improve quality recommendation proposal deep variational model aim neural architecture join best deepmf ncf model vae concept novel model called respec tively variational deep matrix factorization vdeepmf variational neural collaborative filtering vncf contrast autoencoder generative adversarial network gan approach cf Ô¨Åeld shall use generative decoder stage maintain regression output layer presented deepmf ncf model main advantage use vae operation robustness confers latent representation robustness seen observing fig consider dot drawn train representation latent space test sample likely correctly classiÔ¨Åed vae right graph fig correctly classiÔ¨Åed regular autoencoder left graph fig short variational stochastically spread sam ples latent space improving chance classi fying correctly training sample proposed r cf scenario expect rating value better predicted variational latent space learnt space cover wider robust representative latent area whereas traditional autoencoders would coded latent space white circle fig vae encodes parameter multivariate distri bution eg mean variance blue orange gaussian distribution fig learnt distribution parameter random sampling carried generate stochastic latent space value gray circle fig epoch learning process generates new set latent space value proposed trained h user item tuple presented obtained latent space green circle fig better predicted vae scenario regular autoencoder scenario random sampled value gray circle enriched latent space help associate predicted green circle neural computing application associated training sample white circle making prediction process much robust accurate explanation vae operation deÔ¨Åned following fig variational layer stage Ô¨Årst two dense layer code normal distribution parameter set mean variance latent factor cf scenario two dense layer arranged code normal distribution parameter item two different dense layer used code normal distribution parameter user variational regularizes latent factor make po sible reach explained completeness continuity goal distribution parameter layer regular ized necessary obtain single latent factor point code user item dataset user item input need combine mean variance normal random function used generate latent factor point coding item user input latent factor point obtained combining normal random item mean user mean item variance user variance operation usually performed neural lambda layer lambda layer seen regularized version deepmf nonvariational fig operation trained variational autoencoder vae new presented encoder stage handwritten digit example produce latent space probability distribution typically distribution belongs known family multivariate normal distribution example shape determined numerical parameter mean standard deviation decoder stage generates instance sampling distribution getting slightly different digit example introduces stochastic component generation procedure enriches latent space variability generative fig representation vae latent space mnist dataset left side cumulative normal distribution right side neural computing application finally obtain prediction rating user item combining lambda user item factor dot product short variational incorporates following substages con verting input embedding factor normal distribution value thus making regularization generate continuous complete latent factor code combin ing normal distribution latent factor code obtain single latent factor value predicting rating making dot product regularized latent factor value vaes recommender system current cfbased variational autoencoders usually obtain raw augmented one strategy synthetize rating user item generated relevant versus relevant vote user item another pretrain vae map vector latent space idea intensively studied several variant strategy force practitioner sequentially run two separated model generative gan vae provides augmented regression cf make prediction rec ommendations present three main draw back complexity two separate model necessary large time consumption sparsity management explain deeper following section proposed generate raw aug mented contrary innovation use single internally manage augmen tation prediction aim particularly signiÔ¨Åcant way proposed address sparsity problem make augmentation sparse raw rating cast user item internal augmentation process dense latent space fig randomly gen erated latent space feed regression layer thereby Ô¨Årst generates stochastic variational sample dense latent space generated sample act input regres sion stage test idea hypothesis considered augmented sample accurate effective generated inner dense latent space rather sparse input space important realize enriching inner latent space improve recommendation result also injects noise latent space may potentially worsen result expected proposed work better poor latent space whereas applied rich space spurious entropy added variational stage could worsen recommendation thus mediumsize cf datasets large complex one better candi date improve result variational proposal applied whereas large datasets predictable distribution probably beneÔ¨Åt noise injection variational architecture proposed proposed neural architecture mix vae deepmf ncf model vae take encoder stage variational process deepmf ncf use regression layer innovative r Ô¨Åeld since vae gan neural network used posteriori stage make augmentation ie obtain enriched input datasets feed cf deepmf ncf model hence traditional need separately train two model Ô¨Årst vae deepmfncf network discussed sect combined solu tions present important disadvantage term complexity time consumption poor sparsity management sharp contrast proposed efÔ¨Åciently join vae deep cf regression concept obtain improved prediction single training process learning stage training sample feed left hand side fig training consists tuple h user item rating rating casted user item deepmfncf architecture user represented hisher vector voted rating item represented vector received rating learns rating third element tuples casted user item Ô¨Årst second element fig latent space representation proposed variational learnt mean variance multivariate gaussian distribution random sampling process run spread latent space value gray circle help accurately predict unknown rating value green circle neural computing application tuples word rating output neural network right hand side fig thanks architecture variational stage nat urally embedded Ô¨Çexibly used inject variability sample worth mentioning stage also trained simultaneously pre dictive part mutually inÔ¨Çuencing expect lead better result simple separate learning formalization architectural detail proposed model shown fig simplicity variational deep matrix factorization vdeepmf architecture shown Ô¨Ågure corresponding ncf named varia tional neural collaborative filtering vncf analogous vdeepmf one embedding variational layer replace dot layer deepmf concatenate layer fol lowed mlp Ô¨Åx notation let u suppose dataset contains u user item general aim deep learning cfbased prediction train stochastic neural network implement function h r u r r function h operates follows let u codify u th user dataset resp th item onehoten coding u th canonical basis vector e u resp th canonical basis vector e outcome following h √∞ e u e √æ r ¬º prediction score u th user would assign th item train function h learning phase neural network fed set x ¬º h u r f g training tuples h u r user u rated item score r function h trained minimize error e √∞ h √æ ¬º x h u r x √∞ h √∞ e u e √æ r √æ √∞ √æ r r r metric r typical choice socalled mean squared error mse mean absolute error mae respectively given mse √∞ x √æ ¬º √∞ x √æ mae √∞ x √æ ¬º j x j proposal vdeepmf consist decomposing h combination embedding followed variational stage Ô¨Ånal dot layer shown fig h ¬º dot variational embedding notice end day h deep leaning novel customary layer designed r problem way h trained reduce error e √∞ h √æ eq standard deep learning dl method backpropagation embedding layer Ô¨Årst embedding layer left hand side fig borrowed natural language processing nlp idea layer provides fast translation user item respective fig proposed vdeepmf ncf cf sample encoded latent space mean variational process prediction obtained regression neural network neural computing application representation latent space precise layer implement linear map embedding r u r r l r l map pair √∞ e u e √æ pair dense vector √∞ v u w √æ r l r l represents u th user th item l dimension representation purpose implement embedding layer regular mlp dense layer sharp contrast approach nlp wordvec glove elmo among others reason later approach seek Ô¨Ånd embedding preserving metric word typically likelihood Ô¨Ånding two word together semantic similarity however since perform contextfree cf prediction priori similarity user item available indeed precisely ultimate goal r Ô¨Ånd appropriate repre sentations user item latent space reason decided add extra mechanism could bias training process embedding layer act regular dense layer trained parallel learning process finally would like point even though conceptual point view embedding layer dense layer save time space embedding layer typically implemented lookup table way instead feeding network onehot encoding user u resp item input via id user resp item lookup efÔ¨Åciently recovers u th resp th column embedding matrix contains v u resp w translation conducted efÔ¨Åcient way standard mlp layer exploiting sparsity input variational layer variational process carried varia tional stage labeled variational layer middle fig core proposed latent space representation √∞ v u w √æ r l r l u th user th item two separated dense layer return mean variance parameter two gaussian multivariate distribution way Ô¨Åx latent space dimension k Ô¨Årst part variational stage left part middle rectangle fig computes map √∞ v u w √æ ¬º √∞ l √∞ v u √æ r √∞ v u √æ l √∞ w √æ r √∞ w √æ√æ r k output l √∞ v u √æ l √∞ w √æ interpreted mean two gaussian distribution user item respectively whereas r √∞ v u √æ r √∞ w √æ represent variance second part variational stage left right middle rectangle fig ruled pair random vector √∞ p l √∞ v u √æ r √∞ v u √æ q l √∞ w √æ r √∞ w √æ √æ p n √∞ l √∞ v u √æ diag r √∞ v u √æ√æ q n √∞ l √∞ w u √æ diag r √∞ w √æ√æ n √∞ l r √æ denotes k dimensional multivariate mal distribution mean vector l diagonal covariance matrix r ie whose probability density function fig proposed vdeepmf architecture ncf architecture identical embedding variational layer vdeepmf one replace dot layer concatenate layer followed mlp neural computing application f √∞ √æ ¬º Ô¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨ÉÔ¨É √∞ p √æ k det r q exp √∞ l √æ r √∞ l √æ notice covariance matrix always diagonal setting task variational stage p q manner variational √∞ v u w √æ ¬º √∞ p q √æ r k r k p p ¬º p √∞ √∞ v u w √æ√æ n √∞ l √∞ v u √æ diag r √∞ v u √æ√æ q q ¬º q √∞ √∞ v u w √æ√æ n √∞ l √∞ w u √æ diag r √∞ w √æ√æ pair represents stochastic latent representation associated √∞ v u w √æ join layer layer depends particular choice architecture variational deep matrix factorization vdeepmf architecture Ô¨Ånal layer dot layer labeled regression layer right hand side fig linear layer simply computes dot product latent vector p q therefore dot √∞ p q √æ ¬º p q vncf simple layer replaced fully connected mlp h r k r k r extract nonlinear relation p q therefore summarizing process proposed vdeepmf h computes h √∞ e u e √æ ¬º dot variational embedding √∞ e u e √æ ¬º p l √∞ v u √æ r √∞ v u √æ q l √∞ w √æ r √∞ w √æ analogously vncf return proposed vdeepmf h computes h √∞ e u e √æ ¬º h variational embedding √∞ e u e √æ ¬º h √∞ p l √∞ v u √æ r √∞ v u √æ q l √∞ w √æ r √∞ w √æ √æ case h √∞ e u e √æ random variable sampled return natural number inter preted predicted rating h user u regarding item empirical evaluation section describe empirical experiment carried evaluate performance variational deepmf ncf model experimental setup experimental evaluation performed four different datasets measure performance pro posed different environment selected datasets filmtrust small dataset contains rating thousand item movie movielens gold standard dataset cfbased r myanimelist dataset extracted kaggle contains rating thousand user anime comic netÔ¨Çix popular dataset hundred million rating used netÔ¨Çix prize competition show main parameter datasets corpus datasets randomly splitted training rating rating test rating rating evaluation proposed ana lyzed three different point view quality prediction quality recommendation quality recommendation list measure quality prediction compared real rating r u user u item test split r test predicted one r u compar isons carried three way mae eq mse eq computing proportion explained variance r eq notice eq r denotes mean rating contained test split mae ¬º r test x h u r test j r u r u j √∞ √æ mse ¬º r test x h u r test r u r u √∞ √æ r ¬º x h u r test r u r u x h u r test r u r √∞ √æ measure quality recommendation analyzed impact top n recommended item user u collected list n u precision eq measure proportion relevant recommendation ie user rated item rated equal greater threshold h among top n u denotes set user test split similar vein recall eq measure proportion test item rated user u r test u relevant included recommended item n u con ducted experiment used threshold h ¬º filmtrust h ¬º movielens netÔ¨Çix h ¬º myanimelist threshold chosen agreement wwwkagglecom neural computing application result shown value represent fair tradeoff provided coverage dataset prediction accuracy precision ¬º u x u u f n u j r u h g n √∞ √æ recall ¬º u x u u f n u j r u h g f r test u j r u h g √∞ √æ additionally measure quality recom mendations harmonic mean precision recall f score eq f ¬º precision recall precision √æ recall √∞ √æ however evaluating quality recommendation solely user rating provides biased view rec ommenders performance therefore also deter mined novelty eq recommendation novelty calculated assigning weight item received fewer rating word nov elty item inversely proportional number rating received item r respect total number vote recommender r novelty ¬º u x u u p n u log r r n √∞ √æ finally measure quality recommendation list use normalized discounted cumulative gain ndcg suppose recommendation list user u n u sorted decreasingly item predicted relevant placed Ô¨Årst position given n u let po n u √∞ √æ position item recommendation list analogously suppose real top n recommendation user u r n u sorted decreas ingly denote po r nu √∞ √æ position item r n u list setting discounted cumulative gain dcg ideal cumulative gain idcg user u u deÔ¨Åned eq dcg u ¬º x n u r u log po nu √∞ √æ √æ idcg u ¬º x r n u r u log po r nu √∞ √æ √æ √∞ √æ way ndcg given mean ratio dcg idcg eq ndcg ¬º u x u u dcg u idcg u √∞ √æ due stochastic nature variational embedded space proposed test prediction used evaluate proposed computed average prediction performed pair user u item overall proposed variational architecture ade quately improves simple model deepmf one approaching result larger model ncf tendency observed prediction recommendation quality measure additionally shorter running time needed train proposed variational compared baseline expected behavior hypothesis remarkable constraint must considered variational stage work particularly well applied large datasets whereas large datasets variational could necessary key idea ability main parameter datasets used experiment dataset n user n item n rating score sparsity filmtrust movielens myanimelist netÔ¨Çix quality prediction filmtrust movielens myanimelist netÔ¨Çix mean absolute error lower better vdeepmf deepmf vncf ncf b mean squared error lower better vdeepmf deepmf vncf ncf c r score higher better vdeepmf deepmf vncf ncf best result quality measure highlighted bold neural computing application proposed deal entropy variational stage increase entropy generating stochastic latent factor enriching latent space making robust input variability intrinsic com pleteness continuity property vae foundation variational get robust continuous structured latent space enriched space provide improved result obtained experiment experimental result includes quality prediction performed proposed best value dataset highlighted bold contains mae eq b contains mse eq c contains r score eq observe proposed variational improves prediction capability deepmf datasets except netÔ¨Çix report worse prediction applied ncf justify result taking account fea tures deep learning model used property dataset one hand larger size dataset less necessary enrich vote proposed variational word dataset small amount shannon entropy contains might quite limited variational generate new sample add extra entropy enriches dataset giving chance regressive part exploiting extra however large datasets usually present large entropy way regressive model effectively extract subtle setting add varia tional stage instead adding new relevant variability dataset add noise muddies underlying pattern reason variational beneÔ¨Åt huge datasets like netÔ¨Çix hand ncf complex deepmf one enrichment less impact complex model able Ô¨Ånd sophisticated relationship simpler model fact fig quality recommendation measured precision recall higher better neural computing application result assert including variational simple deepmf equivalent complex ncf furthermore fig show quality recommendation precision eq recall eq f eq quality measure filmtrust fig movielens fig b b myanimelist fig c c observe proposed variational report beneÔ¨Åt deepmf worsens result ncf addition vdeepmf computes best recommendation datasets contrast netÔ¨Çix fig proposed variational improve quality recommen dations ncf provides best recommendation dataset result con sistent analyzed measuring quality prediction consequently evident pro posed variational work adequately dataset large used complex fig contains quality recommendation regard ing novelty eq observed variational stage added deepmf signiÔ¨Åcant improvement novelty recommendation small datasets achieved dataset becomes larger impact variational step detrimental thus variational stage positive impact filmtrust fig movielens fig b datasets negative impact myanimelist fig c netÔ¨Çix fig datasets contrary varia tional stage added ncf impact novelty practically zero regardless dataset size experiment like previous one reafÔ¨Årms variational step improves result simple model small datasets addition fig contains ndcg result observe trend shown previous experiment filmtrust fig quality recommendation list vary independently whether variational used movielens fig b myanimelist fig c combination variational simple modeling deepmf provides best result netÔ¨Çix fig variational signiÔ¨Åcantly worsens quality recommendation list fig quality recommendation measured f higher better neural computing application conclusion latest trend accuracy rss improved deep learning model deep matrix factor ization neural collaborative Ô¨Åltering however model incorporate stochasticity design unlike variational autoencoders variational random sampling used create augmented input raw collaborative Ô¨Åltering context inherent col laborative Ô¨Åltering sparsity make difÔ¨Åcult get accurate result applies variational concept generate augmented sparse create aug mented sample latent space codiÔ¨Åed dense inner layer proposed neural network innovative trying combine potential variational stochasticity augmentation concept augmented sample generated dense latent space neural network way avoid sparse scenario variational process observe proposed also encodes intrinsic locality user item latent space recall regular mf model capture similarity user item latent space since pre diction constructed via inner product continuous function spirit variational model also preserve locality since output still computed continuous function feedforward neural network much complicated function eventu ally continuous moreover since probability distribu tions representing user item latent space depend continuous parameter mean standard deviation gaussian distribution small variation parameter corresponding similar item user also encoded almost equal distribution thus sample tend also close distributional sense thanks idea result experimental analysis conducted show important improvement proposed model applied middlesize representative collaborative Ô¨Åltering datasets compared stateoftheart baseline testing prediction recommendation quality measure sharp contrast testing huge netÔ¨Çix dataset lead improvement recommendation quality fig quality recommendation measured novelty higher better neural computing application actually get worse manner increasing shannon entropy rich latent space cause negative effect introduced noise exceeds beneÔ¨Åt therefore proposed deep variational model applied seek fair balance positive enrichment negative noise injection emphasize idea show total time epoch required Ô¨Åtted dataset quadro rtx gpu best time dataset bold observe including varia tional layer signiÔ¨Åcantly reduces required time Ô¨Åtting variational model able generate shannon entropy transferred regression stage leading effective training requires fewer epoch Ô¨Åtted therefore Ô¨Åtting time needed reach acceptable result substantially lower result presented work considered generalizable since analyzed four represen tative open cf datasets researcher reproduce experiment easily create model provided framework referenced sect author work committed reproducible science code used experiment publicly available among promising future work following introducing variational process alternative inner layer relevant architecture collaborative Ô¨Åltering area screening learning evolution training process since faster classical model also requires early stopping fig quality recommendation list measured ndcg higher better fitting time quadro rtx filmtrust movielens myanimelist netÔ¨Çix vdeepmf epoch epoch epoch epoch deepmf epoch epoch epoch epoch vncf epoch epoch epoch epoch ncf epoch epoch epoch epoch best Ô¨Åtting time datased bold neural computing application training stage providing theoretical explana tions property cf datasets term shannon entropy statistical feature ensure good performance proposed model applying probabilistic deep learning model cf Ô¨Åeld cap ture complex nonlinear stochastic relationship random variable testing impact pro posed concept recommendation made group user acknowledgement gp acknowledges hospitality department mathematics universidad autonoma de part work developed work partially supported ministerio de ciencia e innovacion spain project pidrbi dlcemg comunidad de convenio plurianual universidad politecnica de actuation line programa de excelencia para el profesorado universitario forth author partially sup ported government comunidad de spain multiannual agreement universidad complutense de line research incentive young phd context v pricit regional programme research technological innovation project pr funding open access funding provided thanks cruecsic agreement springer nature availability datasets analyzed current available repository referred reference declaration conflict interest author declare conflict interest open access article licensed creative common attribution international license permit use sharing adaptation distribution reproduction medium format long give appropriate credit original author source provide link creative common licence indicate change made image third party material article included article creative common licence unless indicated otherwise credit line material material included article creative common licence intended use permitted statutory regulation exceeds permitted use need obtain permission directly copyright holder view copy licence visit httpcreativecommons orglicensesby reference beel j langer genzmehr gipp b breitinger c nurnberger research recommender evaluation quantitative literature survey proceeding international workshop reproducibility replication recommender system evaluation pp bobadilla j gonzalezprieto ortega f laracabrera r deep learning feature selection unhide demographic recom mender system factor neural comput appl deldjoo schedl cremonesi p pasi g recommender system leveraging multimedia content acm comput survey csur kulkarni rodd sf context aware recommendation system review state art technique comput sci rev shokeen j rana c feature social recom mender system artif intell rev bobadilla j alonso hernando deep learning archi tecture collaborative Ô¨Åltering recommender system appl sci forouzandeh berahmand k rostami presentation recommender ensemble learning graph embedding movielens multimed tool appl c ano e morisio hybrid recommender system systematic literature review intell anal mnih salakhutdinov rr probabilistic matrix factor ization adv neural inf process syst fevotte c idier j algorithm nonnegative matrix factorization b divergence neural comput hernando bobadilla j ortega f non negative matrix factorization collaborative Ô¨Åltering recommender system bayesian probabilistic knowlbased syst rendle krichene w zhang l anderson j neural collaborative Ô¨Åltering v matrix factorization revisited fourteenth acm conference recommender system pp x liao l zhang h nie l hu x chua t neural collaborative Ô¨Åltering proceeding th international conference world wide web pp narang taneja n deep contentcollaborative recom mender dccrs international conference advance computing communication control networking icacccn pp ieee bobadilla j laracabrera r gonzalezprieto ortega f deepfair deep learning improving fairness recommender system int j interact multimed artif intell gao zhang j yu j li j wen j xiong q recom mender system generative adversarial network problemdriven perspective inf sci xue hj dai x zhang j huang chen j deep matrix factorization model recommender system ijcai mel bourne australia vol pp wen j j li x mao h visual background recom mendation dance performance deep matrix factoriza tion acm trans multimed comput commun appl tomm wan l xia f kong x hsu ch huang r j deep matrix factorization trustaware recommendation social network ieee trans network sci eng zou g chen j q li kc zhang b gan ndmf neighborhoodintegrated deep matrix factorization service qos prediction ieee trans netw serv manage trigeorgis g bousmalis k zafeiriou schuller bw deep matrix factorization learning attribute repre sentations ieee trans pattern anal mach intell fan j cheng j matrix completion deep matrix fac torization neural netw liu x gherbi wei z li w cheriet multispectral image reconstruction color image enhanced varia tional autoencoder generative adversarial network ieee access neural computing application liu z siu wc wang lw li ct cani mp unsupervised real image superresolution via generative varia tional autoencoder proceeding ieeecvf conference computer vision pattern recognition workshop pp liu z siu wc chan yl photorealistic image super resolution via variational autoencoders ieee trans circ syst video technol zhang s liu jw zuo x lu rk lian sm online deep learning autoencoder appl intell liang krishnan rg hoffman md jebara varia tional autoencoders collaborative Ô¨Åltering proceeding world wide web conference pp nisha c mohan social recommender deep architecture network embedding appl intell rama k kumar p bhasker b deep autoencoders feature learning embeddings recommendation novel recommender solution neural comput appl tahmasebi h ravanmehr r mohamadrezaei r social movie recommender deep autoencoder network twitter neural comput appl li x j collaborative variational autoencoder recommender system proceeding rd acm sigkdd international conference knowledge discovery mining pp meng q zhang collaborative additional varia tional autoencoder topn recommender system ieee access nahta r meena yk gopalani chauhan g twostep hybrid collaborative Ô¨Åltering deep variational bayesian autoencoders inf sci shenbin alekseev tutubalina e malykh v nikolenko si recvae new variational autoencoder topn recom mendations implicit feedback proceeding th international conference web search mining pp wang k xu l huang l wang cd lai jh sddrs stacked discriminative denoising autoencoder recom mender cogn syst re liu wang khan m j novel deep hybrid recommender autoencoder neural collab orative Ô¨Åltering big mining anal mikolov sutskever chen k corrado g dean j distributed representation word phrase com positionality adv neural inform process syst mikolov chen k corrado g dean j efÔ¨Åcient esti mation word representation vector space arxiv preprint arxiv pennington j socher r manning cd glove global vector word representation proceeding conference empirical method natural language processing emnlp pp peter neumann iyyer gardner clark c lee k zettlemoyer l deep contextualized word representation arxiv preprint arxiv guo g zhang j yorkesmith n novel bayesian simi larity measure recommender system proceeding rd international joint conference artiÔ¨Åcial intelligence ijcai pp harper fm konstan ja movielens datasets history context acm trans interact intell syst tiis azathoth myanimelist dataset httpswwwkagglecomaza thothmyanimelist online accessed july bennett j lanning et al netÔ¨Çix prize pro ceedings kdd cup workshop new york ny usa vol p bobadilla j hernando ortega f bernal j framework collaborative Ô¨Åltering recommender system expert syst appl herlocker jl konstan ja terveen lg riedl jt evaluating collaborative Ô¨Åltering recommender system acm trans inf syst gunawardana shani g evaluating recommender sys tems handbook boston ortega f laracabrera r gonzalezprieto bobadilla j providing reliability recommender system bernoulli matrix factorization inf sci castells p vargas wang j novelty diversity metric recommender system choice discovery rele vance proceeding rd european conference retrieval ecir shannon ce weaver w mathematical theory communication university illinois press urbana publisher note springer nature remains neutral regard jurisdictional claim published map institutional afÔ¨Åliations neural computing application,1,latent space and group in synthetic datasets
Neural group recommendation based on a probabilistic semantic aggregation.pdf,Neural group recommendation based on a probabilistic semantic | aggregation,Group recommender system  Collaborative Ô¨Åltering  Aggregation models  Deep learning,"ORIGINAL ARTICLE Neural group recommendation based on a probabilistic semantic aggregation Jorge DuenÀúas-Lerƒ±¬¥n 2,3 ‚Ä¢ Rau¬¥l Lara-Cabrera 1,2 ‚Ä¢ Fernando Ortega 1,2 ‚Ä¢ Jesu¬¥s Bobadilla 1,2 Received: 28 July 2022 / Accepted: 13 February 2023 / Published online: 22 March 2023  The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2023 Abstract Recommendation to groups of users is a challenging subÔ¨Åeld of recommendation systems. Its key concept is how and where to make the aggregation of each set of user information into an individual entity, such as a ranked recommendation list, a virtual user, or a multi-hot input vector encoding. This paper proposes an innovative strategy where aggregation is made in the multi-hot vector that feeds the neural network model. The aggregation provides a probabilistic semantic, and the resulting input vectors feed a model that is able to conveniently generalize the group recommendation from the individual predictions. Furthermore, using the proposed architecture, group recommendations can be obtained by simply feedforwarding the pre-trained model with individual ratings; that is, without the need to obtain datasets containing group of user information, and without the need of running two separate trainings (individual and group). This approach also avoids maintaining two different models to support both individual and group learning. Experiments have tested the proposed architecture using three representative collaborative Ô¨Åltering datasets and a series of baselines; results show suitable accuracy improvements compared to the state of the art. Keywords Group recommender system  Collaborative Ô¨Åltering  Aggregation models  Deep learning 1 Introduction Personalization is one of the Ô¨Åelds of ArtiÔ¨Åcial Intelligence (AI) that has a greater impact on the lives of individuals. We can Ô¨Ånd a multitude of services that provide us with a personalized choice of news, videos, songs, restaurants, clothes, travels, etc. The most relevant tech companies make extensive use of personalization services: Amazon, NetÔ¨Çix, Spotify, TripAdvisor, Google, TikTok, etc. These companies generate their personalized recommendations using Recommender System (RS) [ 1 ] applications. Rec- ommender System (RS) provides to their users personal- ized products or services (items) by Ô¨Åltering the most relevant information regarding the logs of items consumed by the users, the time and place that took place, as well as the existing information about users, their social networks, and the content of items (texts, pictures, videos, etc.). We can classify Recommender System (RS) attending to their Ô¨Åltering strategy as demographic [ 2 ], content-based [ 3 ], context-aware [ 4 ], social [ 5 ], Collaborative Filtering (CF) [ 6 , 7 ] and Ô¨Åltering ensembles [ 8 , 9 ]. Currently, the Matrix Factorization (MF) [ 10 ] machine learning model is used to obtain accurate and fast recommendations between input data (votes). Matrix Factorization (MF) translates the very sparse and huge matrix of discrete votes (from users to items) into two dense and relatively small matrices of real values. One of the matrices contains the set of short and dense vectors representing users, whereas the second matrix vectors represent items. Each vector element (real Jorge DuenÀúas-Lerƒ±¬¥n, Rau¬¥l Lara-Cabrera, Fernando Ortega and Jesu¬¥s Bobadilla have contributed equally to this work. & Jorge DuenÀúas-Lerƒ±¬¥n jorgedl@alumnos.upm.es Rau¬¥l Lara-Cabrera raul.lara@upm.es Fernando Ortega fernando.ortega@upm.es Jesu¬¥s Bobadilla jesus.bobadilla@upm.es 1 Departamento de Sistemas Informa¬¥ticos, Universidad Polite¬¥cnica de Madrid, Alan Turing s/n, 28031 Madrid, Spain 2 KNODIS Research Group, Universidad Polite¬¥cnica de Madrid, 28031 Madrid, Spain 3 Universidad Polite¬¥cnica de Madrid, Madrid, Spain Neural Computing and Applications (2023) 35:14081‚Äì14092 https://doi.org/10.1007/s00521-023-08410-6 (0123456789().,-volV) (0123456789(). ,- volV) value) is called the ‚Äò hidden factor value ‚Äô, since it represents some complex and unknown relationship between the input data (votes). However, Matrix Factorization (MF) machine learning models are fast and accurate, and they also present a remarkable drawback: They cannot detect, in their hidden factors, the complex nonlinear relationships between the input data. Neural Network (NN) can solve this problem through their nonlinear activation functions. Neural Net- work (NN)-based Recommender System (RS) [ 2 , 11 ] makes a compression of information by coding the patterns of the rating matrix in their embeddings and hidden lay- ers [ 12 ]. These embeddings play the role of the Matrix Factorization (MF) hidden factors, enriching the result by incorporating non-linear relations. The most well-known Neural Network (NN) base Recommender System (RS) approaches are Generalized Matrix Factorization (GMF) and Multi-Layer Perceptron (MLP) [ 13 ]. Group Recommendation (GR) [ 7 , 14 ] is a subÔ¨Åeld of the Recommender System (RS) area where recommendations are made to sets of users instead of to individual users (e.g., to recommend a movie to a group of three friends). As in the regular Recommender System (RS), the goal is to make accurate recommendations to the group. In this case, sev- eral policies can be followed; the most popular are (a) to minimize the mean accuracy error: to recommend the items that, on average, most like to all the group members, and (b) to minimize the maximum accuracy error: to recom- mend the items that does not excessively dislike to any of the group members. It is important to state that there are not open datasets containing group information to be used by group recommendation models; for this reason, gener- ally randomly generated groups are used for training and testing research models. Regardless of the machine learning approach used to implement Group Recommendation (GR) Recommender System (RS), the most notable design concept is to estab- lish where to locate the aggregation stage to convert indi- vidual information to group information. The general rule is the sooner the aggregation stage, the better the perfor- mance of Group Recommendation (GR) [ 14 ]. There are three different locations where group information can be aggregated into a uniÔ¨Åed group entity: (a) before the model, (b) in the model, and (c) after the model. The most intuitive approach is to combine individual recommenda- tions into a uniÔ¨Åed group recommendation (option c) [ 15 ]. This approach is known as Individual Preference Aggre- gation (IPA) and requires processing several individual recommendations followed by rank aggregation. However, the process is slow and not particularly accurate. On the other hand, to consider the entire group for the recom- mendation, we should work before or inside the model (options a or b). These approaches are known as Group Preference Aggregation (GPA). Aggregating group infor- mation before the model requires working with the user- item interaction matrix in a higher-dimensional space, which can lead to misinformation problems. To aggregate group information in the model, we need to work with the user‚Äòs hidden vector in the low-dimensional space. Aggregating several hidden vectors from individual users into a uniÔ¨Åed virtual user hidden vector [ 16 ] avoids compute the model predictions several times and makes the rank aggregation stage unnecessary. In addition, it takes advantage of operating with condensed information com- ing from the Matrix Factorization (MF) compression of information: the virtual user can be obtained simply by averaging the representative short and dense vectors of the users group; this is efÔ¨Åcient and accurate. An interesting question is can Neural Network (NN) operate the same way that Matrix Factorization (MF) does to obtain virtual users and generate recommendations? First, note that many Neural Network (NN)-based Recommender System (RS) models compress the user embedding in a different latent space than the item embedding, and it can be a problem; then, the Neural Network (NN) nonlinear ensemble repre- sentations are more complex than the Matrix Factorization (MF) hidden factor representations; consequently, simply averaging the ensembles of the users in the group does not automatically ensure a representative virtual user embed- ding. Furthermore, model-based aggregations (option ‚Äòb‚Äô in the previous paragraph) are model dependent, and then, it is necessary to design and test different solutions for dif- ferent Neural Network (NN)-based Recommender System (RS) models, whereas the Neural Network (NN) latent spaces are the state of the art to catch users and items relations, some other machine learning approaches have been designed, such as the use of the random walk with restart method [ 17 ] providing a framework to relate users, items, and groups, and to exploit the item content and the proÔ¨Åles of the users. A three-stage method [ 18 ] is proposed to increase the precision and fairness of Group Recom- mendation (GR), where binary Matrix Factorization (MF), graphs and the dynamic consensus model are processed sequentially. Some relevant and current GR research aims to make use of the concept of member preference (inÔ¨Çu- ence or expertise) concept, based on similarity and trust. The key idea is to detect the group leaders as group members that are trusted more than others and have more inÔ¨Çuence than others. In [ 19 ], fuzzy clustering and an implicit trust metric are combined to Ô¨Ånd neighborhoods. Group Recommendation (GR) based on an average strategy applied to user preference differences [ 20 ] has been com- bined with trusted social networks to correct recommen- dations. An aggregation approach for GR mimics crowd- sourcing concepts to estimate the level of expertise of group members [ 21 ]; it is implemented using parameters of 14082 Neural Computing and Applications (2023) 35:14081‚Äì14092 sensitivity and speciÔ¨Åcity. The impact of social factors on a Group Recommendation (GR) computational model is evaluated in [ 22 ], using the expertise factor, the inÔ¨Çuences of personality, preference similarities, and interpersonal relationships. In this paper, we present how we can generate Group Recommendation (GR) using Neural Network (NN)-based Recommender System (RS) by training the model using raw Collaborative Filtering (CF) data (i.e., the ratings of individual users to the items without any additional infor- mation). The Group Recommendation (GR) have been tested using the two most popular implementations of Neural Network (NN)-based Recommender System (RS): Generalized Matrix Factorization (GMF) and Multi-Layer Perceptron (MLP). As stated previously, to make recom- mendations to groups using Neural Network (NN)-based Recommender System (RS), information of the individual users must be aggregated. The chosen information aggre- gation design is to merge the users of the group in the input vector that feeds the user embedding of the Neural Net- work (NN). This aggregation design is not novel, since it has been used by [ 23 ] applied to a Multi-Layer Perceptron (MLP) architecture. However, our approach combines several innovative aspects in comparison with the state of the art. On the one hand, the aggregation of the users in the group is a probabilistic function rather than a simple multi- hot encoding [ 23 ]; this better captures the relative impor- tance of users in the input vector that feeds the Neural Network (NN), moreover: This aggregation approach serves as front-end for any Neural Network (NN) Group Recommendation (GR) model. On the other hand, we propose the use of a simple Recommender System (RS) Neural Network (NN) model (Generalized Matrix Factor- ization (GMF)) instead of the deepest Multi-Layer Per- ceptron (MLP) one [ 23 ]; the hypothesis is that complex models overÔ¨Åt Group Recommendation (GR) scenarios, since they are designed to accurately predict individual predictions, whereas Group Recommendation (GR) must satisfy an average of the tastes in the group of users, that is, Group Recommendation (GR) should be designed to gen- eralize the set of individual tastes in the group. Further- more, the proposed architecture just needs a single training to provide both individual recommendations and group recommendations; particularly, the model is trained by only using individual recommendations (as in regular Recommender System (RS)). Once the model is trained to return individual predictions, we can Ô¨Åll the input vector by aggregating all the users in the group, then feedforward the trained model and Ô¨Ånally obtain the recommendation for the group of users. Anyway, the impact of these innovative aspects can be evaluated in Sect. 3 , where we empirically compare the proposed aggregation designs with respect to the main baseline [ 23 ] In summary, the Group Recommendation (GR) state of the art presents the following drawbacks: (a) Some research relies on additional data to the Collaborative Fil- tering (CF) ratings, such as trust or reputation information that is not available on the majority of datasets, (b) differ- ent proposals make the aggregation of individual users before (Individual Preference Aggregation (IPA)) or after (Ranking) the model, making it impossible to beneÔ¨Åt from the machine learning model inner representations (Group Preference Aggregation (GPA)), and (c) The proposed GR neural model solutions tend to apply architectures designed to make individual recommendations, rather than group ones; this leads to the model overÔ¨Åtting and to a low scalability referred to the number of users in a group. To Ô¨Åll the gap, our proposed model: (a) Acts exclusively on Collaborative Filtering (CF) ratings, (b) Makes user aggregation in the model, and (c) Its model depth and design enable adequate learning generalizations. Addi- tionally, the provided experiments test the proposed model according to different aggregation strategies to set the group labels used in the learning stage. In contrast, a notable limitation of our architecture and the experiments is the lack of testing on particularly demanding scenarios such as cold start in groups users, extremely sparse data sets, impact of popular item bias, and fear Group Recom- mendation (GR). The rest of the paper is structured as follows: Sect. 2 introduces the tested models and aggregation functions; Sect. 3 describes the experiment design, the selected quality measures, the chosen datasets and shows the results obtained; Sect. 4 provides their explanations; and Sect. 5 highlights the main conclusions of the article and the suggested future work. 2 Proposed model In Collaborative Filtering (CF), interactions (purchase, viewing, rating, etc.) between users and items are stored in a sparse matrix since it is common for users to interact only with a small proportion of the available items and, in the same way, only a small percentage of existing users interact with the items. The sparsity levels of this matrix are around 95‚Äì98% as shown in Table 2 . To handle this sparsity, current Collaborative Filtering (CF) models based on Neural Network (NN) [ 13 ] work with a projection of users and items into a low-dimensional latent space using embedding layers. Embedding layers are a very popular type of layer used in Neural Network (NN) that receive as input any entity and return a vector with a low-dimensional representation of the entity in a latent space. These vectors are commonly named latent factors . In order to transform the entity into its low-dimensional representation, the Neural Computing and Applications (2023) 35:14081‚Äì14092 14083 embedding layer Ô¨Årst transforms the entity into a one hot encoding representation (typically using a hash function). Figure 1 summarizes this process. In the context of Collaborative Filtering (CF), two embedding layers are required: one for the users and the other for the items. Later, both embedding layers are combined using a Neural Network (NN) architecture (see Fig. 2 ). For example, the models Generalized Matrix Factorization (GMF) and Multi-Layer Perceptron (MLP) use a dot layer and a concatenate layer followed by some fully connected dense layers as architectures, respectively. Formally, we deÔ¨Åne a Neural Network (NN) model U that predicts the rating that a user u will give to an item i ( ^ r u ; i ) combining the latent factors provided by the embed- ding layer (Emb L ) of the user u ( l u ~ ) and the item i ( l i ~ ): Emb L √∞ u √û ¬º l u ~ Emb L √∞ i √û ¬º l i ~ ; U √∞ l ~ u ; l ~ i √û ¬º ^ r u ; i √∞ 1 √û As stated in Sect. 1 , when working with Group Recom- mendation (GR), a straightforward strategy is Individual Preference Aggregation (IPA) [ 24 ]. This strategy makes a prediction for each member of the group and then performs an aggregation. This strategy does not treat the group as a whole. If we have a group of users G ¬º f u 1 ; u 2 ; :::; u n g , the prediction of the rating of this group G to an item i ( ^ r G ; i ) is computed as the average value of the individual predictions: ^ r G ; i ¬º 1 k G k X u 2 G ^ r u ; i ¬º 1 k G k X u 2 G U √∞ l u ~ ; l i ~ √û √∞ 2 √û On the other hand, the Group Preference Aggregation (GPA) strategies take into account the group as a whole. It should be noted that the order of users within the group and the length of it should not affect the aggregation; thus, the aggregations should meet the constraints of permutation invariant and Ô¨Åxed result length [ 23 ]. Our goal with the Group Preference Aggregation (GPA) strategy is to be able to obtain a prediction ^ r G ; i with a single forward propagation and to treat the group as a whole entity. We can achieve this by aggregating the latent factors of each user that belongs to the group to obtain the latent factor of the group l ~ G . Once the latent factors of the group are aggregated, the model U can be used to compute the predictions: Emb L √∞ G √û ¬º l ~ G ^ r Gi ¬º U √∞ l ~ G ; l ~ i √û √∞ 3 √û The aggregation of group latent factors in embedding layers can be achieved by modifying the input of the Neural Network (NN). As mentioned previously, embed- ding layers have as input a one hot representation of the entities. This approach is adequate when performing indi- vidual predictions, however, for group recommendations, we need to apply a multi-hot representation to the users‚Äô embedding layer, i.e., we encode the group by setting multiple inputs of the user embedding layer (the inputs related with the users that belong to the group) to a value higher than 0. This encoding allows us to take into account all group users at the same time for the extraction of latent factors of the group l ~ G . The simplest aggregation, which is used by the DeepGroup model [ 23 ], is to use as input for embedding a constant value proportional to the size of the group. We deÔ¨Åne the input of the user‚Äôs embedding layer for the user u as EmbeddingInput Average √∞ u √û ¬º 1 k G k if u 2 G 0 if u 62 G 8 < : √∞ 4 √û We call this aggregation ‚Äò Average ‚Äô since the embedding layer will generate the group latent factor equal to the average of the latent factors of all users in the group. Recommender System (RS) can give better predictions the more information they have about users, so to take advantage of this fact, we have tested the ‚Äò Expertise ‚Äô aggregation in which we give a weight to the users pro- portional to the number of votes they have entered into the system. Let k R u k the number of ratings of the user u , the input of the users‚Äô embedding layer for the user u is deÔ¨Åned as Fig. 1 Embedding layer schema Fig. 2 Collaborative Ô¨Åltering-based neural network model 14084 Neural Computing and Applications (2023) 35:14081‚Äì14092 EmbeddingInput Expertise √∞ u √û ¬º k R u k P g 2 G k R g k if u 2 G 0 if u 62 G 8 < : √∞ 5 √û In addition to the ‚Äò Expertise ‚Äô aggregation, we also pro- posed the ‚Äò Softmax aggregation as a smooth version of the ‚Äò Expertise ‚Äô aggregation. In this case, the input of the users‚Äô embedding layer for the user u is deÔ¨Åned as EmbeddingInput Softmax √∞ u √û ¬º e k R u k P g 2 G e k R g k if u 2 G 0 if u 62 G 8 > < > : √∞ 6 √û In Fig. 3 , we can see where the equations Ô¨Åt in the group recommendation process. The Ô¨Årst step is to generate the multi-hot vector with some of the described aggregation (Eqs. 4 , 5 , 6 ). This vector (multi-hot representation of the group) is fed into the embedding layer to obtain a vector of the latent factors of the groups l ~ G (Eq. 3 ). Once the latent Fig. 3 Graphical representation of the proposed model Table 1 Complete aggregation example (a) Rating count. User . u 13 . u 24 . u 30 . u 42 . #Rating 2 5 6 3 (b) Input values to the users‚Äô embedding layer. Strategy/ User . u 13 . u 24 . u 30 . u 42 . Average 0,25 0,25 0,25 0,25 Expertise 0,13 0,31 0,38 0,19 Softmax 0,01 0,26 0,70 0,03 Users‚Äô latent factors assuming a latent space of size 3. User/factor l 1 l 2 l 3 u 13 0,1 0,6 0,3 u 24 0,7 0,2 0,9 u 30 0,8 0,4 0,1 u 42 0,5 0,7 0,8 Group latent factors using different aggregations Agg factor l G 1 l G 2 l G 3 Average 0,525 0,475 0,525 Expertise 0,629 0,425 0,508 Softmax 0,758 0,359 0,331 Neural Computing and Applications (2023) 35:14081‚Äì14092 14085 factors of the group and the item are obtained, they are used to feed the model U (Generalized Matrix Factoriza- tion (GMF) or Multi-Layer Perceptron (MLP)) and produce the rating prediction for the group G on the item i (Eq. 2 ). In Table 1, we can Ô¨Ånd an example with some users (13, 24, 30 and 42) with different rating counts (Table 1 a), their input values to the users‚Äô embedding layer in a multi-hot fashion (Table 1 b), their individual latent factors (Table 1 c), and the Ô¨Ånal group latent factors with different aggregations (Table 1 d). 3 Experimental evaluation In this section, we show the experiments carried out to validate the aggregation proposed in this manuscript. As previously stated, the experiments have been performed using the most popular Neural Network (NN)-based Rec- ommender System (RS) architectures: Generalized Matrix Factorization (GMF) and Multi-Layer Perceptron (MLP). We have chosen these two architectures because they are the best known and offer the best results for individual predictions. However, the aggregation strategies proposed can be applied to any Neural Network (NN) architecture based on embedding layers. The choice of datasets has been made considering that (a) there are no open datasets containing information on group voting; and (b) Generalized Matrix Factorization (GMF) and Multi-Layer Perceptron (MLP) models should be trained using individual voting, since the proposed aggregations allow computing predictions for groups on already trained models. For these reasons, we have chosen the following gold standard datasets in the Ô¨Åeld of Rec- ommender System (RS): MovieLens1M [ 25 ], the most popular dataset in the research of Recommender System (RS); FilmTrust [ 26 ], a dataset smaller than MovieLens1M to measure the performance of the aggregation in datasets with a lower number of users, items, and ratings; and MyAnimeList , a dataset with a range of votes higher than the MovieLens1M . Other popular datasets such as NetÔ¨Çix Prize or MovieLens10M have not been selected due to the high computational time required to train and test the models. The main parameters of the selected datasets can be found in Table 2 . The generation of synthetic groups has been carried out in such a way that all groups have voted at least Ô¨Åve items in test. In this way, it is possible to evaluate both the quality of the predictions and the quality of the recom- mendations to the groups as detailed below. Groups of different sizes (from 2 to 10 users) have been generated. For each group size, 10000 synthetic groups have been generated. The generation of a group has been carried out following the following algorithm: 1. DeÔ¨Åne the size of the group S . 2. Random select 5 items rated in test by at least S users. 3. Find all users who have rated the 5 items selected in 2. 4. If we found fewer than S users, go back to 2. Otherwise, random select S users and create a group. To measure the quality of the predictions for the group, we have calculated the mean absolute error MAE ¬º 1 # groups X G 1 k G k  k I G k X u 2 G X i 2 I G j ^ r G ; i  r u ; i j ; √∞ 7 √û the mean squared error MSE ¬º 1 # groups X G 1 k G k 1 k G k  k I G k X u 2 G X i 2 I G ^ r G ; i  r u ; i   2 ; √∞ 8 √û and mean maximum group error MAX ¬º 1 # groups X G max u 2 G max i 2 I G j ^ r G ; i  r u ; i j ; √∞ 9 √û where I G denotes the items rated by the group G To measure the quality of the recommendations for the group, we have calculated the Normalized Discounted Cumulative Gain (NDCG) score NDCG @ N ¬º 1 # groups X G DCG G @ N IDCG G @ N ; √∞ 10 √û DCG G @ N ¬º X i 2 X N G  r G ; i log 2 √∞ pos G √∞ i √û √æ 1 √û ; √∞ 11 √û IDCG G @ N ¬º X i 2 T N G  r G ; i log 2 √∞ ipos G √∞ i √û √æ 1 √û ; √∞ 12 √û where N is the number of items recommended to the group (in our experiments N ¬º 5 according to the generation of synthetic groups), X N G is the set of N items recommended to the group G , pos G √∞ i √û is the position of the item i in the group‚Äôs G recommendation list, T N G is the set of the top N items for the group G , ipos G √∞ i √û is the ideal rank of the item Table 2 Main parameters of the datasets used in the experiments Dataset #users #items #ratings Scores Sparsity Movie lens1M 6040 3706 911,031 1‚Äì5 95.94 Filmtrust 1508 2071 35,497 0‚Äì5 87.98 My anime list 19,179 2692 548,967 1‚Äì10 98.94 14086 Neural Computing and Applications (2023) 35:14081‚Äì14092 Table 3 Mean absolute error Model \ Group Size 2 3 4 5 6 7 8 9 10 GMF IPA GMF Avg 0.74205 (0.409) 0.76075 (0.341) 0.76893 (0.299) 0.77009 (0.271) 0.77745 (0.249) 0.77659 (0.234) 0.77681 (0.221) 0.77599 (0.212) 0.77558 (0.201) GMF Expertise 0.74393 (0.41) 0.76207 (0.341) 0.77018 (0.299) 0.77155 (0.27) 0.779 (0.249) 0.77782 (0.234) 0.77834 (0.221) 0.77729 (0.211) 0.77685 (0.201) GMF Softmax 0.74246 (0.409) 0.7608 (0.341) 0.76891 (0.299) 0.77012 (0.27) 0.77751 (0.249) 0.7766 (0.234) 0.77687 (0.221) 0.77602 (0.212) 0.77562 (0.201) MLP IPA 0.74956 (0.444) 0.77342 (0.361) 0.78055 (0.313) 0.78211 (0.28) 0.78853 (0.258) 0.78633 (0.241) 0.78678 (0.228) 0.78591 (0.219) 0.78509 (0.207) MLP Avg DeepGroup 0.75537 (0.275) MLP Expertise 0.72596 (0.486) 0.74432 (0.405) 0.75031 (0.355) 0.75132 (0.32) 0.75787 (0.295) 0.75607 (0.276) 0.75709 (0.261) 0.75481 (0.25) 0.755 (0.238) MLP Softmax 0.72407 (0.485) 0.74297 (0.404) 0.74925 (0.355) 0.75019 (0.32) 0.75669 (0.295) 0.7556 (0.261) 0.75389 (0.25) 0.75361 (0.238) Model \ Group Size 2 3 4 5 6 7 8 9 10 GMF IPA GMF Avg 0.61552 (0.451) 0.71033 (0.32) 0.73011 (0.28) 0.73419 (0.252) 0.73606 (0.232) 0.73832 (0.217) 0.74045 (0.203) 0.74298 (0.193) 0.74212 (0.185) GMF Expertise 0.6149 (0.444) 0.71239 (0.319) 0.73144 (0.281) 0.73583 (0.252) 0.73742 (0.232) 0.7396 (0.217) 0.74166 (0.203) 0.74418 (0.193) 0.74336 (0.184) GMF Softmax 0.61512 (0.448) 0.71088 (0.319) 0.73035 (0.28) 0.73445 (0.252) 0.73624 (0.232) 0.73847 (0.217) 0.74057 (0.203) 0.74309 (0.193) 0.74222 (0.185) MLP IPA 0.58165 (0.442) 0.70368 (0.325) 0.72062 (0.281) 0.7252 (0.252) 0.72788 (0.232) 0.73073 (0.217) 0.73353 (0.203) 0.73623 (0.193) 0.73525 (0.185) MLP Avg DeepGroup 0.58199 (0.447) MLP Expertise 0.70449 (0.321) 0.71891 (0.276) 0.72315 (0.247) 0.72581 (0.228) 0.72865 (0.213) 0.73127 (0.2) 0.73429 (0.191) 0.73336 (0.183) MLP Softmax 0.58063 (0.45) 0.70226 (0.319) 0.71734 (0.275) 0.72153 (0.247) 0.72443 (0.228) 0.7272 (0.214) 0.72993 (0.2) 0.73295 (0.191) 0.73202 (0.183) Model \ Group Size 2 3 4 5 6 7 8 9 10 GMF IPA GMF Avg 0.95819 (0.477) 0.97595 (0.417) 0.99149 (0.38) 1.0017 (0.346) 1.01404 (0.329) 1.01942 (0.312) 1.022 (0.297) 1.02445 (0.282) GMF Expertise 0.93675 (0.572) 0.96424 (0.48) 0.98092 (0.419) 0.99603 (0.382) 1.00649 (0.349) 1.01805 (0.331) 1.02352 (0.314) 1.0258 (0.3) 1.0284 (0.284) GMF Softmax 0.93219 (0.568) 0.95848 (0.477) 0.97559 (0.417) 0.99104 (0.38) 1.00133 (0.346) 1.01363 (0.329) 1.0191 (0.312) 1.02173 (0.297) 1.02422 (0.282) MLP IPA 0.95479 (0.585) 0.98155 (0.484) 0.99709 (0.42) 1.00977 (0.381) 1.01745 (0.347) 1.02794 (0.329) 1.03188 (0.311) 1.03335 (0.298) 1.03451 (0.282) MLP Avg DeepGroup 0.93161 (0.618) 0.95609 (0.515) 0.98456 (0.408) 0.99331 (0.371) 1.0052 (0.351) 1.00857 (0.332) 1.01039 (0.317) 1.01233 (0.3) MLP Expertise 0.93803 (0.622) 0.96132 (0.517) 0.97587 (0.453) 0.98923 (0.409) 0.99851 (0.373) 1.00879 (0.353) 1.01258 (0.334) 1.01493 (0.319) 1.01599 (0.302) MLP Softmax 0.93351 (0.619) 0.97007 (0.451) Neural Computing and Applications (2023) 35:14081‚Äì14092 14087 Table 4 Mean squared error Model \ Group Size 2 3 4 5 6 7 8 9 10 GMF IPA GMF Avg 0.92437 (0.676) 0.92648 (0.609) 0.94191 (0.567) 0.93896 (0.53) 0.9376 (0.5) 0.93832 (0.48) 0.93571 (0.454) GMF Expertise 0.88044 (0.918) 0.91329 (0.77) 0.92754 (0.678) 0.92979 (0.61) 0.94504 (0.568) 0.94135 (0.531) 0.93994 (0.501) 0.94037 (0.481) 0.93737 (0.454) GMF Softmax 0.87614 (0.914) 0.90952 (0.767) MLP IPA 0.94301 (0.982) 0.96557 (0.814) 0.96809 (0.712) 0.96499 (0.635) 0.97727 (0.591) 0.96889 (0.55) 0.96634 (0.518) 0.96648 (0.498) 0.96187 (0.47) MLP Avg DeepGroup 0.99415 (1.037) 1.03182 (0.875) 1.04278 (0.779) 1.04242 (0.695) 1.05597 (0.651) 1.05056 (0.605) 1.04927 (0.574) 1.04836 (0.552) 1.04669 (0.524) MLP Expertise 0.9986 (1.038) 1.03522 (0.88) 1.04511 (0.78) 1.04435 (0.696) 1.05806 (0.651) 1.05121 (0.604) 1.05084 (0.575) 1.0491 (0.553) 1.04787 (0.523) MLP Softmax 0.99487 (1.035) 1.03145 (0.874) 1.04258 (0.779) 1.04235 (0.694) 1.05605 (0.651) 1.05034 (0.604) 1.04925 (0.574) 1.04822 (0.552) 1.04659 (0.524) Model \ Group Size 2 3 4 5 6 7 8 9 10 GMF IPA GMF Avg 0.67941 (1.077) 0.7889 (0.688) 0.82014 (0.608) 0.82302 (0.544) 0.82574 (0.502) 0.83038 (0.469) 0.8324 (0.44) 0.8375 (0.42) 0.83544 (0.401) GMF Expertise 0.67314 (1.05) 0.79105 (0.686) 0.82229 (0.608) 0.82546 (0.543) 0.82758 (0.501) 0.83205 (0.468) 0.83382 (0.439) 0.83875 (0.418) 0.83673 (0.399) GMF Softmax 0.67596 (1.063) 0.7892 (0.687) 0.82043 (0.608) 0.82333 (0.544) 0.82592 (0.502) 0.83053 (0.469) 0.83251 (0.44) 0.83758 (0.42) 0.83552 (0.401) MLP IPA 0.77197 (0.683) 0.79514 (0.592) 0.7988 (0.528) 0.80315 (0.487) 0.80807 (0.454) 0.81084 (0.427) 0.81611 (0.406) 0.81408 (0.388) MLP Avg DeepGroup 0.61859 (1.009) MLP Expertise 0.62484 (0.979) 0.7691 (0.68) 0.78956 (0.586) 0.79332 (0.522) 0.79799 (0.483) 0.80305 (0.45) 0.80595 (0.423) 0.81166 (0.403) 0.80977 (0.385) MLP Softmax 0.62106 (0.992) 0.7649 (0.675) 0.78709 (0.585) 0.79116 (0.523) 0.79625 (0.484) 0.80142 (0.452) 0.80456 (0.424) 0.81033 (0.404) 0.8085 (0.387) Model \ Group Size 2 3 4 5 6 7 8 9 10 GMF IPA GMF Avg GMF Expertise 1.49874 (1.963) 1.57277 (1.689) 1.61625 (1.463) 1.66444 (1.351) 1.69199 (1.239) 1.73293 (1.202) 1.74812 (1.133) 1.75649 (1.087) 1.76487 (1.035) GMF Softmax 1.47707 (1.932) 1.54383 (1.654) 1.58617 (1.433) 1.63575 (1.326) 1.66342 (1.214) 1.70677 (1.179) 1.72239 (1.112) 1.73223 (1.066) 1.74092 (1.016) MLP IPA 1.56623 (1.959) 1.61737 (1.655) 1.64909 (1.431) 1.69132 (1.32) 1.71029 (1.209) 1.74683 (1.169) 1.75711 (1.105) 1.76368 (1.058) 1.76877 (1.008) MLP Avg DeepGroup 1.61669 (2.032) 1.68103 (1.718) 1.71103 (1.492) 1.75681 (1.368) 1.77828 (1.254) 1.81759 (1.217) 1.82764 (1.148) 1.83403 (1.098) 1.84177 (1.049) MLP Expertise 1.64412 (2.059) 1.70965 (1.747) 1.74467 (1.517) 1.78446 (1.386) 1.80671 (1.276) 1.84221 (1.232) 1.85095 (1.163) 1.85803 (1.116) 1.86351 (1.063) MLP Softmax 1.62458 (2.038) 1.68445 (1.723) 1.7153 (1.496) 1.75838 (1.368) 1.78024 (1.256) 1.81848 (1.218) 1.82855 (1.149) 1.83446 (1.099) 1.84249 (1.049) 14088 Neural Computing and Applications (2023) 35:14081‚Äì14092 Table 5 Mean max error Model \ Group Size 2 3 4 5 6 7 8 9 10 GMF IPA GMF Avg 1.35658 (0.588) 1.59908 (0.577) 1.64979 (0.573) 1.69807 (0.576) 1.73598 (0.571) GMF Expertise 1.02474 (0.602) 1.22441 (0.599) 1.35928 (0.59) 1.4551 (0.584) 1.54414 (0.579) 1.60112 (0.577) 1.65118 (0.574) 1.69926 (0.576) 1.7366 (0.571) GMF Softmax 1.02191 (0.6) 1.22143 (0.598) 1.45202 (0.583) 1.54118 (0.578) MLP IPA 1.04098 (0.642) 1.25715 (0.614) 1.38214 (0.602) 1.47972 (0.591) 1.56516 (0.586) 1.62067 (0.581) 1.66905 (0.576) 1.71687 (0.58) 1.7528 (0.573) MLP Avg DeepGroup 1.07144 (0.666) 1.28743 (0.643) 1.41937 (0.635) 1.51234 (0.633) 1.59812 (0.638) 1.65421 (0.642) 1.70673 (0.641) 1.75552 (0.647) 1.79703 (0.645) MLP Expertise 1.07476 (0.667) 1.28932 (0.644) 1.42078 (0.635) 1.51325 (0.634) 1.59883 (0.638) 1.65371 (0.64) 1.70637 (0.64) 1.75428 (0.645) 1.79566 (0.643) MLP Softmax 1.07226 (0.666) 1.28716 (0.643) 1.41906 (0.635) 1.51227 (0.633) 1.59788 (0.638) 1.65391 (0.641) 1.7066 (0.641) 1.75515 (0.646) 1.79669 (0.645) Model \ Group Size 2 3 4 5 6 7 8 9 10 GMF IPA GMF Avg 0.85192 (0.555) 1.13757 (0.573) 1.27696 (0.573) 1.36783 (0.57) 1.44244 (0.571) 1.51262 (0.575) 1.56818 (0.573) 1.62204 (0.571) 1.6636 (0.567) GMF Expertise 0.85171 (0.549) 1.13845 (0.571) 1.27815 (0.571) 1.36895 (0.567) 1.4425 (0.569) 1.51199 (0.573) 1.56717 (0.57) 1.62058 (0.569) 1.66146 (0.565) GMF Softmax 0.85147 (0.552) 1.13761 (0.572) 1.27708 (0.572) 1.3679 (0.569) 1.44234 (0.571) 1.51245 (0.575) 1.56799 (0.572) 1.62184 (0.571) 1.66335 (0.567) MLP IPA 1.11519 (0.564) 1.24935 (0.56) 1.33899 (0.555) 1.41348 (0.556) 1.48001 (0.557) 1.5341 (0.554) 1.58622 (0.552) 1.62791 (0.549) MLP Avg DeepGroup 0.79205 (0.553) 1.33662 (0.555) 1.4118 (0.557) 1.47902 (0.559) 1.53438 (0.556) 1.58697 (0.555) 1.62916 (0.55) MLP Expertise 0.79191 (0.56) 1.11441 (0.556) 1.24814 (0.555) 1.33715 (0.551) MLP Softmax 0.79235 (0.555) 1.11261 (0.556) 1.24698 (0.556) 1.41161 (0.556) 1.47872 (0.558) 1.53406 (0.555) 1.58662 (0.554) 1.62879 (0.55) Model \ Group Size 2 3 4 5 6 7 8 9 10 GMF IPA GMF Avg GMF Expertise 1.31784 (0.858) 1.60964 (0.883) 1.8266 (0.882) 1.99902 (0.894) 2.13631 (0.891) 2.25748 (0.91) 2.34706 (0.908) 2.42357 (0.922) 2.49875 (0.932) GMF Softmax 1.30626 (0.847) 1.59061 (0.869) 1.80139 (0.867) 1.97309 (0.879) 2.10896 (0.878) 2.23046 (0.898) 2.31946 (0.896) 2.39701 (0.911) 2.47222 (0.92) MLP IPA 1.34151 (0.874) 1.63805 (0.873) 1.84317 (0.862) 2.01188 (0.868) 2.1406 (0.863) 2.25649 (0.876) 2.33763 (0.875) 2.4112 (0.889) 2.4836 (0.896) MLP Avg DeepGroup 1.36617 (0.893) 1.66385 (0.902) 1.8675 (0.896) 2.03818 (0.907) 2.17095 (0.906) 2.28936 (0.924) 2.37588 (0.921) 2.4495 (0.934) 2.52558 (0.943) MLP Expertise 1.38038 (0.9) 1.68165 (0.913) 1.89237 (0.908) 2.0611 (0.918) 2.1951 (0.914) 2.31311 (0.929) 2.39796 (0.923) 2.47081 (0.935) 2.54585 (0.943) MLP Softmax 1.37076 (0.894) 1.66676 (0.904) 1.87147 (0.898) 2.04076 (0.908) 2.17377 (0.907) 2.29111 (0.924) 2.37734 (0.921) 2.45073 (0.934) 2.52696 (0.943) Neural Computing and Applications (2023) 35:14081‚Äì14092 14089 i for the group G , and  r G ; i is the average rating of the users belonging to the group G for the item i . We can see the results of the experiment executed with these scores in Table 3 (MAE), Table 4 (MSE), Table 5 (Max), and Table 6 (NDCG). The cells with the best results Table 6 Discounted cumulative gain Model \ Group Size 2 3 4 5 6 7 8 9 10 GMF IPA GMF Avg 0.9886 (0.015) 0.99178 (0.011) 0.99286 (0.01) 0.99358 (0.009) GMF Expertise 0.97995 (0.024) 0.98528 (0.019) 0.98853 (0.015) 0.99058 (0.012) 0.99171 (0.011) 0.99282 (0.01) 0.99351 (0.009) 0.99411 (0.008) 0.99454 (0.008) GMF Softmax 0.98006 (0.024) 0.98536 (0.019) 0.99064 (0.012) 0.99415 (0.008) 0.99456 (0.008) MLP IPA 0.97854 (0.026) 0.98342 (0.02) 0.98689 (0.016) 0.98906 (0.014) 0.99046 (0.012) 0.99178 (0.011) 0.99251 (0.01) 0.99303 (0.009) 0.99358 (0.009) MLP Avg DeepGroup 0.97778 (0.026) 0.98247 (0.021) 0.98556 (0.017) 0.98762 (0.015) 0.98894 (0.014) 0.98999 (0.013) 0.99064 (0.012) 0.99109 (0.011) 0.99152 (0.011) MLP Expertise 0.97777 (0.026) 0.98251 (0.021) 0.9855 (0.017) 0.98763 (0.015) 0.98894 (0.014) 0.99004 (0.013) 0.99071 (0.012) 0.99116 (0.011) 0.9916 (0.011) MLP Softmax 0.97784 (0.026) 0.98248 (0.021) 0.98554 (0.017) 0.98762 (0.015) 0.98895 (0.014) 0.98998 (0.013) 0.99069 (0.012) 0.9911 (0.011) 0.99153 (0.011) Model \ Group Size 2 3 4 5 6 7 8 9 10 GMF IPA GMF Avg 0.96788 (0.028) 0.97795 (0.022) 0.9815 (0.019) 0.98393 (0.016) 0.98596 (0.014) 0.9876 (0.013) 0.98869 (0.011) 0.98967 (0.011) 0.99038 (0.01) GMF Expertise 0.96795 (0.028) 0.97794 (0.022) 0.9815 (0.019) 0.98392 (0.016) 0.98593 (0.014) 0.9876 (0.013) 0.98868 (0.012) 0.98965 (0.011) 0.99038 (0.01) GMF Softmax 0.96795 (0.028) 0.97796 (0.022) 0.9815 (0.019) 0.98394 (0.016) 0.98596 (0.014) 0.9876 (0.013) 0.98868 (0.012) 0.98967 (0.011) 0.99038 (0.01) MLP IPA 0.9788 (0.023) 0.98249 (0.019) 0.98523 (0.016) 0.98704 (0.015) 0.98994 (0.011) 0.99165 (0.01) MLP Avg DeepGroup 0.96897 (0.027) 0.9789 (0.022) 0.98275 (0.018) 0.98527 (0.016) 0.98895 (0.012) 0.99104 (0.01) 0.99166 (0.009) MLP Expertise 0.9694 (0.027) 0.98276 (0.018) 0.98724 (0.014) 0.98893 (0.012) 0.98993 (0.011) 0.99106 (0.01) 0.99166 (0.009) MLP Softmax 0.9693 (0.027) 0.97891 (0.022) 0.98527 (0.016) 0.98728 (0.014) 0.98895 (0.012) 0.98998 (0.011) 0.99106 (0.01) Model \ Group Size 2 3 4 5 6 7 8 9 10 GMF IPA GMF Avg 0.98898 (0.014) 0.9949 (0.007) 0.99571 (0.006) 0.99662 (0.005) 0.99679 (0.005) 0.99714 (0.004) GMF Expertise 0.98893 (0.014) 0.99209 (0.01) 0.99383 (0.008) 0.99479 (0.007) 0.99566 (0.006) 0.99609 (0.005) 0.99658 (0.005) 0.99674 (0.005) 0.99708 (0.004) GMF Softmax 0.99217 (0.01) 0.99399 (0.008) 0.99615 (0.005) MLP IPA 0.98723 (0.015) 0.99062 (0.011) 0.99255 (0.009) 0.9936 (0.008) 0.99458 (0.007) 0.99507 (0.006) 0.99573 (0.006) 0.99591 (0.005) 0.99632 (0.005) MLP Avg DeepGroup 0.9868 (0.016) 0.99023 (0.012) 0.99212 (0.01) 0.99307 (0.008) 0.99415 (0.007) 0.99459 (0.007) 0.99519 (0.006) 0.99537 (0.006) 0.99565 (0.005) MLP Expertise 0.9867 (0.016) 0.99021 (0.012) 0.9921 (0.01) 0.99312 (0.008) 0.99414 (0.007) 0.99458 (0.007) 0.99521 (0.006) 0.99542 (0.006) 0.9957 (0.005) MLP Softmax 0.98684 (0.016) 0.99028 (0.012) 0.99211 (0.01) 0.99308 (0.008) 0.99416 (0.007) 0.9946 (0.007) 0.99521 (0.006) 0.99539 (0.006) 0.99566 (0.005) 14090 Neural Computing and Applications (2023) 35:14081‚Äì14092 have been highlighted (gray background and bold), while the standard deviation of each metric is in parentheses. All results are analyzed in Sect. 4 . All experiments have been run using an NVIDIA Quadro RTX 8000 GPU with 48 GB GDDR6 of memory, 4,608 NVIDIA Tensor Cores and a performance of 16.3 TFLOPS. We are committed to reproducible science, so the source code of all experiments with the values of the parameters used and their random seeds have been shared on GitHub. 1 4 Discussion The main goal of this research is to evaluate different aggregation techniques to make recommendations to groups. As shown in Sect. 3 , we can see different trends according to (a) the models used; (b) the way group information is aggregated; (c) the datasets on which they act; and (d) the size of the groups. Focusing on the models, we can see how Multi-Layer Perceptron (MLP), which has several hidden layers, obtains a lower MAE; however, Generalized Matrix Factorization (GMF), a simpler model, obtains a lower MSE. Although the Multi-Layer Perceptron (MLP) model has great power in these types of problem, it seems to overÔ¨Åt, generating very good recommendations for some users in the group but bad ones for the rest, hence achieving higher MSE values. On the other hand, the Generalized Matrix Fac- torization (GMF) model can obtain smaller maximum errors in each group, which means that no user in the group is badly affected by the recommendation. In the results, we can also observe how the models with higher maximum errors lead to a poorer order of items according to user preferences and obtain worse performance in the Normal- izaed Discounted Cumulative Gain (NDCG) metric. Looking at the aggregation of users, we can see that the best performing user aggregation is the average, followed by a very similar performance by the Softmax. However, the use of expert user weighting without softmax produces worse results. Based on the results, we can observe that in models that do not use a deep architecture, with several hidden layers, the Individual Preference Aggregation (IPA) and Group Preference Aggregation (GPA) strategies pro- duce similar results when the aggregation function is a linear transformation of latent factors (Generalized Matrix Factorization (GMF)). However, we can see how the nonlinearity of Multi-Layer Perceptron (MLP) produces different results between both two strategies. Regarding the different datasets, we can see that there is a clear trend in the models that achieve the best results in complex datasets with a large number of users, items, and votes, such as Movilens or MyAnimeList, while in the FilmTrust dataset, with a smaller number of votes, there is no clear trend. In terms of group size, as more users have the group, the probability of Ô¨Ånding discrepancies between user prefer- ences increases. Therefore, we can see how a larger group size leads to higher values in all error metrics. 5 Conclusions and future work With the irruption of Neural Network (NN) in the world of Collaborative Filtering (CF), the possibilities of their ability to Ô¨Ånd nonlinear patterns within user preferences to generate better predictions are opening up. To use these systems to generate a recommendation for a group of users, we need to aggregate their preferences. As we have seen in this research, there are several key points at which aggre- gation can be performed. Group Preference Aggregation (GPA) strategies do the aggregation before or inside the model, so they have the advantage of taking into account the preferences of the entire group and that a single feed- forward step generates the prediction. In contrast, the Individual Preference Aggregation (IPA) strategy, requires multiple predictions for each user and performs the aggregations after the model. In this study, we have tested how different approaches to perform Group Preference Aggregation (GPA) work in different datasets comparing different metrics. As future work, there are two key factors to consider. First, in this research, the researchers have designed user aggregation techniques presented to the models; in future work, these functions will be explored by different machine learning models. The second key point is that in this work, models perform a knowledge transfer from the model trained for individuals to make group predictions; it is shown that although the models have high performance (MAE improvement), they tend to overÔ¨Åt when working in groups (larger errors in group prediction leading to worse MSE). To solve this problem, future work will try to per- form a specialization training stage for groups after indi- vidual training. Funding This work has been co-funded by the Ministerio de Ciencia e Innovacio¬¥n of Spain and the European Regional Development Fund (FEDER) under grants PID2019-106493RB-I00 (DL-CEMG) and the Comunidad de Madrid under Convenio Plurianual with the Uni- versidad Polite¬¥cnica de Madrid in the actuation line of Programa de Excelencia para el Profesorado Universitario . Data availability The MovieLens1M , FilmTrust and MyAni- meList dataset along with the source code of the experiments that support the Ô¨Åndings of this study is available in neural-cf-for- 1 https://github.com/KNODIS-Research-Group/neural-cf-for-groups Neural Computing and Applications (2023) 35:14081‚Äì14092 14091 groups GitHub‚Äôs repository [ https://github.com/KNODIS- Research-Group/neural-cf-for-groups ]. Declarations Conflict of interest The authors of this paper declare that they have no conflict of interest. References 1. Batmaz Z, Yurekli A, Bilge A, Kaleli C (2019) A review on deep learning for recommender systems: challenges and remedies. Artif Intell Rev 52(1):1‚Äì37. https://doi.org/10.1007/s10462-018- 9654-y 2. Bobadilla J, Gonza¬¥lez-Prieto A ¬¥ , Ortega F, Lara-Cabrera R (2021) Deep learning feature selection to unhide demographic recom- mender systems factors. Neural Comput Appl 33(12):7291‚Äì7308. https://doi.org/10.1007/s00521-020-05494-2 3. Deldjoo Y, Schedl M, Cremonesi P, Pasi G (2020) Recommender systems leveraging multimedia content. ACM Comput Surv 53(5):1‚Äì38. https://doi.org/10.1145/3407190 4. Kulkarni S, Rodd SF (2020) Context aware recommendation systems: a review of the state of the art techniques. Comput Sci Rev 37:100255. https://doi.org/10.1016/j.cosrev.2020.100255 5. Shokeen J, Rana C (2020) A study on features of social recom- mender systems. Artif Intell Rev 53(2):965‚Äì988. https://doi.org/ 10.1007/s10462-019-09684-w 6. Bobadilla J, Alonso S, Hernando A (2020) Deep learning archi- tecture for collaborative Ô¨Åltering recommender systems. Appl Sci 10(7):2441. https://doi.org/10.3390/app10072441 7. Dara S, Chowdary CR, Kumar C (2020) A survey on group recommender systems. J Intell Inf Syst 54(2):271‚Äì295. https:// doi.org/10.1007/s10844-018-0542-3 8. Forouzandeh S, Berahmand K, Rostami M (2021) Presentation of a recommender system with ensemble learning and graph embedding: a case on movielens. Multimed Tools Appl 80(5):7805‚Äì7832. https://doi.org/10.1007/s11042-020-09949-5 9. C¬∏ ano E, Morisio M (2017) Hybrid recommender systems: a systematic literature review. Intell Data Anal 21(6):1487‚Äì1524. https://doi.org/10.3233/IDA-163209 10. Salakhutdinov R, Mnih A (2007) Probabilistic matrix factoriza- tion. In: Proceedings of the 20th international conference on neural information processing systems. NIPS‚Äô07, pp. 1257‚Äì1264. Curran Associates Inc., Red Hook, NY, USA. https://doi.org/10. 5555/2981562.2981720 11. Bobadilla J, Gonza¬¥lez-Prieto A ¬¥ , Ortega F, Lara-Cabrera R (2022) Deep learning approach to obtain collaborative Ô¨Åltering neigh- borhoods. Neural Comput Appl 34(4):2939‚Äì2951. https://doi.org/ 10.1007/s00521-021-06493-7 12. Huang T, Zhang D-f, Bi L (2020) Neural embedding collabora- tive Ô¨Åltering for recommender systems. Neural Comput Appl 32:1‚Äì15. https://doi.org/10.1007/s00521-020-04920-9 13. He X, Liao L, Zhang H, Nie L, Hu X, Chua T-S (2017) Neural collaborative Ô¨Åltering. In: Proceedings of the 26th international conference on world wide web. WWW ‚Äô17, pp. 173‚Äì182. Inter- national World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE. https://doi.org/10.1145/ 3038912.3052569 14. Ortega F, Bobadilla J, Hernando A, Gutie¬¥Rrez A (2013) Incor- porating group recommendations to recommender systems: alternatives and performance. Inf Process Manage 49(4):895‚Äì901. https://doi.org/10.1016/j.ipm.2013.02.003 15. Baltrunas L, Makcinskas T, Ricci F (2010) Group recommen- dations with rank aggregation and collaborative Ô¨Åltering. In: Proceedings of the fourth acm conference on recommender sys- tems. RecSys ‚Äô10, pp. 119‚Äì126. Association for Computing Machinery, New York, NY, USA. https://doi.org/10.1145/ 1864708.1864733 16. Ortega F, Hernando A, Bobadilla J, Kang JH (2016) Recom- mending items to group of users using matrix factorization based collaborative Ô¨Åltering. Inf Sci 345:313‚Äì324. https://doi.org/10. 1016/j.ins.2016.01.083 17. Feng S, Zhang H, Wang L, Liu L, Xu Y (2019) Detecting the latent associations hidden in multi-source information for better group recommendation. Know-Based Syst 171:56‚Äì68. https://doi. org/10.1016/j.knosys.2019.02.002 18. Abolghasemi R, Engelstad P, Herrera-Viedma E, Yazidi A (2022) A personality-aware group recommendation system based on pairwise preferences. Inf Sci 595:1‚Äì17. https://doi.org/10.1016/j. ins.2022.02.033 19. Barzegar Nozari R, Koohi H (2020) A novel group recommender system based on members‚Äô inÔ¨Çuence and leader impact. Know- Based Syst 205:106296. https://doi.org/10.1016/j.knosys.2020. 106296 20. Wang X, Su L, Zhou Q, Wu L, Zhang Y (2020) Group recom- mender systems based on members‚Äô preference for trusted social networks. Sec Commun Netw 2020:1‚Äì11. https://doi.org/10. 1155/2020/1924140 21. Ismailoglu F (2022) Aggregating user preferences in group rec- ommender systems: a crowdsourcing approach. Decis Support Syst 152:113663. https://doi.org/10.1016/j.dss.2021.113663 22. Guo J, Zhu Y, Li A, Wang Q, Han W (2016) A social inÔ¨Çuence approach for group user modeling in group recommendation systems. IEEE Intell Syst 31(5):40‚Äì48. https://doi.org/10.1109/ MIS.2016.28 23. Sajjadi Ghaemmaghami S, Salehi-Abari A (2021) DeepGroup: group recommendation with implicit feedback. Association for Computing Machinery, New York, pp 3408‚Äì3412 24. Hu L, Cao J, Xu G, Cao L, Gu Z, Cao W (2014) Deep modeling of group preferences for group-based recommendation. In: Pro- ceedings of the twenty-eighth AAAI conference on artiÔ¨Åcial intelligence. AAAI‚Äô14, pp. 1861‚Äì1867. AAAI Press, Palo Alto, California. https://doi.org/10.1609/aaai.v28i1.9007 25. Harper FM, Konstan JA (2015) The movielens datasets: history and context. ACM Trans Interact Intell Syst 5(4):1‚Äì19. https:// doi.org/10.1145/2827872 26. Guo G, Zhang J, Yorke-Smith N (2013) A novel bayesian simi- larity measure for recommender systems. In: Proceedings of the twenty-third international joint conference on artiÔ¨Åcial intelli- gence. IJCAI ‚Äô13, pp. 2619‚Äì2625. AAAI Press, Menlo Park, California. https://doi.org/10.5555/2540128.2540506 Publisher‚Äôs Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional afÔ¨Åliations. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. 14092 Neural Computing and Applications (2023) 35:14081‚Äì14092",original article neural group recommendation probabilistic semantic aggregation jorge duenaslerƒ±n raul laracabrera fernando ortega jesus bobadilla received july accepted february published online march author exclusive licence springerverlag london ltd part springer nature recommendation group user challenging subÔ¨Åeld recommendation system key concept make aggregation set user individual entity ranked recommendation list virtual user multihot input vector encoding proposes innovative strategy aggregation made multihot vector feed neural network aggregation provides probabilistic semantic resulting input vector feed able conveniently generalize group recommendation individual prediction furthermore proposed architecture group recommendation obtained simply feedforwarding pretrained individual rating without need obtain datasets containing group user without need running two separate training individual group also avoids maintaining two different model support individual group learning experiment tested proposed architecture three representative collaborative Ô¨Åltering datasets series baseline result show suitable accuracy improvement compared state art keywords group recommender collaborative Ô¨Åltering aggregation model deep learning personalization one Ô¨Åelds artiÔ¨Åcial intelligence ai greater impact life individual Ô¨Ånd multitude service provide u personalized choice news video song restaurant clothes travel etc relevant tech company make extensive use personalization service amazon netÔ¨Çix spotify tripadvisor google tiktok etc company generate personalized recommendation recommender r application rec ommender r provides user personal ized product service item Ô¨Åltering relevant regarding log item consumed user time place took place well existing user social network content item text picture video etc classify recommender r attending Ô¨Åltering strategy demographic contentbased contextaware social collaborative filtering cf Ô¨Åltering ensemble currently matrix factorization mf machine learning used obtain accurate fast recommendation input vote matrix factorization mf translates sparse huge matrix discrete vote user item two dense relatively small matrix real value one matrix contains set short dense vector representing user whereas second matrix vector represent item vector element real jorge duenaslerƒ±n raul laracabrera fernando ortega jesus bobadilla contributed equally work jorge duenaslerƒ±n jorgedlalumnosupmes raul laracabrera raullaraupmes fernando ortega fernandoortegaupmes jesus bobadilla jesusbobadillaupmes departamento de sistemas informaticos universidad politecnica de alan turing sn spain knodis research group universidad politecnica de spain universidad politecnica de spain neural computing application httpsdoiorgs volv volv called hidden factor since represents complex unknown relationship input vote however matrix factorization mf machine learning model fast accurate also present remarkable drawback detect hidden factor complex nonlinear relationship input neural network nn solve problem nonlinear activation function neural net work nnbased recommender r make compression coding pattern rating matrix embeddings hidden lay er embeddings play role matrix factorization mf hidden factor enriching incorporating nonlinear relation wellknown neural network nn base recommender r approach generalized matrix factorization gmf multilayer perceptron mlp group recommendation gr subÔ¨Åeld recommender r area recommendation made set user instead individual user eg recommend movie group three friend regular recommender r goal make accurate recommendation group sev eral policy followed popular minimize mean accuracy error recommend item average like group member b minimize maximum accuracy error recom mend item excessively dislike group member important state open datasets containing group used group recommendation model reason gener ally randomly generated group used training testing research model regardless machine learning used implement group recommendation gr recommender r notable design concept estab lish locate aggregation stage convert indi vidual group general rule sooner aggregation stage better perfor mance group recommendation gr three different location group aggregated uniÔ¨Åed group entity b c intuitive combine individual recommenda tions uniÔ¨Åed group recommendation option c known individual preference aggre gation ipa requires processing several individual recommendation followed rank aggregation however process slow particularly accurate hand consider entire group recom mendation work inside option b approach known group preference aggregation gpa aggregating group infor mation requires working user item interaction matrix higherdimensional space lead misinformation problem aggregate group need work user hidden vector lowdimensional space aggregating several hidden vector individual user uniÔ¨Åed virtual user hidden vector avoids compute prediction several time make rank aggregation stage unnecessary addition take advantage operating condensed com ing matrix factorization mf compression virtual user obtained simply averaging representative short dense vector user group efÔ¨Åcient accurate interesting question neural network nn operate way matrix factorization mf obtain virtual user generate recommendation first note many neural network nnbased recommender r model compress user embedding different latent space item embedding problem neural network nn nonlinear ensemble repre sentations complex matrix factorization mf hidden factor representation consequently simply averaging ensemble user group automatically ensure representative virtual user embed ding furthermore modelbased aggregation option b previous paragraph dependent necessary design test different solution dif ferent neural network nnbased recommender r model whereas neural network nn latent space state art catch user item relation machine learning approach designed use random walk restart providing framework relate user item group exploit item content proÔ¨Åles user threestage proposed increase precision fairness group recom mendation gr binary matrix factorization mf graph dynamic consensus processed sequentially relevant current gr research aim make use concept member preference inÔ¨Çu ence expertise concept similarity trust key idea detect group leader group member trusted others inÔ¨Çuence others fuzzy clustering implicit trust metric combined Ô¨Ånd neighborhood group recommendation gr average strategy applied user preference difference com bined trusted social network correct recommen dations aggregation gr mimic crowd sourcing concept estimate level expertise group member implemented parameter neural computing application sensitivity speciÔ¨Åcity impact social factor group recommendation gr computational evaluated expertise factor inÔ¨Çuences personality preference similarity interpersonal relationship present generate group recommendation gr neural network nnbased recommender r training raw collaborative filtering cf ie rating individual user item without additional infor mation group recommendation gr tested two popular implementation neural network nnbased recommender r generalized matrix factorization gmf multilayer perceptron mlp stated previously make recom mendations group neural network nnbased recommender r individual user must aggregated chosen aggre gation design merge user group input vector feed user embedding neural net work nn aggregation design novel since used applied multilayer perceptron mlp architecture however combine several innovative aspect comparison state art one hand aggregation user group probabilistic function rather simple multi hot encoding better capture relative impor tance user input vector feed neural network nn moreover aggregation serf frontend neural network nn group recommendation gr hand use simple recommender r neural network nn generalized matrix factor ization gmf instead deepest multilayer per ceptron mlp one hypothesis complex model overÔ¨Åt group recommendation gr scenario since designed accurately predict individual prediction whereas group recommendation gr must satisfy average taste group user group recommendation gr designed gen eralize set individual taste group proposed architecture need single training provide individual recommendation group recommendation particularly trained individual recommendation regular recommender r trained return individual prediction Ô¨Åll input vector aggregating user group feedforward trained Ô¨Ånally obtain recommendation group user anyway impact innovative aspect evaluated sect empirically compare proposed aggregation design respect main baseline summary group recommendation gr state art present following drawback research relies additional collaborative fil tering cf rating trust reputation available majority datasets b differ ent proposal make aggregation individual user individual preference aggregation ipa ranking making impossible beneÔ¨Åt machine learning inner representation group preference aggregation gpa c proposed gr neural solution tend apply architecture designed make individual recommendation rather group one lead overÔ¨Åtting low scalability referred number user group Ô¨Åll gap proposed act exclusively collaborative filtering cf rating b make user aggregation c depth design enable adequate learning generalization addi tionally provided experiment test proposed according different aggregation strategy set group label used learning stage contrast notable limitation architecture experiment lack testing particularly demanding scenario cold start group user extremely sparse set impact popular item bias fear group recom mendation gr rest structured follows sect introduces tested model aggregation function sect describes experiment design selected quality measure chosen datasets show result obtained sect provides explanation sect highlight main conclusion article suggested future work proposed collaborative filtering cf interaction purchase viewing rating etc user item stored sparse matrix since common user interact small proportion available item way small percentage existing user interact item sparsity level matrix around shown handle sparsity current collaborative filtering cf model neural network nn work projection user item lowdimensional latent space embedding layer embedding layer popular type layer used neural network nn receive input entity return vector lowdimensional representation entity latent space vector commonly named latent factor order transform entity lowdimensional representation neural computing application embedding layer Ô¨Årst transforms entity one hot encoding representation typically hash function summarizes process context collaborative filtering cf two embedding layer required one user item later embedding layer combined neural network nn architecture see fig example model generalized matrix factorization gmf multilayer perceptron mlp use dot layer concatenate layer followed fully connected dense layer architecture respectively formally deÔ¨Åne neural network nn u predicts rating user u give item r u combining latent factor provided embed ding layer emb l user u l u item l emb l √∞ u √æ ¬º l u emb l √∞ √æ ¬º l u √∞ l u l √æ ¬º r u √∞ √æ stated sect working group recom mendation gr straightforward strategy individual preference aggregation ipa strategy make prediction member group performs aggregation strategy treat group whole group user g ¬º f u u u n g prediction rating group g item r g computed average individual prediction r g ¬º k g k x u g r u ¬º k g k x u g u √∞ l u l √æ √∞ √æ hand group preference aggregation gpa strategy take account group whole noted order user within group length affect aggregation thus aggregation meet constraint permutation invariant Ô¨Åxed length goal group preference aggregation gpa strategy able obtain prediction r g single forward propagation treat group whole entity achieve aggregating latent factor user belongs group obtain latent factor group l g latent factor group aggregated u used compute prediction emb l √∞ g √æ ¬º l g r gi ¬º u √∞ l g l √æ √∞ √æ aggregation group latent factor embedding layer achieved modifying input neural network nn mentioned previously embed ding layer input one hot representation entity adequate performing indi vidual prediction however group recommendation need apply multihot representation user embedding layer ie encode group setting multiple input user embedding layer input related user belong group higher encoding allows u take account group user time extraction latent factor group l g simplest aggregation used deepgroup use input embedding constant proportional size group deÔ¨Åne input user embedding layer user u embeddinginput average √∞ u √æ ¬º k g k u g u g √∞ √æ call aggregation average since embedding layer generate group latent factor equal average latent factor user group recommender r give better prediction user take advantage fact tested expertise aggregation give weight user pro portional number vote entered let k r u k number rating user u input user embedding layer user u deÔ¨Åned fig embedding layer schema fig collaborative Ô¨Ålteringbased neural network neural computing application embeddinginput expertise √∞ u √æ ¬º k r u k p g g k r g k u g u g √∞ √æ addition expertise aggregation also pro posed softmax aggregation smooth version expertise aggregation input user embedding layer user u deÔ¨Åned embeddinginput softmax √∞ u √æ ¬º e k r u k p g g e k r g k u g u g √∞ √æ fig see equation Ô¨Åt group recommendation process Ô¨Årst step generate multihot vector described aggregation eq vector multihot representation group fed embedding layer obtain vector latent factor group l g eq latent fig graphical representation proposed complete aggregation example rating count user u u u u rating b input value user embedding layer strategy user u u u u average expertise softmax user latent factor assuming latent space size userfactor l l l u u u u group latent factor different aggregation agg factor l g l g l g average expertise softmax neural computing application factor group item obtained used feed u generalized matrix factoriza tion gmf multilayer perceptron mlp produce rating prediction group g item eq Ô¨Ånd example user different rating count input value user embedding layer multihot fashion b individual latent factor c Ô¨Ånal group latent factor different aggregation experimental evaluation section show experiment carried validate aggregation proposed manuscript previously stated experiment performed popular neural network nnbased rec ommender r architecture generalized matrix factorization gmf multilayer perceptron mlp chosen two architecture best known offer best result individual prediction however aggregation strategy proposed applied neural network nn architecture embedding layer choice datasets made considering open datasets containing group voting b generalized matrix factorization gmf multilayer perceptron mlp model trained individual voting since proposed aggregation allow computing prediction group already trained model reason chosen following gold standard datasets Ô¨Åeld rec ommender r movielensm popular dataset research recommender r filmtrust dataset smaller movielensm measure performance aggregation datasets lower number user item rating myanimelist dataset range vote higher movielensm popular datasets netÔ¨Çix prize movielensm selected due high computational time required train test model main parameter selected datasets found generation synthetic group carried way group voted least Ô¨Åve item test way possible evaluate quality prediction quality recom mendations group detailed group different size user generated group size synthetic group generated generation group carried following following deÔ¨Åne size group random select item rated test least user find user rated item selected found fewer user go back otherwise random select user create group measure quality prediction group calculated mean absolute error mae ¬º group x g k g k k g k x u g x g j r g r u j √∞ √æ mean squared error mse ¬º group x g k g k k g k k g k x u g x g r g r u √∞ √æ mean maximum group error max ¬º group x g max u g max g j r g r u j √∞ √æ g denotes item rated group g measure quality recommendation group calculated normalized discounted cumulative gain ndcg score ndcg n ¬º group x g dcg g n idcg g n √∞ √æ dcg g n ¬º x x n g r g log √∞ po g √∞ √æ √æ √æ √∞ √æ idcg g n ¬º x n g r g log √∞ ipo g √∞ √æ √æ √æ √∞ √æ n number item recommended group experiment n ¬º according generation synthetic group x n g set n item recommended group g po g √∞ √æ position item group g recommendation list n g set top n item group g ipo g √∞ √æ ideal rank item main parameter datasets used experiment dataset user item rating score sparsity movie lensm filmtrust anime list neural computing application mean absolute error group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax neural computing application mean squared error group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax neural computing application mean max error group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax neural computing application group g r g average rating user belonging group g item see result experiment executed score mae mse max ndcg cell best result discounted cumulative gain group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax neural computing application highlighted gray background bold standard deviation metric parenthesis result analyzed sect experiment run nvidia quadro rtx gpu gb gddr memory nvidia tensor core performance tflops committed reproducible science source code experiment value parameter used random seed shared github discussion main goal research evaluate different aggregation technique make recommendation group shown sect see different trend according model used b way group aggregated c datasets act size group focusing model see multilayer perceptron mlp several hidden layer obtains lower mae however generalized matrix factorization gmf simpler obtains lower mse although multilayer perceptron mlp great power type problem seems overÔ¨Åt generating good recommendation user group bad one rest hence achieving higher mse value hand generalized matrix fac torization gmf obtain smaller maximum error group mean user group badly affected recommendation result also observe model higher maximum error lead poorer order item according user preference obtain worse performance normal izaed discounted cumulative gain ndcg metric looking aggregation user see best performing user aggregation average followed similar performance softmax however use expert user weighting without softmax produce worse result result observe model use deep architecture several hidden layer individual preference aggregation ipa group preference aggregation gpa strategy pro duce similar result aggregation function linear transformation latent factor generalized matrix factorization gmf however see nonlinearity multilayer perceptron mlp produce different result two strategy regarding different datasets see clear trend model achieve best result complex datasets large number user item vote movilens myanimelist filmtrust dataset smaller number vote clear trend term group size user group probability Ô¨Ånding discrepancy user prefer ences increase therefore see larger group size lead higher value error metric conclusion future work irruption neural network nn world collaborative filtering cf possibility ability Ô¨Ånd nonlinear pattern within user preference generate better prediction opening use system generate recommendation group user need aggregate preference seen research several key point aggre gation performed group preference aggregation gpa strategy aggregation inside advantage taking account preference entire group single feed forward step generates prediction contrast individual preference aggregation ipa strategy requires multiple prediction user performs aggregation tested different approach perform group preference aggregation gpa work different datasets comparing different metric future work two key factor consider first research researcher designed user aggregation technique presented model future work function explored different machine learning model second key point work model perform knowledge transfer trained individual make group prediction shown although model high performance mae improvement tend overÔ¨Åt working group larger error group prediction leading worse mse solve problem future work try per form specialization training stage group indi vidual training funding work cofunded ministerio de ciencia e innovacion spain european regional development fund feder grant pidrbi dlcemg comunidad de convenio plurianual uni versidad politecnica de actuation line programa de excelencia para el profesorado universitario availability movielensm filmtrust myani melist dataset along source code experiment support Ô¨Åndings available neuralcffor httpsgithubcomknodisresearchgroupneuralcfforgroups neural computing application group githubs repository httpsgithubcomknodis researchgroupneuralcfforgroups declaration conflict interest author declare conflict interest reference batmaz z yurekli bilge kaleli c review deep learning recommender system challenge remedy artif intell rev httpsdoiorgs bobadilla j gonzalezprieto ortega f laracabrera r deep learning feature selection unhide demographic recom mender system factor neural comput appl httpsdoiorgs deldjoo schedl cremonesi p pasi g recommender system leveraging multimedia content acm comput surv httpsdoiorg kulkarni rodd sf context aware recommendation system review state art technique comput sci rev httpsdoiorgjcosrev shokeen j rana c feature social recom mender system artif intell rev httpsdoiorg sw bobadilla j alonso hernando deep learning archi tecture collaborative Ô¨Åltering recommender system appl sci httpsdoiorgapp dara chowdary cr kumar c survey group recommender system j intell inf syst http doiorgs forouzandeh berahmand k rostami presentation recommender ensemble learning graph embedding movielens multimed tool appl httpsdoiorgs c ano e morisio hybrid recommender system systematic literature review intell anal httpsdoiorgida salakhutdinov r mnih probabilistic matrix factoriza tion proceeding th international conference neural processing system nip pp curran associate inc red hook ny usa httpsdoiorg bobadilla j gonzalezprieto ortega f laracabrera r deep learning obtain collaborative Ô¨Åltering neigh borhoods neural comput appl httpsdoiorg huang zhang df bi l neural embedding collabora tive Ô¨Åltering recommender system neural comput appl httpsdoiorgs x liao l zhang h nie l hu x chua t neural collaborative Ô¨Åltering proceeding th international conference world wide web www pp inter national world wide web conference steering committee republic canton geneva che httpsdoiorg ortega f bobadilla j hernando gutierrez incor porating group recommendation recommender system alternative performance inf process manage httpsdoiorgjipm baltrunas l makcinskas ricci f group recommen dations rank aggregation collaborative Ô¨Åltering proceeding fourth acm conference recommender sys tems recsys pp association computing machinery new york ny usa httpsdoiorg ortega f hernando bobadilla j kang jh recom mending item group user matrix factorization collaborative Ô¨Åltering inf sci httpsdoiorg jins feng zhang h wang l liu l xu detecting latent association hidden multisource better group recommendation knowbased syst httpsdoi orgjknosys abolghasemi r engelstad p herreraviedma e yazidi personalityaware group recommendation pairwise preference inf sci httpsdoiorgj in barzegar nozari r koohi h novel group recommender member inÔ¨Çuence leader impact know syst httpsdoiorgjknosys wang x su l zhou q wu l zhang group recom mender system member preference trusted social network sec commun netw httpsdoiorg ismailoglu f aggregating user preference group rec ommender system crowdsourcing decis support syst httpsdoiorgjdss guo j zhu li wang q han w social inÔ¨Çuence group user modeling group recommendation system ieee intell syst httpsdoiorg mi sajjadi ghaemmaghami salehiabari deepgroup group recommendation implicit feedback association computing machinery new york pp hu l cao j xu g cao l gu z cao w deep modeling group preference groupbased recommendation pro ceedings twentyeighth aaai conference artiÔ¨Åcial intelligence aaai pp aaai press palo alto california httpsdoiorgaaaivi harper fm konstan ja movielens datasets history context acm trans interact intell syst http doiorg guo g zhang j yorkesmith n novel bayesian simi larity measure recommender system proceeding twentythird international joint conference artiÔ¨Åcial intelli gence ijcai pp aaai press menlo park california httpsdoiorg publisher note springer nature remains neutral regard jurisdictional claim published map institutional afÔ¨Åliations springer nature licensor eg society partner hold exclusive right article publishing agreement author rightsholders author selfarchiving accepted manuscript version article solely governed term publishing agreement applicable law neural computing application,neural group recommendation probabilistic semantic aggregation,group recommender collaborative Ô¨Åltering aggregation model deep learning,neural group recommendation probabilistic semantic aggregation neural group recommendation probabilistic semantic aggregation neural group recommendation probabilistic semantic aggregation group recommender collaborative Ô¨Åltering aggregation model deep learning group recommender collaborative Ô¨Åltering aggregation model deep learning original article neural group recommendation probabilistic semantic aggregation jorge duenaslerƒ±n raul laracabrera fernando ortega jesus bobadilla received july accepted february published online march author exclusive licence springerverlag london ltd part springer nature recommendation group user challenging subÔ¨Åeld recommendation system key concept make aggregation set user individual entity ranked recommendation list virtual user multihot input vector encoding proposes innovative strategy aggregation made multihot vector feed neural network aggregation provides probabilistic semantic resulting input vector feed able conveniently generalize group recommendation individual prediction furthermore proposed architecture group recommendation obtained simply feedforwarding pretrained individual rating without need obtain datasets containing group user without need running two separate training individual group also avoids maintaining two different model support individual group learning experiment tested proposed architecture three representative collaborative Ô¨Åltering datasets series baseline result show suitable accuracy improvement compared state art keywords group recommender collaborative Ô¨Åltering aggregation model deep learning personalization one Ô¨Åelds artiÔ¨Åcial intelligence ai greater impact life individual Ô¨Ånd multitude service provide u personalized choice news video song restaurant clothes travel etc relevant tech company make extensive use personalization service amazon netÔ¨Çix spotify tripadvisor google tiktok etc company generate personalized recommendation recommender r application rec ommender r provides user personal ized product service item Ô¨Åltering relevant regarding log item consumed user time place took place well existing user social network content item text picture video etc classify recommender r attending Ô¨Åltering strategy demographic contentbased contextaware social collaborative filtering cf Ô¨Åltering ensemble currently matrix factorization mf machine learning used obtain accurate fast recommendation input vote matrix factorization mf translates sparse huge matrix discrete vote user item two dense relatively small matrix real value one matrix contains set short dense vector representing user whereas second matrix vector represent item vector element real jorge duenaslerƒ±n raul laracabrera fernando ortega jesus bobadilla contributed equally work jorge duenaslerƒ±n jorgedlalumnosupmes raul laracabrera raullaraupmes fernando ortega fernandoortegaupmes jesus bobadilla jesusbobadillaupmes departamento de sistemas informaticos universidad politecnica de alan turing sn spain knodis research group universidad politecnica de spain universidad politecnica de spain neural computing application httpsdoiorgs volv volv called hidden factor since represents complex unknown relationship input vote however matrix factorization mf machine learning model fast accurate also present remarkable drawback detect hidden factor complex nonlinear relationship input neural network nn solve problem nonlinear activation function neural net work nnbased recommender r make compression coding pattern rating matrix embeddings hidden lay er embeddings play role matrix factorization mf hidden factor enriching incorporating nonlinear relation wellknown neural network nn base recommender r approach generalized matrix factorization gmf multilayer perceptron mlp group recommendation gr subÔ¨Åeld recommender r area recommendation made set user instead individual user eg recommend movie group three friend regular recommender r goal make accurate recommendation group sev eral policy followed popular minimize mean accuracy error recommend item average like group member b minimize maximum accuracy error recom mend item excessively dislike group member important state open datasets containing group used group recommendation model reason gener ally randomly generated group used training testing research model regardless machine learning used implement group recommendation gr recommender r notable design concept estab lish locate aggregation stage convert indi vidual group general rule sooner aggregation stage better perfor mance group recommendation gr three different location group aggregated uniÔ¨Åed group entity b c intuitive combine individual recommenda tions uniÔ¨Åed group recommendation option c known individual preference aggre gation ipa requires processing several individual recommendation followed rank aggregation however process slow particularly accurate hand consider entire group recom mendation work inside option b approach known group preference aggregation gpa aggregating group infor mation requires working user item interaction matrix higherdimensional space lead misinformation problem aggregate group need work user hidden vector lowdimensional space aggregating several hidden vector individual user uniÔ¨Åed virtual user hidden vector avoids compute prediction several time make rank aggregation stage unnecessary addition take advantage operating condensed com ing matrix factorization mf compression virtual user obtained simply averaging representative short dense vector user group efÔ¨Åcient accurate interesting question neural network nn operate way matrix factorization mf obtain virtual user generate recommendation first note many neural network nnbased recommender r model compress user embedding different latent space item embedding problem neural network nn nonlinear ensemble repre sentations complex matrix factorization mf hidden factor representation consequently simply averaging ensemble user group automatically ensure representative virtual user embed ding furthermore modelbased aggregation option b previous paragraph dependent necessary design test different solution dif ferent neural network nnbased recommender r model whereas neural network nn latent space state art catch user item relation machine learning approach designed use random walk restart providing framework relate user item group exploit item content proÔ¨Åles user threestage proposed increase precision fairness group recom mendation gr binary matrix factorization mf graph dynamic consensus processed sequentially relevant current gr research aim make use concept member preference inÔ¨Çu ence expertise concept similarity trust key idea detect group leader group member trusted others inÔ¨Çuence others fuzzy clustering implicit trust metric combined Ô¨Ånd neighborhood group recommendation gr average strategy applied user preference difference com bined trusted social network correct recommen dations aggregation gr mimic crowd sourcing concept estimate level expertise group member implemented parameter neural computing application sensitivity speciÔ¨Åcity impact social factor group recommendation gr computational evaluated expertise factor inÔ¨Çuences personality preference similarity interpersonal relationship present generate group recommendation gr neural network nnbased recommender r training raw collaborative filtering cf ie rating individual user item without additional infor mation group recommendation gr tested two popular implementation neural network nnbased recommender r generalized matrix factorization gmf multilayer perceptron mlp stated previously make recom mendations group neural network nnbased recommender r individual user must aggregated chosen aggre gation design merge user group input vector feed user embedding neural net work nn aggregation design novel since used applied multilayer perceptron mlp architecture however combine several innovative aspect comparison state art one hand aggregation user group probabilistic function rather simple multi hot encoding better capture relative impor tance user input vector feed neural network nn moreover aggregation serf frontend neural network nn group recommendation gr hand use simple recommender r neural network nn generalized matrix factor ization gmf instead deepest multilayer per ceptron mlp one hypothesis complex model overÔ¨Åt group recommendation gr scenario since designed accurately predict individual prediction whereas group recommendation gr must satisfy average taste group user group recommendation gr designed gen eralize set individual taste group proposed architecture need single training provide individual recommendation group recommendation particularly trained individual recommendation regular recommender r trained return individual prediction Ô¨Åll input vector aggregating user group feedforward trained Ô¨Ånally obtain recommendation group user anyway impact innovative aspect evaluated sect empirically compare proposed aggregation design respect main baseline summary group recommendation gr state art present following drawback research relies additional collaborative fil tering cf rating trust reputation available majority datasets b differ ent proposal make aggregation individual user individual preference aggregation ipa ranking making impossible beneÔ¨Åt machine learning inner representation group preference aggregation gpa c proposed gr neural solution tend apply architecture designed make individual recommendation rather group one lead overÔ¨Åtting low scalability referred number user group Ô¨Åll gap proposed act exclusively collaborative filtering cf rating b make user aggregation c depth design enable adequate learning generalization addi tionally provided experiment test proposed according different aggregation strategy set group label used learning stage contrast notable limitation architecture experiment lack testing particularly demanding scenario cold start group user extremely sparse set impact popular item bias fear group recom mendation gr rest structured follows sect introduces tested model aggregation function sect describes experiment design selected quality measure chosen datasets show result obtained sect provides explanation sect highlight main conclusion article suggested future work proposed collaborative filtering cf interaction purchase viewing rating etc user item stored sparse matrix since common user interact small proportion available item way small percentage existing user interact item sparsity level matrix around shown handle sparsity current collaborative filtering cf model neural network nn work projection user item lowdimensional latent space embedding layer embedding layer popular type layer used neural network nn receive input entity return vector lowdimensional representation entity latent space vector commonly named latent factor order transform entity lowdimensional representation neural computing application embedding layer Ô¨Årst transforms entity one hot encoding representation typically hash function summarizes process context collaborative filtering cf two embedding layer required one user item later embedding layer combined neural network nn architecture see fig example model generalized matrix factorization gmf multilayer perceptron mlp use dot layer concatenate layer followed fully connected dense layer architecture respectively formally deÔ¨Åne neural network nn u predicts rating user u give item r u combining latent factor provided embed ding layer emb l user u l u item l emb l √∞ u √æ ¬º l u emb l √∞ √æ ¬º l u √∞ l u l √æ ¬º r u √∞ √æ stated sect working group recom mendation gr straightforward strategy individual preference aggregation ipa strategy make prediction member group performs aggregation strategy treat group whole group user g ¬º f u u u n g prediction rating group g item r g computed average individual prediction r g ¬º k g k x u g r u ¬º k g k x u g u √∞ l u l √æ √∞ √æ hand group preference aggregation gpa strategy take account group whole noted order user within group length affect aggregation thus aggregation meet constraint permutation invariant Ô¨Åxed length goal group preference aggregation gpa strategy able obtain prediction r g single forward propagation treat group whole entity achieve aggregating latent factor user belongs group obtain latent factor group l g latent factor group aggregated u used compute prediction emb l √∞ g √æ ¬º l g r gi ¬º u √∞ l g l √æ √∞ √æ aggregation group latent factor embedding layer achieved modifying input neural network nn mentioned previously embed ding layer input one hot representation entity adequate performing indi vidual prediction however group recommendation need apply multihot representation user embedding layer ie encode group setting multiple input user embedding layer input related user belong group higher encoding allows u take account group user time extraction latent factor group l g simplest aggregation used deepgroup use input embedding constant proportional size group deÔ¨Åne input user embedding layer user u embeddinginput average √∞ u √æ ¬º k g k u g u g √∞ √æ call aggregation average since embedding layer generate group latent factor equal average latent factor user group recommender r give better prediction user take advantage fact tested expertise aggregation give weight user pro portional number vote entered let k r u k number rating user u input user embedding layer user u deÔ¨Åned fig embedding layer schema fig collaborative Ô¨Ålteringbased neural network neural computing application embeddinginput expertise √∞ u √æ ¬º k r u k p g g k r g k u g u g √∞ √æ addition expertise aggregation also pro posed softmax aggregation smooth version expertise aggregation input user embedding layer user u deÔ¨Åned embeddinginput softmax √∞ u √æ ¬º e k r u k p g g e k r g k u g u g √∞ √æ fig see equation Ô¨Åt group recommendation process Ô¨Årst step generate multihot vector described aggregation eq vector multihot representation group fed embedding layer obtain vector latent factor group l g eq latent fig graphical representation proposed complete aggregation example rating count user u u u u rating b input value user embedding layer strategy user u u u u average expertise softmax user latent factor assuming latent space size userfactor l l l u u u u group latent factor different aggregation agg factor l g l g l g average expertise softmax neural computing application factor group item obtained used feed u generalized matrix factoriza tion gmf multilayer perceptron mlp produce rating prediction group g item eq Ô¨Ånd example user different rating count input value user embedding layer multihot fashion b individual latent factor c Ô¨Ånal group latent factor different aggregation experimental evaluation section show experiment carried validate aggregation proposed manuscript previously stated experiment performed popular neural network nnbased rec ommender r architecture generalized matrix factorization gmf multilayer perceptron mlp chosen two architecture best known offer best result individual prediction however aggregation strategy proposed applied neural network nn architecture embedding layer choice datasets made considering open datasets containing group voting b generalized matrix factorization gmf multilayer perceptron mlp model trained individual voting since proposed aggregation allow computing prediction group already trained model reason chosen following gold standard datasets Ô¨Åeld rec ommender r movielensm popular dataset research recommender r filmtrust dataset smaller movielensm measure performance aggregation datasets lower number user item rating myanimelist dataset range vote higher movielensm popular datasets netÔ¨Çix prize movielensm selected due high computational time required train test model main parameter selected datasets found generation synthetic group carried way group voted least Ô¨Åve item test way possible evaluate quality prediction quality recom mendations group detailed group different size user generated group size synthetic group generated generation group carried following following deÔ¨Åne size group random select item rated test least user find user rated item selected found fewer user go back otherwise random select user create group measure quality prediction group calculated mean absolute error mae ¬º group x g k g k k g k x u g x g j r g r u j √∞ √æ mean squared error mse ¬º group x g k g k k g k k g k x u g x g r g r u √∞ √æ mean maximum group error max ¬º group x g max u g max g j r g r u j √∞ √æ g denotes item rated group g measure quality recommendation group calculated normalized discounted cumulative gain ndcg score ndcg n ¬º group x g dcg g n idcg g n √∞ √æ dcg g n ¬º x x n g r g log √∞ po g √∞ √æ √æ √æ √∞ √æ idcg g n ¬º x n g r g log √∞ ipo g √∞ √æ √æ √æ √∞ √æ n number item recommended group experiment n ¬º according generation synthetic group x n g set n item recommended group g po g √∞ √æ position item group g recommendation list n g set top n item group g ipo g √∞ √æ ideal rank item main parameter datasets used experiment dataset user item rating score sparsity movie lensm filmtrust anime list neural computing application mean absolute error group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax neural computing application mean squared error group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax neural computing application mean max error group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax neural computing application group g r g average rating user belonging group g item see result experiment executed score mae mse max ndcg cell best result discounted cumulative gain group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax group size gmf ipa gmf avg gmf expertise gmf softmax mlp ipa mlp avg deepgroup mlp expertise mlp softmax neural computing application highlighted gray background bold standard deviation metric parenthesis result analyzed sect experiment run nvidia quadro rtx gpu gb gddr memory nvidia tensor core performance tflops committed reproducible science source code experiment value parameter used random seed shared github discussion main goal research evaluate different aggregation technique make recommendation group shown sect see different trend according model used b way group aggregated c datasets act size group focusing model see multilayer perceptron mlp several hidden layer obtains lower mae however generalized matrix factorization gmf simpler obtains lower mse although multilayer perceptron mlp great power type problem seems overÔ¨Åt generating good recommendation user group bad one rest hence achieving higher mse value hand generalized matrix fac torization gmf obtain smaller maximum error group mean user group badly affected recommendation result also observe model higher maximum error lead poorer order item according user preference obtain worse performance normal izaed discounted cumulative gain ndcg metric looking aggregation user see best performing user aggregation average followed similar performance softmax however use expert user weighting without softmax produce worse result result observe model use deep architecture several hidden layer individual preference aggregation ipa group preference aggregation gpa strategy pro duce similar result aggregation function linear transformation latent factor generalized matrix factorization gmf however see nonlinearity multilayer perceptron mlp produce different result two strategy regarding different datasets see clear trend model achieve best result complex datasets large number user item vote movilens myanimelist filmtrust dataset smaller number vote clear trend term group size user group probability Ô¨Ånding discrepancy user prefer ences increase therefore see larger group size lead higher value error metric conclusion future work irruption neural network nn world collaborative filtering cf possibility ability Ô¨Ånd nonlinear pattern within user preference generate better prediction opening use system generate recommendation group user need aggregate preference seen research several key point aggre gation performed group preference aggregation gpa strategy aggregation inside advantage taking account preference entire group single feed forward step generates prediction contrast individual preference aggregation ipa strategy requires multiple prediction user performs aggregation tested different approach perform group preference aggregation gpa work different datasets comparing different metric future work two key factor consider first research researcher designed user aggregation technique presented model future work function explored different machine learning model second key point work model perform knowledge transfer trained individual make group prediction shown although model high performance mae improvement tend overÔ¨Åt working group larger error group prediction leading worse mse solve problem future work try per form specialization training stage group indi vidual training funding work cofunded ministerio de ciencia e innovacion spain european regional development fund feder grant pidrbi dlcemg comunidad de convenio plurianual uni versidad politecnica de actuation line programa de excelencia para el profesorado universitario availability movielensm filmtrust myani melist dataset along source code experiment support Ô¨Åndings available neuralcffor httpsgithubcomknodisresearchgroupneuralcfforgroups neural computing application group githubs repository httpsgithubcomknodis researchgroupneuralcfforgroups declaration conflict interest author declare conflict interest reference batmaz z yurekli bilge kaleli c review deep learning recommender system challenge remedy artif intell rev httpsdoiorgs bobadilla j gonzalezprieto ortega f laracabrera r deep learning feature selection unhide demographic recom mender system factor neural comput appl httpsdoiorgs deldjoo schedl cremonesi p pasi g recommender system leveraging multimedia content acm comput surv httpsdoiorg kulkarni rodd sf context aware recommendation system review state art technique comput sci rev httpsdoiorgjcosrev shokeen j rana c feature social recom mender system artif intell rev httpsdoiorg sw bobadilla j alonso hernando deep learning archi tecture collaborative Ô¨Åltering recommender system appl sci httpsdoiorgapp dara chowdary cr kumar c survey group recommender system j intell inf syst http doiorgs forouzandeh berahmand k rostami presentation recommender ensemble learning graph embedding movielens multimed tool appl httpsdoiorgs c ano e morisio hybrid recommender system systematic literature review intell anal httpsdoiorgida salakhutdinov r mnih probabilistic matrix factoriza tion proceeding th international conference neural processing system nip pp curran associate inc red hook ny usa httpsdoiorg bobadilla j gonzalezprieto ortega f laracabrera r deep learning obtain collaborative Ô¨Åltering neigh borhoods neural comput appl httpsdoiorg huang zhang df bi l neural embedding collabora tive Ô¨Åltering recommender system neural comput appl httpsdoiorgs x liao l zhang h nie l hu x chua t neural collaborative Ô¨Åltering proceeding th international conference world wide web www pp inter national world wide web conference steering committee republic canton geneva che httpsdoiorg ortega f bobadilla j hernando gutierrez incor porating group recommendation recommender system alternative performance inf process manage httpsdoiorgjipm baltrunas l makcinskas ricci f group recommen dations rank aggregation collaborative Ô¨Åltering proceeding fourth acm conference recommender sys tems recsys pp association computing machinery new york ny usa httpsdoiorg ortega f hernando bobadilla j kang jh recom mending item group user matrix factorization collaborative Ô¨Åltering inf sci httpsdoiorg jins feng zhang h wang l liu l xu detecting latent association hidden multisource better group recommendation knowbased syst httpsdoi orgjknosys abolghasemi r engelstad p herreraviedma e yazidi personalityaware group recommendation pairwise preference inf sci httpsdoiorgj in barzegar nozari r koohi h novel group recommender member inÔ¨Çuence leader impact know syst httpsdoiorgjknosys wang x su l zhou q wu l zhang group recom mender system member preference trusted social network sec commun netw httpsdoiorg ismailoglu f aggregating user preference group rec ommender system crowdsourcing decis support syst httpsdoiorgjdss guo j zhu li wang q han w social inÔ¨Çuence group user modeling group recommendation system ieee intell syst httpsdoiorg mi sajjadi ghaemmaghami salehiabari deepgroup group recommendation implicit feedback association computing machinery new york pp hu l cao j xu g cao l gu z cao w deep modeling group preference groupbased recommendation pro ceedings twentyeighth aaai conference artiÔ¨Åcial intelligence aaai pp aaai press palo alto california httpsdoiorgaaaivi harper fm konstan ja movielens datasets history context acm trans interact intell syst http doiorg guo g zhang j yorkesmith n novel bayesian simi larity measure recommender system proceeding twentythird international joint conference artiÔ¨Åcial intelli gence ijcai pp aaai press menlo park california httpsdoiorg publisher note springer nature remains neutral regard jurisdictional claim published map institutional afÔ¨Åliations springer nature licensor eg society partner hold exclusive right article publishing agreement author rightsholders author selfarchiving accepted manuscript version article solely governed term publishing agreement applicable law neural computing application,1,latent space and group in synthetic datasets
